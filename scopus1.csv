"Authors","Author full names","Author(s) ID","Title","Year","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Link","Abstract","Author Keywords","Index Keywords","Funding Details","Editors","Publisher","PubMed ID"
"Wu X.; Ding Y.; Zhou X.; Xu Y.; Wang S.; Xu X.; Qi L.","Wu, Xiaotong (59294184600); Ding, Yan (59293385600); Zhou, Xiaokang (55514932700); Xu, Yanwei (57193221446); Wang, Shoujin (57196155993); Xu, Xiaolong (55706201200); Qi, Lianyong (36519541200)","59294184600; 59293385600; 55514932700; 57193221446; 57196155993; 55706201200; 36519541200","Fuzzy Federated Learning for Privacy-Preserving Detection of Adolescent Idiopathic Scoliosis","2024","","","","1","15","14","10.1109/TFUZZ.2024.3445468","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201786408&doi=10.1109%2fTFUZZ.2024.3445468&partnerID=40&md5=73b9c04b1160bd503cdb85a22d093b80","As a distributed intelligent paradigm, fuzzy federated learning (FuzzyFL) can reduce the uncertainty and noise of biomedical data and is suited to enhance the accurate detection of adolescent idiopathic scoliosis (AIS). The advanced paradigm requires the hospitals to share the gradient of the fuzzy deep neural network (FDNN) rather than biomedical data. Not only that, the recent research works have been devoted to privacy-preserving FuzzyFL for secure AIS detection, that adds differential privacy-based noise to the gradients against membership inference attack, attribute inference attack. However, a novel reconstruction attack called gradient leakage attack (GLA) on inferring biomedical data over the gradient brings the security challenges to FuzzyFL and thus has a negative influence on AIS detection. It is natural to ask a fundamental question: Can differentially private FuzzyFL for AIS detection over biomedical data defend GLA? In this paper, we construct a privacy-preserving FuzzyFL framework called <monospace>PrivateFuzzyFL</monospace>, that offers a great opportunity to present the systematic evaluation of the private FDNN threatened by the GLAs. In our experiments on a set of chest X-ray images and four FDNNs, we compare more than ten private fuzzy federated optimization algorithms in terms of the defense effect and the utility cost and derive that (1) The existing private FDNNs in FuzzyFL can offer a certain amount of privacy protection for biomedical data against the GLA; and (2) The perturbation algorithm with better defense effect usually causes the worse AIS detection of the FDNN. IEEE","Artificial intelligence; Bioinformatics; disease detection; Federated learning; fuzzy federated learning; fuzzy neural network; Fuzzy systems; Hospitals; Privacy; privacy protection; Protection; reconstruction attack","Contrastive Learning; Deep neural networks; Differential privacy; Fuzzy inference; Fuzzy neural networks; Adolescent idiopathic scoliosis; Biomedical data; Disease detection; Fuzzy federated learning; Fuzzy-neural-networks; Privacy; Privacy preserving; Privacy protection; Protection; Reconstruction attacks; Federated learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Sattar S.; Mumtaz R.; Qadir M.; Mumtaz S.; Khan M.A.; De Waele T.; De Poorter E.; Moerman I.; Shahid A.","Sattar, Shoaib (57224463985); Mumtaz, Rafia (16176156800); Qadir, Mamoon (58903996900); Mumtaz, Sadaf (46761367800); Khan, Muhammad Ajmal (58549607900); De Waele, Timo (57414680000); De Poorter, Eli (23396863400); Moerman, Ingrid (7005875225); Shahid, Adnan (36083258800)","57224463985; 16176156800; 58903996900; 46761367800; 58549607900; 57414680000; 23396863400; 7005875225; 36083258800","Cardiac Arrhythmia Classification Using Advanced Deep Learning Techniques on Digitized ECG Datasets","2024","24","8","2484","","","","10.3390/s24082484","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191369948&doi=10.3390%2fs24082484&partnerID=40&md5=d2655de24c17f6f20ad4b2fba0bee8ca","ECG classification or heartbeat classification is an extremely valuable tool in cardiology. Deep learning-based techniques for the analysis of ECG signals assist human experts in the timely diagnosis of cardiac diseases and help save precious lives. This research aims at digitizing a dataset of images of ECG records into time series signals and then applying deep learning (DL) techniques on the digitized dataset. State-of-the-art DL techniques are proposed for the classification of the ECG signals into different cardiac classes. Multiple DL models, including a convolutional neural network (CNN), a long short-term memory (LSTM) network, and a self-supervised learning (SSL)-based model using autoencoders are explored and compared in this study. The models are trained on the dataset generated from ECG plots of patients from various healthcare institutes in Pakistan. First, the ECG images are digitized, segmenting the lead II heartbeats, and then the digitized signals are passed to the proposed deep learning models for classification. Among the different DL models used in this study, the proposed CNN model achieves the highest accuracy of ∼92%. The proposed model is highly accurate and provides fast inference for real-time and direct monitoring of ECG signals that are captured from the electrodes (sensors) placed on different parts of the body. Using the digitized form of ECG signals instead of images for the classification of cardiac arrhythmia allows cardiologists to utilize DL models directly on ECG signals from an ECG machine for the real-time and accurate monitoring of ECGs. © 2024 by the authors.","arrhythmia; deep learning; digitization; ECG classification; self-supervised learning","Algorithms; Arrhythmias, Cardiac; Deep Learning; Electrocardiography; Heart Rate; Humans; Neural Networks, Computer; Signal Processing, Computer-Assisted; Biomedical signal processing; Classification (of information); Diseases; Heart; Lead compounds; Long short-term memory; Signal analysis; Arrhythmia; Cardiac arrhythmia; Convolutional neural network; Deep learning; Digitisation; ECG classification; ECG signals; Learning models; Learning techniques; Self-supervised learning; algorithm; artificial neural network; classification; deep learning; electrocardiography; heart arrhythmia; heart rate; human; pathophysiology; physiology; procedures; signal processing; Electrocardiograms","Erasmus+; European Commission, EC, (619193-EPP-1-2020-BE-EPPKA2-CBHE-JP); European Commission, EC","","Multidisciplinary Digital Publishing Institute (MDPI)","38676101"
"Chen J.; Lu R.; Ye S.; Guang M.; Tassew T.M.; Jing B.; Zhang G.; Chen G.; Shen D.","Chen, Jian (59290232700); Lu, Ranlin (58726106400); Ye, Shilin (58726298700); Guang, Mengting (58726106500); Tassew, Tewodros Megabiaw (57920908400); Jing, Bin (36451950200); Zhang, Guofu (55739024300); Chen, Geng (56903235100); Shen, Dinggang (57226254008)","59290232700; 58726106400; 58726298700; 58726106500; 57920908400; 36451950200; 55739024300; 56903235100; 57226254008","Image Recovery Matters: A Recovery-Extraction Framework for Robust Fetal Brain Extraction From MR Images","2024","28","2","","823","834","11","10.1109/JBHI.2023.3333953","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178028463&doi=10.1109%2fJBHI.2023.3333953&partnerID=40&md5=d611984aa0f1dad1ea5e2909abbb841b","The extraction of the fetal brain from magnetic resonance (MR) images is a challenging task. In particular, fetal MR images suffer from different kinds of artifacts introduced during the image acquisition. Among those artifacts, intensity inhomogeneity is a common one affecting brain extraction. In this work, we propose a deep learning-based recovery-extraction framework for fetal brain extraction, which is particularly effective in handling fetal MR images with intensity inhomogeneity. Our framework involves two stages. First, the artifact-corrupted images are recovered with the proposed generative adversarial learning-based image recovery network with a novel region-of-darkness discriminator that enforces the network focusing on artifacts of the images. Second, we propose a brain extraction network for more effective fetal brain segmentation by strengthening the association between lower- and higher-level features as well as suppressing task-irrelevant features. Thanks to the proposed recovery-extraction strategy, our framework is able to accurately segment fetal brains from artifact-corrupted MR images. The experiments show that our framework achieves promising performance in both quantitative and qualitative evaluations, and outperforms state-of-the-art methods in both image recovery and fetal brain extraction.  © 2013 IEEE. ","brain extraction; Fetal MRI; image recovery; image segmentation; intensity inhomogeneity","Brain; Fetus; Head; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Brain; Computer system recovery; Deep learning; Extraction; Feature extraction; Generative adversarial networks; Image segmentation; Job analysis; Medical imaging; Recovery; Biomedical imaging; Brain extraction; Brain modeling; Features extraction; Fetal MRI; Image recovery; Images segmentations; Intensity inhomogeneity; Nonhomogeneous medium; Task analysis; algorithm; Article; artifact; brain analysis; classification algorithm; conceptual framework; convolutional neural network; deep learning; diagnostic accuracy; feature extraction; fetus; fetus brain; histogram; human; image analysis; image processing; image quality; image segmentation; imagery; learning; learning algorithm; machine learning; mathematical analysis; nerve cell network; neuroradiologist; nuclear magnetic resonance; nuclear magnetic resonance imaging; qualitative analysis; receptive field; retrospective study; signal noise ratio; signal processing; support vector machine; training; visual field; brain; diagnostic imaging; head; image processing; nuclear magnetic resonance imaging; procedures; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.","37995170"
"Woessner A.E.; Anjum U.; Salman H.; Lear J.; Turner J.T.; Campbell R.; Beaudry L.; Zhan J.; Cornett L.E.; Gauch S.; Quinn K.P.","Woessner, Alan E. (57202230415); Anjum, Usman (57367380200); Salman, Hadi (57526140800); Lear, Jacob (58848242400); Turner, Jeffrey T. (59233896100); Campbell, Ross (57204853222); Beaudry, Laura (59231463000); Zhan, Justin (59233555300); Cornett, Lawrence E. (7004305090); Gauch, Susan (6602196195); Quinn, Kyle P. (16647213500)","57202230415; 57367380200; 57526140800; 58848242400; 59233896100; 57204853222; 59231463000; 59233555300; 7004305090; 6602196195; 16647213500","Identifying and training deep learning neural networks on biomedical-related datasets","2024","25","","bbae232","","","","10.1093/bib/bbae232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199492909&doi=10.1093%2fbib%2fbbae232&partnerID=40&md5=aaa77e45465e75e2c5cea912d90afc82","This manuscript describes the development of a resources module that is part of a learning platform named ‘NIGMS Sandbox for Cloud-based Learning’ https://github.com/NIGMS/NIGMS-Sandbox. The overall genesis of the Sandbox is described in the editorial NIGMS Sandbox at the beginning of this Supplement. This module delivers learning materials on implementing deep learning algorithms for biomedical image data in an interactive format that uses appropriate cloud resources for data access and analyses. Biomedical-related datasets are widely used in both research and clinical settings, but the ability for professionally trained clinicians and researchers to interpret datasets becomes difficult as the size and breadth of these datasets increases. Artificial intelligence, and specifically deep learning neural networks, have recently become an important tool in novel biomedical research. However, use is limited due to their computational requirements and confusion regarding different neural network architectures. The goal of this learning module is to introduce types of deep learning neural networks and cover practices that are commonly used in biomedical research. This module is subdivided into four submodules that cover classification, augmentation, segmentation and regression. Each complementary submodule was written on the Google Cloud Platform and contains detailed code and explanations, as well as quizzes and challenges to facilitate user training. Overall, the goal of this learning module is to enable users to identify and integrate the correct type of neural network with their data while highlighting the ease-of-use of cloud computing for implementing neural networks. This manuscript describes the development of a resource module that is part of a learning platform named “NIGMS Sandbox for Cloud-based Learning” https://github.com/NIGMS/NIGMS-Sandbox. The overall genesis of the Sandbox is described in the editorial NIGMS Sandbox [1] at the beginning of this Supplement. This module delivers learning materials on the analysis of bulk and single-cell ATACseq data in an interactive format that uses appropriate cloud resources for data access and analyses. © The Author(s) 2024. Published by Oxford University Press.","artificial intelligence; biomedical research; cloud-based computing; deep learning; engineering education","Algorithms; Biomedical Research; Cloud Computing; Deep Learning; Humans; Neural Networks, Computer; algorithm; artificial neural network; cloud computing; deep learning; human; medical research","National Institute of General Medical Sciences, NIGMS, (3P20GM103429-21S2); National Institute of General Medical Sciences, NIGMS; Arkansas Integrative Metabolic Research Center, (P20GM139768); National Institutes of Health, NIH, (R01AG056560, R01EB031032); National Institutes of Health, NIH","","Oxford University Press","39041915"
"Macsik P.; Pavlovicova J.; Kajan S.; Goga J.; Kurilova V.","Macsik, Peter (57816114600); Pavlovicova, Jarmila (6506666238); Kajan, Slavomir (6507799334); Goga, Jozef (57200530641); Kurilova, Veronika (56403179400)","57816114600; 6506666238; 6507799334; 57200530641; 56403179400","Image preprocessing-based ensemble deep learning classification of diabetic retinopathy","2024","18","3","","807","828","21","10.1049/ipr2.12987","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176916713&doi=10.1049%2fipr2.12987&partnerID=40&md5=d8e87e5a1443cc09c87afa93b2866c1a","Diabetic retinopathy (DR) can cause irreversible eye damage, even blindness. The prognosis improves with early diagnosis. According to the International Classification of Diabetic Retinopathy Severity Scale (ICDRSS), DR has five stages. Modern, cost-effective techniques for automatic DR screening and staging of fundus images are based on deep learning (DL). To obtain higher classification accuracy, the combination of several diverse individual DL models into one ensemble could be used. A new approach to model diversity in an ensemble is proposed by manipulating the training input data involving original and four variants of preprocessed image datasets. There are publicly available datasets with labels for all five stages, but some contain poor-quality images. In contrast, this algorithm was trained on images from a six-class DDR dataset, including the class of poor-quality ungradable images, to enhance the classification performance. The solution was evaluated on the APTOS dataset, containing only ICDRSS classes. Classification results of the ensemble model were presented on two different ensemble convolutional neural network (CNN) models, based on Xception and EfficientNetB4 architectures using two fusion approaches. Our proposed ensemble models outperformed all other single deep learning architectures regarding overall accuracy and Cohen's Kappa, with the best results using the EfficientNetB4 architecture. © 2023 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.","biomedical optical imaging; computer vision; convolutional neural nets; image classification; medical image processing","Computer aided diagnosis; Computer vision; Convolution; Convolutional neural networks; Cost effectiveness; Deep learning; Eye protection; Image classification; Image enhancement; Learning systems; Medical imaging; Network architecture; Biomedical optical imaging; Convolutional neural net; Cost effective; Diabetic retinopathy; Diabetic retinopathy screening; Early diagnosis; Ensemble models; Image preprocessing; Images classification; Medical images processing; Classification (of information)","Nitto; Vedecká Grantová Agentúra MŠVVaŠ SR a SAV, VEGA, (1/0202/23, APVV‐22‐606); Vedecká Grantová Agentúra MŠVVaŠ SR a SAV, VEGA; European Regional Development Fund, ERDF","","John Wiley and Sons Inc",""
"Agbozo E.; Balungu D.M.","Agbozo, Ebenezer (57195492315); Balungu, Daniel Musafiri (58949345900)","57195492315; 58949345900","Liver Disease Classification - An XAI Approach to Biomedical AI","2024","48","1","","79","90","11","10.31449/inf.v48i1.4611","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188317900&doi=10.31449%2finf.v48i1.4611&partnerID=40&md5=a021e1a72473d9df7ca91907e267d3f5","Explosive amounts of biological and physiological data, including medical images, electroencephalograms, genomic information, and protein sequences, have been made available to us thanks to advances in biological and medical technologies. Understanding human health and disease is made easier by using this data for learning. Deep learning-based algorithms, which were developed from artificial neural networks, have significant potential for identifying patterns and extracting features from large amounts of complex data. However, these recent advancements involve blackbox models: algorithms that do not provide human-understandable explanations in support of their decisions. This limitation hampers the fairness, accountability and transparency of these models; the field of XAI tries to solve this problem providing human-understandable explanations for black-box models. This paper focuses on the requirement for XAI to be able to explain in detail the decisions made by an AI in a biomedical setting to the expert in the domain, e.g., the physician in the case of AI-based clinical decisions related to diagnosis, treatment, or prognosis of a disease. In this paper, we made use of the Indian Patient Liver Dataset (IPLD) collected from Andhra Pradesh region. The deep learning model with a 0.81 accuracy score (0.82 for the hyperparameter- tuned model) is built on Keras-Tensorflow and due to the imbalance in the target values, we integrated GANs as a means of oversampling the dataset. This study integrated the XAI concept of Shapley Values to shed light on the predictive results obtained by the liver disease detection model. © 2024 Slovene Society Informatika. All rights reserved.","biomedical science; data-driven decision making; deep learning; explainable ai; prescriptive analytics; shapley values","Bioelectric phenomena; Biomedical engineering; Deep learning; Diagnosis; Diseases; Learning systems; Medical imaging; Neural networks; Biomedical science; Black box modelling; Data driven decision; Data-driven decision making; Decisions makings; Deep learning; Explainable ai; Liver disease; Prescriptive analytic; Shapley value; Decision making","","","Slovene Society Informatika",""
"Li Y.; Huang H.; Wu J.; Qu L.; Liu C.; Tian C.; Yang B.; Han T.","Li, Yuanyuan (59232177000); Huang, Haimeng (59232395700); Wu, Jun (57266847900); Qu, Lei (36175185400); Liu, Chao (59232173200); Tian, Chong (59232064900); Yang, Bo (59232286800); Han, Tingting (57203482754)","59232177000; 59232395700; 57266847900; 36175185400; 59232173200; 59232064900; 59232286800; 57203482754","Depth Feature Matching Based Coherence Registration of 3D Biological Images","2024","","","","88","92","4","10.1109/ICIPMC62364.2024.10586679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199474082&doi=10.1109%2fICIPMC62364.2024.10586679&partnerID=40&md5=834d35be79224edb3e44d9b0160747e9","Establishing dense anatomical correspondences across different imaging modalities is a fundamental yet challenging task in many medical image analysis studies. Existing multimodal registration algorithms depend on optimal transformation estimation based on feature point matching or deformation prediction based on depth learning. However, the former fails to capture the deeper semantic information of images effectively, while the latter tends to lose critical detail features when registering high-resolution images. In this paper, we propose a three-dimensional coherent registration method for biological images (DFMCR), based on deep feature matching. Leveraging deep neural networks trained on large-scale data, we learn a multimodal feature representation and similarity metric. Through feature point matching, we significantly reduce the computational burden, enabling registration of images at resolutions of 25um and higher.  © 2024 IEEE.","Biomedical imaging; Cross-mode registration; Deep feature matching; Similarity measure","Computer vision; Medical imaging; Semantics; Biomedical imaging; Cross-mode registration; Deep feature matching; Depth features; Feature points matching; Features matching; Imaging modality; Medical image analysis; Multimodal registration; Similarity measure; Deep neural networks","Natural Science Foundation of Anhui Province, (KJ2021A0017); Natural Science Foundation of Anhui Province; National Natural Science Foundation of China, NSFC, (62271003, 62201008); National Natural Science Foundation of China, NSFC; Sci-Tech Innovation 2030 Agenda, (2022ZD0205204, 2022ZD0205200); University Synergy Innovation Program of Anhui Province, (GXXT-2021-001)","","Institute of Electrical and Electronics Engineers Inc.",""
"Karthikeyani S.; Sasipriya S.; Ramkumar M.","Karthikeyani, S. (57223006025); Sasipriya, S. (57218355576); Ramkumar, M. (57214979824)","57223006025; 57218355576; 57214979824","Cardiac arrhythmias detection framework based on higher-order spectral distribution with deep learning","2024","92","","105997","","","","10.1016/j.bspc.2024.105997","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185390878&doi=10.1016%2fj.bspc.2024.105997&partnerID=40&md5=3be79368aec83f5c3696084d95ec3804","In this article, a new framework for arrhythmia identification using higher-order spectral distributions and deep learning approaches has been proposed. The input signal is first pre-processed using the Sparse Low-Rank filter (CVSS-NLMS-LRF) and Cascaded Variable step size-Normalized least mean square algorithm (CVSS-NLMS-LRF) techniques. This method eliminates various types of noise signals from the Electrocardiogram (ECG) signals, such as power line noise, baseline wander noise (BW), and high-frequency muscle artefacts. After pre-processing the signal, the features are selected using a Higher-order spectral energy distribution image (HSDI) obtained using a two-dimensional Fourier transform from the third-order cumulant process. Finally, the multi-stage dual swin transformer with attention learning (MS-DSwin-AL) is proposed to classify cardiac arrhythmias in the input ECG spectral. The Dual Swin Transformer, the Channel and Element-wise Attention Mechanism (CEAM) and the Transitional Module (TM) form the framework of the proposed classification. Additionally, the classification parameters are fine-tuned using an Integrated Average Subtraction and Standard Deviation based Optimizer (IASSD) algorithm. As a result, the proposed model is executed in the Python platform using the MIT-BIH dataset, and the performance is considered in terms of various evaluation metrics. Furthermore, the performance of a proposed model is compared with existing classifiers. The proposed model achieves an accuracy (96.01%), specificity (94%), recall (93.02%), and F1-score (89.14%) higher than the existing classifiers for cardiac arrhythmia classification. As a result, it can be said that the proposed model has a strong chance of identifying cardiac arrhythmias from the provided data. © 2024 Elsevier Ltd","Cascaded variable step size (CVSS); Channel and Element-wise Attention Mechanism (CEAM); integrated average subtraction and standard deviation-based optimizer (IASSD); Normalized least-mean-square (NLMS); sparse low-rank filter (LRF); Third-order cumulants (ToC)","Biomedical signal processing; Deep learning; Electrocardiograms; Heart; Python; Statistics; Attention mechanisms; Cascaded variable step size; Channel and element-wise attention mechanism; Integrated average subtraction and standard deviation-based optimizer; Least mean squares; Normalized least-mean-square; Optimizers; Rank filters; Sparse low-rank filter; Standard deviation; Third-order cumulant; Variable step size; Article; cardiologist; comparative study; controlled study; deep learning; deep neural network; diagnostic accuracy; diagnostic test accuracy study; dimensionality reduction; electrocardiogram; electrocardiography; feature detection; feature extraction; feature selection; Fourier transform spectroscopy; heart arrhythmia; human; long short term memory network; metaheuristics; sensitivity and specificity; supraventricular premature beat; Diseases","","","Elsevier Ltd",""
"Khan R.U.; Almakdi S.; Alshehri M.; Haq A.U.; Ullah A.; Kumar R.","Khan, Riaz Ullah (57202445169); Almakdi, Sultan (57211498975); Alshehri, Mohammed (57210193521); Haq, Amin Ul (59157731200); Ullah, Aman (57208471108); Kumar, Rajesh (58488212700)","57202445169; 57211498975; 57210193521; 59157731200; 57208471108; 58488212700","An intelligent neural network model to detect red blood cells for various blood structure classification in microscopic medical images","2024","10","4","e26149","","","","10.1016/j.heliyon.2024.e26149","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187303011&doi=10.1016%2fj.heliyon.2024.e26149&partnerID=40&md5=adad2207a4666da4c8a5340283f9cd09","Biomedical image analysis plays a crucial role in enabling high-performing imaging and various clinical applications. For the proper diagnosis of blood diseases related to red blood cells, red blood cells must be accurately identified and categorized. Manual analysis is time-consuming and prone to mistakes. Analyzing multi-label samples, which contain clusters of cells, is challenging due to difficulties in separating individual cells, such as touching or overlapping cells. High-performance biomedical imaging and several medical applications are made possible by advanced biosensors. We develop an intelligent neural network model that can automatically identify and categorize red blood cells from microscopic medical images using region-based convolutional neural networks (RCNN) and cutting-edge biosensors. Our model successfully navigates obstacles like touching or overlapping cells and accurately recognizes various blood structures. Additionally, we utilized data augmentation as a pre-processing method on microscopic images to enhance the model's computational efficiency and expand the sample size. To refine the data and eliminate noise from the dataset, we utilized the Radial Gradient Index filtering algorithm for imaging data equalization. We exhibit improved detection accuracy and a reduced model loss rate when using medical imagery datasets to apply our proposed model in comparison to existing ResNet and GoogleNet models. Our model precisely detected red blood cells in a collection of medical images with 99% training accuracy and 91.21% testing accuracy. Our proposed model outperformed earlier models like ResNet-50 and GoogleNet by 10-15%. Our results demonstrated that Artificial intelligence (AI)-assisted automated red blood cell detection has the potential to revolutionize and speed up blood cell analysis, minimizing human error and enabling early illness diagnosis. © 2024 The Author(s)","Deep learning; Image processing; Object detection; RBC detection","","University of Electronic Science and Technology of China, UESTC, (U03210068); University of Electronic Science and Technology of China, UESTC; Deanship of Scientific Research, University of Jordan, DSR, (NU/RG/SERC/12/3); Deanship of Scientific Research, University of Jordan, DSR","","Elsevier Ltd",""
"Mishra A.K.; Gupta I.K.; Diwan T.D.; Srivastava S.","Mishra, Awanish Kumar (57222248739); Gupta, Indresh Kumar (57188752252); Diwan, Tarun Dhar (57195319554); Srivastava, Swati (57198632001)","57222248739; 57188752252; 57195319554; 57198632001","Cervical precancerous lesion classification using quantum invasive weed optimization with deep learning on biomedical pap smear images","2024","41","7","e13308","","","","10.1111/exsy.13308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158055678&doi=10.1111%2fexsy.13308&partnerID=40&md5=07f0811a97227eda45c6eebe7a88a959","Biomedical imaging devices, in general, have been made and used a lot lately to examine the insides of the body during diagnostic and analytic procedures. Biomedical imaging gives accurate information about metabolites, which can be used to find and classify diseases because it is not invasive. For the study of cervical cancer (CC), the pap smear is a crucial type of biological imaging. CC is a crucial reason to enhance the rate of women's mortalities. Proper screening of pap smear images is critical for assisting in the early detection and analysis of CC. Computer-aided systems for cancerous cell recognition need well established artificial intelligence (AI) methods. In this study, we introduce an automated Cervical Precancerous Lesion Classification using Quantum Invasive Weed Optimization with Deep Learning (CPLC-QIWODL) on biomedical pap smear images. The presented CPLC-QIWODL technique examines the pap smear images for cervical cancer classification. To do so, the presented CPLC-QIWODL technique pre-processes the biomedical images using a Gabor filtering (GF) approach. Moreover, the CPLC-QIWODL technique uses a deep convolutional neural network-based SqueezeNet system for feature extraction. Furthermore, the hyperparameter tuning of the SqueezeNet methodology takes place using the QIWO technique, showing the novelty of the work. Finally, to classify CC, the deep variational autoencoder (DVAE) model is applied. The experimental result analysis of the CPLC-QIWODL technique is tested using a benchmark medical image database. Extensive comparative results demonstrated the enhanced outcomes of the CPLC-QIWODL technique over other existing algorithms, with a maximum accuracy of 99.07%. © 2023 John Wiley & Sons Ltd.","artificial intelligence; biomedical imaging; cervical cancer; metaheuristics; pap smear images","Classification (of information); Computer aided analysis; Computer aided diagnosis; Deep neural networks; Diseases; Image analysis; Image classification; Learning systems; Medical imaging; Metabolites; Biological imaging; Biomedical imaging; Cervical cancers; Imaging device; Invasive weed optimization; Learning techniques; Lesion classification; Metaheuristic; Pap smear; Pap smear images; Invasive weed optimization","","","John Wiley and Sons Inc",""
"Rahman M.M.; Marculescu R.","Rahman, Md Mostafijur (57204151210); Marculescu, Radu (35555100900)","57204151210; 35555100900","G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D Medical Image Segmentation","2024","","","","7713","7722","9","10.1109/WACV57701.2024.00755","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186954038&doi=10.1109%2fWACV57701.2024.00755&partnerID=40&md5=0f3bf563cbf0d441124cbc8fc04d42ec","In this paper, we are the first to propose a new graph convolution-based decoder namely, Cascaded Graph Convolutional Attention Decoder (G-CASCADE), for 2D medical image segmentation. G-CASCADE progressively refines multi-stage feature maps generated by hierarchical transformer encoders with an efficient graph convolution block. The encoder utilizes the self-attention mechanism to capture long-range dependencies, while the decoder refines the feature maps preserving long-range information due to the global receptive fields of the graph convolution block. Rigorous evaluations of our decoder with multiple transformer encoders on five medical image segmentation tasks (i.e., Abdomen organs, Cardiac organs, Polyp lesions, Skin lesions, and Retinal vessels) show that our model outperforms other state-of-the-art (SOTA) methods. We also demonstrate that our decoder achieves better DICE scores than the SOTA CASCADE decoder with 80.8% fewer parameters and 82.3% fewer FLOPs. Our decoder can easily be used with other hierarchical encoders for general-purpose semantic and medical image segmentation tasks. The implementation can be found at: https://github.com/SLDGroup/G-CASCADE. © 2024 IEEE.","Algorithms; Algorithms; and algorithms; Applications; Biomedical / healthcare / medicine; formulations; Image recognition and understanding; Machine learning architectures","Bioinformatics; Convolutional neural networks; Decoding; Deep learning; Image recognition; Medical imaging; Semantic Segmentation; Semantics; Signal encoding; And algorithm; Biomedical / healthcare / medicine; Convolutional decoding; Feature map; Formulation; Learning architectures; Machine learning architecture; Machine-learning; Medical image segmentation; Multi-stages; Convolution","National Science Foundation, NSF, (CNS 2007284); National Science Foundation, NSF","","Institute of Electrical and Electronics Engineers Inc.",""
"Bajpai A.; Kesaria A.; Briskilal J.","Bajpai, Anubhav (59229610800); Kesaria, Anishka (59229485700); Briskilal, J. (56483236600)","59229610800; 59229485700; 56483236600","Schizophrenia Detection using Electroencephalography Signals Using Deep Learning","2024","","","","","","","10.1109/ICCTAC61556.2024.10581211","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199277180&doi=10.1109%2fICCTAC61556.2024.10581211&partnerID=40&md5=d44f51aeeacca277d336d17445b670d9","The objective of the project is to see whether deep learning can be used to identify schizophrenia in teenagers by analysing their EEG data. The work takes advantage of both conventional and novel preprocessing techniques, such as the Short-Time Fourier Transform, to extract characteristic signals associated with schizophrenia from EEG data. The study highlights encouraging results with models including VGG-16, Long Short-Term Memory (LSTM), Convolutional Neural Network (CNN)[24], and Pyramidal Spatial-based Feature Attention Network (PSFAN). Notably, PSFAN presents a novel diagnostic methodology that extracts multiscale features from 4-second EEG recordings and converts them into 2-dimensional images using dilated convolutions. On two datasets, custom CNN shows statistical superiority over eleven state-of-The-Art algorithms through subject-dependent, subject-independent, and cross-dataset experiments [16]. This paper highlights the usefulness of deep learning in medical settings and highlights its potential.  © 2024 IEEE.","CNN; deep learning; EEG recordings; LSTM; preprocessing techniques; signal classification; statistical hypothesis testing; VGG-16; VGG-16","Biomedical signal processing; Convolution; Convolutional neural networks; Diseases; Electrophysiology; Long short-term memory; Convolutional neural network; Deep learning; EEG recording; Pre-processing techniques; Short time Fourier transforms; Signal classification; Spatial-based features; Statistical hypothesis testing; VGG-16; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Wang B.; Pan H.; Aboah A.; Zhang Z.; Keles E.; Torigian D.; Turkbey B.; Krupinski E.; Udupa J.; Bagci U.","Wang, Bin (57230029000); Pan, Hongyi (57216394593); Aboah, Armstrong (57211179136); Zhang, Zheyuan (57712650100); Keles, Elif (57200083115); Torigian, Drew (6507843349); Turkbey, Baris (9435311800); Krupinski, Elizabeth (26643320200); Udupa, Jayaram (35448144000); Bagci, Ulas (24176491700)","57230029000; 57216394593; 57211179136; 57712650100; 57200083115; 6507843349; 9435311800; 26643320200; 35448144000; 24176491700","GazeGNN: A Gaze-Guided Graph Neural Network for Chest X-ray Classification","2024","","","","2183","2192","9","10.1109/WACV57701.2024.00219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188894457&doi=10.1109%2fWACV57701.2024.00219&partnerID=40&md5=ad9a3524a6dd792d76c08987b654abd2","Eye tracking research is important in computer vision because it can help us understand how humans interact with the visual world. Specifically for high-risk applications, such as in medical imaging, eye tracking can help us to comprehend how radiologists and other medical professionals search, analyze, and interpret images for diagnostic and clinical purposes. Hence, the application of eye tracking techniques in disease classification has become increasingly popular in recent years. Contemporary works usually transform gaze information collected by eye tracking devices into visual attention maps (VAMs) to supervise the learning process. However, this is a time-consuming preprocessing step, which stops us from applying eye tracking to radiologists' daily work. To solve this problem, we propose a novel gaze-guided graph neural network (GNN), GazeGNN, to leverage raw eye-gaze data without being converted into VAMs. In GazeGNN, to directly integrate eye gaze into image classification, we create a unified representation graph that models both images and gaze pattern information. With this benefit, we develop a real-time, real-world, end-to-end disease classification algorithm for the first time in the literature. This achievement demonstrates the practicality and feasibility of integrating real-time eye tracking techniques into the daily work of radiologists. To our best knowledge, GazeGNN is the first work that adopts GNN to integrate image and eye-gaze data. Our experiments on the public chest X-ray dataset show that our proposed method exhibits the best classification performance compared to existing methods. The code is available at https://github.com/ukaukaaaa/GazeGNN. © 2024 IEEE.","Algorithms; and algorithms; Applications; Biomedical / healthcare / medicine; formulations; Machine learning architectures","Behavioral research; Bioinformatics; Classification (of information); Computer aided diagnosis; Deep learning; Graph neural networks; Learning algorithms; Medical imaging; Network architecture; And algorithm; Biomedical / healthcare / medicine; Eye-gaze; Eye-tracking; Formulation; Graph neural networks; Learning architectures; Machine learning architecture; Machine-learning; Tracking techniques; Eye tracking","Northwestern University, NU; National Institutes of Health, NIH, (R01-CA246704, R15-EB030356, R01-CA240639, R03-EB032943, U01-CA268808, U01-DK127384-02S1); National Institutes of Health, NIH","","Institute of Electrical and Electronics Engineers Inc.",""
"Khabti J.; AlAhmadi S.; Soudani A.","Khabti, Joharah (57202792336); AlAhmadi, Saad (56223622500); Soudani, Adel (6602550839)","57202792336; 56223622500; 6602550839","Optimal Channel Selection of Multiclass Motor Imagery Classification Based on Fusion Convolutional Neural Network with Attention Blocks","2024","24","10","3168","","","","10.3390/s24103168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194217923&doi=10.3390%2fs24103168&partnerID=40&md5=57c3e5bf0343c8cc9bb4fbf452a42299","The widely adopted paradigm in brain–computer interfaces (BCIs) involves motor imagery (MI), enabling improved communication between humans and machines. EEG signals derived from MI present several challenges due to their inherent characteristics, which lead to a complex process of classifying and finding the potential tasks of a specific participant. Another issue is that BCI systems can result in noisy data and redundant channels, which in turn can lead to increased equipment and computational costs. To address these problems, the optimal channel selection of a multiclass MI classification based on a Fusion convolutional neural network with Attention blocks (FCNNA) is proposed. In this study, we developed a CNN model consisting of layers of convolutional blocks with multiple spatial and temporal filters. These filters are designed specifically to capture the distribution and relationships of signal features across different electrode locations, as well as to analyze the evolution of these features over time. Following these layers, a Convolutional Block Attention Module (CBAM) is used to, further, enhance EEG signal feature extraction. In the process of channel selection, the genetic algorithm is used to select the optimal set of channels using a new technique to deliver fixed as well as variable channels for all participants. The proposed methodology is validated showing 6.41% improvement in multiclass classification compared to most baseline models. Notably, we achieved the highest results of 93.09% for binary classes involving left-hand and right-hand movements. In addition, the cross-subject strategy for multiclass classification yielded an impressive accuracy of 68.87%. Following channel selection, multiclass classification accuracy was enhanced, reaching 84.53%. Overall, our experiments illustrated the efficiency of the proposed EEG MI model in both channel selection and classification, showing superior results with either a full channel set or a reduced number of channels. © 2024 by the authors.","attention module; brain–computer interface (BCI); channel selection; convolutional neural network (CNN); deep learning (DL); electroencephalogram (EEG); genetic algorithm (GA); motor imagery (MI)","Algorithms; Attention; Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Neural Networks, Computer; Signal Processing, Computer-Assisted; Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Electroencephalography; Image classification; Image enhancement; Lead compounds; Attention module; Brain–computer interface; Channel selection; Convolutional neural network; Deep learning; Electroencephalogram; Genetic algorithm; Motor imagery; algorithm; artificial neural network; attention; brain computer interface; electroencephalography; human; imagination; physiology; procedures; signal processing; Genetic algorithms","Ministry of Education – Kingdom of Saudi Arabi, MOE, (IFKSUOR3-506-1); Ministry of Education – Kingdom of Saudi Arabi, MOE","","Multidisciplinary Digital Publishing Institute (MDPI)","38794022"
"Govarthan P.K.; Peddapalli S.K.; Ganapathy N.; Ronickom J.F.A.","Govarthan, Praveen Kumar (57224574002); Peddapalli, Sriram Kumar (59173161400); Ganapathy, Nagarajan (58296234200); Ronickom, Jac Fredo Agastinose (58190339800)","57224574002; 59173161400; 58296234200; 58190339800","Emotion classification using electrocardiogram and machine learning: A study on the effect of windowing techniques","2024","254","","124371","","","","10.1016/j.eswa.2024.124371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196013973&doi=10.1016%2fj.eswa.2024.124371&partnerID=40&md5=162179b9db3524d62c55d5955188da1d","Automated emotion recognition using physiological signals has gained significant attention in recent years due to its potential applications in human–computer interaction, healthcare, and psychology. Electrocardiogram (ECG) signals are widely used due to their non-invasiveness, high temporal resolution, and direct relationship with the autonomic nervous system. In this study, we propose a novel approach for ECG-based emotion recognition using time-series to image encoding techniques and texture-based features combined with machine learning algorithms and deep learning architectures. The ECG data used in this study were obtained from the Continuously Annotated Signals of Emotion (CASE) and Wearable Stress and Affect Detection (WESAD) datasets. We categorized emotional states based on valence and arousal annotations into four classes: High-Valence High-Arousal, High-Valence Low-Arousal, Low-Valence High-Arousal, and Low-Valence Low-Arousal. The ECGs were segmented into 5 and 7-window segments and transformed into 2D representations using Gramian Angular Summation Field, Markov Transition Field, Recurrence Plot (RP), and the triple-channel fusion of all these images. Total of 85 textural features based on the Gray-Level Co-occurrence Matrix (GLCM), Gray-Level Run Length Matrix, Zernike's Moments, Hu's Moments, Fractal Dimension Texture Analysis (FDTA), and First-Order Statistics were extracted. Classifiers, namely Random Forest, Support Vector Machine (SVM), eXtreme Gradient Boosting (XGB), 1D Convolutional Neural Network (CNN), and Multi-head Attention Network were considered to classify the emotional states. The performance of the classifiers varied depending on the time-series to image encoding technique, segmentation approaches, and the classifier employed. We achieved the highest Weighted F-measure (F-m) of 94.91% (RP + XGB) and 86.78% (RP + SVM) using the 7-window and 5-window approaches, respectively. Our proposed 1D CNN architecture achieved the highest classification metrics (F-m = 92.52%, Balanced accuracy = 92.0%, Recall = 91.96%, and Precision = 93.16%) with RP images in a 7-window approach. GLCM and FDTA features made significant contributions to the classification of emotional states. Overall, our results suggest that the proposed method holds promise for developing more accurate and efficient emotion recognition systems. © 2024 Elsevier Ltd","Convolutional neural network; Dimensional classification; Electrocardiogram; Emotion recognition; Machine learning; Time-series to image encoding","Adaptive boosting; Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Emotion Recognition; Encoding (symbols); Forestry; Fractal dimension; Image classification; Image segmentation; Learning systems; Network architecture; Signal encoding; Speech recognition; Support vector machines; Textures; Time series; Convolutional neural network; Dimensional classification; Emotion recognition; Emotional state; Encoding techniques; Image encoding; Machine-learning; Recurrence plot; Time-series to image encoding; Times series; Electrocardiograms","","","Elsevier Ltd",""
"","","","16th Asian Conference on Intelligent Information and Database Systems , ACIIDS 2024","2024","2144 CCIS","","","","","709","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201968307&partnerID=40&md5=1f272029380e0da84a0e046159b4a562","The proceedings contain 58 papers. The special focus in this conference is on Intelligent Information and Database Systems. The topics include: A Deep Neural Networks Approach for Speaker Verification on Embedded Devices; phishing Detection Using Ensemble of Classifiers; an Effective Ensemble Classification Algorithm for Intrusion Detection System; mean-Square Consensus of Second-Order Multi-agent Systems with Semi-Markov Switching for Non-periodic DoS Attacks; an Attention-Driven Hybrid Network for Survival Analysis of Tumorigenesis Patients Using Whole Slide Images; a Deep Learning Approach to Diabetes Diagnosis; a Novel Approach for Medical E-Consent: Leveraging Language Models for Informed Consent Management; Multi-scale and Multi-level Attention Based on External Knowledge in EHRs; Exploring XAI Attention Maps to Investigate the Effect of Distance Metric and Lesion-Shaped Border Expansion Size for Effective Content-Based Dermatological Lesion Retrieval; d-MiQ: Deep Multimodal Interactive Healthcare Query Expansion Approach for Web Search Engines Retrieval Effectiveness; complexity of Transforming Decision Rule Systems into Decision Trees and Acyclic Decision Graphs; depth of Deterministic and Nondeterministic Decision Trees for Decision Tables with Many-Valued Decisions from Closed Classes; gradient Overdrive: Avoiding Negative Randomness Effects in Stochastic Gradient Descent; blockchain-Based Educational Certification Systems Using a Modified Hash Algorithm; the Merged Longest Common Increasing Subsequence Problem; applying Transformation to Reduce Model Sizes for Constrained Optimization Problems; multiple Traveling Salesman Problem with a Drone Station: Using Multi-package Payload Compartments; unveiling the Power of Hybrid Balancing Techniques and Ensemble Stacked and Blended Classifiers for Enhanced Churn Prediction; improvement of a Forward Reasoning Engine FreeEnCal for Trust Reasoning; a Structure Based on B+ Trees to Represent a Large Number of k-Multisets Stored in Non-volatile Memory; optimizing Option Short Strangle Strategies Through Genetic Algorithm; optimizing Airline Pilots Training Plans: A Mixed Integer Linear Programming Approach; towards an Ontological Approach for Verifying the Well-Formedness of Training Programs; penetration Testing and Security Assessment Methodology for Biomedical Devices.","","","","Nguyen N.T.; Wojtkiewicz K.; Chbeir R.; Manolopoulos Y.; Fujita H.; Hong T.-P.; Nguyen L.M.","Springer Science and Business Media Deutschland GmbH",""
"Ng H.W.; Guan C.","Ng, Han Wei (57844280000); Guan, Cuntai (7101632622)","57844280000; 7101632622","Subject-independent meta-learning framework towards optimal training of EEG-based classifiers","2024","172","","106108","","","","10.1016/j.neunet.2024.106108","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182608674&doi=10.1016%2fj.neunet.2024.106108&partnerID=40&md5=74c03dbbbe8ecd95844b7b43bb613633","Advances in deep learning have shown great promise towards the application of performing high-accuracy Electroencephalography (EEG) signal classification in a variety of tasks. However, many EEG-based datasets are often plagued by the issue of high inter-subject signal variability. Robust deep learning models are notoriously difficult to train under such scenarios, often leading to subpar or widely varying performance across subjects under the leave-one-subject-out paradigm. Recently, the model agnostic meta-learning framework was introduced as a way to increase the model's ability to generalize towards new tasks. While the original framework focused on task-based meta-learning, this research aims to show that the meta-learning methodology can be modified towards subject-based signal classification while maintaining the same task objectives and achieve state-of-the-art performance. Namely, we propose the novel implementation of a few/zero-shot subject-independent meta-learning framework towards multi-class inner speech and binary class motor imagery classification. Compared to current subject-adaptive methods which utilize large number of labels from the target, the proposed framework shows its effectiveness in training zero-calibration and few-shot models for subject-independent EEG classification. The proposed few/zero-shot subject-independent meta-learning mechanism performs well on both small and large datasets and achieves robust, generalized performance across subjects. The results obtained shows a significant improvement over the current state-of-the-art, with the binary class motor imagery achieving 88.70% and the accuracy of multi-class inner speech achieving an average of 31.15%. Codes will be made available to public upon publication. © 2024","Brain-computer interface; Inner speech; Meta-learning; Motor imagery; Natural language; Transfer learning","Algorithms; Brain-Computer Interfaces; Calibration; Electroencephalography; Humans; Imagination; Biomedical signal processing; Brain computer interface; Deep learning; Electrophysiology; Image classification; Image enhancement; Large dataset; Learning systems; Natural language processing systems; Transfer learning; 'current; Inner speech; Meta-learning frameworks; Metalearning; Motor imagery; Natural languages; Optimal training; Performance; Signal classification; Transfer learning; accuracy; Article; classification algorithm; clinical effectiveness; convolutional neural network; electroencephalography; intermethod comparison; learning algorithm; mathematical model; meta learning framework; publication; algorithm; calibration; electroencephalography; human; imagination; procedures; Electroencephalography","RIE2020 AME Programmatic Fund, (A20G8b0102); National Research Foundation Singapore, NRF, (AISG2-PhD-2021-08-021); National Research Foundation Singapore, NRF","","Elsevier Ltd","38219680"
"Yoo Y.; Lee J.Y.; Lee D.-J.; Jeon J.; Kim J.","Yoo, Youngbeom (59011516800); Lee, Jae Young (58376857900); Lee, Dong-Jae (57909970800); Jeon, Jiwoon (59012650100); Kim, Junmo (36015494900)","59011516800; 58376857900; 57909970800; 59012650100; 36015494900","Real-Time Polyp Detection in Colonoscopy using Lightweight Transformer","2024","","","","7794","7804","10","10.1109/WACV57701.2024.00763","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191951533&doi=10.1109%2fWACV57701.2024.00763&partnerID=40&md5=3da3da24819424c01e0d63419b82bff9","Colorectal cancer (CRC) represents a major global health challenge, and early detection of polyps is crucial in preventing its progression. Although colonoscopy is the gold standard for polyp detection, it has limitations, such as human error and missed detection rates. In response, computer-aided detection (CADe) systems have been developed to enhance the efficiency and accuracy of polyp detection. As deep learning gained prominence, the incorporation of Convolutional Neural Networks (CNNs) into CADe systems emerged as a breakthrough approach. However, CADe systems based on CNNs often demand significant computational resources, making them unsuitable for deployment in resource-constrained environments. To mitigate this, we propose a novel and lightweight polyp detection model that integrates a Transformer layer into the You Only Look Once (YOLO) architecture, focusing on optimizing the neck part responsible for feature fusion and rescaling. Our model demonstrates a substantial reduction in computational complexity and the number of parameters, without compromising detection performances. The lightweight model makes it accessible and feasibly deployable in medically underserved regions, serving a significant public interest by potentially expanding the reach of critical diagnostic tools for CRC prevention. By optimizing the architecture to reduce resource requirements while maintaining performance, our model becomes a practical solution to assist healthcare professionals in the real-time identification of polyps, even with resource-constraint devices. © 2024 IEEE.","Algorithms; Applications; Biomedical / healthcare / medicine; Image recognition and understanding","Bioinformatics; Computer aided diagnosis; Convolutional neural networks; Deep learning; Diseases; Endoscopy; Network architecture; Biomedical / healthcare / medicine; Colonoscopy; Computer aided detection systems; Convolutional neural network; Global health; Gold standards; Human error detection; Missed detections; Polyp detection; Real- time; Image recognition","","","Institute of Electrical and Electronics Engineers Inc.",""
"Gautam G.K.; Singh S.; Singh A.","Gautam, Gaurav Kumar (59250744600); Singh, Sofia (57208923466); Singh, Archana (56820324000)","59250744600; 57208923466; 56820324000","Skin Cancer Identification Using Deep Learning Technique","2024","","","","553","559","6","10.1109/IC3SE62002.2024.10593153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200670756&doi=10.1109%2fIC3SE62002.2024.10593153&partnerID=40&md5=d8ca45e27731eb77f108704fed9b985b","The most common diseases in the world are skin problems because of hereditary features and environmental factors. It frequently suffers from both common and uncommon ailments. Skin cancer presents in various forms, including squamous cell carcinoma, basal cell carcinoma, and the highly aggressive melanoma, which accounts for the majority of fatalities associated with this condition. Dermatology poses unique diagnostic challenges due to its intricate nature, often necessitating thorough testing to accurately determine the specific type of skin disorder afflicting patients. It can be very challenging to distinguish between different skin illnesses and their different types. The person's personal knowledge of the subject also matters. It is essential to use a technique that is unrestricted by these limitations in order to detect skin diseases. Due to the complexity of human skin complexion and the visual proximity effect on the illnesses, it can be quite difficult to pinpoint the exact type of disease. Therefore, it's crucial to recognize and classify skin problems as soon as they are found. The identification of human skin diseases is thus the most complex and difficult area of research. This work presents an automated deep learning-based image-based system for recognizing and categorizing skin problems along with the implementation of new approach called federated learning for the same. In the biomedical sector, Ml & DL techniques are extensively used for segmentation and augmentation, feature extraction and classification diagnosis and detection. Advanced techniques like Convolutional Neural Network (CNN) can be employed to extract characteristics from a picture, classify the image using the EfficientNet algorithm with fairness evaluation was used to detect the two primary types of tumours, malignant and benign, using the HAM10000 dataset and using federated learning approach using different datasets, and generate a diagnostic report. Since this research will provide results more quickly and accurately than the previous procedure, it will be a more reliable and effective strategy than the conventional method for identifying dermatological problems. The necessity for a lot of manual diagnosis work might potentially be eliminated by a system that can analyze images and alert physicians to the presence of a certain type of skin cancer. © 2024 IEEE.","convolution neural network (CNN); deep learning; EfficientNet; fairness evaluation; federated learning; machine learning; neural networks; skin lesion/cancer","Complex networks; Computer aided diagnosis; Convolution; Convolutional neural networks; Deep learning; Diseases; Feature extraction; Image classification; Learning systems; Convolution neural network; Deep learning; Efficientnet; Fairness evaluation; Federated learning; Machine-learning; Neural-networks; Skin lesion; Skin lesion/cancer; Dermatology","","","Institute of Electrical and Electronics Engineers Inc.",""
"Haider H.; Shah J.A.; Javeed U.; Butt S.A.; Kadir K.","Haider, Hassaan (56539520000); Shah, Jawad Ali (54930956400); Javeed, Umer (59293698300); Butt, Sharjeel Abid (59287921300); Kadir, Kushsairy (37079357500)","56539520000; 54930956400; 59293698300; 59287921300; 37079357500","DISTA-CSNet: Efficient Data Aware Deep Learning Model for CS MRI Recovery","2024","","","","1","1","0","10.1109/ACCESS.2024.3448612","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201746873&doi=10.1109%2fACCESS.2024.3448612&partnerID=40&md5=7c6227287788574707721ece48b842e8","This research paper explores the rising interest in utilising deep learning methods, specifically Convolution Neural Network (CNN), to improve the reconstruction of Compressively Sampled Magnetic Resonance Imaging (CS MRI) images from under-sampled data. By training deep learning architectures on extensive data sets of paired under sampled and fully sampled MR images, these models aim to capture intricate patterns and structures, ultimately enhancing the accuracy of MR image reconstructions. A novel deep learning model is proposed dubbed as ""Deep Iterative Shrinkage Thresholding Algorithm-Compressed Sensing Network"" (DISTA-CSNet), specifically designed for efficient recovery of CS MRI. Our model showcases impressive results with only 20 epochs and can be effortlessly trained on diverse datasets. To ensure robustness across different datasets, the dropouts are incorporated into the model, evident from testing results. The trained DISTA-CSNet exhibits remarkable performance in recovering CS MRI from various data sets, surpassing several advanced deep learning techniques with changing compression ratios consistently. The proposed model demonstrates significant enhancements in both Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) metrics, affirming the efficacy of our proposed model. The capability of our DISTA-CSNet in accurately reconstructing CS MRI images from 5-fold undersampled data shows promise in improving medical imaging applications and advancing the field of compressed sensing MRI. Authors","Accuracy; Biomedical imaging; Compressed Sensing; Compressively Sampled MRI; Computational modeling; Deep learning; Deep Neural Networks; Dropouts; Image reconstruction; Iterative Shrinkage; Magnetic resonance imaging; MRI; Soft Thresholding; Training","Data compression ratio; Deep neural networks; Diffusion tensor imaging; Image compression; Image enhancement; Image reconstruction; Accuracy; Biomedical imaging; Compressed-Sensing; Compressively sampled MRI; Computational modelling; Deep learning; Dropout; Images reconstruction; Iterative shrinkages; Neural-networks; Soft thresholding; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"Dhananjay B.; Kumar R.P.; Neelapu B.C.; Pal K.; Sivaraman J.","Dhananjay, B. (57218596449); Kumar, R. Pradeep (58263545500); Neelapu, Bala Chakravarthy (57188654546); Pal, Kunal (12807107200); Sivaraman, J. (6701384500)","57218596449; 58263545500; 57188654546; 12807107200; 6701384500","A Q-transform-based deep learning model for the classification of atrial fibrillation types","2024","47","2","","621","631","10","10.1007/s13246-024-01391-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185138399&doi=10.1007%2fs13246-024-01391-3&partnerID=40&md5=1990ef8cf790f64ad9d42b39a04c5e57","According to the World Health Organization (WHO), Atrial Fibrillation (AF) is emerging as a global epidemic, which has resulted in a need for techniques to accurately diagnose AF and its various subtypes. While the classification of cardiac arrhythmias with AF is common, distinguishing between AF subtypes is not. Accurate classification of AF subtypes is important for making better clinical decisions and for timely management of the disease. AI techniques are increasingly being considered for image classification and detection in various ailments, as they have shown promising results in improving diagnosis and treatment outcomes. This paper reports the development of a custom 2D Convolutional Neural Network (CNN) model with six layers to automatically differentiate Non-Atrial Fibrillation (Non-AF) rhythm from Paroxysmal Atrial Fibrillation (PAF) and Persistent Atrial Fibrillation (PsAF) rhythms from ECG images. ECG signals were obtained from a publicly available database and segmented into 10-second segments. Applying Constant Q-Transform (CQT) to the segmented ECG signals created a time-frequency depiction, yielding 98,966 images for Non-AF, 16,497 images for PAF, and 52,861 images for PsAF. Due to class imbalance in the PAF and PsAF classes, data augmentation techniques were utilized to increase the number of PAF and PsAF images to match the count of Non-AF images. The training, validation, and testing ratios were 0.7, 0.15, and 0.15, respectively. The training set consisted of 207,828 images, whereas the testing and validation set consisted of 44,538 images and 44,532 images, respectively. The proposed model achieved accuracy, precision, sensitivity, specificity, and F1 score values of 0.98, 0.98, 0.98, 0.97, and 0.98, respectively. This model has the potential to assist physicians in selecting personalized AF treatment and reducing misdiagnosis. © Australasian College of Physical Scientists and Engineers in Medicine 2024.","Classification; Constant Q- transform; Non-atrial fibrillation; Paroxysmal atrial fibrillation; Persistent atrial fibrillation; Time-frequency representation","Atrial Fibrillation; Deep Learning; Electrocardiography; Humans; Neural Networks, Computer; Signal Processing, Computer-Assisted; Biomedical signal processing; Cardiology; Convolutional neural networks; Deep learning; Electrocardiograms; Image enhancement; Multilayer neural networks; Neural network models; Atrial fibrillation; Constant Q- transform; ECG signals; Learning models; Non-atrial fibrillation; Paroxysmal atrial fibrillations; Persistent atrial fibrillation; Time-frequency representations; World Health Organization; Article; artificial neural network; atrial fibrillation; convolutional neural network; deep learning; electrocardiogram; human; image segmentation; learning algorithm; paroxysmal atrial fibrillation; persistent atrial fibrillation; Q-transform; sensitivity and specificity; support vector machine; diagnostic imaging; electrocardiography; signal processing; Diseases","Science and Engineering Research Board, SERB, (EEQ/2019/000148); Science and Engineering Research Board, SERB; Ministry of Education, India, MoE","","Springer Science and Business Media Deutschland GmbH","38353927"
"Chen R.; Wang Q.; Huang X.","Chen, Rongcan (58508148800); Wang, Qinglian (57212104509); Huang, Xiaoyuan (58543221500)","58508148800; 57212104509; 58543221500","Intelligent deep learning supports biomedical image detection and classification of oral cancer","2024","32","","","S465","S475","10","10.3233/THC-248041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195530501&doi=10.3233%2fTHC-248041&partnerID=40&md5=7a182e955099d55de2fab4ff1623b77f","BACKGROUND: Oral cancer is a malignant tumor that usually occurs within the tissues of the mouth. This type of cancer mainly includes tumors in the lining of the mouth, tongue, lips, buccal mucosa and gums. Oral cancer is on the rise globally, especially in some specific risk groups. The early stage of oral cancer is usually asymptomatic, while the late stage may present with ulcers, lumps, bleeding, etc. OBJECTIVE: The objective of this paper is to propose an effective and accurate method for the identification and classification of oral cancer. METHODS: We applied two deep learning methods, CNN and Transformers. First, we propose a new CANet classification model for oral cancer, which uses attention mechanisms combined with neglected location information to explore the complex combination of attention mechanisms and deep networks, and fully tap the potential of attention mechanisms. Secondly, we design a classification model based on Swim transform. The image is segmented into a series of two-dimensional image blocks, which are then processed by multiple layers of conversion blocks. RESULTS: The proposed classification model was trained and predicted on Kaggle Oral Cancer Images Dataset, and satisfactory results were obtained. The average accuracy, sensitivity, specificity and F1-Socre of Swin transformer architecture are 94.95%, 95.37%, 95.52% and 94.66%, respectively. The average accuracy, sensitivity, specificity and F1-Score of CANet model were 97.00%, 97.82%, 97.82% and 96.61%, respectively. CONCLUSIONS: We studied different deep learning algorithms for oral cancer classification, including convolutional neural networks, converters, etc. Our Attention module in CANet leverages the benefits of channel attention to model the relationships between channels while encoding precise location information that captures the long-term dependencies of the network. The model achieves a high classification effect with an accuracy of 97.00%, which can be used in the automatic recognition and classification of oral cancer.  © 2024 - The authors. Published by IOS Press.","attention mechanism; Oral cancer classification; transformer","Deep Learning; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Mouth Neoplasms; Neural Networks, Computer; Sensitivity and Specificity; Article; cancer classification; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; human; image analysis; image segmentation; learning algorithm; major clinical study; mouth cancer; sensitivity and specificity; artificial neural network; classification; computer assisted diagnosis; diagnosis; diagnostic imaging; image processing; mouth tumor; pathology; procedures","National Natural Science Foundation of China, NSFC, (62002304); National Natural Science Foundation of China, NSFC; Fundamental Research Funds for the Central Universities, (20720210053); Fundamental Research Funds for the Central Universities","","IOS Press BV","38759069"
"Allam J.P.; Sahoo S.P.; Ari S.","Allam, Jaya Prakash (57215046766); Sahoo, Suraj Prakash (57189244809); Ari, Samit (23666484300)","57215046766; 57189244809; 23666484300","Multi-stream Bi-GRU network to extract a comprehensive feature set for ECG signal classification","2024","92","","106097","","","","10.1016/j.bspc.2024.106097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185264075&doi=10.1016%2fj.bspc.2024.106097&partnerID=40&md5=d73351cf74620f62b03876cd1008559f","Electrocardiogram (ECG) signal analysis plays a crucial role in diagnosing and monitoring various cardiac diseases. Automatic ECG beat classification is necessary to analyze long-term ECG recordings. The major limitations of the traditional automatic ECG beat classification approaches are the constraints of hand-crafted feature extraction, the requirement of an extensive training dataset, dealing with the ECG signal as an image, and poor performance in detecting supraventricular ectopic and ventricular (S and V) beats. To overcome the above-mentioned difficulties, a novel approach to ECG signal classification based on deep feature extraction with minimum complexity along with random forest is proposed in this work. Three different individual blocks are designed with convolutional neural networks (CNN), residuals, and bi-directional gated recurrent units (Bi-GRU) to extract distributed representative, hierarchical & condensed, and long-term dependency features. These extracted features are used to form deep features with the help of concatenation and fusion techniques. The resulting features are able to capture both the morphology and temporal dynamics of the ECG signal. These features are more effective in identifying different types of arrhythmias, predicting future cardiac events, and filtering out noise and artifacts. The unique nature of the features obtained by combining CNN, residual blocks, and Bi-GRU enables a more comprehensive and accurate analysis of the ECG signal, which is particularly important for diagnosing and monitoring cardiac abnormalities. Finally, the extracted deep feature set is utilized to train and test the random forest algorithm. The proposed approach was evaluated on three publicly available datasets and achieved better performance with an overall accuracy of more than 98.00%. Our approach outperforms existing literature by providing a more accurate classification of ECG signals. © 2024 Elsevier Ltd","Arrhythmia; Classification; Convolutional neural network (CNN); Deep learning; Electrocardiogram (ECG)","Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Extraction; Feature extraction; Heart; Recurrent neural networks; Arrhythmia; Beat classification; Bi-directional; Convolutional neural network; Deep learning; Electrocardiogram; Electrocardiogram signal; Electrocardiogram signal classifications; Features sets; Article; atrial fibrillation; autoencoder; classification; controlled study; convolutional neural network; coronary artery disease; cross validation; decision tree; deep learning; delayed emergence from anesthesia; dyspnea; electrocardiogram; electrocardiography; feature extraction; Fourier transform; gated recurrent unit network; heart arrhythmia; heart infarction; heart supraventricular arrhythmia; heart ventricle extrasystole; heart ventricle tachycardia; human; ischemic heart disease; random forest; recurrent neural network; residual neural network; sudden cardiac death; T wave amplitude; Electrocardiograms","","","Elsevier Ltd",""
"Chao L.I.U.; Yuan Z.; Qiao L.I.U.; Song K.; Kong B.; Su X.","Chao, L.I.U. (58970685700); Yuan, Zeng (55565551200); Qiao, L.I.U. (58970381500); Song, Kun (8924791700); Kong, Beihua (7005061628); Su, Xuantao (55619294154)","58970685700; 55565551200; 58970381500; 8924791700; 7005061628; 55619294154","Siamese deep learning video flow cytometry for automatic and label-free clinical cervical cancer cell analysis","2024","15","4","","2063","2077","14","10.1364/BOE.510022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189484281&doi=10.1364%2fBOE.510022&partnerID=40&md5=c3a37cfcf1f24ad19e436c7a565ec065","Automatic and label-free screening methods may help to reduce cervical cancer mortality rates, especially in developing regions. The latest advances of deep learning in the biomedical optics field provide a more automatic approach to solving clinical dilemmas. However, existing deep learning methods face challenges, such as the requirement of manually annotated training sets for clinical sample analysis. Here, we develop Siamese deep learning video flow cytometry for the analysis of clinical cervical cancer cell samples in a smear-free manner. High-content light scattering images of label-free single cells are obtained via the video flow cytometer. Siamese deep learning, a self-supervised method, is built to introduce cell lineage cells into an analysis of clinical cells, which utilizes generated similarity metrics as label annotations for clinical cells. Compared with other deep learning methods, Siamese deep learning achieves a higher accuracy of up to 87.11%, with about 5.62% improvement for label-free clinical cervical cancer cell classification. The Siamese deep learning video flow cytometry demonstrated here is promising for automatic, label-free analysis of many types of cells from clinical samples without cell smears. © 2024 Optica Publishing Group (formerly OSA). All rights reserved.","","Cytology; Deep learning; Diseases; Flow cytometry; Learning systems; Light scattering; Cancer mortality; Cell analysis; Cervical cancer cells; Cervical cancers; Clinical samples; Label free; Learning methods; Mortality rate; Screening methods; Video flow; accuracy; Article; artificial neural network; body weight loss; cancer cell; cancer mortality; cancer screening; cell differentiation; cell lineage; deep learning; diagnostic accuracy; female; flow cytometry; human; human cell; image processing; image segmentation; learning; learning algorithm; light scattering; machine learning; mortality; nerve cell network; Papanicolaou test; protein secondary structure; sensitivity and specificity; signal noise ratio; support vector machine; training; uterine cervix cancer; videorecording; Cells","National Natural Science Foundation of China, NSFC, (81271615); National Natural Science Foundation of China, NSFC; National Key Research and Development Program of China, NKRDPC, (2022YFC2406300); National Key Research and Development Program of China, NKRDPC; Fundamental Research Funds for the Central Universities, (2022JC025); Fundamental Research Funds for the Central Universities; Key Technology Research and Development Program of Shandong Province, (2019JZZY011016); Key Technology Research and Development Program of Shandong Province","","Optica Publishing Group (formerly OSA)",""
"Kukkar S.; Singh J.","Kukkar, Saruchi (58974204600); Singh, Jaspreet (57213875589)","58974204600; 57213875589","Biomedical mammography images classification by patches based feature engineering using deep learning with ensemble classifier","2024","3072","1","020018","","","","10.1063/5.0198740","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189627407&doi=10.1063%2f5.0198740&partnerID=40&md5=30501da65759193d6364db5e441d9810","Deep learning algorithms have been in use in the mammography processing business recently to help cut radiologists' cost. Breast masses are currently classified using deep learning-based techniques, including a Convolutional Neural Network (CNN). CNN-based systems have a clear advantage over machine learning-based systems when it comes to categorizing mammography images, but it does have its drawbacks. Additional difficulties are a lack of information about feature engineering, and feature analysis is not feasible for current patches of photos, which are not very distinct in low contrast mammograms. Mammography image patches have contributed to an increase in misleading information, greater computation costs, faulty patch assessments, and non-recovered patch intensity variance. Because of this, it was shown that with the help of a convolutional neural network (CNN), a CNN-based method for classifying breast masses obtained poor classification accuracy. This innovative breast mass categorization methodology, dubbed Deep Learning Feature Engineering, is used to improve accuracy on low contrast images (DFN). To characterize breast masses, this system incorporates both CNN architectures, such as VGG 16 and Resnet 50, as well as random forest boosting techniques. The proposed DFN method is also compared to current classification algorithms that utilize two publicly available datasets of mammographic photos. © 2024 AIP Publishing LLC.","","","","Gupta M.; Kumar R.","American Institute of Physics",""
"Natha S.; Laila U.; Gashim I.A.; Mahboob K.; Saeed M.N.; Noaman K.M.","Natha, Sarfaraz (57195632598); Laila, Umme (55940033900); Gashim, Ibrahim Ahmed (56716434500); Mahboob, Khalid (57202833152); Saeed, Muhammad Noman (57225433370); Noaman, Khaled Mohammed (57700990200)","57195632598; 55940033900; 56716434500; 57202833152; 57225433370; 57700990200","Automated Brain Tumor Identification in Biomedical Radiology Images: A Multi-Model Ensemble Deep Learning Approach","2024","14","5","2210","","","","10.3390/app14052210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192480941&doi=10.3390%2fapp14052210&partnerID=40&md5=f4b9df5875d39810de4d20c58f3ce338","Brain tumors (BT) represent a severe and potentially life-threatening cancer. Failing to promptly diagnose these tumors can significantly shorten a person’s life. Therefore, early and accurate detection of brain tumors is essential, allowing for appropriate treatment and improving the chances of a patient’s survival. Due to the different characteristics and data limitations of brain tumors is challenging problems to classify the three different types of brain tumors. A convolutional neural networks (CNNs) learning algorithm integrated with data augmentation techniques was used to improve the model performance. CNNs have been extensively utilized in identifying brain tumors through the analysis of Magnetic Resonance Imaging (MRI) images The primary aim of this research is to propose a novel method that achieves exceptionally high accuracy in classifying the three distinct types of brain tumors. This paper proposed a novel Stack Ensemble Transfer Learning model called “SETL_BMRI”, which can recognize brain tumors in MRI images with elevated accuracy. The SETL_BMRI model incorporates two pre-trained models, AlexNet and VGG19, to improve its ability to generalize. Stacking combined outputs from these models significantly improved the accuracy of brain tumor detection as compared to individual models. The model’s effectiveness is evaluated using a public brain MRI dataset available on Kaggle, containing images of three types of brain tumors (meningioma, glioma, and pituitary). The experimental findings showcase the robustness of the SETL_BMRI model, achieving an overall classification accuracy of 98.70%. Additionally, it delivers an average precision, recall, and F1-score of 98.75%, 98.6%, and 98.75%, respectively. The evaluation metric values of the proposed solution indicate that it effectively contributed to previous research in terms of achieving high detection accuracy. © 2024 by the authors.","AlexNet; biomedical imaging; brain tumor 1; CNN; data augmentation; deep learning; ensemble model; MRI 2; transfer learning","","Ministry of Education in Saudi Arabia, (ISP-2024)","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Gallazzi M.; Biavaschi S.; Bulgheroni A.; Gatti T.M.; Corchs S.; Gallo I.","Gallazzi, Mirco (59253424400); Biavaschi, Sara (59253248600); Bulgheroni, Alessandro (59253515100); Gatti, Tommaso M. (59253516500); Corchs, Silvia (6701629398); Gallo, Ignazio (7003336792)","59253424400; 59253248600; 59253515100; 59253516500; 6701629398; 7003336792","A Large Dataset to Enhance Skin Cancer Classification With Transformer-Based Deep Neural Networks","2024","12","","","109544","109559","15","10.1109/ACCESS.2024.3439365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200803372&doi=10.1109%2fACCESS.2024.3439365&partnerID=40&md5=fb2dc9885da16c04303c70383645e083","The advent of Deep Learning methodologies has revolutionized the field of medical image analysis, particularly in skin lesion diagnosis and classification. This paper proposes an explorative approach utilizing Transformer-based deep neural networks to classify multiclass skin lesion datasets. Initially introduced for natural language processing tasks, Transformers have remarkably succeeded in capturing long-range dependencies in sequential data. However, their application to image data, especially in medical imaging, remains relatively unexplored. Our proposed framework leverages the self-attention mechanism of Transformer models to effectively capture spatial dependencies across image regions without relying on handcrafted features or extensive pre-processing. We present a comprehensive evaluation of several Deep Learning models on skin imaging reference datasets for various types of skin lesions, including melanoma. We objectively evaluate the test performance of the different trained models using a test dataset released in 2023 with ground-truth labels. Our experiments demonstrate that the Transformer-based architecture achieves high performance in lesion classification tasks. The best result was obtained using a Large Dataset, which we modeled by merging smaller datasets, achieving a test accuracy of 86.37%. This dataset can be considered a good solution to improve the generalization capabilities of the Transformer neural network. Our work establishes Transformer-based deep neural networks as a promising framework for skin-lesion classification in medical imaging and potential clinical utility. This research paves the way for further exploration and integration of advanced Deep Learning techniques into medical image analysis, ultimately contributing to a powerful initial analysis tool for clinicians. The code is publicly available at https://github.com/UnluckyMirco/A-Large-Dataset-to-Enhance-Skin-Cancer-Classification-with-Transformer-Based-DNN.  © 2013 IEEE.","image classification; Skin cancer; skin lesion; transformer neural network","Classification (of information); Computer aided diagnosis; Dermatology; Diseases; Image analysis; Image classification; Image enhancement; Learning algorithms; Medical imaging; Natural language processing systems; Oncology; Statistical tests; Biomedical imaging; Features extraction; Images classification; Lesion; Melanoma; Neural-networks; Skin cancers; Skin lesion; Transformer; Transformer neural network; Deep neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Akuthota S.; Rajkumar K.; Janapati R.","Akuthota, Srinath (58515964300); Rajkumar, K. (57363744200); Janapati, Ravichander (56572844000)","58515964300; 57363744200; 56572844000","Intelligent EEG Artifact Removal in Motor ImageryBCI: Synergizing FCIF,FCFBCSP, and Modified DNN with SNR, PSD, and Spectral Coherence Evaluation","2024","","","","","","","10.1109/ICCSC62074.2024.10616497","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201259094&doi=10.1109%2fICCSC62074.2024.10616497&partnerID=40&md5=79236537e1e63ee6098fadc8a0d2ee33","Motor Imagery Brain-Computer Interfaces (MI BCIs) face challenges due to artifacts in electroencephalogram (EEG) signals, hindering accurate decoding of imagined movements. This study introduces an innovative method for intelligent EEG artifact removal in MI BCIs. By synergizing Four Class Iterative Filtering (FCIF), Four Class FBCSP (FCFBCSP), and a Modified Deep Neural Network (DNN) with Signal-to-Noise Ratio (SNR), Power Spectral Density (PSD), and Spectral Coherence evaluation, our approach enhances feature extraction specificity and extends the Filter Bank Common Spatial Pattern (FBCSP) algorithm for four MI classes. The primary objective is to improve MI BCI reliability through refined artifact removal, thus advancing EEG signal processing for MI applications.  © 2024 IEEE.","Brain-Computer Interface; Deep Learning; EEG Artifact Removal; Motor Imagery; Signal Processing","Biomedical signal processing; Brain computer interface; Brain mapping; Deep neural networks; Image enhancement; Photomapping; Power spectral density; Deep learning; Electroencephalogram artifact removals; Iterative filtering; Motor imagery; Neural-networks; Noise ratio; Power spectral; Signal to noise; Signal-processing; Spectral coherence; Signal to noise ratio","","El Ghzaoui M.; Aghoutane B.","Institute of Electrical and Electronics Engineers Inc.",""
"Peng Z.; Yin L.; Sun Z.; Liang Q.; Ma X.; An Y.; Tian J.; Du Y.","Peng, Zhengyao (57764837500); Yin, Lin (57208445264); Sun, Zewen (58186069800); Liang, Qian (57207843752); Ma, Xiaopeng (56134378800); An, Yu (56028192500); Tian, Jie (57217303750); Du, Yang (56086011600)","57764837500; 57208445264; 58186069800; 57207843752; 56134378800; 56028192500; 57217303750; 56086011600","DERnet: a deep neural network for end-to-end reconstruction in magnetic particle imaging","2024","69","1","015002","","","","10.1088/1361-6560/ad13cf","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181151508&doi=10.1088%2f1361-6560%2fad13cf&partnerID=40&md5=826df69b731634029a64a14d89b5d044","Objective. Magnetic particle imaging (MPI) shows potential for contributing to biomedical research and clinical practice. However, MPI images are effectively affected by noise in the signal as its reconstruction is an ill-posed inverse problem. Thus, effective reconstruction method is required to reduce the impact of the noise while mapping signals to MPI images. Traditional methods rely on the hand-crafted data-consistency (DC) term and regularization term based on spatial priors to achieve noise-reducing and reconstruction. While these methods alleviate the ill-posedness and reduce noise effects, they may be difficult to fully capture spatial features. Approach. In this study, we propose a deep neural network for end-to-end reconstruction (DERnet) in MPI that emulates the DC term and regularization term using the feature mapping subnetwork and post-processing subnetwork, respectively, but in a data-driven manner. By doing so, DERnet can better capture signal and spatial features without relying on hand-crafted priors and strategies, thereby effectively reducing noise interference and achieving superior reconstruction quality. Main results. Our data-driven method outperforms the state-of-the-art algorithms with an improvement of 0.9-8.8 dB in terms of peak signal-to-noise ratio under various noise levels. The result demonstrates the advantages of our approach in suppressing noise interference. Furthermore, DERnet can be employed for measured data reconstruction with improved fidelity and reduced noise. In conclusion, our proposed method offers performance benefits in reducing noise interference and enhancing reconstruction quality by effectively capturing signal and spatial features. Significance. DERnet is a promising candidate method to improve MPI reconstruction performance and facilitate its more in-depth biomedical application. © 2023 Institute of Physics and Engineering in Medicine.","deep learning; end-to-end reconstruction; image reconstruction; magnetic particle imaging","Algorithms; Diagnostic Imaging; Image Processing, Computer-Assisted; Magnetic Phenomena; Neural Networks, Computer; Phantoms, Imaging; Signal-To-Noise Ratio; Clinical research; Image reconstruction; Inverse problems; Mapping; Medical applications; Signal to noise ratio; Data consistency; Deep learning; End to end; End-to-end reconstruction; Images reconstruction; Magnetic particle imaging; Noise interference; Regularization terms; Spatial features; Subnetworks; algorithm; artificial neural network; diagnostic imaging; image processing; magnetism; procedures; signal noise ratio; Deep neural networks","National Natural Science Foundation of China, NSFC, (61901472,62201570, 62027901, 81871514, 82230067, 82272111, 92159303); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Beijing Municipality, (4332058, 7212207); Natural Science Foundation of Beijing Municipality","","Institute of Physics","38064750"
"Gilmore J.; Nasseri M.","Gilmore, Justin (59144863200); Nasseri, Mona (35731992700)","59144863200; 35731992700","Human Activity Recognition Algorithm with Physiological and Inertial Signals Fusion: Photoplethysmography, Electrodermal Activity, and Accelerometry","2024","24","10","3005","","","","10.3390/s24103005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194218128&doi=10.3390%2fs24103005&partnerID=40&md5=f2969f2e92c60b27d810adb737e2f139","Inertial signals are the most widely used signals in human activity recognition (HAR) applications, and extensive research has been performed on developing HAR classifiers using accelerometer and gyroscope data. This study aimed to investigate the potential enhancement of HAR models through the fusion of biological signals with inertial signals. The classification of eight common low-, medium-, and high-intensity activities was assessed using machine learning (ML) algorithms, trained on accelerometer (ACC), blood volume pulse (BVP), and electrodermal activity (EDA) data obtained from a wrist-worn sensor. Two types of ML algorithms were employed: a random forest (RF) trained on features; and a pre-trained deep learning (DL) network (ResNet-18) trained on spectrogram images. Evaluation was conducted on both individual activities and more generalized activity groups, based on similar intensity. Results indicated that RF classifiers outperformed corresponding DL classifiers at both individual and grouped levels. However, the fusion of EDA and BVP signals with ACC data improved DL classifier performance compared to a baseline DL model with ACC-only data. The best performance was achieved by a classifier trained on a combination of ACC, EDA, and BVP images, yielding F1-scores of 69 and 87 for individual and grouped activity classifications, respectively. For DL models trained with additional biological signals, almost all individual activity classifications showed improvement (p-value < 0.05). In grouped activity classifications, DL model performance was enhanced for low- and medium-intensity activities. Exploring the classification of two specific activities, ascending/descending stairs and cycling, revealed significantly improved results using a DL model trained on combined ACC, BVP, and EDA spectrogram images (p-value < 0.05). © 2024 by the authors.","accelerometer; blood volume pulse (BVP); convolutional neural network (CNN); electrodermal activity (EDA); human activity recognition; machine learning; multi-modal classification","Accelerometry; Adult; Algorithms; Female; Galvanic Skin Response; Human Activities; Humans; Machine Learning; Male; Photoplethysmography; Signal Processing, Computer-Assisted; Wearable Electronic Devices; Young Adult; Biomedical signal processing; Blood; Classification (of information); Convolutional neural networks; Deep learning; Electrodes; Feature extraction; Forestry; Hemodynamics; Image enhancement; Learning algorithms; Learning systems; Spectrographs; Blood volume pulse; Convolutional neural network; Electrodermal activity; Human activity recognition; Machine-learning; Multi-modal; Multi-modal classification; accelerometry; adult; algorithm; electrodermal response; female; human; human activities; machine learning; male; photoelectric plethysmography; physiology; procedures; signal processing; wearable computer; young adult; Accelerometers","University of North Florida, UNF","","Multidisciplinary Digital Publishing Institute (MDPI)","38793858"
"Asif S.; Zheng X.; Zhu Y.","Asif, Sohaib (57221248320); Zheng, Xiaolong (57957660700); Zhu, Yusen (56172378600)","57221248320; 57957660700; 56172378600","An optimized fusion of deep learning models for kidney stone detection from CT images","2024","36","7","102130","","","","10.1016/j.jksuci.2024.102130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198985257&doi=10.1016%2fj.jksuci.2024.102130&partnerID=40&md5=1f81bfe7987e3d620998e6bff837a323","Accurate diagnosis of kidney disease is crucial, as it is a significant health concern that demands precise identification for effective and appropriate treatment. Deep learning methods are increasingly recognized as valuable tools for disease diagnosis in the biomedical field. However, current models utilizing deep networks often encounter challenges of overfitting and low accuracy, necessitating further refinement for optimal performance. To overcome these challenges, this paper proposes the introduction of two ensemble models designed for kidney stone detection in CT images. The first model, called StackedEnsembleNet, is a two-level deep stack ensemble model that effectively integrates the predictions from four base models: InceptionV3, InceptionResNetV2, MobileNet, and Xception. By leveraging the collective knowledge of these models, StackedEnsembleNet improves the accuracy and reliability of kidney stone detection. The second model PSOWeightedAvgNet, leverages the Particle Swarm Optimization (PSO) algorithm to determine the optimal weights for the weighted average ensemble. Through PSO, this ensemble approach assigns optimized weights to each model during the ensembling process, effectively enhancing the performance by optimizing the combination of their predictions. Experimental results conducted on a large dataset of 1799 CT images demonstrate that both StackedEnsembleNet and PSOWeightedAvgNet outperform the individual base models, achieving high accuracy rates in kidney stone detection. Furthermore, additional experiments on an unseen dataset validate the models’ ability to generalize. The comparison with previous methods confirms the superior performance of the proposed ensemble models. The paper also presents Grad-CAM visualizations and error case analysis to provide insights into the decision-making processes of the models. By overcoming the limitations of existing deep learning models, StackedEnsembleNet and PSOWeightedAvgNet offer a promising approach for accurate kidney stone detection, contributing to improved diagnosis and treatment outcomes in the field of nephrology. © 2024 The Author(s)","Biomedical image classification; Deep neural networks; Kidney stone detection; Particle swarm optimization; Stack ensemble","","","","King Saud bin Abdulaziz University",""
"Song C.; Shi X.","Song, Chen (58158525900); Shi, Xinghua (57220003341)","58158525900; 57220003341","ReActHE: A homomorphic encryption friendly deep neural network for privacy-preserving biomedical prediction","2024","32","","100469","","","","10.1016/j.smhl.2024.100469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190944374&doi=10.1016%2fj.smhl.2024.100469&partnerID=40&md5=4c04dfa75c74359a0652dc393be28df7","The growing distribution of deep learning models to individuals’ devices on sensitive healthcare data introduces challenging privacy and security problems when computation is being operated on an untrusted server. Homomorphic encryption (HE) is one of the appropriate cryptographic techniques to provide secure machine learning computation by directly computing over encrypted data, so that allows the data owner and model owner to outsource processing of sensitive information to an untrusted server without leaking any information about the data. However, most current HE schemes only support limited arithmetic operations, which significantly hinder their applications to implement a secure deep learning algorithm, especially on the nonlinear activation function of a deep neural network. In this paper, we develop a novel HE-friendly deep neural network, named REsidue ACTivation HE (ReActHE), to implement a precise and privacy-preserving algorithm with a non-approximating HE scheme on the activation function. We consider a residue activation strategy with a scaled power activation function in a deep neural network for HE-friendly nonlinear activation. Moreover, we propose a residue activation network structure to constrain the latent space in the training process to alleviate the optimization difficulty. We comprehensively evaluate the proposed ReActHE method using various biomedical datasets and widely-used image datasets. Our results demonstrate that ReActHE outperforms other alternative solutions to secure machine learning with HE and achieves low approximation errors in classification and regression tasks. © 2024","Biomedical application; Cryptography; Homomorphic encryption; Machine learning; Privacy-preserving","algorithm; arithmetic; article; deep learning; deep neural network; encryption; human; learning algorithm; machine learning; prediction; privacy","","","Elsevier B.V.",""
"Contino S.; Cruciata L.; Gambino O.; Pirrone R.","Contino, Salvatore (57211202805); Cruciata, Luca (58752332700); Gambino, Orazio (14015507500); Pirrone, Roberto (6603614874)","57211202805; 58752332700; 14015507500; 6603614874","IODeep: An IOD for the introduction of deep learning in the DICOM standard","2024","248","","108113","","","","10.1016/j.cmpb.2024.108113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187197133&doi=10.1016%2fj.cmpb.2024.108113&partnerID=40&md5=a3495bbfa202199428925edb28fe80a8","Background and objective: In recent years, Artificial Intelligence (AI) and in particular Deep Neural Networks (DNN) became a relevant research topic in biomedical image segmentation due to the availability of more and more data sets along with the establishment of well known competitions. Despite the popularity of DNN based segmentation on the research side, these techniques are almost unused in the daily clinical practice even if they could support effectively the physician during the diagnostic process. Apart from the issues related to the explainability of the predictions of a neural model, such systems are not integrated in the diagnostic workflow, and a standardization of their use is needed to achieve this goal. Methods: This paper presents IODeep a new DICOM Information Object Definition (IOD) aimed at storing both the weights and the architecture of a DNN already trained on a particular image dataset that is labeled as regards the acquisition modality, the anatomical region, and the disease under investigation. Results: The IOD architecture is presented along with a DNN selection algorithm from the PACS server based on the labels outlined above, and a simple PACS viewer purposely designed for demonstrating the effectiveness of the DICOM integration, while no modifications are required on the PACS server side. Also a service based architecture in support of the entire workflow has been implemented. Conclusion: IODeep ensures full integration of a trained AI model in a DICOM infrastructure, and it is also enables a scenario where a trained model can be either fine-tuned with hospital data or trained in a federated learning scheme shared by different hospitals. In this way AI models can be tailored to the real data produced by a Radiology ward thus improving the physician decision making process. Source code is freely available at https://github.com/CHILab1/IODeep.git. © 2024 The Author(s)","Artificial Intelligence; Decision making in medical diagnosis; Deep Neural Networks; DICOM; Information Object Definition; Medical image segmentation","Artificial Intelligence; Computers; Deep Learning; Radiology Information Systems; Software; Clinical research; Computer aided diagnosis; Deep neural networks; Hospitals; Image segmentation; Learning systems; Medical imaging; Network architecture; Biomedical image segmentation; Decision making in medical diagnose; Decisions makings; DICOM; Information object; Information object definition; Intelligence models; Medical image segmentation; Research topics; Work-flows; algorithm; article; artificial intelligence; clinical practice; decision making; deep learning; deep neural network; diagnosis; digital imaging and communications in medicine; human; image segmentation; infrastructure; learning; physician; prediction; standardization; ward; workflow; artificial intelligence; software; Decision making","Sicilian MicronanoTech Research And Innovation Center, (B73C22000810001, DM 1061/2021, ECS_00000022)","","Elsevier Ireland Ltd","38479148"
"Sonia S.V.E.; Nedunchezhian R.; Rajalakshmi M.","Sonia, S. V. Evangelin (58091412200); Nedunchezhian, R. (35812145400); Rajalakshmi, M. (55650289300)","58091412200; 35812145400; 55650289300","Cardiac abnormalities from 12-Lead ECG signals prediction based on deep convolutional neural network optimized with nomadic people optimization algorithm","2024","38","4","","1136","1152","16","10.1002/acs.3739","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181489543&doi=10.1002%2facs.3739&partnerID=40&md5=29ff08f3f008139a02fc07ce924f6706","Cardiovascular disease (CVD) is a most dangerous disease in the world. Early accurate and automated identification helps the medical professional make a correct diagnosis and administer fast treatment and saving many lives. Several studies have been suggested in this area, but no one yield the expected outcomes owing to data imbalance issue in the medical and healthcare industries. To overcome this problem, a Deep Convolutional Neural Network Optimized with Nomadic People Optimization for Cardiac Abnormalities from 12-Lead ECG Signals Prediction (CCA-12L ECG-DCNN-NPO) is proposed in this manuscript. At first, the input data is pre-processed under Morphological filtering and Extended Empirical wavelet transformation (MF-EEWT) for removing the noise. Then one hot encoding technique is used to improve the predictions and classification accuracy of the method. Afterward, Residual Exemplars Local Binary Pattern (RELBP) based Feature extraction is used to extract the morphological and statistical features. These extracted features are given to DCNN classifier. It contains fully convolutional neural network (FCN) and encoder with decoder framework, which activates pixel-wise categorization to exactly identify Cardiac abnormalities from 12-Lead ECG signals. The visual geometry group network (VGGNet) is considered as a backbone of FCN for end-to-end training. Generally, DCNN method does not adopt any optimization modes to define the optimum parameters and to assure exact detection. Therefore, Nomadic People Optimization (NPO) is considered to enhance the DCNN weight parameters. The CCA-12L ECG-DCNN-NPO technique is implemented in python and the efficacy is analyzed under performance metrics, such as sensitivity, precision, F-Score, specificity, accuracy and error rate. From the analysis, the proposed technique attains higher accuracy 27.5%, 10.32%, and 16.65%, higher f-score 30.93%, 11.14% and 15.3%, lower error rate 36.31%, 15.78%, and 28.08% compared with the existing methods, such as Detecting Cardiac Abnormalities from 12-lead ECG Signals Under Feature Selection, Feature Extraction, and deep Learning Classification (CCA-12L ECG-RFC), Channel self-attention deep learning framework for multi-cardiac abnormality diagnosis from varied-lead ECG signals (CCA-12L ECG-CSA-DNN) and Cardiac disease categorization by electrocardiogram sensing utilizing deep neural network (CCA-12L ECG-DNN) respectively. © 2024 John Wiley & Sons Ltd.","cardiac abnormalities; deep convolutional neural network; encoder and decoder framework; fully convolutional neural network; nomadic people optimization; visual geometry group network","Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Decoding; Deep neural networks; Extraction; Feature extraction; Forecasting; Heart; Image segmentation; Metadata; Network coding; Optimization; Cardiac abnormality; Convolutional neural network; Deep convolutional neural network; Encoder and decoder framework; Encoders and decoders; Fully convolutional neural network; Group networks; Nomadic people optimization; Optimisations; Visual geometry group network; Electrocardiograms","","","John Wiley and Sons Ltd",""
"Tang L.; Zhang Z.; Yang J.; Feng Y.; Sun S.; Liu B.; Ma J.; Liu J.; Shao H.","Tang, Lingzhi (58556589600); Zhang, Zitian (57211980113); Yang, Jinzhu (14829817400); Feng, Yong (58164874000); Sun, Song (58429461200); Liu, Baoxin (58812329200); Ma, Junting (57222361550); Liu, Jiaxi (58744230000); Shao, Haibo (7203046125)","58556589600; 57211980113; 14829817400; 58164874000; 58429461200; 58812329200; 57222361550; 58744230000; 7203046125","A New Automated Prognostic Prediction Method Based on Multi-Sequence Magnetic Resonance Imaging for Hepatic Resection of Colorectal Cancer Liver Metastases","2024","28","3","","1528","1539","11","10.1109/JBHI.2024.3350247","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182368176&doi=10.1109%2fJBHI.2024.3350247&partnerID=40&md5=03126844052eb721725969fcfa2f45d6","Colorectal cancer is a prevalent and life-threatening disease, where colorectal cancer liver metastasis (CRLM) exhibits the highest mortality rate. Currently, surgery stands as the most effective curative option for eligible patients. However, due to the insufficient performance of traditional methods and the lack of multi-modality MRI feature complementarity in existing deep learning methods, the prognosis of CRLM surgical resection has not been fully explored. This paper proposes a new method, multi-modal guided complementary network (MGCNet), which employs multi-sequence MRI to predict 1-year recurrence and recurrence-free survival in patients after CRLM resection. In light of the complexity and redundancy of features in the liver region, we designed the multi-modal guided local feature fusion module to utilize the tumor features to guide the dynamic fusion of prognostically relevant local features within the liver. On the other hand, to solve the loss of spatial information during multi-sequence MRI fusion, the cross-modal complementary external attention module designed an external mask branch to establish inter-layer correlation. The results show that the model has accuracy (ACC) of 0.79, the area under the curve (AUC) of 0.84, C-Index of 0.73, and hazard ratio (HR) of 4.0, which is a significant improvement over state-of-the-art methods. Additionally, MGCNet exhibits good interpretability.  © 2013 IEEE.","Colorectal Cancer Liver Metastases; Multi-sequence MRI; Recurrence prediction","Colorectal Neoplasms; Humans; Liver Neoplasms; Magnetic Resonance Imaging; Prognosis; Deep learning; Diagnosis; Diseases; Feature extraction; Forecasting; Medical imaging; Pathology; Surgery; Tumors; Biomedical imaging; Cancer; Cancer liver; Colorectal cancer liver metastasis; Features extraction; Liver metastasis; Multi-sequences; Multisequence MRI; Prognostic and health management; Recurrence predictions; accuracy; algorithm; amino acid sequence; area under the curve; article; Article; cancer prognosis; classification algorithm; colorectal cancer; colorectal liver metastasis; computer assisted tomography; deep learning; diagnostic accuracy; electroencephalography; entropy; feature extraction; glioblastoma; gray matter; hazard assessment; hazard ratio; hepatectomy; human; image quality; image segmentation; learning algorithm; liver; liver cancer; liver cell carcinoma; liver metastasis; machine learning; measurement accuracy; mortality rate; neural stem cell; nuclear magnetic resonance imaging; pancreas cancer; pedestrian; prediction; protein secondary structure; receiver operating characteristic; rectum cancer; recurrence free survival; signal noise ratio; support vector machine; tumor model; tumor volume; validation process; colorectal tumor; diagnostic imaging; liver tumor; nuclear magnetic resonance imaging; prognosis; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.","38446655"
"Singh H.; Kaur H.","Singh, Harjeet (59203137600); Kaur, Harpreet (59202462900)","59203137600; 59202462900","A Systematic Survey on Biological Cell Image Segmentation and Cell Counting Techniques in Microscopic Images Using Machine Learning","2024","137","2","","813","851","38","10.1007/s11277-024-11379-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197399800&doi=10.1007%2fs11277-024-11379-7&partnerID=40&md5=f4fea2779c7806e63310a94c3d343b1e","The article focuses on the concepts of Cell Image Segmentation (CIS) and the gradual introduction of cell counting. Motivated by the rapid development of Machine learning (ML) methods, which is carried out in this investigation. ML is evolving from theory to practical applications, with deep neural network models extensively used in academia and business for various applications, including image counting and natural language processing. These advancements can greatly influence medical imaging technologies, data processing, diagnostics, and healthcare in general. Main objectives of the research are to provide an overview of biological cell counting methods in microscopic images and to explore deep learning (DL)-based image segmentation approaches. The study expertly describes current trends, cutting-edge learning technologies, and platforms utilized for DL approaches. Cell counting is one of the most researched and challenging subjects in computer vision systems. Academics are increasingly interested in this area due to its real-time applications in biology, biochemistry, medical diagnostics, computer vision-based cell tracking systems for large populations, and stem cell manufacturing. Counting cells in the biological field is beneficial. For instance, the ratio of white blood cells to cancer cells in the blood can help determine the origin of a disease. Biologists also need to count cells within cell cultures to monitor the time-dependent growth of cells during bacterial experiments. Numerous methods for cell counting have been developed, after addressing the challenges with Cell Counting algorithms; the article explores promising future directions in CIS and cell counting research fields. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","Automatic Cell Counting; Biology; Biomedical; Cell Image Segmentation; Image Analysis; White Blood Cell","Blood; Computer vision; Data handling; Deep neural networks; Diagnosis; Image segmentation; Learning algorithms; Learning systems; Medical imaging; Natural language processing systems; Stem cells; Automatic cell counting; Biological cells; Biomedical; Cell counting; Cell image segmentation; Counting techniques; Image-analysis; Machine-learning; Microscopic image; White blood cells; Cell culture","","","Springer",""
"Zhang H.; Zhang P.; Wang Z.; Chao L.; Chen Y.; Li Q.","Zhang, Haobo (57207736721); Zhang, Peng (57193577233); Wang, Zhiwei (57216175393); Chao, Lianying (57203116498); Chen, Yuting (57219195452); Li, Qiang (59281965800)","57207736721; 57193577233; 57216175393; 57203116498; 57219195452; 59281965800","Multi-Feature Decision Fusion Network for Heart Sound Abnormality Detection and Classification","2024","28","3","","1386","1397","11","10.1109/JBHI.2023.3307870","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168730681&doi=10.1109%2fJBHI.2023.3307870&partnerID=40&md5=246a71d003734294189d49c1123bc9c5","The heart sound reflects the movement status of the cardiovascular system and contains the early pathological information of cardiovascular diseases. Automatic heart sound diagnosis plays an essential role in the early detection of cardiovascular diseases. In this study, we aim to develop a novel end-to-end heart sound abnormality detection and classification method, which can be adapted to different heart sound diagnosis tasks. Specifically, we developed a Multi-feature Decision Fusion Network (MDFNet) composed of a Multi-dimensional Feature Extraction (MFE) module and a Multi-dimensional Decision Fusion (MDF) module. The MFE module extracted spatial features, multi-level temporal features and spatial-temporal fusion features to learn heart sound characteristics from multiple perspectives. Through deep supervision and decision fusion, the MDF module made the multi-dimensional features extracted by the MFE module more discriminative, and fused the decision results of multi-dimensional features to integrate complementary information. Furthermore, attention modules were embedded in the MDFNet to emphasize the fundamental heart sounds containing effective feature information. Finally, we proposed an efficient data augmentation method to circumvent the diagnosis performance degradation caused by the lack of cardiac cycle segmentation in other end-to-end methods. The developed method achieved an overall accuracy of 94.44% and a F1-score of 86.90% on the binary classification task and a F1-score of 99.30% on the five-classification task. Our method outperformed other state-of-the-art methods and had good clinical application prospects.  © 2013 IEEE.","abnormality detection; cardiac diseases classification; deep learning; Heart sound","Cardiovascular Diseases; Heart; Heart Sounds; Humans; Movement; Biomedical signal processing; Cardiology; Classification (of information); Computer aided diagnosis; Deep learning; Diseases; Extraction; Heart; Job analysis; Abnormality detection; Cardiac disease; Cardiac disease classification; Data augmentation; Deep learning; Disease classification; Features extraction; Heart sounds; Recording; Task analysis; aortic stenosis; Article; artificial neural network; cardiovascular disease; channel and timestep attention module; classification algorithm; complementarity module; controlled study; convolutional neural network; cross validation; decision tree; deep learning; diagnostic accuracy; diagnostic test accuracy study; disease classification; feature extraction; heart sound abnormality; human; image processing; imaging algorithm; interrater reliability; learning algorithm; mathematical computing; mathematical parameters; measurement precision; mitral valve prolapse; mitral valve regurgitation; mitral valve stenosis; multi dimensional decision fusion module; multi feature decision fusion network; multilayer perceptron; phonocardiography; predictive value; reaction diffusion neural network; recall; receiver operating characteristic; segmentation algorithm; sensitivity and specificity; spatial temporal fusion feature module; time series analysis; cardiovascular disease; heart; heart sound; movement (physiology); Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.","37610909"
"Tekin H.; Kaya Y.","Tekin, Hazret (57219358203); Kaya, Yllmaz (58062717700)","57219358203; 58062717700","A new approach for heart disease detection using Motif transform-based CWT's time-frequency images with DenseNet deep transfer learning methods","2024","69","4","","407","417","10","10.1515/bmt-2023-0580","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187157313&doi=10.1515%2fbmt-2023-0580&partnerID=40&md5=79f7dfdb17261e170654eb2f1aa6dcf3","Objectives: Electrocardiogram (ECG) signals are extensively utilized in the identification and assessment of diverse cardiac conditions, including congestive heart failure (CHF) and cardiac arrhythmias (ARR), which present potential hazards to human health. With the aim of facilitating disease diagnosis and assessment, advanced computer-aided systems are being developed to analyze ECG signals. Methods: This study proposes a state-of-the-art ECG data pattern recognition algorithm based on Continuous Wavelet Transform (CWT) as a novel signal preprocessing model. The Motif Transformation (MT) method was devised to diminish the drawbacks and limitations inherent in the CWT, such as the issue of boundary effects, limited localization in time and frequency, and overfitting conditions. This transformation technique facilitates the formation of diverse patterns (motifs) within the signals. The patterns (motifs) are constructed by comparing the amplitudes of each individual sample value in the ECG signals in terms of their largeness and smallness. In the subsequent stage, the obtained one-dimensional signals from the MT transformation were subjected to CWT to obtain scalogram images. In the last stage, the obtained scalogram images were subjected to classification using DenseNET deep transfer learning techniques. Results and Conclusions: The combined approach of MT + CWT + DenseNET yielded an impressive success rate of 99.31%. © 2024 Walter de Gruyter GmbH, Berlin/Boston.","arrhythmias (ARR); congestive heart failure (CHF); continuous wavelet transform (CWT); DenseNET; MIT-BIH dataset; Motif transformation (MT)","Algorithms; Arrhythmias, Cardiac; Deep Learning; Electrocardiography; Heart Diseases; Heart Failure; Humans; Signal Processing, Computer-Assisted; Wavelet Analysis; Biomedical signal processing; Cardiology; Computer aided diagnosis; Deep learning; Diseases; Health hazards; Heart; Learning systems; Pattern recognition; Wavelet transforms; Arrhythmia; Condition; Congestive heart failure; Congestive heart failures; Continuous wavelet transform; Densenet; Electrocardiogram signal; MIT-BIH dataset; Motif transformation; adult; aged; Article; clinical article; congestive heart failure; continuous wavelet transform; controlled study; convolutional neural network; deep learning; electrocardiogram; female; heart arrhythmia; heart disease; human; male; short time Fourier transform; transfer of learning; algorithm; deep learning; diagnostic imaging; electrocardiography; heart disease; heart failure; pathophysiology; procedures; signal processing; wavelet analysis; Electrocardiograms","","","Walter de Gruyter GmbH","38425179"
"Luo X.; Qu L.; Guo Q.; Song Z.; Wang M.","Luo, Xiaoyuan (57222524929); Qu, Linhao (57370593200); Guo, Qinhao (55995418500); Song, Zhijian (22735320500); Wang, Manning (22735212300)","57222524929; 57370593200; 55995418500; 22735320500; 22735212300","Negative Instance Guided Self-Distillation Framework for Whole Slide Image Analysis","2024","28","2","","964","975","11","10.1109/JBHI.2023.3298798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165915630&doi=10.1109%2fJBHI.2023.3298798&partnerID=40&md5=927484f0068f975be1a33b4a02df9551","Histopathology image classification is an important clinical task, and current deep learning-based whole-slide image (WSI) classification methods typically cut WSIs into small patches and cast the problem as multi-instance learning. The mainstream approach is to train a bag-level classifier, but their performance on both slide classification and positive patch localization is limited because the instance-level information is not fully explored. In this article, we propose a negative instance-guided, self-distillation framework to directly train an instance-level classifier end-to-end. Instead of depending only on the self-supervised training of the teacher and the student classifiers in a typical self-distillation framework, we input the true negative instances into the student classifier to guide the classifier to better distinguish positive and negative instances. In addition, we propose a prediction bank to constrain the distribution of pseudo instance labels generated by the teacher classifier to prevent the self-distillation from falling into the degeneration of classifying all instances as negative. We conduct extensive experiments and analysis on three publicly available pathological datasets: CAMELYON16, PANDA, and TCGA, as well as an in-house pathological dataset for cervical cancer lymph node metastasis prediction. The results show that our method outperforms existing methods by a large margin. Code will be publicly available.  © 2013 IEEE.","Multiple instance learning; self-distillation; whole slide image analysis","Distillation; Female; Humans; Image Processing, Computer-Assisted; Lymphatic Metastasis; Self-Management; Uterine Cervical Neoplasms; Classification (of information); Deep learning; Diseases; Distillation; Image analysis; Image classification; Job analysis; Pathology; Teaching; Cancer; Features extraction; Histopathology; Image-analysis; Metastasis; Multiple-instance learning; Self-distillation; Self-supervised learning; Task analysis; Whole slide image analyse; Whole slide images; algorithm; Article; artificial neural network; biomedical disciplines, science and art; classification algorithm; classifier; clinical decision making; entropy; feature extraction; histopathology; human; image analysis; image segmentation; learning; learning algorithm; lymph node metastasis; machine learning; mathematical model; multiple instance learning; negative instance guided self distillation framework; prediction; supervised machine learning; support vector machine; training; uterine cervix cancer; distillation; female; image processing; self care; uterine cervix tumor; Personnel training","","","Institute of Electrical and Electronics Engineers Inc.","37494153"
"Rachmadi M.F.; Byra M.; Skibbe H.","Rachmadi, Muhammad Febrian (54974181500); Byra, Michal (56414988400); Skibbe, Henrik (14021955900)","54974181500; 56414988400; 14021955900","A new family of instance-level loss functions for improving instance-level segmentation and detection of white matter hyperintensities in routine clinical brain MRI","2024","174","","108414","","","","10.1016/j.compbiomed.2024.108414","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189928902&doi=10.1016%2fj.compbiomed.2024.108414&partnerID=40&md5=201cdad67fee8975ed00ebd4596a05d6","In this study, we introduce “instance loss functions”, a new family of loss functions designed to enhance the training of neural networks in the instance-level segmentation and detection of objects in biomedical image data, particularly those of varied numbers and sizes. Intended to be utilized conjointly with traditional loss functions, these proposed functions, prioritize object instances over pixel-by-pixel comparisons. The specific functions, the instance segmentation loss (Linstance), the instance center loss (Lcenter), the false instance rate loss (Lfalse), and the instance proximity loss (Lproximity), serve distinct purposes. Specifically, Linstance improves instance-wise segmentation quality, Lcenter enhances segmentation quality of small instances, Lfalse minimizes the rate of false and missed detections across varied instance sizes, and Lproximity improves detection quality by pulling predicted instances towards the ground truth instances. Through the task of segmenting white matter hyperintensities (WMH) in brain MRI, we benchmarked our proposed instance loss functions, both individually and in combination via an ensemble inference models approach, against traditional pixel-level loss functions. Data were sourced from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and the WMH Segmentation Challenge datasets, which exhibit significant variation in WMH instance sizes. Empirical evaluations demonstrate that combining two instance-level loss functions through ensemble inference models outperforms models using other loss function on both the ADNI and WMH Segmentation Challenge datasets for the segmentation and detection of WMH instances. Further, applying these functions to the segmentation of nuclei in histopathology images demonstrated their effectiveness and generalizability beyond WMH, improving performance even in contexts with less severe instance imbalance. © 2024 The Author(s)","Brain lesions; Ensemble inference; Instance-level detection loss; Instance-level segmentation loss; White matter hyperintensities","Algorithms; Alzheimer Disease; Brain; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; White Matter; Image enhancement; Image segmentation; Magnetic resonance imaging; Neurodegenerative diseases; Neuroimaging; Object detection; Brain lesions; Brain MRI; Detection loss; Ensemble inference; Instance-level detection loss; Instance-level segmentation loss; Level detections; Loss functions; Segmentation quality; White matter hyperintensities; Alzheimer disease; Article; artificial neural network; brain; comparative study; deep learning; fluid-attenuated inversion recovery imaging; human; image segmentation; instance loss function; major clinical study; neuroimaging; nuclear magnetic resonance imaging; qualitative analysis; quantitative analysis; size; T2 weighted imaging; white matter; algorithm; computer assisted diagnosis; diagnostic imaging; procedures; Pixels","RIKEN; Fakultas Ilmu Komputer, Universitas Indonesia, CS UI; Japan Agency for Medical Research and Development, AMED, (JP15dm0207001); Japan Agency for Medical Research and Development, AMED","","Elsevier Ltd","38599072"
"Digumarthi J.; Gayathri V.M.; Pitchai R.","Digumarthi, Jyothirmai (57209828520); Gayathri, V.M. (59164042200); Pitchai, R. (57188562135)","57209828520; 59164042200; 57188562135","Dilated U-Net model assisted Swin Patch deep convolutional network for enhanced segmentation and classification of cardiac arrhythmia","2024","97","","106744","","","","10.1016/j.bspc.2024.106744","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200824462&doi=10.1016%2fj.bspc.2024.106744&partnerID=40&md5=d39ee545d79d6d0120f7c7f68fb46d33","Arrhythmias are irregular changes in the normal heartbeat that take a long time to diagnose manually and depend on the doctor's experience. In everyday clinical practice, the electrocardiogram (ECG) is a critical diagnostic tool for predicting cardiac arrhythmias. However, in order to produce superior results, the feature learning ability and parameter consideration must be efficient. As a result, this paper proposes a novel automated deep-learning model for improving segmentation and classification performance. First, the collected ECG signals are pre-processed using the sequential Savitzky-Golay filter model (SEQ-SG) to remove noises and unwanted artifacts from the signal. Using the Markov Transition Field (MTF), Recurrence Plot (RP), and Gramian Angular Field (GAF), the pre-processed ECG data are turned into a multi-modal image. The converted images are segmented using the Attention Dilated U-Net Model (ADil-UNet) to identify the relevant regions in the multi-modal image. The appropriate features are extracted from the segmented images using the Swin-Patch Transformer (Swin-PT) model to reduce feature dimensionality issues. The extracted features can be merged using a weighted fusion method, and the Coati Depth Wise Convolutional Deep Capsule Network (DeW-DCN) is used to classify arrhythmias as normal or abnormal. To optimize the loss function, the network model's hyperparameters are tuned using the Coati optimization algorithm (CoA). Python software is used to implement the proposed method. The proposed method results in 99.31 % accuracy for the MIT-BIH arrhythmia dataset and 99.58 % accuracy using the UCI arrhythmia ECG dataset. © 2024 Elsevier Ltd","Attention Dilated U-Net; Cardiac arrhythmia; Coati optimization; Deep capsule network; ECG; Sequential Savitzky-Golay; Swin patch transformer","Biomedical signal processing; Computer software; Convolution; Deep learning; Diseases; Attention dilated U-net; Cardiac arrhythmia; Coati optimization; Deep capsule network; Multimodal images; Net model; Optimisations; Savitzky-Golay; Sequential savitzky-golay; Swin patch transformer; Article; automation; controlled study; convolutional neural network; diagnostic test accuracy study; disease classification; electrocardiography; feature extraction; heart arrhythmia; human; image segmentation; multimodal imaging; predictive value; receiver operating characteristic; sensitivity and specificity; Electrocardiograms","","","Elsevier Ltd",""
"Koehler G.; Wald T.; Ulrich C.; Zimmerer D.; Jaeger P.F.; Franke J.K.H.; Kohl S.; Isensee F.; Maier-Hein K.H.","Koehler, Gregor (36129538900); Wald, Tassilo (57223727513); Ulrich, Constantin (57207832034); Zimmerer, David (57193016967); Jaeger, Paul F. (57201075948); Franke, Jörg K. H. (57219620326); Kohl, Simon (57204142298); Isensee, Fabian (57194378532); Maier-Hein, Klaus H. (55647018100)","36129538900; 57223727513; 57207832034; 57193016967; 57201075948; 57219620326; 57204142298; 57194378532; 55647018100","RecycleNet: Latent Feature Recycling Leads to Iterative Decision Refinement","2024","","","","799","807","8","10.1109/WACV57701.2024.00086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191952760&doi=10.1109%2fWACV57701.2024.00086&partnerID=40&md5=65615c039c35bdbc6e208c595128e79d","Despite the remarkable success of deep learning systems over the last decade, a key difference still remains between neural network and human decision-making: As humans, we can not only form a decision on the spot, but also ponder, revisiting an initial guess from different angles, distilling relevant information, arriving at a better decision. Here, we propose RecycleNet, a latent feature recycling method, instilling the pondering capability for neural networks to refine initial decisions over a number of recycling steps, where outputs are fed back into earlier network layers in an iterative fashion. This approach makes minimal assumptions about the neural network architecture and thus can be implemented in a wide variety of contexts. Using medical image segmentation as the evaluation environment, we show that latent feature recycling enables the network to iteratively refine initial predictions even beyond the iterations seen during training, converging towards an improved decision. We evaluate this across a variety of segmentation benchmarks and show consistent improvements even compared with top-performing segmentation methods. This allows trading increased computation time for improved performance, which can be beneficial, especially for safety-critical applications. © 2024 IEEE.","Algorithms; Algorithms; and algorithms; Applications; Biomedical / healthcare / medicine; formulations; Image recognition and understanding; Machine learning architectures","Decision making; Deep learning; Image enhancement; Image recognition; Image segmentation; Learning algorithms; Learning systems; Medical imaging; Multilayer neural networks; Network architecture; Network layers; Recycling; Safety engineering; And algorithm; Biomedical / healthcare / medicine; Formulation; Human decision-making; Initial guess; Learning architectures; Machine learning architecture; Machine-learning; Neural-networks; On the spots; Iterative methods","Helmholtz Association; Helmholtz Imaging","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","16th Asian Conference on Intelligent Information and Database Systems , ACIIDS 2024","2024","2145 CCIS","","","","","709","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202151787&partnerID=40&md5=a57b7fd285d282a8b11dd25c8f9caf3f","The proceedings contain 58 papers. The special focus in this conference is on Intelligent Information and Database Systems. The topics include: A Deep Neural Networks Approach for Speaker Verification on Embedded Devices; phishing Detection Using Ensemble of Classifiers; an Effective Ensemble Classification Algorithm for Intrusion Detection System; mean-Square Consensus of Second-Order Multi-agent Systems with Semi-Markov Switching for Non-periodic DoS Attacks; an Attention-Driven Hybrid Network for Survival Analysis of Tumorigenesis Patients Using Whole Slide Images; a Deep Learning Approach to Diabetes Diagnosis; a Novel Approach for Medical E-Consent: Leveraging Language Models for Informed Consent Management; Multi-scale and Multi-level Attention Based on External Knowledge in EHRs; Exploring XAI Attention Maps to Investigate the Effect of Distance Metric and Lesion-Shaped Border Expansion Size for Effective Content-Based Dermatological Lesion Retrieval; d-MiQ: Deep Multimodal Interactive Healthcare Query Expansion Approach for Web Search Engines Retrieval Effectiveness; complexity of Transforming Decision Rule Systems into Decision Trees and Acyclic Decision Graphs; depth of Deterministic and Nondeterministic Decision Trees for Decision Tables with Many-Valued Decisions from Closed Classes; gradient Overdrive: Avoiding Negative Randomness Effects in Stochastic Gradient Descent; blockchain-Based Educational Certification Systems Using a Modified Hash Algorithm; the Merged Longest Common Increasing Subsequence Problem; applying Transformation to Reduce Model Sizes for Constrained Optimization Problems; multiple Traveling Salesman Problem with a Drone Station: Using Multi-package Payload Compartments; unveiling the Power of Hybrid Balancing Techniques and Ensemble Stacked and Blended Classifiers for Enhanced Churn Prediction; improvement of a Forward Reasoning Engine FreeEnCal for Trust Reasoning; a Structure Based on B+ Trees to Represent a Large Number of k-Multisets Stored in Non-volatile Memory; optimizing Option Short Strangle Strategies Through Genetic Algorithm; optimizing Airline Pilots Training Plans: A Mixed Integer Linear Programming Approach; towards an Ontological Approach for Verifying the Well-Formedness of Training Programs; penetration Testing and Security Assessment Methodology for Biomedical Devices.","","","","Nguyen N.T.; Wojtkiewicz K.; Chbeir R.; Manolopoulos Y.; Fujita H.; Hong T.-P.; Nguyen L.M.","Springer Science and Business Media Deutschland GmbH",""
"Rahmaniar W.; Suzuki K.; Lin T.-L.","Rahmaniar, Wahyu (56982984800); Suzuki, Kenji (8649300700); Lin, Ting-Lan (34869939900)","56982984800; 8649300700; 34869939900","Auto-CA: Automated Cobb Angle Measurement Based on Vertebrae Detection for Assessment of Spinal Curvature Deformity","2024","71","2","","640","649","9","10.1109/TBME.2023.3313126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171594351&doi=10.1109%2fTBME.2023.3313126&partnerID=40&md5=624d3d6b6a1a2a299bf711f7f20f4e95","An accurate identification and localization of vertebrae in X-ray images can assist doctors in measuring Cobb angles for treating patients with adolescent idiopathic scoliosis. It is useful for clinical decision support systems for diagnosis, surgery planning, and spinal health analysis. Currently, publicly available annotated datasets on spinal vertebrae are small, making deep-learning-based detection methods that are highly data-dependent less accurate. In this article, we propose an algorithm based on convolutional neural networks that can be trained to detect vertebrae from a small set of images. This method can display critical information on a patient's spine, display vertebrae and their labels on the thoracic and lumbar, calculate the Cobb angle, and evaluate the severity of spinal deformities. The proposed achieved an average accuracy of 0.958 and 0.962 for classifying spinal deformities (i.e., C-shaped, S-shaped type 1, and S-shaped type 2) and severity of Cobb angle (i.e., normal, mild, moderate, and severe), respectively. The Cobb angle measurement had a median difference of less than 5° from the ground-truth with SMAPE of 5.27% and an error on landmark detection of 19.73. In addition, Lenke classification is used to analyze spinal deformities as types A, B, and C, which have an average accuracy of 0.924. Physicians can use the proposed system in clinical practice by providing X-ray images via the user interface.  © 1964-2012 IEEE.","Cobb angle; convolutional neural network; scoliosis; spine; vertebrae","Adolescent; Algorithms; Humans; Lumbar Vertebrae; Neural Networks, Computer; Scoliosis; Spine; Thoracic Vertebrae; Angle measurement; Convolution; Decision support systems; Deep learning; Diagnosis; Feature extraction; Image segmentation; Musculoskeletal system; Biomedical measurements; Cobb angles; Convolutional neural network; Features extraction; Images segmentations; Labelings; Scoliosis; Spine; Vertebra; X-ray imaging; adolescent; adolescent idiopathic scoliosis; adult; anatomic landmark; Article; clinical practice; Cobb angle; convolutional neural network; deep learning; disease severity; human; intervertebral disk; lumbar spine; physician; scoliosis; spine malformation; thoracic spine; algorithm; artificial neural network; diagnostic imaging; lumbar vertebra; scoliosis; spine; thoracic vertebra; Neural networks","JST-Mirai Program, (JPMJMI20B8); JST-Mirai Program","","IEEE Computer Society","37682652"
"Latonen L.; Koivukoski S.; Khan U.; Ruusuvuori P.","Latonen, Leena (7801518847); Koivukoski, Sonja (57222077516); Khan, Umair (57873881400); Ruusuvuori, Pekka (8594550600)","7801518847; 57222077516; 57873881400; 8594550600","Virtual staining for histology by deep learning","2024","42","9","","1177","1191","14","10.1016/j.tibtech.2024.02.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187567343&doi=10.1016%2fj.tibtech.2024.02.009&partnerID=40&md5=2a48f351114f2ca5f6a5e9bde0bbca1d","In pathology and biomedical research, histology is the cornerstone method for tissue analysis. Currently, the histological workflow consumes plenty of chemicals, water, and time for staining procedures. Deep learning is now enabling digital replacement of parts of the histological staining procedure. In virtual staining, histological stains are created by training neural networks to produce stained images from an unstained tissue image, or through transferring information from one stain to another. These technical innovations provide more sustainable, rapid, and cost-effective alternatives to traditional histological pipelines, but their development is in an early phase and requires rigorous validation. In this review we cover the basic concepts of virtual staining for histology and provide future insights into the utilization of artificial intelligence (AI)-enabled virtual histology. © 2024 The Author(s)","artificial intelligence (AI); deep learning; histology; microscopy; pathology; virtual staining","Cost effectiveness; Deep learning; E-learning; Pathology; Tissue; collagen type 4; epidermal growth factor receptor; tumor marker; Artificial intelligence; Biomedical research; Chemical water; Deep learning; Neural-networks; Technical innovation; Tissue analysis; Tissue images; Virtual staining; Work-flows; artificial intelligence; autofluorescence; breast cancer; cancer screening; colorectal carcinoma; computer assisted tomography; cost effectiveness analysis; deep learning; diagnostic accuracy; Fourier transform infrared spectroscopy; hallucination; histology; histopathology; human; human tissue; immunocytochemistry; immunofluorescence; immunohistochemistry; kidney biopsy; learning algorithm; lung parenchyma; machine learning; micro-computed tomography; microscopy; nerve cell plasticity; neuroendocrine tumor; prostate biopsy; proteomics; Review; spectroscopy; staining; tissue microarray; training; ultra performance liquid chromatography; Histology","Syöpäsäätiö; Emil Aaltosen Säätiö; University of Turku Graduate School (U.K.); Research Council of Finland, AKA, (357490, 359230, 341967, 359229); Research Council of Finland, AKA","","Elsevier Ltd","38480025"
"Tahmid M.T.; Kader M.E.; Mahmud T.; Fattah S.A.","Tahmid, Md Toki (57219985836); Kader, Muhammad Ehsanul (57221447013); Mahmud, Tanvir (57215274134); Fattah, Shaikh Anowarul (36550158900)","57219985836; 57221447013; 57215274134; 36550158900","MD-CardioNet: A Multi-Dimensional Deep Neural Network for Cardiovascular Disease Diagnosis From Electrocardiogram","2024","28","4","","2005","2013","8","10.1109/JBHI.2023.3308856","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169702157&doi=10.1109%2fJBHI.2023.3308856&partnerID=40&md5=10c1129335b9a009be5cb4c9f7b2fe50","Automated classification of cardiovascular diseases from electrocardiogram (ECG) signals using deep learning has gained significant interest due to its wide range of applications. However, existing deep learning approaches often overlook inter-channel shared information or lose time-sequence dependent information when considering 1D and 2D ECG representations, respectively. Moreover, besides considering spatial dimension, it is necessary to understand the context of the signals from a global feature space. We propose MD-CardioNet, an efficient deep learning architecture that captures temporal, spatial, and volumetric features from multi-lead ECG signals using multidimensional (1D, 2D, and 3D) convolutions to address these challenges. Sequential feature extractors capture time-dependent information, while a 2D convolution is applied to form an image representation from the multi-channel ECG signal, extracting inter-channel features. Additionally, a volumetric feature extraction network is designed to incorporate intra-channel, inter-channel, and inter-filter global space information. To reduce computational complexity, we introduce a practical knowledge distillation framework that reduces the number of trainable parameters by up to eight times (from 4,304,910 parameters to 94,842 parameters) while maintaining satisfactory performance compatible with the other existing approaches. The proposed architecture is evaluated on a large publicly available dataset containing ECG signals from over 10,000 patients, achieving an accuracy of 97.3% in classifying six heartbeat rhythms. Our results surpass the performance of some state-of-the-art approaches. This paper presents a novel deep-learning approach for ECG classification that addresses the limitations of existing methods. The experimental results highlight the robustness and accuracy of MD-CardioNet in cardiovascular disease classification, offering valuable insights for future research in this field.  © 2013 IEEE.","computational complexity; computer aided analysis; convolutional neural network; Deep learning; ECG signal analysis","Biomedical signal processing; Cardiology; Classification (of information); Complex networks; Computational complexity; Computer aided analysis; Computer aided diagnosis; Computer architecture; Convolution; Convolutional neural networks; Deep neural networks; Diseases; Distillation; Electrocardiography; Extraction; Network architecture; Signal analysis; Arrhythmia; Computational modelling; Computer-aided analysis; Convolutional neural network; Deep learning; Electrocardiogram signal; Electrocardiogram signal analyse; Features extraction; Heart beats; Signals analysis; architecture; Article; atrial fibrillation; cardiovascular disease; deep neural network; electrocardiography; entropy; feature extraction; female; human; learning algorithm; long term memory; major clinical study; male; measurement accuracy; multi dimensional deep neural network; physical parameters; short term memory; sinus bradycardia; sinus rhythm; spatial feature optimizer; temporal feature optimizer; volumetric feature optimizer; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.","37651481"
"Gu S.; Wen C.; Xiao Z.; Huang Q.; Jiang Z.; Liu H.; Gao J.; Li J.; Sun C.; Yang N.","Gu, Shuang (57851448000); Wen, Chaoliang (57203167284); Xiao, Zhen (58851784100); Huang, Qiang (55543093800); Jiang, Zheyi (58851319600); Liu, Honghong (57851241300); Gao, Jia (58851319700); Li, Junying (36064053600); Sun, Congjiao (55362524200); Yang, Ning (57203492918)","57851448000; 57203167284; 58851784100; 55543093800; 58851319600; 57851241300; 58851319700; 36064053600; 55362524200; 57203492918","MyoV: a deep learning-based tool for the automated quantification of muscle fibers","2024","25","2","bbad528","","","","10.1093/bib/bbad528","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183492860&doi=10.1093%2fbib%2fbbad528&partnerID=40&md5=be2347923e2cd2f5c01dd3313155f694","Accurate approaches for quantifying muscle fibers are essential in biomedical research and meat production. In this study, we address the limitations of existing approaches for hematoxylin and eosin-stained muscle fibers by manually and semiautomatically labeling over 660 000 muscle fibers to create a large dataset. Subsequently, an automated image segmentation and quantification tool named MyoV is designed using mask regions with convolutional neural networks and a residual network and feature pyramid network as the backbone network. This design enables the tool to allow muscle fiber processing with different sizes and ages. MyoV, which achieves impressive detection rates of 0.93–0.96 and precision levels of 0.91–0.97, exhibits a superior performance in quantification, surpassing both manual methods and commonly employed algorithms and software, particularly for whole slide images (WSIs). Moreover, MyoV is proven as a powerful and suitable tool for various species with different muscle development, including mice, which are a crucial model for muscle disease diagnosis, and agricultural animals, which are a significant meat source for humans. Finally, we integrate this tool into visualization software with functions, such as segmentation, area determination and automatic labeling, allowing seamless processing for over 400 000 muscle fibers within a WSI, eliminating the model adjustment and providing researchers with an easy-to-use visual interface to browse functional options and realize muscle fiber quantification from WSIs. © 2024 Oxford University Press. All rights reserved.","automatic quantification; cell segmentation; deep learning; muscle fiber; MyoV","Algorithms; Animals; Deep Learning; Humans; Image Processing, Computer-Assisted; Mice; Muscle Fibers, Skeletal; Neural Networks, Computer; algorithm; animal; artificial neural network; deep learning; human; image processing; mouse; procedures; skeletal muscle cell","Anhui Provincial Key Laboratory of Livestock and Poultry Product Safety Engineering; National Natural Science Foundation of China, NSFC, (32102535); National Natural Science Foundation of China, NSFC; National Key Research and Development Program of China, NKRDPC, (2022YFF1000204); National Key Research and Development Program of China, NKRDPC; Key Research and Development Project of Hainan Province, (ZDYF2023XDNY036); Key Research and Development Project of Hainan Province","","Oxford University Press","38271484"
"Alzakari S.A.; Maashi M.; Alahmari S.; Arasi M.A.; Alharbi A.A.K.; Sayed A.","Alzakari, Sarah A. (57220890847); Maashi, Mashael (57216199758); Alahmari, Saad (57924413000); Arasi, Munya A. (57200158993); Alharbi, Abeer A. K. (59076056000); Sayed, Ahmed (58872962100)","57220890847; 57216199758; 57924413000; 57200158993; 59076056000; 58872962100","Towards laryngeal cancer diagnosis using Dandelion Optimizer Algorithm with ensemble learning on biomedical throat region images","2024","14","1","19713","","","","10.1038/s41598-024-70525-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201977162&doi=10.1038%2fs41598-024-70525-0&partnerID=40&md5=1c1904975c5ce2060b207f25be6ab435","Laryngeal cancer exhibits a notable global health burden, with later-stage detection contributing to a low mortality rate. Laryngeal cancer diagnosis on throat region images is a pivotal application of computer vision (CV) and medical image diagnoses in the medical sector. It includes detecting and analysing abnormal or cancerous tissue from the larynx, an integral part of the vocal and respiratory systems. The computer-aided system makes use of artificial intelligence (AI) through deep learning (DL) and machine learning (ML) models, including convolution neural networks (CNN), for automated disease diagnoses and detection. Various DL and ML approaches are executed to categorize the extraction feature as healthy and cancerous tissues. This article introduces an automated Laryngeal Cancer Diagnosis using the Dandelion Optimizer Algorithm with Ensemble Learning (LCD-DOAEL) method on Biomedical Throat Region Image. The LCD-DOAEL method aims to investigate the images of the throat region for the presence of laryngeal cancer. In the LCD-DOAEL method, the Gaussian filtering (GF) approach is applied to eliminate the noise in the biomedical images. Besides, the complex and intrinsic feature patterns can be extracted by the MobileNetv2 model. Meanwhile, the DOA model carries out the hyperparameter selection of MobileNetV2 architecture. Finally, the ensemble of three classifiers such as bidirectional long short-term memory (BiLSTM), regularized extreme learning machine (ELM), and backpropagation neural network (BPNN) models, are utilized for the classification process. A comprehensive set of simulations is conducted on the biomedical image dataset to highlight the efficient performance of the LCD-DOAEL technique. The comparison analysis of the LCD-DOAEL method exhibited a superior accuracy outcome of 97.54% over other existing techniques. © The Author(s) 2024.","Biomedical image; Dandelion Optimizer Algorithm; Ensemble learning; Laryngeal cancer; Narrow-band imaging","Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Laryngeal Neoplasms; Machine Learning; Neural Networks, Computer; Pharynx; algorithm; artificial neural network; computer assisted diagnosis; deep learning; diagnosis; diagnostic imaging; human; image processing; larynx tumor; machine learning; pharynx; procedures","","","Nature Research","39181918"
"Lin W.; Gao Z.; Liu H.; Zhang H.","Lin, Weiyuan (57912217700); Gao, Zhifan (55320405200); Liu, Hui (56120191700); Zhang, Heye (58447662800)","57912217700; 55320405200; 56120191700; 58447662800","A Deformable Constraint Transport Network for Optimal Aortic Segmentation From CT Images","2024","43","4","","1462","1475","13","10.1109/TMI.2023.3339142","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179829295&doi=10.1109%2fTMI.2023.3339142&partnerID=40&md5=42fcf8430a7de7084d94ae2c9078c5c1","Aortic segmentation from computed tomography (CT) is crucial for facilitating aortic intervention, as it enables clinicians to visualize aortic anatomy for diagnosis and measurement. However, aortic segmentation faces the challenge of variable geometry in space, as the geometric diversity of different diseases and the geometric transformations that occur between raw and measured images. Existing constraint-based methods can potentially solve the challenge, but they are hindered by two key issues: inaccurate definition of properties and inappropriate topology of transformation in space. In this paper, we propose a deformable constraint transport network (DCTN). The DCTN adaptively extracts aortic features to define intra-image constrained properties and guides topological implementation in space to constrain inter-image geometric transformation between raw and curved planar reformation (CPR) images. The DCTN contains a deformable attention extractor, a geometry-aware decoder and an optimal transport guider. The extractor generates variable patches that preserve semantic integrity and long-range dependency in long-sequence images. The decoder enhances the perception of geometric texture and semantic features, particularly for low-intensity aortic coarctation and false lumen, which removes background interference. The guider explores the geometric discrepancies between raw and CPR images, constructs probability distributions of discrepancies, and matches them with inter-image transformation to guide geometric topology in space. Experimental studies on 267 aortic subjects and four public datasets show the superiority of our DCTN over 23 methods. The results demonstrate DCTN’s advantages in aortic segmentation for different types of aortic disease, for different aortic segments, and in the measurement of clinical indexes. © 2023 The Authors.","aortic segmentation; Computed tomography; geometric constraint; optimal transport; transformer","Aorta; Humans; Image Processing, Computer-Assisted; Tomography, X-Ray Computed; Blood vessels; Computerized tomography; Decoding; Diagnosis; Image segmentation; Mathematical transformations; Medical imaging; Probability distributions; Semantics; Topology; Aortic segmentation; Biomedical imaging; Computed tomography; Decoding; Features extraction; Geometric constraint; Images segmentations; Optimal transport; Transformer; affine transform; aorta; aortic coarctation; Article; back propagation; benchmarking; computer assisted tomography; computer vision; controlled study; convolutional neural network; deep learning; deformable registration algorithm; feature extraction; geometry; human; image segmentation; major clinical study; morphology; prediction; quality control; random forest; retrospective study; diagnostic imaging; image processing; procedures; x-ray computed tomography; Geometry","","","Institute of Electrical and Electronics Engineers Inc.","38048241"
"Babu T.R.G.; Saravanakumar U.; Pattanaik B.","Babu, T. R. Ganesh (50261588000); Saravanakumar, U. (55148035200); Pattanaik, Balachandra (54420927600)","50261588000; 55148035200; 54420927600","COMPUTATIONAL IMAGING AND ANALYTICS IN BIOMEDICAL ENGINEERING: Algorithms and Applications","2024","","","","1","329","328","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199671408&partnerID=40&md5=100ea5185201e038d1b391488e286587","Computational Imaging and Analytics in Biomedical Engineering: Algorithms and Applications focuses on mathematical and numerical methods for medical images and data. The book presents the various mathematical modeling techniques, numerical analysis, computing and computational techniques, and applications of machine learning for medical images and medical informatics. It also focuses on programming concepts using MATLAB and Phython for medical image and signal analytics. The volume demonstrates the use of various computational techniques and tools such as machine learning, deep neural networks, artificial intelligence and human-computer interaction, fusion methods for CT and pet images, etc. for diagnosis of brain disorders, cervical cancer, lung disease, melanoma, atrial fibrillation and other circulatory issues, dental images, diabetes, and other medical issues. Key features: • Addresses the various common challenges related to biomedical image analysis • Presents a variety of mathematical models for medical images • Discusses applications of algorithms on medical images for various medical issuses • Describes the development of intelligent computing machines such as embedded systems • Explores the programming techniques using MATLAB and Phython for biomedical applications This book presents a plethora of uses of algorithms and applications in computational imaging and analytics for the medical/health field. It will serve as a resource on recent advances and trends in the field of computational imaging, where computation is playing a dominant role in imaging systems. © 2024 by Apple Academic Press, Inc.","","","","","Apple Academic Press",""
"Fiscone C.; Curti N.; Ceccarelli M.; Remondini D.; Testa C.; Lodi R.; Tonon C.; Manners D.N.; Castellani G.","Fiscone, Cristiana (57226395069); Curti, Nico (57204364998); Ceccarelli, Mattia (57224689530); Remondini, Daniel (8988871200); Testa, Claudia (56887437000); Lodi, Raffaele (7006552946); Tonon, Caterina (6603945656); Manners, David Neil (7004151863); Castellani, Gastone (55925089300)","57226395069; 57204364998; 57224689530; 8988871200; 56887437000; 7006552946; 6603945656; 7004151863; 55925089300","Generalizing the Enhanced-DeepSuper-Resolution Neural Network to Brain MR Images: A Retrospective Study on the Cam-CAN Dataset","2024","11","5","ENEURO.0458-22.2023","","","","10.1523/ENEURO.0458-22.2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195227322&doi=10.1523%2fENEURO.0458-22.2023&partnerID=40&md5=174951f1980c355179286c5a74eb77eb","The Enhanced-Deep-Super-Resolution (EDSR) model is a state-of-the-art convolutional neural network suitable for improving image spatial resolution. It was previously trained with general-purpose pictures and then, in this work, tested on biomedical magnetic resonance (MR) images, comparing the network outcomes with traditional up-sampling techniques. We explored possible changes in the model response when different MR sequences were analyzed. T1 w and T2 w MR brain images of 70 human healthy subjects (F:M, 40:30) from the Cambridge Centre for Ageing and Neuroscience (Cam-CAN) repository were down-sampled and then up-sampled using EDSR model and BiCubic (BC) interpolation. Several reference metrics were used to quantitatively assess the performance of up-sampling operations (RMSE, pSNR, SSIM, and HFEN). Two-dimensional and three-dimensional reconstructions were evaluated. Different brain tissues were analyzed individually. The EDSR model was superior to BC interpolation on the selected metrics, both for two-and three-dimensional reconstructions. The reference metrics showed higher quality of EDSR over BC reconstructions for all the analyzed images, with a significant difference of all the criteria in T1w images and of the perception-based SSIM and HFEN in T2w images. The analysis per tissue highlights differences in EDSR performance related to the gray-level values, showing a relative lack of outperformance in reconstructing hyperintense areas. The EDSR model, trained on general-purpose images, better reconstructs MR T1w and T2 w images than BC, without any retraining or fine-tuning. These results highlight the excellent generalization ability of the network and lead to possible applications on other MR measurements. © 2024 Fiscone et al.","brain; deep learning; image processing; MRI; super-resolution","Adult; Aged; Brain; Datasets as Topic; Deep Learning; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Neural Networks, Computer; Retrospective Studies; algorithm; Article; brain cortex; controlled study; convolutional neural network; deep learning; gray matter; human; image processing; image quality; machine learning; magnetoencephalography; major clinical study; nerve cell network; normal human; nuclear magnetic resonance; three-dimensional imaging; training; white matter; adult; aged; artificial neural network; brain; diagnostic imaging; female; information processing; male; middle aged; nuclear magnetic resonance imaging; procedures; retrospective study","Medical Research Council, MRC; Biotechnology and Biological Sciences Research Council, BBSRC; Cambridge Centre for Ageing and Neuroscience; Italian National Institute for Nuclear Physics; Ministero della Salute; University of Cambridge","","Society for Neuroscience","38729763"
"Sadam S.S.P.; Nalini N.J.","Sadam, Sesha Sai Priya (58675348800); Nalini, N.J. (57210067762)","58675348800; 57210067762","Epileptic seizure detection using scalogram-based hybrid CNN model on EEG signals","2024","18","2","","1577","1588","11","10.1007/s11760-023-02871-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177650142&doi=10.1007%2fs11760-023-02871-x&partnerID=40&md5=63b4718aa15220bd9516ad494407ee50","Epilepsy is one of the most usual neurological diseases characterized by abnormal brain activity, resulting in seizures or strange behavior, sensations, and, in some cases, loss of consciousness. It is a persistent, non-communicable brain condition that can affect anyone at any age, nearly 50 million people globally, with about 80% of sufferers living in low- and middle-income countries. Electroencephalography (EEG) signals are largely used in epilepsy research to examine brain activity during seizures. The extraction of features and selection from EEG signals plays a major role in epileptic seizure detection. In traditional machine learning techniques, the hard-core feature extraction needs domain expertise, and this can be eliminated by deep learning. The benefits of deep learning techniques are they try to learn high-level features from the input signals in an incremental method. To meet the requirements of complicated feature engineering, deep learning techniques have received greater attention than conventional methods. A hybrid seizure detection-convolutional neural network and vector machine (SD-CNN and SVM) model is proposed for epileptic seizure detection with EEG signals. Transformation of signal to image is performed using continuous wavelet transform technique to generate scaleogram images and also SD-CNN works as a learnable feature extractor from the generated images and SVM works as a binary classifier. The experimental results extracted 94% with high quality of scaleogram images using hybrid SD-CNN and SVM model and removed the noise levels and time–frequency data from EEG signals. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2023.","CWT; EEG; Epilepsy; Scaleogram; SD-CNN; SVM","Biomedical signal processing; Brain; Convolutional neural networks; Deep learning; Electrophysiology; Extraction; Feature extraction; Image processing; Learning algorithms; Learning systems; Neurodegenerative diseases; Neurophysiology; Signal detection; Support vector machines; Wavelet transforms; Brain activity; CNN models; CWT; Epilepsy; Epileptic seizure detection; Learning techniques; Scaleogram; SD-CNN; SVM; SVM model; Electroencephalography","","","Springer Science and Business Media Deutschland GmbH",""
"Singh S.A.; Singh S.A.; Singh A.D.","Singh, Sinam Ashinikumar (57224946224); Singh, Sinam Ajitkumar (57202977140); Singh, Aheibham Dinamani (59244318500)","57224946224; 57202977140; 59244318500","Ensemble learning for accurate prediction of heart sounds using gammatonegram images","2024","32","4","","555","573","18","10.55730/1300-0632.4087","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200230063&doi=10.55730%2f1300-0632.4087&partnerID=40&md5=a96b642497b35bf555188404527f9c8d","The analysis of heart sound signals constitutes a pivotal domain in healthcare, with the prediction of imbalanced heart sounds offering critical diagnostic insights. However, the inherent diversity in cardiac sound patterns presents a substantial challenge in predicting imbalanced signals. Many scientific disciplines have focused a great deal of emphasis on the problem of class inequality. We introduce an ensemble learning approach employing a convolutional neural network model-based deep learning algorithm to effectively tackle the challenges associated with predicting imbalanced heart sound signals. We use a gammatone filter bank to extract relevant features from the heard sound signal. Our approach leverages a pretrained convolutional neural network architecture, fine-tuning it with gammatonegram images to improve the classification performance. To overcome the challenges posed by imbalanced datasets, we integrate data augmentation into the image processing pipeline. The images are subsequently subjected to classification through deep convolutional neural network employing a transfer learning technique. This involves the utilization of convolutional neural network models such as AlexNet, SqueezeNet, GoogLeNet, and VGG19 to address concerns related to model overfitting. Our experimental results are rigorously validated using the publicly accessible PhysioNet 2016 dataset. The proposed ensemble methodology, incorporating AlexNet, SqueezeNet, and VGG19 models, demonstrated superior performance, attaining an accuracy of 99.51%, a sensitivity rate of 99.34%, and a specificity rate of 99.67%. These results emphasize the substantial clinical promise inherent in our methodology, particularly in the realm of identifying imbalanced and noisy heart sound signals. This, in turn, serves to advance the diagnosis of cardiovascular diseases. © TÜBİTAK.","convolutional neural network; deep learning; gammatonegram; phonocardiogram; PhysioNet","Biomedical signal processing; Cardiology; Convolution; Convolutional neural networks; Deep neural networks; Heart; Image enhancement; Learning algorithms; Network architecture; Neural network models; Phonocardiography; Signal analysis; Accurate prediction; Convolutional neural network; Deep learning; Ensemble learning; Gammatonegram; Heart sound signal; Heart sounds; Neural network model; Phonocardiograms; PhysioNet; Forecasting","Ministry of Electronics and Information technology, Meity","","Turkiye Klinikleri",""
"Zhao Y.; Guo M.; Chen X.; Sun J.; Qiu J.","Zhao, Yan (57387964200); Guo, Ming (56949682900); Chen, Xiangyong (42660946200); Sun, Jianqiang (57216161701); Qiu, Jianlong (8950212900)","57387964200; 56949682900; 42660946200; 57216161701; 8950212900","Attention-Based CNN Fusion Model for Emotion Recognition during Walking Using Discrete Wavelet Transform on EEG and Inertial Signals","2024","7","1","","188","204","16","10.26599/BDMA.2023.9020018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183076226&doi=10.26599%2fBDMA.2023.9020018&partnerID=40&md5=b6815649424933bb3057e0fe6e2386e3","Walking as a unique biometric tool conveys important information for emotion recognition. Individuals in different emotional states exhibit distinct walking patterns. For this purpose, this paper proposes a novel approach to recognizing emotion during walking using electroencephalogram (EEG) and inertial signals. Accurate recognition of emotion is achieved by training in an end-to-end deep learning fashion and taking into account multi-modal fusion. Subjects wear virtual reality head-mounted display (VR-HMD) equipment to immerse in strong emotions during walking. VR environment shows excellent imitation and experience ability, which plays an important role in awakening and changing emotions. In addition, the multi-modal signals acquired from EEG and inertial sensors are separately represented as virtual emotion images by discrete wavelet transform (DWT). These serve as input to the attention-based convolutional neural network (CNN) fusion model. The designed network structure is simple and lightweight while integrating the channel attention mechanism to extract and enhance features. To effectively improve the performance of the recognition system, the proposed decision fusion algorithm combines Critic method and majority voting strategy to determine the weight values that affect the final decision results. An investigation is made on the effect of diverse mother wavelet types and wavelet decomposition levels on model performance which indicates that the 2.2-order reverse biorthogonal (rbio2.2) wavelet with two-level decomposition has the best recognition performance. Comparative experiment results show that the proposed method outperforms other existing state-of-the-art works with an accuracy of 98.73%. © 2018 Tsinghua University Press.","attention mechanism; discrete wavelet transform; emotion recognition; multi-modal fusion; virtual reality; walking","Biomedical signal processing; Deep learning; Electroencephalography; Emotion Recognition; Helmet mounted displays; Neural networks; Signal reconstruction; Speech recognition; Virtual reality; Wavelet decomposition; Attention mechanisms; Convolutional neural network; Discrete-wavelet-transform; Emotion recognition; Emotional state; Fusion model; Multi-modal fusion; Neural network fusions; Performance; Walking; Discrete wavelet transforms","National Natural Science Foundation of China, NSFC, (61877033, 61903170, 62173175)","","Tsinghua University Press",""
"Arı E.; Taçgın E.","Arı, Emre (57923583700); Taçgın, Ertuğrul (6507195953)","57923583700; 6507195953","NF-EEG: A generalized CNN model for multi class EEG motor imagery classification without signal preprocessing for brain computer interfaces","2024","92","","106081","","","","10.1016/j.bspc.2024.106081","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184747053&doi=10.1016%2fj.bspc.2024.106081&partnerID=40&md5=0696f451b921ebd9f1e36457444e6f7b","Objective: Brain Computer Interface (BCI) systems have been developed to identify and classify brain signals and integrate them into a control system. Even though many different methods and models have been developed for the brain signals classification, the majority of these studies have emerged as specialized models. In addition, preprocessing and signal preprocessing methods which are largely based on human knowledge and experience have been used extensively for classification models. These methods degrade the performance of real-time BCI systems and require great time and effort to design and implement the right method. Approach: In order to eliminate these disadvantages, we developed a generalized and robust CNN model called as No-Filter EEG (NF-EEG) to classify multi class motor imagery brain signals with raw data and without applying any signal preprocessing methods. In an attempt to increase the speed and success of this developed model, input reshaping has been made and various data augmentation methods have been applied to the data. Main results: Compared to many other state-of-the-art models, NF-EEG outperformed leading state-of-the-art models in two most used motor imagery datasets and achieved 93.56% in the two-class BCI-IV-2A dataset and 88.40% in the two-class BCI-IV-2B dataset and 81.05% accuracy in the classification of four-class BCI-IV-2A dataset. Significance: This proposed method has emerged as a generalized model without signal preprocessing and it greatly reduces the time and effort required for preparation for classification, prevents human-induced errors on the data, presents very effective input reshaping, and also increases the classification accuracy. © 2024 Elsevier Ltd","Brain computer interface (BCI); Classification; Data augmentation; Deep learning; EEG motor imagery; Input reshaping","Biomedical signal processing; Brain computer interface; Computer control systems; Deep learning; Image classification; Real time systems; Brain computer interface; Brain signals; CNN models; Data augmentation; Deep learning; EEG motor imagery; Input reshaping; Interface system; Motor imagery; Signal preprocessing; algorithm; Article; controlled study; convolutional neural network; deep learning; electroencephalogram; feature extraction; feature selection; machine learning; signal processing; three-dimensional imaging; Classification (of information)","","","Elsevier Ltd",""
"Mwata-Velu T.; Zamora E.; Vasquez-Gomez J.I.; Ruiz-Pinales J.; Sossa H.","Mwata-Velu, Tat’y (57222520987); Zamora, Erik (56038568300); Vasquez-Gomez, Juan Irving (54415023500); Ruiz-Pinales, Jose (15837609100); Sossa, Humberto (6602238115)","57222520987; 56038568300; 54415023500; 15837609100; 6602238115","Multiclass Classification of Visual Electroencephalogram Based on Channel Selection, Minimum Norm Estimation Algorithm, and Deep Network Architectures","2024","24","12","3968","","","","10.3390/s24123968","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197143454&doi=10.3390%2fs24123968&partnerID=40&md5=3729a4ffc4051da9d62bd2c6fd5bbcdd","This work addresses the challenge of classifying multiclass visual EEG signals into 40 classes for brain–computer interface applications using deep learning architectures. The visual multiclass classification approach offers BCI applications a significant advantage since it allows the supervision of more than one BCI interaction, considering that each class label supervises a BCI task. However, because of the nonlinearity and nonstationarity of EEG signals, using multiclass classification based on EEG features remains a significant challenge for BCI systems. In the present work, mutual information-based discriminant channel selection and minimum-norm estimate algorithms were implemented to select discriminant channels and enhance the EEG data. Hence, deep EEGNet and convolutional recurrent neural networks were separately implemented to classify the EEG data for image visualization into 40 labels. Using the k-fold cross-validation approach, average classification accuracies of 94.8% and 89.8% were obtained by implementing the aforementioned network architectures. The satisfactory results obtained with this method offer a new implementation opportunity for multitask embedded BCI applications utilizing a reduced number of both channels (<50%) and network parameters (<110 K). © 2024 by the authors.","brain–computer interfaces (BCIs); convolutional neural network (CNN); EEGNet; long short-term memory (LSTM); minimum-norm estimate (MNE); mutual information (MutIn); visual EEG classification","Algorithms; Brain-Computer Interfaces; Deep Learning; Electroencephalography; Humans; Neural Networks, Computer; Signal Processing, Computer-Assisted; Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Data visualization; Electroencephalography; Network architecture; Brain–computer interface; Convolutional neural network; EEG classification; EEGNet; Long short-term memory; Minimum norm estimate; Minimum-norm estimate; Mutual information; Mutual informations; Visual EEG classification; algorithm; artificial neural network; brain computer interface; deep learning; electroencephalography; human; procedures; signal processing; Long short-term memory","Centro de Investigación en Computación—Insituto Politécnico Nacional, (20220002, 20231622, SIP/1988/DI/DAI/2022, 20230232, 20240108, 20240956); Mexican National Council of Humanities, Science, and Technology CONAHCyT, (2022-2024 CVU No. 763527)","","Multidisciplinary Digital Publishing Institute (MDPI)","38931751"
"Thakkar P.B.; Talwekar R.H.","Thakkar, Priyanka Bibay (58002473400); Talwekar, R.H. (55463418000)","58002473400; 55463418000","An Efficient Blood Pressure Estimation and Risk Analysis System of PPG Signals Using IDA and MPPIW-DLNN Algorithms","2024","24","2","2450015","","","","10.1142/S0219467824500153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143855833&doi=10.1142%2fS0219467824500153&partnerID=40&md5=c28460f39f4cf3aa756cfa7b8b3d8a17","The non-invasive Blood Pressure Estimation (BPE) utilizing the technology of photoplethysmography (PPG) gains significant interest because PPG could be extensively employed to wearable sensors. Here, a method for estimating Systolic Blood pressure (SBP), as well as Diastolic Blood pressure (DBP), grounded only on a PPG signal utilizing the Image Denoising Algorithms (IDA) algorithms is proposed. Also, a classification methodology to execute the risk analysis (RA) of the BP patients utilizing Moore-Penrose Pseudo-Inverse Matrix-Deep Learning Neural Network (MPPIW-DLNN) is proposed. The preprocessing is then done on the input PPG signal utilizing the Modified-Chebyshev Filter (CF) to eradicate the unwanted information existent in the signal. Afterward, the BPE is done utilizing IDA, which categorizes those components into (i) SBP and (ii) DBP. The MPPIW-DLNN provides the results of four sorts of risk classes like (i) stroke, (ii) heart failure (HF), (iii) heart attack (HA), and (iv) aneurysm identified from the inputted PPG signal. © 2024 World Scientific Publishing Company.","Blood pressure estimation; diastolic BP (DBP); hypertension; photoplethysmography (PPG); risk analysis; signal decomposition; systolic BP (SBP)","Biomedical signal processing; Blood pressure; Cardiology; Deep learning; Image denoising; Inverse problems; Photoplethysmography; Risk analysis; Risk assessment; Risk perception; Blood pressure estimation; Diastolic blood pressures; Diastolic BP; Hypertension; Image denoising algorithm; Photoplethysmography; Risk analysis systems; Signal decomposition; Systolic blood pressure; Systolic BP; Blood","","","World Scientific",""
"Chen J.; Han W.; Fu L.; Lv Z.; Chen H.; Fang W.; Hou J.; Yu H.; Huang X.; Sun L.","Chen, Jin (57195544072); Han, Wentao (57221530544); Fu, Liangzun (58973627000); Lv, Zhihang (58973749700); Chen, Haotian (58973991200); Fang, Wenjing (58974241000); Hou, Jiale (57437696400); Yu, Haohan (58973503300); Huang, Xiwei (37361093600); Sun, Lingling (55619293938)","57195544072; 57221530544; 58973627000; 58973749700; 58973991200; 58974241000; 57437696400; 58973503300; 37361093600; 55619293938","A Miniaturized and Intelligent Lensless Holographic Imaging System with Auto-Focusing and Deep Learning-Based Object Detection for Label-Free Cell Classification","2024","16","3","3900208","1","8","7","10.1109/JPHOT.2024.3385182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189617812&doi=10.1109%2fJPHOT.2024.3385182&partnerID=40&md5=3ab13d1b2635e66321bbeb7fac3c0b46","Cell detection and classification is a key technique for disease diagnosis, but conventional methods such as optical microscopy and flow cytometry have limitations in terms of field-of-view (FOV), throughput, cost, size, and operation complexity. Lensless holographic imaging is a promising alternative that offers large FOV, rich information content, and simple structure. However, its performance on cell detection and classification still needs to be improved. In this paper, we propose an intelligent cell detection system based on lensless holographic imaging and deep learning. Our system uses unstained cells suspended in solution as samples and employs a threshold segmentation-based auto-focusing algorithm to determine the optimal focusing distance for each imaging session. We also use a deep learning-based object detection neural network to classify different types of cells from the focused holographic images without the need for cell segmentation. We demonstrated the performance of our system using four cell detection tasks: tumor cells vs. polystyrene microspheres (77.6% accuracy), different tumor cells (80.1% accuracy), red blood cells vs. white blood cells (78.1% accuracy), white blood cell subtypes (88% accuracy), which showed that our system achieved high accuracy with label-free, portable, intelligent, and fast cell detection capabilities. It has potential applications in the miniaturized cell detection field.  © 2009-2012 IEEE.","Auto-focusing algorithm; deep learning; label-free; lensless holographic imaging; object detection and classification","Bioinformatics; Blood; Cells; Classification (of information); Computer aided diagnosis; Cytology; Deep learning; Holography; Image segmentation; Medical imaging; Object recognition; Optical microscopy; Tumors; Auto-focusing; Auto-focusing algorithm; Biomedical optical imaging; Deep learning; Focusing algorithm; Holographic imaging; Holographic optical components; Label free; Lensless holographic imaging; Object classification; Objects detection; Optical imaging; Object detection","","","Institute of Electrical and Electronics Engineers Inc.",""
"Islam M.M.; Rifat H.R.; Shahid M.S.B.; Akhter A.; Uddin M.A.","Islam, Md Manowarul (57214493772); Rifat, Habibur Rahman (58959300900); Shahid, Md. Shamim Bin (59217707800); Akhter, Arnisha (57192673414); Uddin, Md Ashraf (7003509328)","57214493772; 58959300900; 59217707800; 57192673414; 7003509328","Utilizing Deep Feature Fusion for Automatic Leukemia Classification: An Internet of Medical Things-Enabled Deep Learning Framework","2024","24","13","4420","","","","10.3390/s24134420","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198480468&doi=10.3390%2fs24134420&partnerID=40&md5=6f534b8501de3b096ad18508b9a94d82","Acute lymphoblastic leukemia, commonly referred to as ALL, is a type of cancer that can affect both the blood and the bone marrow. The process of diagnosis is a difficult one since it often calls for specialist testing, such as blood tests, bone marrow aspiration, and biopsy, all of which are highly time-consuming and expensive. It is essential to obtain an early diagnosis of ALL in order to start therapy in a timely and suitable manner. In recent medical diagnostics, substantial progress has been achieved through the integration of artificial intelligence (AI) and Internet of Things (IoT) devices. Our proposal introduces a new AI-based Internet of Medical Things (IoMT) framework designed to automatically identify leukemia from peripheral blood smear (PBS) images. In this study, we present a novel deep learning-based fusion model to detect ALL types of leukemia. The system seamlessly delivers the diagnostic reports to the centralized database, inclusive of patient-specific devices. After collecting blood samples from the hospital, the PBS images are transmitted to the cloud server through a WiFi-enabled microscopic device. In the cloud server, a new fusion model that is capable of classifying ALL from PBS images is configured. The fusion model is trained using a dataset including 6512 original and segmented images from 89 individuals. Two input channels are used for the purpose of feature extraction in the fusion model. These channels include both the original and the segmented images. VGG16 is responsible for extracting features from the original images, whereas DenseNet-121 is responsible for extracting features from the segmented images. The two output features are merged together, and dense layers are used for the categorization of leukemia. The fusion model that has been suggested obtains an accuracy of 99.89%, a precision of 99.80%, and a recall of 99.72%, which places it in an excellent position for the categorization of leukemia. The proposed model outperformed several state-of-the-art Convolutional Neural Network (CNN) models in terms of performance. Consequently, this proposed model has the potential to save lives and effort. For a more comprehensive simulation of the entire methodology, a web application (Beta Version) has been developed in this study. This application is designed to determine the presence or absence of leukemia in individuals. The findings of this study hold significant potential for application in biomedical research, particularly in enhancing the accuracy of computer-aided leukemia detection. © 2024 by the authors.","DenseNet-121; feature fusion; internet of medical things; leukemia; segmentation; transfer learning; VGG16","Algorithms; Artificial Intelligence; Deep Learning; Humans; Image Processing, Computer-Assisted; Internet of Things; Leukemia; Neural Networks, Computer; Precursor Cell Lymphoblastic Leukemia-Lymphoma; Blood; Cloud computing; Convolutional neural networks; Deep learning; Diagnosis; Image fusion; Internet of things; Medical imaging; Neural network models; Transfer learning; Densenet-121; Features fusions; Fusion model; Internet of medical thing; Leukemia; Peripheral blood smears; Segmentation; Segmented images; Transfer learning; VGG16; algorithm; artificial intelligence; artificial neural network; B cell acute lymphoblastic leukemia; classification; deep learning; diagnosis; human; image processing; internet of things; leukemia; pathology; procedures; Diseases","Jagannath University, JnU","","Multidisciplinary Digital Publishing Institute (MDPI)","39001200"
"Thenmoezhi N.; Perumal B.; Lakshmi A.","Thenmoezhi, N. (56884735800); Perumal, B. (56352303700); Lakshmi, A. (55314493600)","56884735800; 56352303700; 55314493600","Multi-view Image Fusion Using Ensemble Deep Learning Algorithm For MRI And CT Images","2024","23","3","40","","","","10.1145/3640811","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188347633&doi=10.1145%2f3640811&partnerID=40&md5=895bd700c0f37b9de8f8c15ae13ccf62","Medical image fusions are crucial elements in image-based health care diagnostics or therapies and generic applications of computer visions. However, the majority of existing methods suffer from noise distortion that affects the overall output. When pictures are distorted by noises, classical fusion techniques perform badly. Hence, fusion techniques that properly maintain information comprehensively from multiple faulty pictures need to be created. This work presents Enhanced Lion Swarm Optimization (ESLO) with Ensemble Deep Learning (EDL) to address the aforementioned issues. The primary steps in this study include image fusions, segmentation, noise reduction, feature extraction, picture classification, and feature selection. Adaptive Median Filters are first used for noise removal in sequence to enhance image quality by eliminating noises. The MRIs and CT images are then segmented using the Region Growing–based k-Means Clustering (RKMC) algorithm to separate the images into their component regions or objects. Images in black and white are divided into image. In the white image, the RKMC algorithm successfully considered the earlier tumour probability. The next step is feature extraction, which is accomplished by using the Modified Principal Component Analysis (MPCA) to draw out the most informative aspects of the images. Then the ELSO algorithm is applied for optimal feature selection, which is computed by best fitness values. After that, multi-view image fusions of multi modal images derive lower-, middle-, and higher-level image contents. It is done by using Deep Convolution Neural Network (DCNN) and the Tissue-Aware Conditional Generative Adversarial Network (TAcGAN) algorithm, which fuses the multi-view features and relevant image features, and it is used for real-time applications. ELSO +EDL algorithm gives better results in terms of accuracy, Peak Signal-To-Noise Ratio (PSNR), and lower Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE) when compared to other existing algorithms. © 2024 Copyright held by the owner/author(s).","Computed Tomography (CT) images; Enhanced Lion Swarm Optimization (ELSO); Ensemble Deep Learning (EDL) algorithm; Magnetic Resonance Imaging (MRI) images; Multi-view image fusions","Adaptive filtering; Adaptive filters; Biomedical signal processing; Computerized tomography; Deep learning; Diagnosis; Extraction; Feature extraction; Generative adversarial networks; Image enhancement; Image fusion; Image segmentation; K-means clustering; Learning algorithms; Learning systems; Mean square error; Median filters; Medical imaging; Particle swarm optimization (PSO); Principal component analysis; Signal to noise ratio; Computed tomography images; Enhanced lion swarm optimization; Ensemble deep learning  algorithm; Features extraction; Fusion techniques; Magnetic resonance imaging  image; Multi-view image; Multi-view image fusion; Region growing; Swarm optimization; Magnetic resonance imaging","","","Association for Computing Machinery",""
"Jin Z.; Hu C.; Fu Z.; Zhang C.; Wang P.; Zhang H.; Ye X.","Jin, Ziyi (57190222716); Hu, Chunyong (57222400781); Fu, Zuoming (57222137024); Zhang, Chongan (57222402772); Wang, Peng (57221311502); Zhang, Hong (57811324100); Ye, Xuesong (7401899160)","57190222716; 57222400781; 57222137024; 57222402772; 57221311502; 57811324100; 7401899160","Stereo matching of binocular laparoscopic images with improved densely connected neural architecture search","2024","19","4","","677","686","9","10.1007/s11548-023-03035-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183661672&doi=10.1007%2fs11548-023-03035-5&partnerID=40&md5=aa5d643b3912c39b82fb02b064304594","Purpose: Stereo matching is a crucial technology in the binocular laparoscopic-based surgical navigation systems. In recent years, neural networks have been widely applied to stereo matching and demonstrated outstanding performance. however, this method heavily relies on manual feature engineering meaning that professionals must be involved in the feature extraction and matching. This process is both time-consuming and demands specific expertise. Methods: This paper introduces a novel stereo matching framework DCStereo that realizes a fully automatic neural architecture design for the stereo matching of binocular laparoscopic images. The proposed framework utilizes a densely connected search space which enables a more flexible and diverse architecture composition. Furthermore, the proposed algorithm leverages the channel and path sampling strategies to reduce memory consumption during searching. Results: Empirically, our searched DCStereo on the SCARED training dataset achieves a mean absolute error of 3.589 mm on the test dataset, which outperforms hand-crafted stereo matching methods and other approaches. Furthermore, when directly testing on the SERV-CT dataset, our DCStereo demonstrates better generalization ability than other methods. Conclusion: Our proposed approach leverages the neural architecture search technique and a densely connected search space for automatic neural architecture design in stereo matching of binocular laparoscopic images. Our method delivers advanced performance on the SCARED dataset and promising results on the SERV-CT dataset. These findings demonstrate the potential of our approach for improving clinical surgical navigation systems. © CARS 2024.","Binocular laparoscopic images; Neural architecture search; Stereo matching; Surgical navigation","Algorithms; Humans; Laparoscopy; Neural Networks, Computer; architecture; Article; biomedical engineering; cell level; deep learning; feature extraction; image segmentation; laparoscopy; mean absolute error; noise; prediction; probability; algorithm; artificial neural network; human","National Major Scientific Research Instrument Development Project, (81827804); Key Research and Development Program of Zhejiang Province, (2022C03086); Key Research and Development Program of Zhejiang Province","","Springer Science and Business Media Deutschland GmbH","38289466"
"Han Y.; Han P.; Yuan B.; Zhang Z.; Liu L.; Panneerselvam J.","Han, Yibo (57204550942); Han, Pu (57204548570); Yuan, Bo (56530110900); Zhang, Zheng (57215841890); Liu, Lu (57194679110); Panneerselvam, John (55509769900)","57204550942; 57204548570; 56530110900; 57215841890; 57194679110; 55509769900","Novel Transformation Deep Learning Model for Electrocardiogram Classification and Arrhythmia Detection using Edge Computing","2024","22","1","7","","","","10.1007/s10723-023-09717-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181172074&doi=10.1007%2fs10723-023-09717-3&partnerID=40&md5=570c31005ec81a3b1e25172e128139c2","The diagnosis of the cardiovascular disease relies heavily on the automated classification of electrocardiograms (ECG) for arrhythmia monitoring, which is often performed using machine learning (ML) algorithms. However, current ML algorithms are typically deployed using cloud-based inferences, which may not meet the reliability and security requirements for ECG monitoring. A newer solution, edge inference, has been developed to address speed, security, connection, and reliability issues. This paper presents an edge-based algorithm that combines continuous wavelet transform (CWT), and short-time Fourier transform (STFT), in a hybrid convolutional neural network (CNN) and Long Short-Term Memory (LSTM) model techniques for real-time ECG classification and arrhythmia detection. The algorithm incorporates an STFT CWT-based 1D convolutional (Conv1D) layer as a Finite Impulse Response (FIR) filter to generate the spectrogram of the input ECG signal. The output feature maps from the Conv1D layer are then reshaped into a 2D heart map image and fed into a hybrid convolutional neural network (2D-CNN) and Long Short-Term Memory (LSTM) classification model. The MIT-BIH arrhythmia database is used to train and evaluate the model. Using a cloud platform, four model versions are learned, considered, and optimized for edge computing on a Raspberry Pi device. Techniques such as weight quantization and pruning enhance the algorithms created for edge inference. The proposed classifiers can operate with a total target size of 90 KB, an overall inference time of 9 ms, and higher memory use of 12 MB while achieving up to 99.6% classification accuracy and a 99.88% F1-score at the edge. Thanks to its results, the suggested classifier is highly versatile and can be used for arrhythmia monitoring on various edge devices. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.","Convolutional neural network; Edge inference; Electrocardiogram; Finite impulse response; Interpretable neural network; Machine learning; Short-time Fourier transform","Biomedical signal processing; Brain; Convolution; Convolutional neural networks; Diseases; FIR filters; Impulse response; Inference engines; Learning systems; Long short-term memory; Multilayer neural networks; Wavelet transforms; Arrhythmia detection; Convolutional neural network; Edge computing; Edge inference; Finite-impulse response; Interpretable neural network; Machine learning algorithms; Machine-learning; Neural-networks; Short time Fourier transforms; Electrocardiograms","","","Springer Science and Business Media B.V.",""
"Chen L.; Fei Y.; Quan B.; Hao Y.; Chen Q.; Liu G.; Luo X.; Li L.; Wei H.","Chen, Li (58961874000); Fei, Yue (57221832560); Quan, Bin (57222389740); Hao, Yuexing (57217089265); Chen, Qinqun (55533101300); Liu, Guiqing (57222386348); Luo, Xiaomu (35810565500); Li, Li (57216957107); Wei, Hang (55532708800)","58961874000; 57221832560; 57222389740; 57217089265; 55533101300; 57222386348; 35810565500; 57216957107; 55532708800","DANNMCTG: Domain-Adversarial Training of Neural Network for multicenter antenatal cardiotocography signal classification","2024","94","","106259","","","","10.1016/j.bspc.2024.106259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189023178&doi=10.1016%2fj.bspc.2024.106259&partnerID=40&md5=593e586838b984818aa4e9992875bd79","Intelligent classification of cardiotocography (CTG) based on machine learning (ML), a useful tool to improve the accuracy of fetal abnormality detection, can assist obstetricians with clinical decisions. With the advancement of information technologies and medical devices, there are development opportunities for multicenter clinical research and obtaining more digital CTG signals. However, most of the existing clinical multicenter CTG datasets are partially annotated and have discrepancies which do not satisfy the ML condition of independent identical distribution. Therefore, this paper focuses on an unsupervised domain adaptation (UDA) algorithm to realize cross-domain intelligent classification of multimodal CTG signals. We propose a method dubbed domain adversarial training of neural network for multicenter CTG (DANNMCTG), which mainly consists of a label classifier, a feature extractor and a domain discriminator. To match different distribution of fetal heart rate (FHR), uterine contraction (UC) and fetal movement (FetMov) signals, we condition the domain alignment on label predictions by defining the multi-linear map. For analysis, two datasets from the hospital central station and home monitoring devices were considered as the source and target domains. The results showed that the accuracy value, F1 value and area under the curve (AUC) value of the DANNMCTG were 71.25%, 76.08% and 0.7705, respectively. This method significantly improved the performance of the deep learning models without exploiting any information in the target domain, and outperformed the state-of-the-art UDA algorithms for CTG classification. In summary, the DANNMCTG can effectively mitigate the influence of domain shift for multicenter intelligent prenatal fetal monitoring. © 2024 Elsevier Ltd","Cardiotocography; Domain-adversarial training of neural network; Intelligent prenatal fetal monitoring; Multicenter study; Unsupervised domain adaptation","Biomedical signal processing; Classification (of information); Deep learning; Digital devices; Fetal monitoring; Learning systems; Neural networks; Cardiotocography; Condition; Domain adaptation; Domain-adversarial training of neural network; Intelligent classification; Intelligent prenatal fetal monitoring; Machine-learning; Multi-centre study; Neural-networks; Unsupervised domain adaptation; adult; Article; bidirectional gated recurrent unit network; bidirectional long short term memory network; bidirectional recurrent neural network; binary classification; cardiotocography; cesarean section; classification algorithm; classifier; comparative study; confusion matrix; convolutional neural network; data accuracy; data processing; deep learning; deep neural network; domain adversarial training of neural network for multicenter antenatal cardiotocography; false negative result; false positive result; feature extraction; female; fetus; fetus echography; fetus heart rate; fetus monitoring; fetus movement; gated recurrent unit network; home monitoring; human; image enhancement; image segmentation; long short term memory network; machine learning; major clinical study; multicenter study; obstetrician; receiver operating characteristic; recurrent neural network; sensitivity and specificity; signal processing; unsupervised domain adaptation algorithm; uterus contraction; Clinical research","Guangdong Medical Research Foundation, (A2019428); Guangdong Medical Research Foundation; National Natural Science Foundation of China, NSFC, (61976052, 71804031); National Natural Science Foundation of China, NSFC","","Elsevier Ltd",""
"Jang S.-I.; Pan T.; Li Y.; Heidari P.; Chen J.; Li Q.; Gong K.","Jang, Se-In (57317669100); Pan, Tinsu (8664173900); Li, Ye (57191870446); Heidari, Pedram (23979745500); Chen, Junyu (57197845594); Li, Quanzheng (7405862484); Gong, Kuang (57146819700)","57317669100; 8664173900; 57191870446; 23979745500; 57197845594; 7405862484; 57146819700","Spach Transformer: Spatial and Channel-Wise Transformer Based on Local and Global Self-Attentions for PET Image Denoising","2024","43","6","","2036","2049","13","10.1109/TMI.2023.3336237","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178025707&doi=10.1109%2fTMI.2023.3336237&partnerID=40&md5=3f8f73e62eaf3f109a82a388201983ab","Position emission tomography (PET) is widely used in clinics and research due to its quantitative merits and high sensitivity, but suffers from low signal-to-noise ratio (SNR). Recently convolutional neural networks (CNNs) have been widely used to improve PET image quality. Though successful and efficient in local feature extraction, CNN cannot capture long-range dependencies well due to its limited receptive field. Global multi-head self-attention (MSA) is a popular approach to capture long-range information. However, the calculation of global MSA for 3D images has high computational costs. In this work, we proposed an efficient spatial and channel-wise encoder-decoder transformer, Spach Transformer, that can leverage spatial and channel information based on local and global MSAs. Experiments based on datasets of different PET tracers, i.e., 18F-FDG, 18F-ACBC, 18F-DCFPyL, and 68Ga-DOTATATE, were conducted to evaluate the proposed framework. Quantitative results show that the proposed Spach Transformer framework outperforms state-of-the-art deep learning architectures.  © 1982-2012 IEEE.","image denoising; local and global self-attention; low-dose PET; Positron emission tomography; spatial and channel-wise transformer","Algorithms; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Neural Networks, Computer; Positron-Emission Tomography; Signal-To-Noise Ratio; Channel coding; Decoding; Deep learning; Image denoising; Image enhancement; Image reconstruction; Medical imaging; Neural networks; Positron emission tomography; Positrons; Signal to noise ratio; fluciclovine f 18; fluorodeoxyglucose f 18; gallium dotatate ga 68; piflufolastat f 18; tracer; Biomedical imaging; Convolutional neural network; Decoding; High sensitivity; Local and global self-attention; Low dose; Low-dose position emission tomography; Position emission tomography; Spatial and channel-wise transformer; Transformer; Article; artificial neural network; contrast to noise ratio; convolutional neural network; deep learning; feature extraction; gated-convolutional feed-forward network; human; image enhancement; image noise; image quality; image reconstruction; intermethod comparison; kernel method; multilayer perceptron; noise reduction; ordered subset expectation maximization; positron emission tomography; quantitative analysis; receptive field; restormer; signal noise ratio; spatial and channel-wise transformer; standardized uptake value; swin transformer; Unet; whole body PET; algorithm; artificial neural network; image processing; procedures; signal noise ratio; three-dimensional imaging; Convolution","","","Institute of Electrical and Electronics Engineers Inc.","37995174"
"Zein H.; Chantaf S.; Fournier R.; Nait-Ali A.","Zein, Hazem (57468294800); Chantaf, Samer (57200914565); Fournier, Régis (8273261200); Nait-Ali, Amine (57698810500)","57468294800; 57200914565; 8273261200; 57698810500","Generative adversarial networks for anonymous acneic face dataset generation","2024","19","4 April","e0297958","","","","10.1371/journal.pone.0297958","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190751109&doi=10.1371%2fjournal.pone.0297958&partnerID=40&md5=bc74eb40dfa97bdac3312226c840dc71","It is well known that the performance of any classification model is effective if the dataset used for the training process and the test process satisfy some specific requirements. In other words, the more the dataset size is large, balanced, and representative, the more one can trust the proposed model’s effectiveness and, consequently, the obtained results. Unfortunately, large-size anonymous datasets are generally not publicly available in biomedical applications, especially those dealing with pathological human face images. This concern makes using deep-learning-based approaches challenging to deploy and difficult to reproduce or verify some published results. In this paper, we propose an efficient method to generate a realistic anonymous synthetic dataset of human faces, focusing on attributes related to acne disorders at three distinct levels of severity (Mild, Moderate, and Severe). Notably, our approach initiates from a small dataset of facial acne images, leveraging generative techniques to augment and diversify the dataset, ensuring comprehensive coverage of acne severity levels while maintaining anonymity and realism in the synthetic data. Therefore, a specific hierarchy StyleGAN-based algorithm trained at distinct levels is considered. Moreover, the utilization of generative adversarial networks for augmentation offers a means to circumvent potential privacy or legal concerns associated with acquiring medical datasets. This is attributed to the synthetic nature of the generated data, where no actual subjects are present, thereby ensuring compliance with privacy regulations and legal considerations. To evaluate the performance of the proposed scheme, we consider a CNN-based classification system, trained using the generated synthetic acneic face images and tested using authentic face images. Consequently, we show that an accuracy of 97.6% is achieved using InceptionResNetv2. As a result, this work allows the scientific community to employ the generated synthetic dataset for any data processing application without restrictions on legal or ethical concerns. Moreover, this approach can also be extended to other applications requiring the generation of synthetic medical images. © 2024 Zein et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Acne Vulgaris; Algorithms; Humans; Privacy; Trust; accuracy; acne; algorithm; anonymous acneic face dataset; Article; artificial neural network; convolutional neural network; data base; data gathering; data pre processing; data processing; deep learning; generative adversarial network; human; image analysis; image enhancement; learning algorithm; limit of detection; machine learning; natural language processing; nerve cell network; privacy; recall; residual neural network; training; acne vulgaris; trust","","","Public Library of Science","38625866"
"Poonia R.C.; Upreti K.; Jafri S.; Parashar J.; Vats P.; Singh J.","Poonia, Ramesh Chandra (56638603100); Upreti, Kamal (57202706345); Jafri, Samreen (57852595500); Parashar, Jyoti (57204113069); Vats, Prashant (56630562900); Singh, Jagendra (56347348900)","56638603100; 57202706345; 57852595500; 57204113069; 56630562900; 56347348900","Biomedical Mammography Image Classification Using Patches-Based Feature Engineering with Deep Learning and Ensemble Classifier","2024","1046 LNNS","","","275","285","10","10.1007/978-3-031-64813-7_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200652501&doi=10.1007%2f978-3-031-64813-7_29&partnerID=40&md5=0ca86de482edf8996bc11e8bb67acd80","In order to reduce the expense of radiologists, deep learning algorithms have recently been used in the mammograms screening field. Deep learning-based methods, like a Convolutional Neural Network (CNN), are now being used to categorize breast lumps. When it involves classifying mammogram imagery, CNN-based systems clearly outperform machine learning-based systems, but they do have certain disadvantages as well. Additional challenges include a dearth of knowledge on feature engineering and the impossibility of feature analysis for the existing patches of pictures, which are challenging to distinguish in low-contrast mammograms. Inaccurate patch assessments, higher calculation costs, inaccurate patch examinations, and non-recovered patched intensity variation are all results of mammogram image patches. This led to evidence that a CNN-based technique for identifying breast masses had poor classification accuracy. Deep Learning-Based Featured Reconstruction is a novel breast mass classification technique that boosts precision on low-contrast pictures (DFN). This system uses random forest boosting techniques together with CNN architectures like VGG 16 and Resnet 50 to characterize breast masses. Using two publicly accessible datasets of mammographic images, the suggested DFN approach is also contrasted with modern classification methods. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Biomedical images; Breast mass classification technique; CNN; Deep learning; Mammography","Classification (of information); Computer aided diagnosis; Convolutional neural networks; Deep learning; Image classification; Learning algorithms; Learning systems; X ray screens; Biomedical images; Breast mass; Breast mass classification technique; Classification technique; Convolutional neural network; Deep learning; Feature engineerings; Low contrast; Mammography images; Mass classifications; Mammography","","Abraham A.; Bajaj A.; Hanne T.; Siarry P.","Springer Science and Business Media Deutschland GmbH",""
"Zhang D.; Li H.; Xie J.","Zhang, Dongxue (58024064600); Li, Huiying (36552872000); Xie, Jingmeng (58024857600)","58024064600; 36552872000; 58024857600","Unsupervised and semi-supervised domain adaptation networks considering both global knowledge and prototype-based local class information for Motor Imagery Classification","2024","179","","106497","","","","10.1016/j.neunet.2024.106497","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197755907&doi=10.1016%2fj.neunet.2024.106497&partnerID=40&md5=b68d95a93bb7728e76e6dd2d10c866bb","The non-stationarity of EEG signals results in variability across sessions, impeding model building and data sharing. In this paper, we propose a domain adaptation method called GPL, which simultaneously considers global knowledge and prototype-based local class information to enhance the classification accuracy of motor imagery signals. Depending on the amount of labeled data available in the target domain, the method is implemented in both unsupervised and semi-supervised versions. Specifically, at the global level, we employ the maximum mean difference (MMD) loss to globally constrain the feature space, achieving comprehensive alignment. In the context of class-level operations, we propose two memory banks designed to accommodate class prototypes in each domain and constrain feature embeddings by applying two prototype-based contrastive losses. The source contrastive loss is used to organize source features spatially based on categories, thereby reconciling inter-class and intra-class relationships, while the interactive contrastive loss is employed to facilitate cross-domain information interaction. Simultaneously, in unsupervised scenarios, to mitigate the adverse effects of excessive pseudo-labels, we introduce an entropy-aware strategy that dynamically evaluates the confidence level of target data and personalized constraints on the participation of interactive contrastive loss. To validate our approach, extensive experiments were conducted on a highly regarded public EEG dataset, namely Dataset IIa of the BCI Competition IV, as well as a large-scale EEG dataset called GigaDB. The experiments yielded average classification accuracies of 86.03% and 84.22% respectively. These results demonstrate that our method is an effective EEG decoding model, conducive to advancing the development of motor imagery brain–computer interfaces. The architecture proposed in this study and the code for data partitioning can be found at https://github.com/zhangdx21/GPL. © 2024 Elsevier Ltd","Brain–computer Interface (BCI); Deep Learning (DL); Domain adaptation (DA); Electroencephalography (EEG); Motor Imagery (MI)","Biomedical signal processing; Brain computer interface; Classification (of information); Deep learning; Electrophysiology; Image enhancement; Large datasets; Brain–computer interface; Deep learning; Domain adaptation; Electroencephalography; Global knowledge; Global prototype; Motor imagery; Semi-supervised; adaptation; algorithm; Article; artificial neural network; classification algorithm; discriminant analysis; entropy; human; imagery; information processing; knowledge; learning algorithm; machine learning; measurement accuracy; motor imagery classification; nerve cell network; prototype based local class information; semi supervised domain adaptation networks; signal noise ratio; support vector machine; time series analysis; visual field; Electroencephalography","Program for Jilin University Science and Technology Innovative Research Team; Jilin Provincial Scientific and Technological Development Program, (20230201089GX); Jilin Provincial Scientific and Technological Development Program","","Elsevier Ltd",""
"Zhao Y.; Zheng Q.; Zhu P.; Zhang X.; Ma W.","Zhao, Yangyang (56510359500); Zheng, Qingchun (36471511400); Zhu, Peihao (54394695800); Zhang, Xu (57203326688); Ma, Wenpeng (53867032100)","56510359500; 36471511400; 54394695800; 57203326688; 53867032100","TUFusion: A Transformer-Based Universal Fusion Algorithm for Multimodal Images","2024","34","3","","1712","1725","13","10.1109/TCSVT.2023.3296745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165239585&doi=10.1109%2fTCSVT.2023.3296745&partnerID=40&md5=a9d0faf67decad818aa5eb5b6c8508a5","Multimodal image fusion is one of the important research directions in the field of multimodal fusion. This technique can realize image and data enhancement by using complementary multimodal images and be widely used in medicine, industry, security and fire protection, automatic driving and consumer electronics. In this work, we propose a transformer-based universal fusion (TUFusion) algorithm, and it has a multidomain fusion capability. The advantage of TUFusion algorithm is the design of hybrid transformer and convolutional neural network (CNN) encoder structure and a new composite attention fusion strategy, which has the ability of global and local information integration. Compared with the classical state-of-The-Art multimodal image fusion methods, the experimental result on multidomain data sets showed that the TUFusion algorithm has certain universality in image fusion. Meanwhile, the TUFusion algorithm we proposed achieves good values on peak signal to noise ratio (PSNR), root mean square error (RMSE) and structural similarity index measure (SSIM). The code of the TUFusion algorithm in this article is available at https://github.com/windrunners/TUFusion.  © 1991-2012 IEEE.","fusion strategy; hybrid structure; image fusion; Multimodal fusion; transformer","Deep learning; Feature extraction; Image enhancement; Image fusion; Infrared imaging; Mean square error; Neural networks; Signal to noise ratio; Transformer protection; Biomedical imaging; Deep learning; Features extraction; Fusion algorithms; Fusion strategies; Heuristics algorithm; Hybrid structure; Multi-modal fusion; Transformer; Heuristic algorithms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Meyer T.; Shultz C.; Dehak N.; Moro-Velazquez L.; Irazoqui P.","Meyer, Trevor (58414987300); Shultz, Camden (58718637400); Dehak, Najim (16202714800); Moro-Velazquez, Laureano (56938696400); Irazoqui, Pedro (12772995300)","58414987300; 58718637400; 16202714800; 56938696400; 12772995300","Time Scale Network: An Efficient Shallow Neural Network For Time Series Data in Biomedical Applications","2024","","","","1","11","10","10.1109/JSTSP.2024.3443659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201617650&doi=10.1109%2fJSTSP.2024.3443659&partnerID=40&md5=a9d614482b247b9161195c350fa7ddc9","Time series data is often composed of information at multiple time scales, particularly in biomedical data. While numerous deep learning strategies exist to capture this information, many make networks larger, require more data, are more demanding to compute, and are difficult to interpret. This limits their usefulness in real-world settings facing even modest computational or data constraints and can further complicate their translation into real-time processing or edge device applicaitons. We present a minimal, computationally efficient Time Scale Network combining the translation and dilation sequence used in discrete wavelet transforms with traditional convolutional neural networks and back-propagation. The network simultaneously learns features at many time scales for sequence classification with significantly reduced parameters and operations. We demonstrate advantages in Atrial Dysfunction detection including: superior accuracy-per-parameter and accuracy-per-operation, fast training and inference speeds, and visualization and interpretation of learned patterns in atrial dysfunction detection on ECG signals. We also demonstrate impressive performance in seizure prediction using EEG signals, where our network isolated a few time scales that could be strategically selected to achieve 90.9&#x0025; accuracy using only 1,133 active parameters and consistently converged on pulsatile waveform shapes. This method does not rest on any constraints or assumptions regarding signal content and could be leveraged in any area of time series analysis dealing with signals containing features at many time scales. IEEE","Accuracy; Biomedical; Computer architecture; Efficiency; Feature extraction; Shallow NN; Signal processing; Signal processing algorithms; Time-frequency analysis; Transforms; Wavelet","Deep neural networks; Discrete wavelet transforms; Image segmentation; Steganography; Time series; Accuracy; Biomedical; Features extraction; Shallow NN; Signal processing algorithms; Signal-processing; Time-frequency Analysis; Time-scales; Time-series data; Wavelet; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Vizcaíno J.P.; Symvoulidis P.; Wang Z.; Jelten J.; Favaro P.; Boyden E.S.; Lasser T.","Vizcaíno, Josué Page (57192061239); Symvoulidis, Panagiotis (55612044100); Wang, Zeguan (57196421027); Jelten, Jonas (57204971095); Favaro, Paolo (57207500120); Boyden, Edward S. (35291447700); Lasser, Tobias (23467408900)","57192061239; 55612044100; 57196421027; 57204971095; 57207500120; 35291447700; 23467408900","Fast light-field 3D microscopy with out-of-distribution detection and adaptation through conditional normalizing flows","2024","15","2","","1219","1232","13","10.1364/BOE.504039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184517464&doi=10.1364%2fBOE.504039&partnerID=40&md5=de3078611159bf7e6452e2681cf98680","Real-time 3D fluorescence microscopy is crucial for the spatiotemporal analysis of live organisms, such as neural activity monitoring. The eXtended field-of-view light field microscope (XLFM), also known as Fourier light field microscope, is a straightforward, single snapshot solution to achieve this. The XLFM acquires spatial-angular information in a single camera exposure. In a subsequent step, a 3D volume can be algorithmically reconstructed, making it exceptionally well-suited for real-time 3D acquisition and potential analysis. Unfortunately, traditional reconstruction methods (like deconvolution) require lengthy processing times (0.0220 Hz), hampering the speed advantages of the XLFM. Neural network architectures can overcome the speed constraints but do not automatically provide a way to certify the realism of their reconstructions, which is essential in the biomedical realm. To address these shortcomings, this work proposes a novel architecture to perform fast 3D reconstructions of live immobilized zebrafish neural activity based on a conditional normalizing flow. It reconstructs volumes at 8 Hz spanning 512x512x96 voxels, and it can be trained in under two hours due to the small dataset requirements (50 image-volume pairs). Furthermore, normalizing flows provides a way to compute the exact likelihood of a sample. This allows us to certify whether the predicted output is in- or ood, and retrain the system when a novel sample is detected. We evaluate the proposed method on a cross-validation approach involving multiple in-distribution samples (genetically identical zebrafish) and various out-of-distribution ones. © 2024 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement.","","Brain; Fluorescence microscopy; Image reconstruction; Network architecture; Neural networks; Repair; 3-D microscopy; 3d fluorescence microscopies; Activity monitoring; Extended field of views; Fast-light; Light fields; Neural activity; Real- time; Spatiotemporal analysis; Zebrafish; Article; artificial neural network; convolutional neural network; cross validation; deconvolution; deep learning; fluorescence microscopy; Fourier analysis; image analysis; image quality; image segmentation; larva; learning algorithm; machine learning; melanophore; nerve cell network; nonhuman; quality control; refraction index; signal noise ratio; spatiotemporal analysis; three dimensional microscopy; visual field; zebra fish; Neurons","National Science Foundation, NSF, (1848029); National Science Foundation, NSF; National Institutes of Health, NIH, (1R01DA045549, 1R01MH123977, R01DA029639, R01MH122971, RF1NS113287); National Institutes of Health, NIH; University of Bern, UB; Deutsche Forschungsgemeinschaft, DFG, (LA 3264/2-1); Deutsche Forschungsgemeinschaft, DFG; Bundesministerium für Gesundheit, BMG, (2520DAT920); Bundesministerium für Gesundheit, BMG","","Optica Publishing Group (formerly OSA)",""
"Wang Z.; Liu Z.; Yu J.; Gao Y.; Liu M.","Wang, Zenan (56695430000); Liu, Zhen (57222562503); Yu, Jianfeng (57694785600); Gao, Yingxin (57212645196); Liu, Ming (58974184300)","56695430000; 57222562503; 57694785600; 57212645196; 58974184300","Multi-scale nested UNet with transformer for colorectal polyp segmentation","2024","25","6","e14351","","","","10.1002/acm2.14351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189627172&doi=10.1002%2facm2.14351&partnerID=40&md5=916f5b4ecff8fea38a278b1c02a9da3f","Background: Polyp detection and localization are essential tasks for colonoscopy. U-shape network based convolutional neural networks have achieved remarkable segmentation performance for biomedical images, but lack of long-range dependencies modeling limits their receptive fields. Purpose: Our goal was to develop and test a novel architecture for polyp segmentation, which takes advantage of learning local information with long-range dependencies modeling. Methods: A novel architecture combining with multi-scale nested UNet structure integrated transformer for polyp segmentation was developed. The proposed network takes advantage of both CNN and transformer to extract distinct feature information. The transformer layer is embedded between the encoder and decoder of a U-shape net to learn explicit global context and long-range semantic information. To address the challenging of variant polyp sizes, a MSFF unit was proposed to fuse features with multiple resolution. Results: Four public datasets and one in-house dataset were used to train and test the model performance. Ablation study was also conducted to verify each component of the model. For dataset Kvasir-SEG and CVC-ClinicDB, the proposed model achieved mean dice score of 0.942 and 0.950 respectively, which were more accurate than the other methods. To show the generalization of different methods, we processed two cross dataset validations, the proposed model achieved the highest mean dice score. The results demonstrate that the proposed network has powerful learning and generalization capability, significantly improving segmentation accuracy and outperforming state-of-the-art methods. Conclusions: The proposed model produced more accurate polyp segmentation than current methods on four different public and one in-house datasets. Its capability of polyps segmentation in different sizes shows the potential clinical application. © 2024 The Authors. Journal of Applied Clinical Medical Physics published by Wiley Periodicals LLC on behalf of American Association of Physicists in Medicine.","colorectal polyp; deep learning; polyp segmentation; transformer","Algorithms; Colonic Polyps; Colonoscopy; Colorectal Neoplasms; Databases, Factual; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Neural Networks, Computer; algorithm; artificial neural network; colon polyp; colonoscopy; colorectal tumor; computer assisted diagnosis; diagnostic imaging; factual database; human; image processing; pathology; procedures","Beijing Municipal Administration of Hospitals, (XXT12); Beijing Municipal Administration of Hospitals","","John Wiley and Sons Ltd","38551396"
"Tanwar P.; Kumar T.; Kalaiselvi K.; Raza H.; Rawat S.","Tanwar, Poonam (57195426794); Kumar, Tapas (58589437300); Kalaiselvi, K. (58566282100); Raza, Haider (57195623793); Rawat, Seema (56521132600)","57195426794; 58589437300; 58566282100; 57195623793; 56521132600","Predictive data modelling for biomedical data and imaging","2024","","","","1","357","356","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196244210&partnerID=40&md5=68eeb5264ca7555e9b1e8b2df1c34c0f","In this book, we embark on a journey into the realm of predictive data modeling for biomedical data and imaging in healthcare. It explores the potential of predictive analytics in the field of medical science through utilizing various tools and techniques to unravel insights and enhance patient care. This volume creates a medium for an interchange of knowledge from expertise and concerns in the field of predictive data modeling. In detail, the research work on this will include the effective use of predictive data modeling algorithms to run image analysis tasks for understanding. Predictive Data Modelling for Biomedical Data and Imaging is divided into three sections, namely Section I - Beginning of Predictive Data Modeling for Biomedical Data and Imaging/Healthcare, Section II - Data Design and Analysis for Biomedical Data and Imaging/Healthcare, and Section III - Case Studies of Predictive Analytics for Biomedical Data and Imaging/Healthcare. We hope this book will inspire further research and innovation in the field of predictive data modeling for biomedical data and imaging in healthcare. By exploring diverse case studies and methodologies, this book contributes to the advancement of healthcare practices, ultimately improving patient outcomes and well-being. © 2024 River Publishers. All rights reserved.","Biomedical data; Computational intelligence; Convolution neural network; Deep learning; Machine learning; Medical image processing; Predictive data modeling","","","","River Publishers",""
"Tan Y.; Shen W.-D.; Wu M.-Y.; Liu G.-N.; Zhao S.-X.; Chen Y.; Yang K.-F.; Li Y.-J.","Tan, Yubo (58594512600); Shen, Wen-Da (58796160100); Wu, Ming-Yuan (58796257900); Liu, Gui-Na (57222735412); Zhao, Shi-Xuan (57215427845); Chen, Yang (54794854700); Yang, Kai-Fu (55376828200); Li, Yong-Jie (35237689100)","58594512600; 58796160100; 58796257900; 57222735412; 57215427845; 54794854700; 55376828200; 35237689100","Retinal Layer Segmentation in OCT Images with Boundary Regression and Feature Polarization","2024","43","2","","686","700","14","10.1109/TMI.2023.3317072","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180704874&doi=10.1109%2fTMI.2023.3317072&partnerID=40&md5=7724dcfb365e36e9a63757daccf33746","The geometry of retinal layers is an important imaging feature for the diagnosis of some ophthalmic diseases. In recent years, retinal layer segmentation methods for optical coherence tomography (OCT) images have emerged one after another, and huge progress has been achieved. However, challenges due to interference factors such as noise, blurring, fundus effusion, and tissue artifacts remain in existing methods, primarily manifesting as intra-layer false positives and inter-layer boundary deviation. To solve these problems, we propose a method called Tightly combined Cross-Convolution and Transformer with Boundary regression and feature Polarization (TCCT-BP). This method uses a hybrid architecture of CNN and lightweight Transformer to improve the perception of retinal layers. In addition, a feature grouping and sampling method and the corresponding polarization loss function are designed to maximize the differentiation of the feature vectors of different retinal layers, and a boundary regression loss function is devised to constrain the retinal boundary distribution for a better fit to the ground truth. Extensive experiments on four benchmark datasets demonstrate that the proposed method achieves state-of-the-art performance in dealing with problems of false positives and boundary distortion. The proposed method ranked first in the OCT Layer Segmentation task of GOALS challenge held by MICCAI 2022. The source code is available at https://www.github.com/tyb311/TCCT. © 1982-2012 IEEE.","boundary regression; feature polarization; OCT; retinal layer segmentation; vision transformer","Algorithms; Fundus Oculi; Image Interpretation, Computer-Assisted; Retina; Tomography, Optical Coherence; Benchmarking; Convolution; Diagnosis; Feature extraction; Medical imaging; Neural networks; Ophthalmology; Optical tomography; Polarization; Regression analysis; Biomedical imaging; Boundary regression; Convolutional neural network; Feature polarization; Features extraction; Images segmentations; Layer segmentation; Optical variable measurement; Retina; Retinal layer segmentation; Retinal layers; Transformer; Vision transformer; Article; B scan; backbone network; clinical article; comparative study; confocal laser scanning microscopy; controlled study; convolutional neural network; deep learning; diabetic macular edema; false positive result; feature extraction; gated recurrent unit network; glaucoma; human; image artifact; image processing; image segmentation; learning; multiclass classification; multiple sclerosis; optical coherence tomography; prediction; residual network with cross convolution; retina image; retina receptive field; retinal layer segmentation method; segmentation algorithm; self supervision learning; spectral domain optical coherence tomography; temperature; tightly combined cross convolution and transformer with boundary regression and feature polarization; algorithm; computer assisted diagnosis; diagnostic imaging; eye fundus; procedures; retina; Image segmentation","Sichuan Province Science and Technology Support Program, (2022ZYD0112); National Natural Science Foundation of China, NSFC, (62076055); University of Electronic Science and Technology of China, UESTC, (ZYGX2022YGRH013)","","Institute of Electrical and Electronics Engineers Inc.","37725718"
"Wang X.; Dang M.; Yang K.; Cui X.; Zhang D.; Chen C.","Wang, Xiaotian (57202369694); Dang, Min (57837346100); Yang, Kunkuo (59202152000); Cui, Xinyu (58572540500); Zhang, Doudou (59203052400); Chen, Chao (57059996400)","57202369694; 57837346100; 59202152000; 58572540500; 59203052400; 57059996400","The ensemble multi-scale convolution neural network for visual target detection EEG-based brain-computer interfaces","2024","96","","106583","","","","10.1016/j.bspc.2024.106583","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197367392&doi=10.1016%2fj.bspc.2024.106583&partnerID=40&md5=b488cda0ace72d56f273128a250c7d64","Human visual target detection based on electroencephalography (EEG) signals has been widely used to categorize target and non-target images, especially visual event-related potentials (ERPs), showing great promise. However, the methods based on deep learning of image-like input EEG signals seriously lose the original brain topographic information of EEG signals. Furthermore, current methods are limited by the extremely unbalanced distribution of target and non-target classes, resulting in insensitivity to feature learning for minority classes. In this paper, we propose a new approach to extract multi-scale spatial–temporal features of EEG signals using stacked multi-scale convolutional neural networks (MS_CNN) with raw spatially distributed EEG signals as input. The proposed novel MS_CNN extracts spatial features based on a two-dimensional (2D) grid distribution of electrode locations on the human scalp by stacking multi-scale 2D convolutions and extracting temporal features by convolutions with different window lengths. In addition, we adopt the fine-tuning ensemble method based on dynamic class weights to address minority target class samples being overwhelmed in the training process. Experimental evaluations on datasets with different class distributions show consistent improvements in performance both cross-session and cross-subject by incorporating the fine-tuning ensemble method into existing deep learning models. The combination of the fine-tuning ensemble architecture and MS_CNN is called the ensemble multi-scale convolution neural network (E_MS_CNN). Extensive experimental results show that the proposed E_MS_CNN method outperforms existing methods in cross-subject and cross-session situations. © 2024 Elsevier Ltd","Convolutional neural network (CNN); Electroencephalography (EEG); Event-related potentials (ERPs); Spatial–temporal features","Biomedical signal processing; Brain computer interface; Convolution; Convolutional neural networks; Deep learning; Electrophysiology; Learning systems; Tuning; Convolution neural network; Convolutional neural network; Electroencephalography; Event related potentials; Event-related potential; Fine tuning; Multi-scales; Spatial-temporal features; Visual targets; adult; Article; brain tissue; classification algorithm; classifier; clinical evaluation; controlled study; convolutional neural network; deep learning; electroencephalography; feature extraction; female; human; image analysis; long short term memory network; male; multi scale convolutional neural network; neuroimaging; reference electrode; scalp; spatiotemporal analysis; support vector machine; three-dimensional imaging; time series analysis; two-dimensional imaging; Electroencephalography","Excellent Young Scientists Fund; Natural Science Foundation, (62176201, 62293483); National Defense Basic Scientific Research Program of China, (JCKY2021413B005); National Defense Basic Scientific Research Program of China; National Key Research and Development Program of China, NKRDPC, (2019YFA0706604, 2022ZD0208500); National Key Research and Development Program of China, NKRDPC; National Natural Science Foundation of China, NSFC, (62302373); National Natural Science Foundation of China, NSFC","","Elsevier Ltd",""
"Arunkumar N.; Nagaraj B.; Ruth Keziah M.","Arunkumar, N. (24330633400); Nagaraj, Balakrishnan (36495195200); Ruth Keziah, M. (59136210600)","24330633400; 36495195200; 59136210600","Optimized wavelet and feature set of EEG signal for Parkinson disease classification","2024","46","4","236145","9271","9290","19","10.3233/JIFS-236145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193752843&doi=10.3233%2fJIFS-236145&partnerID=40&md5=3b477ecb4a71af13e82f551277a41f8d","Parkinson disease (PD) is a type of neurodegenerative disorder that affects the motor movement of the patient. But each technique has its own advantages or disadvantages. In gene, speech and handwriting data model, the feature extraction and reduction is an important step for efficient classification. These two steps require proper attention for selection and also require high processing time as compared to other data model like images. Because in image modality, the deep learning algorithm can be applied that can perform all process and automate the classification. As compared to these domains, the signal produces better and best results. Because the electroencephalogram (EEG) signal are taken from the brain using electrodes and it helps to observe the brain signals effectively and immediately as compared to the other data modals. Hence, in this paper, the wavelet transform will be used to decompose the signals and statistical features will be extracted from the transformed signal. Here, the satin bower bird optimization will be used for both type of wavelet selection and feature reduction process for final classification. The reduced feature set will be classified using Ensemble Neural Network type including InceptionV3, DenseNet, MobileNet, Xception, and NasNet) recently proposed for medical image classification. The whole process will be realized using MATLAB R2021a software and its performance will be evaluated in terms of Accuracy and is compared against Automated Tunable Q-wavelet transform performance. The proposed ensemble method, employing EEG signal processing and neural networks, achieved a 97% success rate in discriminating PD datasets, surpassing Convolutional Neural Network (CNN) and Machine Learning (ML) classifications (88%–92%). Utilizing MATLAB R2021a, its superiority over Q-wavelet transform was evident, signifying improved PD dataset discrimination. © 2024 – IOS Press. All rights reserved.","classifier; EEG signals; features; optimization; Parkinson diseases; wavelet transform","Biomedical signal processing; Classification (of information); Convolutional neural networks; Deep learning; Electroencephalography; Feature extraction; Image classification; Learning algorithms; MATLAB; Medical imaging; Neurodegenerative diseases; Disease classification; Electroencephalogram signals; Feature; Features sets; Motor movements; Neurodegenerative disorders; Optimisations; Parkinson's disease; Performance; Wavelets transform; Wavelet transforms","","","IOS Press BV",""
"Narmatha C.; Manimurugan S.; Karthikeyan P.","Narmatha, C. (56418673200); Manimurugan, S. (38661419700); Karthikeyan, P. (57195048976)","56418673200; 38661419700; 57195048976","A Smart CIoT with Secure Healthcare Framework Using Optimized Deep Recuperator Neural Network Long Short-Term Memory","2024","11","6","","10551","10562","11","10.1109/JIOT.2023.3326547","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176336444&doi=10.1109%2fJIOT.2023.3326547&partnerID=40&md5=2b9b05f537cf8dc78f6c8d28c1d2edb0","The healthcare system currently relies on the facility to store and process large amounts of health data, supported by efficient management. The Internet of Things (IoT) has driven the growth of Adroit Healthcare, which has vast data processing capabilities and extensive data collection. The consumer IoT (CIoT), also known as the IoT in the context of individual use cases, is dominated by personal healthcare applications. The remarkable expansion of the CIoT can be attributed to the extensive embrace of wearable technology, facilitating everyday monitoring of vital health indicators like blood pressure, heart rate, and respiration rate. However, the CIoT raises concerns about data security, confidentiality, and customer trust. This study proposes an integrating blockchain and deep learning (DL) approach to promote responsible use of CIoT. The study develops an Intelligent IoT (IIoT) and healthcare diagnostic model, named BT-PWO-DRNN-LSTM, using blockchain technology and Prairie Wolf optimization-based deep recuperator neural network (DRNN) and long short-term memory (LSTM). The BT-PWO-DRNN-LSTM approach includes three key processes: 1) encrypted transactions; 2) cryptographic hash feature; and 3) medical diagnosis. The PWO technique is used for secure communication of medical images, the neighborhood catalogue disposition (NCD) technique is used in the cryptographic hash feature operation (CHFO), and the DL approach is employed as a classification algorithm for diagnosing disorders. The use of PWO methodology for secure healthcare communication and optimal parameter fine-tuning highlights the originality of the study. The BT-PWO-DRNN-LSTM prototype showed positive results with high sensitivity, specificity, and accuracy during the diagnostic process.  © 2014 IEEE.","Blockchain technology (BCT); consumer IoT (CIoT); cryptographic hash function; deep learning (DL); deep recuperator neural network (DRNN)-long short-term memory (LSTM); Internet of Things (IoT); Prairie Wolf (PW) optimization","Blood pressure; Brain; Diagnosis; Hash functions; Health care; Information management; Internet of things; Long short-term memory; Medical imaging; Network protocols; Network security; Sensitive data; Wearable technology; Biomedical monitoring; Block-chain; Blockchain technology; Consumer internet of thing; Cryptographic hash functions; Deep learning; Deep recuperator neural network-long short-term memory; Medical services; Neural-networks; Optimisations; Prairie wolf optimization; Security; Blockchain","","","Institute of Electrical and Electronics Engineers Inc.",""
"Yi D.; Baltov P.; Hua Y.; Philip S.; Sharma P.K.","Yi, Dewei (57189461703); Baltov, Petar (58608894300); Hua, Yining (57206481017); Philip, Sam (12797452800); Sharma, Pradip Kumar (57191076911)","57189461703; 58608894300; 57206481017; 12797452800; 57191076911","Compound Scaling Encoder-Decoder (CoSED) Network for Diabetic Retinopathy Related Bio-Marker Detection","2024","28","4","","1959","1970","11","10.1109/JBHI.2023.3313785","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171797427&doi=10.1109%2fJBHI.2023.3313785&partnerID=40&md5=e3fc6d0995809233411e3d70f0087e39","Biomedical image segmentation plays an important role in Diabetic Retinopathy (DR)-related biomarker detection. DR is an ocular disease that affects the retina in people with diabetes and could lead to visual impairment if management measures are not taken in a timely manner. In DR screening programs, the presence and severity of DR are identified and classified based on various microvascular lesions detected by qualified ophthalmic screeners. Such a detection process is time-consuming and error-prone, given the small size of the microvascular lesions and the volume of images, especially with the increasing prevalence of diabetes. Automated image processing using deep learning methods is recognized as a promising approach to support diabetic retinopathy screening. In this article, we propose a novel compound scaling encoder-decoder network architecture to improve the accuracy and running efficiency of microvascular lesion segmentation. In the encoder phase, we develop a lightweight encoder to speed up the training process, where the encoder network is scaled up in depth, width, and resolution dimensions. In the decoder phase, an attention mechanism is introduced to yield higher accuracy. Specifically, we employ Concurrent Spatial and Channel Squeeze and Channel Excitation (scSE) blocks to fully utilise both spatial and channel-wise information. Additionally, a compound loss function is incorporated with transfer learning to handle the problem of imbalanced data and further improve performance. To assess performance, our method is evaluated on two large-scale lesion segmentation datasets: DDR and FGADR datasets. Experimental results demonstrate the superiority of our method compared to other competent methods.  © 2013 IEEE.","attention mechanism; compound scaling; Diabetic retinopathy; fundus image; lesion segmentation; retinal screening","Blood vessels; Channel coding; Decoding; Deep learning; Diagnosis; Eye protection; Large dataset; Medical imaging; Network architecture; Ophthalmology; Signal encoding; biological marker; Attention mechanisms; Biomedical imaging; Compound; Compound scaling; Decoding; Diabetic retinopathy; Fundus image; Images segmentations; Lesion; Lesion segmentations; Retina; Retinal screening; Scalings; Article; artificial neural network; compound scaling encoder decoder network; controlled study; deep learning; diabetic retinopathy; event related potential; human; image processing; image segmentation; learning algorithm; machine learning; mathematical model; nerve cell network; network analysis; prevalence; quality control; refraction index; training; transfer of learning; visual impairment; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.","37695962"
"Fermann B.S.; Nyberg J.; Remme E.W.; Grue J.F.; Grue H.; Haland R.; Lovstakken L.; Dalen H.; Grenne B.; Aase S.A.; Snare S.R.; Ostvik A.","Fermann, Benjamin Strandli (58930227400); Nyberg, John (58701067800); Remme, Espen W. (6602218438); Grue, Jahn Frederik (56414583700); Grue, Helen (58930034200); Haland, Roger (58930811200); Lovstakken, Lasse (16307353600); Dalen, Havard (36019157800); Grenne, Bjornar (25947361800); Aase, Svein Arne (10041890700); Snare, Sten Roar (34873653300); Ostvik, Andreas (57200091455)","58930227400; 58701067800; 6602218438; 56414583700; 58930034200; 58930811200; 16307353600; 36019157800; 25947361800; 10041890700; 34873653300; 57200091455","Cardiac Valve Event Timing in Echocardiography Using Deep Learning and Triplane Recordings","2024","28","5","","2759","2768","9","10.1109/JBHI.2024.3373124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187381001&doi=10.1109%2fJBHI.2024.3373124&partnerID=40&md5=66a1d160418bfa15e4ce8f2a387ccd2c","Cardiac valve event timing plays a crucial role when conducting clinical measurements using echocardiography. However, established automated approaches are limited by the need of external electrocardiogram sensors, and manual measurements often rely on timing from different cardiac cycles. Recent methods have applied deep learning to cardiac timing, but they have mainly been restricted to only detecting two key time points, namely end-diastole (ED) and end-systole (ES). In this work, we propose a deep learning approach that leverages triplane recordings to enhance detection of valve events in echocardiography. Our method demonstrates improved performance detecting six different events, including valve events conventionally associated with ED and ES. Of all events, we achieve an average absolute frame difference (aFD) of maximum 1.4 frames (29 ms) for start of diastasis, down to 0.6 frames (12 ms) for mitral valve opening when performing a ten-fold cross-validation with test splits on triplane data from 240 patients. On an external independent test consisting of apical long-axis data from 180 other patients, the worst performing event detection had an aFD of 1.8 (30 ms). The proposed approach has the potential to significantly impact clinical practice by enabling more accurate, rapid and comprehensive event detection, leading to improved clinical measurements.  © 2013 IEEE.","Cardiac valve event detection; deep learning; echocardiography","Deep Learning; Echocardiography; Heart Valves; Humans; Image Interpretation, Computer-Assisted; Male; Deep learning; Feature extraction; Heart; Timing circuits; Biomedical measurements; Cardiac valve event detection; Cardiac valves; Deep learning; Event timing; Events detection; Features extraction; Recording; Timing; aortic valve; aortic valve stenosis; Article; classification algorithm; clinical practice; computer language; convolutional neural network; cross validation; deep learning; echocardiography; feature extraction; heart valve; human; machine learning; mitral valve; relaxation time; short term memory; speckle tracking echocardiography; computer assisted diagnosis; diagnostic imaging; heart valve; male; physiology; procedures; Echocardiography","","","Institute of Electrical and Electronics Engineers Inc.","38442058"
"Charan K.S.; Krishna O.V.; Sai P.V.; Ilavarasi A.K.","Charan, Kurupati Sai (57219971744); Krishna, Omtri Vijaya (59242876700); Sai, Palla Venkata (59244120800); Ilavarasi, A.K. (57195529643)","57219971744; 59242876700; 59244120800; 57195529643","Transfer Learning Based Multi-Class Lung Disease Prediction Using Textural Features Derived From Fusion Data","2024","12","","","108248","108262","14","10.1109/ACCESS.2024.3435680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200268676&doi=10.1109%2fACCESS.2024.3435680&partnerID=40&md5=fb5ee68755a71d9a57f268bdf24a6379","Lung diseases pose significant challenges to public health worldwide, requiring accurate and efficient diagnostic methods for timely intervention. This research introduces a novel approach that uses deep learning algorithms on chest X-ray images generated from the fusion of individual datasets pertaining to Tuberculosis (TB), COVID-19, and Pneumonia to classify various lung illnesses. Employing the cutting-edge deep learning architectures such as MobileNetV2, Visual Geometry Group 16 (VGG16), InceptionNet, ResNet50, and EfficientNet, the usefulness of textural features derived using Local Binary Patterns (LBP) for improving classification performance is investigated. The EfficientNet and ResNet design achieves remarkable accuracy of 96.3% and 97.1% respectively on the fusion dataset. It is tested rigorously utilizing compound scaling to scale up the network in depth, width, and resolution simultaneously. This has resulted in better feature extraction and image representation. Additionally, methods for enhancing model performance are covered, such as feature engineering, data augmentation, and hyperparameter tuning. The findings demonstrate the potential of textural features-based deep learning techniques to effectively diagnose multiple lung diseases with subtle difference in original features from chest X-ray images. This research has a positive synergy in the clinical decision-making process and health care outcomes. © 2013 IEEE.","Chest X-ray images; COVID-19; EfficientNet; InceptionNet; local binary patterns (LBP); MobileNetV2; pneumonia; ResNet50; tuberculosis (TB); VGG16","Biological organs; Classification (of information); Clinical research; Decision making; Deep learning; Diagnosis; Local binary pattern; Medical imaging; Neural networks; X ray analysis; Biomedical imaging; Chest X-ray image; Convolutional neural network; Covid-19; Deep learning; Efficientnet; Inceptionnet; Local binary pattern; Local binary patterns; Lung; Mobilenetv2; Pneumonia; Resnet50; Tuberculosis; Visual geometry group 16; X-ray imaging; COVID-19","","","Institute of Electrical and Electronics Engineers Inc.",""
"Zhang Y.; Lang S.; Cao X.; Zheng H.; Gong Y.","Zhang, Yanwei (57192284157); Lang, Song (57194637833); Cao, Xuan (57781063000); Zheng, Hanqing (57808469600); Gong, Yan (36108133700)","57192284157; 57194637833; 57781063000; 57808469600; 36108133700","Deep neural network based on multi-level wavelet and attention for structured illumination microscopy","2024","17","2","2350015","","","","10.1142/S1793545823500153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165493409&doi=10.1142%2fS1793545823500153&partnerID=40&md5=3ca346f9bc6b35865c1b5b66ad490f07","Structured illumination microscopy (SIM) is a popular and powerful super-resolution (SR) technique in biomedical research. However, the conventional reconstruction algorithm for SIM heavily relies on the accurate prior knowledge of illumination patterns and signal-to-noise ratio (SNR) of raw images. To obtain high-quality SR images, several raw images need to be captured under high fluorescence level, which further restricts SIM's temporal resolution and its applications. Deep learning (DL) is a data-driven technology that has been used to expand the limits of optical microscopy. In this study, we propose a deep neural network based on multi-level wavelet and attention mechanism (MWAM) for SIM. Our results show that the MWAM network can extract high-frequency information contained in SIM raw images and accurately integrate it into the output image, resulting in superior SR images compared to those generated using wide-field images as input data. We also demonstrate that the number of SIM raw images can be reduced to three, with one image in each illumination orientation, to achieve the optimal tradeoff between temporal and spatial resolution. Furthermore, our MWAM network exhibits superior reconstruction ability on low-SNR images compared to conventional SIM algorithms. We have also analyzed the adaptability of this network on other biological samples and successfully applied the pretrained model to other SIM systems.  © 2024 The Author(s).","multi-level wavelet packet transform; residual channel attention; selective kernel attention; Super-resolution reconstruction","Deep neural networks; Image reconstruction; Optical resolving power; Packet networks; Wavelet analysis; Attention mechanisms; Multi-level wavelet packet transform; Multilevels; Raw images; Residual channel attention; Selective kernel attention; Structured illumination; Super-resolution reconstruction; Superresolution; Wavelet packet transforms; algorithm; article; attention; deep learning; deep neural network; microscopy; signal noise ratio; structured illumination microscopy; Signal to noise ratio","","","World Scientific",""
"Ramarao G.; Bindu C.H.; Murthy T.S.N.","Ramarao, Gude (57202221163); Bindu, Chinni. Hima (57202309691); Murthy, T.S.N. (58707909800)","57202221163; 57202309691; 58707909800","Convolutional laplacian gaussian pyramid approach multimodal medical image fusion","2024","","","","","","","10.1007/s11042-024-19832-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200377199&doi=10.1007%2fs11042-024-19832-2&partnerID=40&md5=c3155c1852270b68e2ccda4d4210e40b","The importance of accurate clinical diagnosis has garnered that for scholars within a particular field of medical imaging, leading to a focus on image fusion as a potential application. As a result, manyimage fusion algorithms have been devised and extensively employed within the biomedical domain. Over the past few decades, a notable increase in interest or research activity has emerged surrounding the application of multimodal image fusion within medical technology. Nevertheless, most current algorithms exhibit diminished brightness, indistinct edges, and ambiguous details. A Multimodal Medical image fusion using the Convolutional Laplacian Gaussian pyramid approach (CLGPA) is proposed to deal with such limitations. It utilizes the Laplacian pyramid reconstruction technique in conjunction with the Gaussian pyramid. The initial step involves preprocessing multimodal medical images using a local Laplacian filter, which effectively enhances the quality of edges. Initially, the mapping process for multimodal medical imagesinvolvesapplying a neural network using augmentation. The Laplacian pyramid is utilized to reconstruct multimodal images using a Gaussian filter to get a fused image. The suggested model is evaluated in comparison to established algorithms, including Guided and Image Statistics,Non-Subsampled Shearlet Transform (NSST) with a Partially Averaged Pooling Convolutional Neural Network (PAPCNN) and Cross Bilateral Filer (CBF). The codesutilized in our study, as well as the extraction and fusion techniques employed for contrast and structure analysis, have yielded improved visual quality performance as measured by several fusion metrics. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","Convolutional pyramid model; Deep learning; Gaussian Filter; Laplacian Filter; Laplacian pyramid; Multi-Model image fusion","Bioinformatics; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Gaussian distribution; Image enhancement; Image fusion; Image reconstruction; Laplace transforms; Medical imaging; Convolutional pyramid model; Deep learning; Gaussian filters; Gaussian pyramids; Laplacian filters; Laplacian Pyramid; Model images; Multi-model image fusion; Multi-modelling; Pyramid models; Quality control","","","Springer",""
"Samprovalaki M.; Chatzipapadopoulou A.; Moschovis G.; Charalampakos F.; Kaliosis P.; Pavlopoulos J.; Androutsopoulos I.","Samprovalaki, Marina (59281954400); Chatzipapadopoulou, Anna (59281432800); Moschovis, Georgios (57866890500); Charalampakos, Foivos (57232257500); Kaliosis, Panagiotis (58665010800); Pavlopoulos, John (25654146700); Androutsopoulos, Ion (6506068227)","59281954400; 59281432800; 57866890500; 57232257500; 58665010800; 25654146700; 6506068227","AUEB NLP Group at ImageCLEFmedical Caption 2024","2024","3740","","","1729","1745","16","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201578472&partnerID=40&md5=6aa8863378db2fa81e7c8a00d481a064","This article describes the approaches that the AUEB NLP Group experimented with during its participation in the 8th edition of the ImageCLEFmedical Caption evaluation campaign, including both Concept Detection and Caption Prediction tasks. The objective of Concept Detection is to automatically categorize biomedical images into a set of one or more concepts. In contrast, the Caption Prediction task focuses on generating a precise and meaningful diagnostic caption that describes the medical conditions depicted in the image. Building on our prior research for the Concept Detection task, we utilized a diverse set of Convolutional Neural Network (CNN) encoders, followed by a Feed-Forward Neural Network. Additionally, we implemented two versions of the retrieval-based k-NN algorithm: a version that assigned concepts based on statistical frequency and a weighted version that took into account the order of the retrieved neighbors. Both models used the CNN image encoders to improve their retrieval capabilities. Regarding the Caption Prediction task, we fine-tuned the InstructBLIP model to generate initial captions and then enhanced it by employing rephrasing techniques with further pre-trained models. We also used synthesizing techniques that incorporated information from similar neighboring images in the training set to refine these captions. Additionally, we employed “Distance from Median Maximum Concept Similarity” (DMMCS), a novel guided-decoding approach that drives the model's behaviour throughout the decoding process, aiming to integrate information from the predicted concepts of Concept Detection. We explored the application of DMMCS to all of our developed systems. Our group ranked 2nd in Concept Detection and 4th in Caption Prediction. © 2024 Copyright for this paper by its authors.","Biomedical Images; Caption Generation; Computer Vision; Convolutional Neural Networks; Deep Learning; Generative Models; Multi-Label Classification; Natural Language Processing; Transformers","Deep neural networks; Feedforward neural networks; Generative adversarial networks; Image coding; Image enhancement; Network coding; Biomedical images; Caption generation; Convolutional neural network; Deep learning; Generative model; Language processing; Multi-label classifications; Natural language processing; Natural languages; Transformer; Convolutional neural networks","","Faggioli G.; Ferro N.; Galuscakova P.; de Herrera A.G.S.","CEUR-WS",""
"Zheng H.; Hu X.","Zheng, Huiru (8982328500); Hu, Xiaohua (57730482300)","8982328500; 57730482300","Computational intelligence in bioinformatics and biomedicine","2024","227","","","58","59","1","10.1016/j.ymeth.2024.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193064120&doi=10.1016%2fj.ymeth.2024.05.006&partnerID=40&md5=39e15743e076135c1fda45fb2ff81b7f","[No abstract available]","","Artificial Intelligence; Biomedical Research; Computational Biology; Humans; algorithm; Alzheimer disease; artificial intelligence; artificial neural network; BayesImpute; bioinformatics; biomedicine; cell infiltration; cell subpopulation; computational intelligence; convolutional neural network; correlation analysis; data processing; deconvolution algorithm; deep learning; differential gene expression; distributed multi-objective evolutionary framework; DNA methylation; drug design; drug repositioning; drug target interaction; Editorial; electronic health record; evolutionary algorithm; gene expression; genetic variation; genomics; graph convolutional network; heterogeneous information network; hexagonal convolutional neural network; high throughput sequencing; human; image segmentation; liver cell carcinoma; machine learning; natural killer cell; photoelectric plethysmography; preference matrix guided sparse canonical correlation analysis; pulse rate; pulse rate variability; quality control; quantitative trait; RabbitQCPlus; random feature augmentation; representation group disentangling network; RNA transcription; single cell RNA seq; single nucleotide polymorphism; transcriptomics; tumor microenvironment; medical research; procedures","","","Academic Press Inc.","38729457"
"Liu C.; He K.; Xu D.; Shi H.; Zhang H.; Zhao K.","Liu, Chenou (58956259800); He, Kangjian (57093043000); Xu, Dan (35622853100); Shi, Hongzhen (55960699900); Zhang, Hao (57191246164); Zhao, Kunyuan (57214803402)","58956259800; 57093043000; 35622853100; 55960699900; 57191246164; 57214803402","RegFSC-Net: Medical Image Registration via Fourier Transform with Spatial Reorganization and Channel Refinement Network","2024","28","6","","3489","3500","11","10.1109/JBHI.2024.3376334","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188689641&doi=10.1109%2fJBHI.2024.3376334&partnerID=40&md5=9300700f2e4b8a4dfbc1ab166c1bc7ca","Medical image registration is crucial in medical image analysis applications. Recently, U-Net-style networks have been commonly used for unsupervised image registration, predicting dense displacement fields in full-resolution space. However, this process is resource-intensive and time-consuming for high-resolution volumetric image data. To address this challenge, this paper proposes a novel model named RegFSC-Net, which utilizes Fourier transform with spatial reorganization (SR) and channel refinement (CR) network for registration. We embed efficient feature extraction modules SR and CR modules into the encoder, and adopt a parameter-free model to drive the decoder to improve the U-shaped network. Precisely, RegFSC-Net does not directly predict the full-resolution displacement field in space but learns the low-dimensional representation of the displacement field in the bandlimited Fourier domain, which is beneficial in reducing network parameters, memory usage, and computational costs. Experimental results show that RegFSC-Net outperforms various state-of-the-art methods. Specifically, in comparison to the widely recognized Transformer-based method TransMorph, RegFSC-Net utilizes only around 8.2% of its parameters, resulting in a 1.95% higher Dice score and significantly faster inference speeds of 126.67% and 419.99% on GPU and CPU, respectively. Furthermore, we also designed three variants of RegFSC-Net and demonstrated their potential applications in computer-aided diagnosis.  © 2013 IEEE.","Brain MRI; deformable image registration; medical image registration; unsupervised registration","Algorithms; Brain; Fourier Analysis; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Computer aided diagnosis; Digital storage; Extraction; Feature extraction; Fourier transforms; Image registration; Magnetic resonance imaging; Medical imaging; Biomedical imaging; Brain MRI; Computational modelling; Deformable image registration; Features extraction; Images registration; Medical image registration; Spatial channels; Spatial reorganization; Unsupervised registration; Article; channel refinement network; cross correlation; data visualization; deep learning; efficiency optimized encoder; feature extraction; Fourier transform; image registration; machine learning; mathematical analysis; network analysis; nuclear magnetic resonance imaging; spatial reorganization network; algorithm; artificial neural network; brain; computer assisted diagnosis; diagnostic imaging; Fourier analysis; human; image processing; procedures; Iterative methods","","","Institute of Electrical and Electronics Engineers Inc.","38483805"
"Chai Z.; Luo L.; Lin H.; Heng P.-A.; Chen H.","Chai, Zhizhong (57220125298); Luo, Luyang (57194519819); Lin, Huangjing (57195683445); Heng, Pheng-Ann (7006677755); Chen, Hao (56493367600)","57220125298; 57194519819; 57195683445; 7006677755; 56493367600","Deep Omni-Supervised Learning for Rib Fracture Detection From Chest Radiology Images","2024","43","5","","1972","1982","10","10.1109/TMI.2024.3353248","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182952418&doi=10.1109%2fTMI.2024.3353248&partnerID=40&md5=77280bac7c2c45d402b7db52aa8f4579","Deep learning (DL)-based rib fracture detection has shown promise of playing an important role in preventing mortality and improving patient outcome. Normally, developing DL-based object detection models requires a huge amount of bounding box annotation. However, annotating medical data is time-consuming and expertise-demanding, making obtaining a large amount of fine-grained annotations extremely infeasible. This poses a pressing need for developing label-efficient detection models to alleviate radiologists' labeling burden. To tackle this challenge, the literature on object detection has witnessed an increase of weakly-supervised and semi-supervised approaches, yet still lacks a unified framework that leverages various forms of fully-labeled, weakly-labeled, and unlabeled data. In this paper, we present a novel omni-supervised object detection network, ORF-Netv2, to leverage as much available supervision as possible. Specifically, a multi-branch omni-supervised detection head is introduced with each branch trained with a specific type of supervision. A co-training-based dynamic label assignment strategy is then proposed to enable flexible and robust learning from the weakly-labeled and unlabeled data. Extensive evaluation was conducted for the proposed framework with three rib fracture datasets on both chest CT and X-ray. By leveraging all forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the three datasets, respectively, surpassing the baseline detector which uses only box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively. Furthermore, ORF-Netv2 consistently outperforms other competitive label-efficient methods over various scenarios, showing a promising framework for label-efficient fracture detection. The code is available at: https://github.com/zhizhongchai/ORF-Net.  © 1982-2012 IEEE.","dynamic label assignment; object detection; omni-supervised learning; Rib fracture","Algorithms; Deep Learning; Humans; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Rib Fractures; Supervised Machine Learning; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Fracture; Image enhancement; Medical imaging; Object recognition; Supervised learning; Annotation; Biomedical imaging; Computed tomography; Dynamic label assignment; Lesion; Objects detection; Omni-supervised learning; Rib; Rib fractures; ambiguity; Article; cancer diagnosis; comparative study; controlled study; deep learning; false positive result; human; learning algorithm; mammography; prediction; radiologist; residual neural network; rib fracture; supervised machine learning; teaching assistant; thorax radiography; algorithm; computer assisted diagnosis; diagnostic imaging; procedures; rib fracture; x-ray computed tomography; Object detection","","","Institute of Electrical and Electronics Engineers Inc.","38215335"
"Abdulwahhab A.H.; Abdulaal A.H.; Thary Al-Ghrairi A.H.; Mohammed A.A.; Valizadeh M.","Abdulwahhab, Ali H. (57222306050); Abdulaal, Alaa Hussein (57638507000); Thary Al-Ghrairi, Assad H. (57210392346); Mohammed, Ali Abdulwahhab (36465387800); Valizadeh, Morteza (35108228000)","57222306050; 57638507000; 57210392346; 36465387800; 35108228000","Detection of epileptic seizure using EEG signals analysis based on deep learning techniques","2024","181","","114700","","","","10.1016/j.chaos.2024.114700","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187239300&doi=10.1016%2fj.chaos.2024.114700&partnerID=40&md5=7ad4eb08baa6076783a3e9fb26365b4e","The brain neurons' electrical activities represented by Electroencephalogram (EEG) signals are the most common data for diagnosing Epilepsy seizure, which is considered a chronic nervous disorder that cannot be controlled medically using surgical operation or medications with more than 40 % of Epilepsy seizure case. With the progress and development of artificial intelligence and deep learning techniques, it becomes possible to detect these seizures over the observation of the non-stationary-dynamic EEG signals, which contain important information about the mental state of patients. This paper provides a concerted deep machine learning model consisting of two simultaneous techniques detecting the activity of epileptic seizures using EEG signals. The time-frequency image of EEG waves and EEG raw waves are used as input components for the convolution neural network (CNN) and recurrent neural network (RNN) with long- and short-term memory (LSTM). Two processing signal methods have been used, Short-Time Fourier Transform (STFT) and Continuous Wavelet Transformation (CWT), have been used for generating spectrogram and scalogram images with sizes of 77 × 75 and 32 × 32, respectively. The experimental results showed a detection accuracy of 99.57 %, 99.57 % using CWT Scalograms, and 99.26 %, 97.12 % using STFT spectrograms as CNN input for the Bonn University dataset and the CHB-MIT dataset, respectively. Thus, the proposed models provide the ability to detect epileptic seizures with high success compared to previous studies. © 2024 Elsevier Ltd","Convolutional neural network; Deep learning; EEG; Electroencephalogram; Epileptic seizure; Recurrent neural network","Biomedical signal processing; Brain; Convolution; Convolutional neural networks; Learning algorithms; Learning systems; Long short-term memory; Neurodegenerative diseases; Neurophysiology; Spectrographs; Surgery; Wavelet transforms; Continuous wavelet transformation; Convolution neural network; Convolutional neural network; Deep learning; Electroencephalogram signals; Epileptic seizures; Learning techniques; Short time Fourier transforms; Signals analysis; Spectrograms; Electroencephalography","","","Elsevier Ltd",""
"Xiong J.; Meng X.-L.; Chen Z.-Q.; Wang C.-S.; Zhang F.-Q.; Grau A.; Chen Y.; Huang J.-W.","Xiong, Jun (58903788100); Meng, Xiang-Long (58703622000); Chen, Zhao-Qi (58185612400); Wang, Chuan-Sheng (57203900374); Zhang, Fu-Quan (57196006398); Grau, Antoni (35760811100); Chen, Yang (58703622100); Huang, Jing-Wei (58703622200)","58903788100; 58703622000; 58185612400; 57203900374; 57196006398; 35760811100; 58703622100; 58703622200","One-Dimensional EEG Artifact Removal Network Based on Convolutional Neural Networks","2024","9","1","","142","159","17","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185847863&partnerID=40&md5=ac350a237179f16c99265a7d2b2ee271","The electroencephalogram (EEG) serves as a significant tool in the realms of clinical medicine, cerebral investigation, and neurological disorders research. However, the EEG records we obtain are often easily contaminated by various artifacts, which can blur or distort the underlying EEG signals and make data interpretation difficult. Generally speaking, removing EEG artifacts is considered an essential step in brain signal analysis. Therefore, removing artifacts is crucial for obtaining accurate and reliable EEG signals for subsequent analysis. Recently, deep learning techniques have found widespread application across various domains for denoising tasks, including image denoising and EEG denoising. Many advanced algorithms have been developed in image denoising, which has achieved good results in enhancing low-quality images. Moreover, it has shown superior performance in EEG denoising. In contrast, few people have devoted themselves to studying EEG denoising, and existing convolutional neural network EEG denoising methods still have problems of overfitting and poor denoising effect in Electromyograph(EMG) and ElectroOculoGram(EOG) artifact removal. Therefore, this paper proposes a method called DWINet (De-artifacting with Image-based Network for EEG Signals) based on an image dehazing network DRHNet for removing artifacts from EEG signals. Specifically, our approach DWINet, addresses the de-artifacting issue in EEG signals by converting it as an image dehazing problem and utilizes the image dehazing capability of DRHNet to enhance the denoising performance of EEG signals. Experimental results demonstrate that the proposed method outperforms the compared algorithms in removing the ocular artifact in EEG signals and exhibits higher accuracy and robustness. © 2024, J. Network Intell. All rights reserved.","CNN; deep learning; Electroencephalogram (EEG) artifact removal; end-to-end","Biomedical signal processing; Clinical research; Convolution; Convolutional neural networks; Deep learning; Electroencephalography; Image denoising; Learning systems; Convolutional neural network; De-noising; Deep learning; Dehazing; Electroencephalogram artifact removals; Electroencephalogram signals; End to end; Network-based; One-dimensional; Performance; Image enhancement","Fujian Guotong Information Technology Co., Ltd., (36); Fujian Polytechnic Normal University, (G3-KF2204); Guiding Project of Fujian Province, (2020H0046); Key Laboratory of Sichuan Province; Key Technology Research and Industrialization Project for Software Industry Innovation in Fujian Province; Min-jiang University, (202101071001); Sichuan Conservatory of Music, (21DMAKL01); Ministry of Education of the People's Republic of China, MOE; Ministerio de Economía y Competitividad, MINECO, (PID2019-106702RB-C21 / AEI / 10.13039/501100011033); Minjiang University, MJU, (MJUKF-FTICIMIS2022, MYK21011)","","Taiwan Ubiquitous Information CO LTD",""
"Hou Y.; Jia S.; Lun X.; Hao Z.; Shi Y.; Li Y.; Zeng R.; Lv J.","Hou, Yimin (14831207400); Jia, Shuyue (57214765091); Lun, Xiangmin (14831612600); Hao, Ziqian (57711235600); Shi, Yan (57190755116); Li, Yang (57202365586); Zeng, Rui (56601099800); Lv, Jinglei (58131694200)","14831207400; 57214765091; 14831612600; 57711235600; 57190755116; 57202365586; 56601099800; 58131694200","GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding Time-Resolved EEG Motor Imagery Signals","2024","35","6","","7312","7323","11","10.1109/TNNLS.2022.3202569","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139403745&doi=10.1109%2fTNNLS.2022.3202569&partnerID=40&md5=38831ea505573f4f831a6fac9a5d5777","Toward the development of effective and efficient brain-computer interface (BCI) systems, precise decoding of brain activity measured by an electroencephalogram (EEG) is highly demanded. Traditional works classify EEG signals without considering the topological relationship among electrodes. However, neuroscience research has increasingly emphasized network patterns of brain dynamics. Thus, the Euclidean structure of electrodes might not adequately reflect the interaction between signals. To fill the gap, a novel deep learning (DL) framework based on the graph convolutional neural networks (GCNs) is presented to enhance the decoding performance of raw EEG signals during different types of motor imagery (MI) tasks while cooperating with the functional topological relationship of electrodes. Based on the absolute Pearson's matrix of overall signals, the graph Laplacian of EEG electrodes is built up. The GCNs-Net constructed by graph convolutional layers learns the generalized features. The followed pooling layers reduce dimensionality, and the fully-connected (FC) softmax layer derives the final prediction. The introduced approach has been shown to converge for both personalized and groupwise predictions. It has achieved the highest averaged accuracy, 93.06% and 88.57% (PhysioNet dataset), 96.24% and 80.89% (high gamma dataset), at the subject and group level, respectively, compared with existing studies, which suggests adaptability and robustness to individual variability. Moreover, the performance is stably reproducible among repetitive experiments for cross-validation. The excellent performance of our method has shown that it is an important step toward better BCI approaches. To conclude, the GCNs-Net filters EEG signals based on the functional topological relationship, which manages to decode relevant features for brain MI. A DL library for EEG task classification including the code for this study is open source at https://github.com/SuperBruceJia/ EEG-DL for scientific research. © 2012 IEEE.","Brain-computer interface (BCI); deep learning (DL); electroencephalography; graph convolutional neural networks; motor imagery (MI)","Adult; Algorithms; Brain; Brain-Computer Interfaces; Deep Learning; Electroencephalography; Humans; Imagination; Neural Networks, Computer; Signal Processing, Computer-Assisted; Biomedical signal processing; Brain; Brain computer interface; Brain mapping; Convolutional neural networks; Decoding; Deep neural networks; Electrodes; Electroencephalography; Electrophysiology; Image enhancement; Laplace transforms; Topology; Brain–computer interface; Convolutional neural network; Decoding; Deep learning; Electroencephalogram signals; Graph convolutional neural network; Motor imagery; Task analysis; adult; algorithm; artificial neural network; brain; brain computer interface; deep learning; electroencephalography; human; imagination; physiology; procedures; signal processing; Convolution","","","Institute of Electrical and Electronics Engineers Inc.","36099220"
"Hasan M.E.; Wagler A.","Hasan, Md Easin (57223897299); Wagler, Amy (37062272800)","57223897299; 37062272800","A novel deep learning graph attention network for Alzheimer's disease image segmentation","2024","5","","100310","","","","10.1016/j.health.2024.100310","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185316951&doi=10.1016%2fj.health.2024.100310&partnerID=40&md5=ac69f48e82dc50e1e87a9324d385860f","Neuronal cell segmentation identifies and separates individual neurons in an image, typically to study their properties or analyze their organization in the nervous system. This is significant because neurological problems and diseases can only be treated effectively when the structure and function of neurons are understood. The proposed method is based on convolutional neural networks (CNNs) and graph attention networks (GATs) for segmenting biomedical images. A contracting path built upon a couple of convolution layers and max pooling is included in the architecture to capture context. After that, the GATs are applied to the captured context. In GATs, each node in the graph is associated with a vector of hidden features, and the model calculates attention coefficients between pairs of nodes. These attention coefficients are learned during training and can be used to weigh the contribution of each node's features to the representation of the graph. An expanding path that utilizes the outputs generated by GATs paves the way for exact segmentation. The dataset comprises 606 microscopic images, mainly categorized into different cell types (astrocytes, cortex, and SHSY5Y). By implementing our proposed U-GAT algorithm, we obtained the highest accuracy of 86.5% and an F1 score of 0.719 compared to the CNN, U-Net, SegResNet, SegNet VGG16, and GAT benchmarking algorithms. This proposed method could help researchers in the biotech industry develop novel drugs since a more accurate deep-learning method is essential for segmenting complex images like neuronal images. © 2024 The Authors","Convolutional neural networks; Deep learning; Graph attention networks; Image segmentation; Neuronal cells; U-Net","accuracy; Alzheimer disease; Article; attention network; benchmarking; cells by body anatomy; convolutional neural network; deep learning; human; image segmentation; imaging algorithm; nerve cell; process development; research gap","","","Elsevier Inc.",""
"Wang H.; He J.; Cui H.; Yuan B.; Xia Y.","Wang, Hongyu (57215109146); He, Jiang (58669362600); Cui, Hengfei (56571910700); Yuan, Bo (58669227300); Xia, Yong (26427407400)","57215109146; 58669362600; 56571910700; 58669227300; 26427407400","Robust Stochastic Neural Ensemble Learning With Noisy Labels for Thoracic Disease Classification","2024","43","6","","2180","2190","10","10.1109/TMI.2024.3357986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184005828&doi=10.1109%2fTMI.2024.3357986&partnerID=40&md5=10a31db27856bf7826be150d31efc407","Chest radiography is the most common radiology examination for thoracic disease diagnosis, such as pneumonia. A tremendous number of chest X-rays prompt data-driven deep learning models in constructing computer-aided diagnosis systems for thoracic diseases. However, in realistic radiology practice, a deep learning-based model often suffers from performance degradation when trained on data with noisy labels possibly caused by different types of annotation biases. To this end, we present a novel stochastic neural ensemble learning (SNEL) framework for robust thoracic disease diagnosis using chest X-rays. The core idea of our method is to learn from noisy labels by constructing model ensembles and designing noise-robust loss functions. Specifically, we propose a fast neural ensemble method that collects parameters simultaneously across model instances and along optimization trajectories. Moreover, we propose a loss function that both optimizes a robust measure and characterizes a diversity measure of ensembles. We evaluated our proposed SNEL method on three publicly available hospital-scale chest X-ray datasets. The experimental results indicate that our method outperforms competing methods and demonstrate the effectiveness and robustness of our method in learning from noisy labels. Our code is available at https://github.com/hywang01/SNEL.  © 1982-2012 IEEE.","chest X-ray; deep learning; image classification; label noise; Thoracic diseases","Algorithms; Databases, Factual; Deep Learning; Humans; Neural Networks, Computer; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Stochastic Processes; Thoracic Diseases; Computer aided diagnosis; Computer aided instruction; Deep learning; Image classification; Medical imaging; Radiology; Stochastic systems; X ray radiography; Biomedical imaging; Chest X-ray; Deep learning; Ensemble learning; Images classification; Label noise; Noise measurements; Optimisations; Thoracic disease; X-ray imaging; Article; deep learning; disease classification; human; major clinical study; neural ensemble learning; noise; stochastic model; thorax disease; thorax radiography; algorithm; artificial neural network; computer assisted diagnosis; diagnostic imaging; factual database; procedures; stochastic model; thorax disease; thorax radiography; Random processes","","","Institute of Electrical and Electronics Engineers Inc.","38265913"
"Lalawat R.S.; Bajaj V.","Lalawat, Rajveer Singh (58928623800); Bajaj, Varun (57209289122)","58928623800; 57209289122","An Automatic Framework for Detecting Autism Spectrum Disorder From EEG Signals Using TFD","2024","24","7","","10632","10639","7","10.1109/JSEN.2024.3362341","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187268194&doi=10.1109%2fJSEN.2024.3362341&partnerID=40&md5=a61bed59931392cba67682562fcbaca0","Autism spectrum disorder (ASD) is an intricate neurodevelopmental disorder with many neurological problems. Social interaction and communication issues, repetitive behaviors, and limited interests are its main symptoms. Manual ASD diagnosis testing is prone to human error, time-consuming, and difficult owing to contamination from a number of factors. Electroencephalogram (EEG) signals are extensively utilized to identify ASD as they represent brain abnormalities. This study employed a novel method that included pre-processing, segmentation, and time-frequency distribution (TFD) of various algorithms such as short-time Fourier transformation (STFT), continuous wavelet transformation (CWT), and smoothed pseudo-Wigner-Ville distribution (SPWVD), which produced corresponding spectrograms, scalograms, and SPWVD-TFD. These TFDs are introduced into the DenseNet-121 and ResNet-101 pre-trained (ImageNet dataset) models, and then subsequently fed into the proposed ASD-Net. Deep learning networks (DLMs) models were utilized to identify ASD and Normal subject using these TFD images. We acquired a 97.35% mean accuracy utilizing the SPWVD-based TFD and ASD-Net model. When compared to the benchmark DenseNet-121 and ResNet-101, the developed convolution neural network (CNN) model with five convolution layers (CLs) not only needs less learnable parameters but is also computationally efficient and quick.  © 2023 IEEE.","Autism spectrum disorder (ASD); convolution neural network (CNN); electroencephalogram (EEG); smoothed pseudo-Wigner-Ville distribution (SPWVD); time-frequency distribution (TFD)","Bandpass filters; Biomedical signal processing; Convolution; Deep learning; Digital storage; Diseases; Electroencephalography; Electrophysiology; Fourier transforms; IIR filters; Wavelet transforms; Autism spectrum disorder; Autism spectrum disorders; Brain modeling; Continuous Wavelet Transform; Convolution neural network; Images segmentations; Smoothed pseudo Wigner Ville distribution; Smoothed pseudo Wigner-Ville distributions; Time-frequency Analysis; Time-frequency distribution; Time-frequency distributions; Variable-speed drives; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Yin C.; Zheng Y.; Ding X.; Shi Y.; Qin J.; Guo X.","Yin, Chongbo (57758780500); Zheng, Yineng (56449700700); Ding, Xiaorong (56145146600); Shi, Yan (57190755116); Qin, Jian (56861604700); Guo, Xingming (7404330466)","57758780500; 56449700700; 56145146600; 57190755116; 56861604700; 7404330466","Detection of Coronary Artery Disease Based on Clinical Phonocardiogram and Multiscale Attention Convolutional Compression Network","2024","28","3","","1353","1362","9","10.1109/JBHI.2024.3354832","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182935131&doi=10.1109%2fJBHI.2024.3354832&partnerID=40&md5=ee749e200775b08e767b53ba08f5e90c","Heart sound is an important physiological signal that contains rich pathological information related with coronary stenosis. Thus, some machine learning methods are developed to detect coronary artery disease (CAD) based on phonocardiogram (PCG). However, current methods lack sufficient clinical dataset and fail to achieve efficient feature utilization. Besides, the methods require complex processing steps including empirical feature extraction and classifier design. To achieve efficient CAD detection, we propose the multiscale attention convolutional compression network (MACCN) based on clinical PCG dataset. Firstly, PCG dataset including 102 CAD subjects and 82 non-CAD subjects was established. Then, a multiscale convolution structure was developed to catch comprehensive heart sound features and a channel attention module was developed to enhance key features in multiscale attention convolutional block (MACB). Finally, a separate downsampling block was proposed to reduce feature losses. MACCN combining the blocks can automatically extract features without empirical and manual feature selection. It obtains good classification results with accuracy 93.43%, sensitivity 93.44%, precision 93.48%, and F1 score 93.42%. The study implies that MACCN performs effective PCG feature mining aiming for CAD detection. Further, it integrates feature extraction and classification and provides a simplified PCG processing case.  © 2013 IEEE.","attention module; convolution attention neural network; coronary artery disease; Heart sounds","Coronary Artery Disease; Data Compression; Heart Sounds; Humans; Machine Learning; Biomedical signal processing; Cardiology; Classification (of information); Computer aided diagnosis; Convolution; Data mining; Diseases; Extraction; Feature extraction; Learning systems; Phonocardiography; Artery; Attention module; Convolution attention neural network; Coronary artery disease; Disease detection; Features extraction; Heart sounds; Neural-networks; Phonocardiograms; Solid modelling; ablation therapy; aged; Article; artificial neural network; classification algorithm; controlled study; convolutional neural network; coronary angiography; coronary artery disease; data processing; deep learning; diagnostic accuracy; diagnostic test accuracy study; disease classification; feature extraction; feature selection; female; global average pooling; global maximum pooling; heart sound; hidden Markov model; human; image processing; image segmentation; machine learning; major clinical study; male; mathematical analysis; multiscale attention convolutional block; multiscale attention convolutional compression network; phonocardiography; receptive field; recurrent neural network; sensitivity and specificity; spectral density; transfer of learning; coronary artery disease; data compression; diagnostic imaging; heart sound; Heart","","","Institute of Electrical and Electronics Engineers Inc.","38227404"
"Shin M.; Seo M.; Lee K.; Yoon K.","Shin, Minwoo (57222380433); Seo, Minjee (58778680400); Lee, Kyunghyun (58945415900); Yoon, Kyungho (57208559577)","57222380433; 58778680400; 58945415900; 57208559577","Super-resolution techniques for biomedical applications and challenges","2024","14","3","","465","496","31","10.1007/s13534-024-00365-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188073218&doi=10.1007%2fs13534-024-00365-4&partnerID=40&md5=306ec4d8fff655a7829bfe31c2deec94","Super-resolution (SR) techniques have revolutionized the field of biomedical applications by detailing the structures at resolutions beyond the limits of imaging or measuring tools. These techniques have been applied in various biomedical applications, including microscopy, magnetic resonance imaging (MRI), computed tomography (CT), X-ray, electroencephalogram (EEG), ultrasound, etc. SR methods are categorized into two main types: traditional non-learning-based methods and modern learning-based approaches. In both applications, SR methodologies have been effectively utilized on biomedical images, enhancing the visualization of complex biological structures. Additionally, these methods have been employed on biomedical data, leading to improvements in computational precision and efficiency for biomedical simulations. The use of SR techniques has resulted in more detailed and accurate analyses in diagnostics and research, essential for early disease detection and treatment planning. However, challenges such as computational demands, data interpretation complexities, and the lack of unified high-quality data persist. The article emphasizes these issues, underscoring the need for ongoing development in SR technologies to further improve biomedical research and patient care outcomes. © Korean Society of Medical and Biological Engineering 2024.","Biomedical imaging; Biomedical simulation; CT; Deep learning; ECG; EEG; Elastography; Microscopy; MRI; MRS; PET; Spectrometry; Spectroscopy; Super-resolution; Thermography; Ultrasound; X-ray","Bioinformatics; Computational efficiency; Computerized tomography; Deep learning; Electroencephalography; Image enhancement; Medical applications; Medical imaging; Optical resolving power; Ultrasonic applications; bisoprolol fumarate; tracer; Biomedical applications; Biomedical imaging; Biomedical simulation; Computed tomography; Deep learning; Elastography; MRS; Resolution techniques; Superresolution; Thermography; artificial neural network; biomedical application; breast cancer; computer assisted tomography; convolutional neural network; deep learning; deep neural network; diagnostic procedure; elastography; electrocardiogram; electroencephalography; electromagnetic radiation; electromyography; electrophysiology; feature extraction; histology; human; image analysis; image processing; image quality; image reconstruction; image segmentation; learning algorithm; machine learning; mass spectrometry; medical technology; microbubble; microscopy; molecular imaging; morphology; myography; neuroimaging; neurologic disease; nuclear magnetic resonance imaging; nuclear magnetic resonance spectroscopy; particle image velocimetry; positron emission tomography; proteomics; Review; scanning electron microscopy; signal noise ratio; signal processing; single molecule force spectroscopy; stimulated emission depletion microscopy; structured illumination microscopy; super-resolution technique; thermography; three-dimensional imaging; transmission electron microscopy; ultrasound; viscoelasticity; X ray; Magnetic resonance imaging","National Research Foundation of Korea, NRF; Ministry of Science, ICT and Future Planning, MSIP, (RS-2023-00220762); Ministry of Science, ICT and Future Planning, MSIP; Yonsei University Research Fund, (2023-12-0018)","","Springer Verlag",""
"Rahman Siddiquee M.M.; Shah J.; Wu T.; Chong C.; Schwedt T.J.; Dumkrieger G.; Nikolova S.; Li B.","Rahman Siddiquee, Md Mahfuzur (57215777586); Shah, Jay (57451223400); Wu, Teresa (12239783200); Chong, Catherine (56229356300); Schwedt, Todd J. (8722272900); Dumkrieger, Gina (56811570300); Nikolova, Simona (59040001500); Li, Baoxin (7410080679)","57215777586; 57451223400; 12239783200; 56229356300; 8722272900; 56811570300; 59040001500; 7410080679","Brainomaly: Unsupervised Neurologic Disease Detection Utilizing Unannotated T1-weighted Brain MR Images","2024","","","","7558","7567","9","10.1109/WACV57701.2024.00740","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191993628&doi=10.1109%2fWACV57701.2024.00740&partnerID=40&md5=6ce6ab5ff69b86f80d91a7f9944ac427","Harnessing the power of deep neural networks in the medical imaging domain is challenging due to the difficulties in acquiring large annotated datasets, especially for rare diseases, which involve high costs, time, and effort for annotation. Unsupervised disease detection methods, such as anomaly detection, can significantly reduce human effort in these scenarios. While anomaly detection typically focuses on learning from images of healthy subjects only, real-world situations often present unannotated datasets with a mixture of healthy and diseased subjects. Recent studies have demonstrated that utilizing such unannotated images can improve unsupervised disease and anomaly detection. However, these methods do not utilize knowledge specific to registered neuroimages, resulting in a subpar performance in neurologic disease detection. To address this limitation, we propose Brainomaly, a GAN-based image-to-image translation method specifically designed for neurologic disease detection. Brainomaly not only offers tailored image-to-image translation suitable for neuroimages but also leverages unannotated mixed images to achieve superior neurologic disease detection. Additionally, we address the issue of model selection for inference without annotated samples by proposing a pseudo-AUC metric, further enhancing Brainomaly's detection performance. Extensive experiments and ablation studies demonstrate that Brainomaly outperforms existing state-of-the-art unsupervised disease and anomaly detection methods by significant margins in Alzheimer's disease detection using a publicly available dataset and headache detection using an institutional dataset. The code is available from https://github.com/mahfuzmohammad/Brainomaly. © 2024 IEEE.","3D; Algorithms; Algorithms; Applications; Biomedical / healthcare / medicine; etc.; Generative models for image; Image recognition and understanding; video","Anomaly detection; Bioinformatics; Deep neural networks; Image enhancement; Large datasets; Magnetic resonance imaging; Medical imaging; Neurodegenerative diseases; 3d; Anomaly detection; Biomedical / healthcare / medicine; Disease detection; Etc.; Generative model; Generative model for image; Image translation; T1-weighted; Video; Image recognition","Arizona State University, ASU; U.S. Department of Defense, DOD, (W81XWH1910534, W81XWH-15-1-0286); U.S. Department of Defense, DOD; National Institutes of Health, NIH, (K23NS070891); National Institutes of Health, NIH; National Institute of Neurological Disorders and Stroke, NINDS, (1R61NS113315-01, 20187183); National Institute of Neurological Disorders and Stroke, NINDS","","Institute of Electrical and Electronics Engineers Inc.",""
"Ren J.; Li J.; Liu C.; Chen S.; Liang L.; Liu Y.","Ren, Jiahao (57221646280); Li, Jian (56414388700); Liu, Chang (57205426891); Chen, Shili (7410249901); Liang, Lin (35734453200); Liu, Yang (57881803100)","57221646280; 56414388700; 57205426891; 7410249901; 35734453200; 57881803100","Deep Learning With Physics-Embedded Neural Network for Full Waveform Ultrasonic Brain Imaging","2024","43","6","","2332","2346","14","10.1109/TMI.2024.3363144","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187304310&doi=10.1109%2fTMI.2024.3363144&partnerID=40&md5=3d5bf309ec6d8197e00391edf84621a4","The convenience, safety, and affordability of ultrasound imaging make it a vital non-invasive diagnostic technique for examining soft tissues. However, significant differences in acoustic impedance between the skull and soft tissues hinder the successful application of traditional ultrasound for brain imaging. In this study, we propose a physics-embedded neural network with deep learning based full waveform inversion (PEN-FWI), which can achieve reliable quantitative imaging of brain tissues. The network consists of two fundamental components: forward convolutional neural network (FCNN) and inversion sub-neural network (ISNN). The FCNN explores the nonlinear mapping relationship between the brain model and the wavefield, replacing the tedious wavefield calculation process based on the finite difference method. The ISNN implements the mapping from the wavefield to the model. PEN-FWI includes three iterative steps, each embedding the F CNN into the ISNN, ultimately achieving tomography from wavefield to brain models. Simulation and laboratory tests indicate that PEN-FWI can produce high-quality imaging of the skull and soft tissues, even starting from a homogeneous water model. PEN-FWI can achieve excellent imaging of clot models with constant uniform distribution of velocity, randomly Gaussian distribution of velocity, and irregularly shaped randomly distributed velocity. Robust differentiation can also be achieved for brain slices of various tissues and skulls, resulting in high-quality imaging. The imaging time for a horizontal cross-sectional imag e of the brain is only 1.13 seconds. This algorithm can effectively promote ultrasound-based brain tomography and provide feasible solutions in other fields. © 1982-2012 IEEE.","brain imaging; deep learning; full waveform inversion; Ultrasound tomography","Algorithms; Animals; Brain; Deep Learning; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Phantoms, Imaging; Ultrasonography; Acoustic impedance; Brain mapping; Deep learning; Finite difference method; Image reconstruction; Iterative methods; Mapping; Neural networks; Noninvasive medical procedures; Three dimensional computer graphics; Three dimensional displays; Tissue; Tomography; Waveform analysis; signal peptide; water; Biomedical imaging; Brain imaging; Brain modeling; Convolutional neural network; Deep learning; Full-waveform inversion; Soft tissue; Three-dimensional display; Ultrasound tomography; Wavefields; Article; controlled study; convolutional neural network; deep learning; electroencephalogram; Fourier transform; human; inversion subneural network; mean squared error; neuroimaging; physical parameters; physics; skull; soft tissue; tomography; ultrasound; algorithm; animal; artificial neural network; brain; diagnostic imaging; echography; image processing; imaging phantom; procedures; Ultrasonic imaging","","","Institute of Electrical and Electronics Engineers Inc.","38329866"
"Sengupta S.; Anastasio M.A.","Sengupta, Sourya (57212026321); Anastasio, Mark A. (7006769220)","57212026321; 7006769220","A Test Statistic Estimation-Based Approach for Establishing Self-Interpretable CNN-Based Binary Classifiers","2024","43","5","","1753","1765","12","10.1109/TMI.2023.3348699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181567530&doi=10.1109%2fTMI.2023.3348699&partnerID=40&md5=9890cd3f99a3baabe632f5f69d4294f2","Interpretability is highly desired for deep neural network-based classifiers, especially when addressing high-stake decisions in medical imaging. Commonly used post-hoc interpretability methods have the limitation that they can produce plausible but different interpretations of a given model, leading to ambiguity about which one to choose. To address this problem, a novel decision-theory-inspired approach is investigated to establish a self-interpretable model, given a pre-trained deep binary black-box medical image classifier. This approach involves utilizing a self-interpretable encoder-decoder model in conjunction with a single-layer fully connected network with unity weights. The model is trained to estimate the test statistic of the given trained black-box deep binary classifier to maintain a similar accuracy. The decoder output image, referred to as an equivalency map, is an image that represents a transformed version of the to-be-classified image that, when processed by the fixed fully connected layer, produces the same test statistic value as the original classifier. The equivalency map provides a visualization of the transformed image features that directly contribute to the test statistic value and, moreover, permits quantification of their relative contributions. Unlike the traditional post-hoc interpretability methods, the proposed method is self-interpretable, quantitative. Detailed quantitative and qualitative analyses have been performed with three different medical image binary classification tasks.  © 1982-2012 IEEE.","classification; Decision theory; deep learning; interpretability; medical imaging","Algorithms; Deep Learning; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Neural Networks, Computer; Computation theory; Decision theory; Decoding; Deep neural networks; Image classification; Job analysis; Medical imaging; Network layers; Statistical tests; Statistics; Binary classifiers; Biomedical imaging; Closed box; Computational modelling; Decoding; Deep learning; Interpretability; Retina; Task analysis; Test statistics; Article; binary classification; breast tumor; cardiomegaly; classifier; controlled study; convolutional neural network; decision theory; deep learning; diagnostic accuracy; diagnostic imaging; diagnostic test accuracy study; digital mammography; drusen; human; optical coherence tomography; post hoc analysis; qualitative analysis; quantitative analysis; receiver operating characteristic; thorax radiography; tumor diagnosis; algorithm; artificial neural network; computer assisted diagnosis; image processing; procedures; Classification (of information)","","","Institute of Electrical and Electronics Engineers Inc.","38163307"
"Krikid F.; Karfoul A.; Chaibi S.; Kachenoura A.; Nica A.; Kachouri A.; Le Bouquin Jeannès R.","Krikid, Fatma (57219441383); Karfoul, Ahmad (24479661600); Chaibi, Sahbi (55078270800); Kachenoura, Amar (23110937500); Nica, Anca (56943180100); Kachouri, Abdennaceur (56017242900); Le Bouquin Jeannès, Régine (6602829468)","57219441383; 24479661600; 55078270800; 23110937500; 56943180100; 56017242900; 6602829468","Multi-classification of high-frequency oscillations in intracranial EEG signals based on CNN and data augmentation","2024","18","2","","1099","1109","10","10.1007/s11760-023-02808-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174921207&doi=10.1007%2fs11760-023-02808-4&partnerID=40&md5=a1190698e8cac9c4017c9e075fa6d76d","Interictal high-frequency oscillations (HFOs) recorded in intracranial electroencephalographic (iEEG) signals are reliable biomarkers for the epileptogenic zone. Visual identification of these particular events is manually time-consuming and is subject to clinicians’ expertise. Moreover, differentiating them from other transient events such as interictal epileptic spikes (IESs) presents a considerable challenge. Hence, various approaches have been developed with the aim of extracting automatically discriminant features for HFOs and IESs events. Typically, these approaches are based on machine learning (ML) algorithms, but their efficiency strongly depends on the computed features. To address this limitation, we explore deep learning (DL), as a powerful framework, for the classification of HFOs and IESs and propose a novel convolutional neural network (CNN) architecture for HFOs multi-classification. Time–frequency (TF)-based images, computed using the Stockwell transform of the events of interest, are used as inputs to the CNN-based approach. Furthermore, data augmentation (DA) is adopted to improve the generalization of the proposed CNN model. The numerical simulations on epileptic iEEG signals demonstrate that the proposed approach yields superior results when the DA is employed. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2023.","Convolutional neural network; Data augmentation; Epilepsy; High-frequency oscillations; Time–frequency representation","Biomedical signal processing; Convolution; Deep learning; Electroencephalography; Convolutional neural network; Data augmentation; EEG signals; Electroencephalographic signals; Epilepsy; Epileptic spikes; High frequency oscillations; Intracranial EEG; Multi-classification; Time-frequency representations; Convolutional neural networks","CMCU, (19G1411); Providence Health Care, PHC, (41711PK)","","Springer Science and Business Media Deutschland GmbH",""
"Pujahari R.M.; Khan R.; Yadav S.P.","Pujahari, Rakesh Mohan (36244323100); Khan, Rijwan (57146279500); Yadav, Satya Praksh (59135661700)","36244323100; 57146279500; 59135661700","Applications of AI and deep learning in biomedicine and healthcare","2024","","","","93","124","31","10.4018/979-8-3693-2426-4.ch006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193676607&doi=10.4018%2f979-8-3693-2426-4.ch006&partnerID=40&md5=aeb0d44e825348f6a5fe872281647b43","The rapid development in the field of medicine and healthcare in the recent years initiated as a large volumes of data are gathered. Taking this advancement, there is a requirement of the process and system needs both technological and analysis methods are to be used to deal with these data. The data which are gathered is health data which are accumulated electronically on the basis of patients' readings, texts, speeches or images as per convenience. The study of models that computer systems use to self-learn instructions based on the weight of parameters without being given explicit instructions is clearly one way to achieve artificial intelligence (AI). Over the past ten years, there has been a noticeable increase in the optimisation of machine learning algorithms and tools in tandem with advances in biomedicine. One of the more intriguing tools of these algorithms that is becoming increasingly important is deep learning. It's an artificial neural network that uses computer design to create multi-layered models that learn several degrees of abstraction from data representations. Deep learning is receiving a lot of attention these days since a lot of research indicates that it may be superior to earlier algorithms that relied just on machine learning and that its results have greater predictive performance. Deep learning has special and broad applications in health informatics and biomedicine, given its many levels of representation and outcomes that outperform human accuracy. In particular, these fall under the umbrella of molecular diagnostics, which includes the interpretation of experimental data involving gene splicing and DNA sequencing, protein structure prediction and classification, biomedical imaging, pharmacogenomics and pathogenic variant identification, drug discovery, and more. This chapter's only goal is to showcase these applications and go into further detail about how they are helping to advance healthcare and medicine in the contemporary world. Deep learning algorithms have enhanced capabilities for identifying patterns and obtaining features from intricate datasets. This chapter will first introduce deep learning and the latest advancements in artificial neural networks. It will then go over its applications in the healthcare industry and, lastly, how they are being used in biomedical informatics and computational biology-related public health research. Furthermore, the applicability of deep learning algorithms would be emphasised from the standpoint of contemporary healthcare. © 2024, IGI Global. All rights reserved.","","","","","IGI Global",""
"Lu K.; Guo H.; Gu Z.; Qi F.; Kuang S.; Sun L.","Lu, Keyi (58089458000); Guo, Hao (56939541300); Gu, Zhihao (58089247700); Qi, Fei (58083332200); Kuang, Shaolong (35746328800); Sun, Lining (57204292698)","58089458000; 56939541300; 58089247700; 58083332200; 35746328800; 57204292698","A parallel-hierarchical neural network (PHNN) for motor imagery EEG signal classification","2024","88","","105621","","","","10.1016/j.bspc.2023.105621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174695811&doi=10.1016%2fj.bspc.2023.105621&partnerID=40&md5=803d7c4e03a757cf1814a7d6ff380472","Motor imagery brain-computer interfaces (MI-BCIs) play a crucial role in fields such as robot control and stroke rehabilitation. With the flourishing development of deep learning, there has been a continuous emergence of motor imagery deep learning models with higher decoding accuracy. Activation of specific brain regions, such as the motor regions in the frontal and parietal lobes, carries information about motor imagery. However, most studies only extract features from the entire brain region, neglecting the potential features of specific brain regions. This may lead to poorer decoding performance. Therefore, this article proposes a parallel-hierarchical neural network (PHNN), which implements a hierarchical approach to feature learning from brain region level to multi-level fusion. Learning at the brain region level mainly explores the key information of specific brain regions (region-level) and the overall features of the entire brain (global-level), to obtain region-level features (RLF) and global-level features (GLF). Furthermore, given that region-level features contain crucial information within specific brain regions, multi-level fusion is employed to capture and fully utilize the differences and connections between the RLF and GLF, resulting in more discriminative multi-level fusion features (MLFF). We evaluate the model performance on the publicly available BCI Competition IV-2a dataset and High Gamma dataset, achieving recognition accuracies of 84.67% and 94.02%, respectively. © 2023 Elsevier Ltd","Brain-computer interface; Deep learning; Electroencephalography; Motor imagery","Biomedical signal processing; Brain; Decoding; Deep learning; Electroencephalography; Electrophysiology; Image classification; Learning systems; Brain regions; Deep learning; EEG signals classification; Hierarchical neural networks; In-field; Motor imagery; Motor imagery EEG; Multi level fusion; Robots control; Stroke rehabilitation; Article; artificial neural network; attention; brain region; classification algorithm; comparative study; controlled study; data accuracy; deep learning; dimensionality reduction; electroencephalogram; electroencephalography; entropy; false negative result; false positive result; feature extraction; frontal lobe; human; human experiment; imagery; motor imagery; natural language processing; normal human; occipital lobe; parallel hierarchical neural network; parietal lobe; recurrent neural network; short term memory; temporal lobe; Brain computer interface","National Natural Science Foundation of China, NSFC, (11402156, 61503269); National Natural Science Foundation of China, NSFC; Special Project for Research and Development in Key areas of Guangdong Province, (2020B010165004); Special Project for Research and Development in Key areas of Guangdong Province","","Elsevier Ltd",""
"Manoharan T.; Velvizhi R.; Juluru T.K.; Kamal S.; Mallick S.; Puliyanjalil E.","Manoharan, Thiyagarajan (58995607200); Velvizhi, Ramalingam (57210977000); Juluru, Tarun Kumar (57218311197); Kamal, Shoaib (57188986928); Mallick, Shrabani (56366477500); Puliyanjalil, Ezudheen (58892168300)","58995607200; 57210977000; 57218311197; 57188986928; 56366477500; 58892168300","Biomedical image classification using seagull optimization with deep learning for colon and lung cancer diagnosis","2024","35","3","","1670","1679","9","10.11591/ijeecs.v35.i3.pp1670-1679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197930832&doi=10.11591%2fijeecs.v35.i3.pp1670-1679&partnerID=40&md5=e3c3c8ff19fafe4934af0c4c72184408","Traditional health care relies on biomedical image categorization to identify and treat various medical conditions. In machine learning and medical imaging, biomedical image classification for colon and lung cancer diagnosis is significant. The work focuses on building novel models and algorithms to accurately detect and categorize tumorous lesions using computer tomography (CT) scans and histopathology slides. These systems use image processing, deep learning (DL), and convolutional neural networks (CNN) to assist medical professionals diagnose cancer sooner and improve patient outcomes. Biomedical image classification using seagull optimization with deep learning (BIC-SGODL) addresses colon and lung cancer diagnosis. The BIC-SGODL method improves cancer diagnosis using hyperparameter optimized DL model. BIC-SGODL utilizes DenseNet to learn complicated features. The convolutional long short-term memory (CLSTM) standard captures spatiotemporal information in sequential picture data. Finally, the SGO method adjusts hyperparameters to improve model performance and generalization. BIC-SGODL performs well with biomedical image dataset simulations. Thus, medical picture cancer diagnosis may be automated using BIC-SGODL. © 2024 Institute of Advanced Engineering and Science. All rights reserved.","Deep learning; Magnetic resonance imaging; Medical imaging; Seagull optimization algorithm; X-ray","","","","Institute of Advanced Engineering and Science",""
"Ali T.; Pathan S.; Salvi M.; Meiburger K.M.; Molinari F.; Acharya U.R.","Ali, Tanweer (55279399000); Pathan, Sameena (57194779855); Salvi, Massimo (57191596088); Meiburger, Kristen M. (37029783100); Molinari, Filippo (7004289592); Acharya, U. Rajendra (7004510847)","55279399000; 57194779855; 57191596088; 37029783100; 7004289592; 7004510847","CAROTIDNet: A Novel Carotid Symptomatic/Asymptomatic Plaque Detection System Using CNN-Based Tangent Optimization Algorithm in B-Mode Ultrasound Images","2024","12","","10536882","73970","73979","9","10.1109/ACCESS.2024.3404023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194055912&doi=10.1109%2fACCESS.2024.3404023&partnerID=40&md5=727093be9477b47ca1baf6921a2fb336","Deep learning methods have shown promise for automated medical image analysis tasks. However, class imbalance is a common challenge that can negatively impact model performance, especially for tasks with minority classes that are clinically significant. This study aims to address this challenge through a novel hyperparameter optimization technique for training convolutional neural networks on imbalanced data. We developed a custom Convolutional Neural Network (CNN) architecture and introduced a Tangent Optimization Algorithm (TOA) based on the trigonometric properties of the tangent function. The TOA optimizes hyperparameters during training without requiring data preprocessing or augmentation steps. We applied our approach to classifying B-mode ultrasound carotid artery plaque images as symptomatic or asymptomatic using a dataset with significant class imbalance. On k-fold cross-validation, our method achieved an average accuracy of 98.82%, a sensitivity of 99.41%, and a specificity of 95.74%. The proposed optimization technique provides a computationally efficient and interpretable solution for training deep learning models on unbalanced medical image datasets.  © 2023 IEEE.","carotid artery imaging; deep learning; Plaque classification; tangent optimization algorithm; ultrasound imaging","Bioinformatics; Classification (of information); Convolution; Deep neural networks; Learning algorithms; Medical imaging; Optimization; Atherosclerose; Biomedical imaging; Carotid artery; Carotid artery imaging; Classification algorithm; Convolutional neural network; Deep learning; Optimisations; Optimization algorithms; Plaque classification; Sensitivity; Tangent optimization algorithm; Ultrasound imaging; Ultrasonic imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","14449 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177829395&partnerID=40&md5=2c68efa2f1a85a474ed80ce2170e721e","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","1965 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178596621&partnerID=40&md5=19f437f49d9e65ba67b8d9c5dfb5867d","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","1967 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180334873&partnerID=40&md5=16d85a38e9dcfbace5d1b62acb39bd6e","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"Tant R.; Mihaly V.","Tant, Rares (59198988700); Mihaly, Vlad (57209975371)","59198988700; 57209975371","Letter Identification in EEG Signals Using Scalograms","2024","","","","","","","10.1109/AQTR61889.2024.10554172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197272428&doi=10.1109%2fAQTR61889.2024.10554172&partnerID=40&md5=e7f01d73ad2c22782e9d761ec5540d8d","Considering the improvements in Brain-Computer interface (BCI) systems and their cost reduction, a new chance for a normal life appeared for people with a wide range of disabilities. With the rise of artificial neural networks (ANN), traditional machine learning (ML) techniques heavily decreased in popularity. These methods are usually a good alternative and, also, an easier-to-understand way to get into data science in plenty of domains. Considering the use of scalograms as training material, the current paper proposes the utilization of classical ML algorithms, such as Random Forest (RF), Support Vector Machine (SVM), Linear Discriminant Analysis (LDA) and k-Nearest Neighbors (KNN). The images are obtained by transforming the electroencephalogram (EEG) signals using continuous wavelet transform (CWT) in order to show their strengths in terms of learning. To illustrate the advantages of the proposed approach, a comparison of the obtained results with those obtained from training on EEG signals directly has been performed. Moreover, another comparison has been made between the results obtained with a neural network-based solution applied to both representations of the training data. © 2024 IEEE.","Brain-computer interface; Continuous wavelet transform; Deep neural networks; Electroencephalogram; Machine learning; P300 Speller","Biomedical signal processing; Brain computer interface; Cost reduction; Discriminant analysis; Electroencephalography; Learning systems; Nearest neighbor search; Support vector machines; Wavelet transforms; 'current; Continuous Wavelet Transform; Costs reduction; Electroencephalogram signals; Interface system; Machine learning algorithms; Machine learning techniques; Machine-learning; P300 spelle; Training material; Deep neural networks","","Enyedi S.; Miclea L.","Institute of Electrical and Electronics Engineers Inc.",""
"Qian H.","Qian, Hao (59185698900)","59185698900","Motion Process Electrocardiogram Detection Algorithm under Self Supervised Deep Learning","2024","","","","","","","10.1109/ICDCECE60827.2024.10548191","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196768782&doi=10.1109%2fICDCECE60827.2024.10548191&partnerID=40&md5=7f1909a2e9c926b4e24c28e348aec1e4","Electrocardiogram is a non-invasive detection technology that detects, predicts, and monitors cardiovascular diseases by reflecting the relationship between the electrical activity of the heart system and time. It does not cause any harm to patients and has a simple detection method and reliable diagnostic results. It plays an important role in the analysis and diagnosis of cardiovascular diseases. The electrocardiogram can automatically record the biological signals generated by myocardial contraction during the activity of the heart system, which is also known as the electrocardiogram signal. This article explores the motion process electrocardiogram detection algorithm based on convolutional neural networks algorithm based on the above issues. It has been experimentally proven that the detection rate of electrocardiogram detection during motion based on CNN algorithm is higher than 87%, with an average detection rate of 93.46%. The false alarm rate of electrocardiogram detection is less than 1%, with an average false alarm rate of 0.54%.  © 2024 IEEE.","CNN algorithm; ECG detection algorithm; process of movement; self supervised deep learning","Biomedical signal processing; Cardiology; Convolutional neural networks; Deep learning; Diseases; Errors; Image resolution; Learning algorithms; Signal detection; Cardiovascular disease; CNN algorithm; Detection algorithm; Detection rates; Detection technology; ECG detection algorithm; False alarm rate; Non-invasive detection; Process of movement; Self supervised deep learning; Electrocardiograms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Mahendran R.K.; Aishwarya R.; Abinayapriya R.; Kumar P.","Mahendran, Rakesh Kumar (58151259500); Aishwarya, R. (57211290628); Abinayapriya, R. (59008113400); Kumar, P. (58265901700)","58151259500; 57211290628; 59008113400; 58265901700","Deep Transfer Learning Based Diagnosis of Multiple Neurodegenerative Disorders","2024","","","","","","","10.1109/ESCI59607.2024.10497320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191699816&doi=10.1109%2fESCI59607.2024.10497320&partnerID=40&md5=f027a0004a4a3732038f587bfc5ad459","Neurodegenerative disorders challenge healthcare systems globally, impacting millions of lives and diminishing quality of life. Machine learning, particularly deep learning, offers promise in improving disease classification. Using a two-step methodology, This study looks into classifying three distinct neurodegenerative diseases using transfer learning: cerebral ataxia, Alzheimer's disease, and Parkinson's disease. First, we use neural network architectures that have already been trained, including VGG16 and ResNet101, which were first trained on large image datasets. This enables us to extract high-level features that capture important disease patterns and characteristics from medical images. By adapting these pre-Trained networks to the unique attributes of each disease, we enhance the model's ability to discriminate between them effectively. We use optimization techniques like SGD, Rmsprop, and Adam algorithm to get the optimized results, we employ a range of evaluation metrics, including accuracy and loss. These metrics provide a comprehensive understanding of the model's competence in accurately classifying patients with diverse neurodegenerative diseases. To make our model more accessible and user-friendly, we deploy it through the Flask web framework. Our research findings conclusively demonstrate that the amalgamation of transfer learning, Flask deployment, and stringent evaluation metrics substantially enhances the accuracy of neurodegenerative disease classification when compared to traditional diagnostic methods. This novel strategy promises to transform the identification and management of neurodegenerative illnesses, resulting in more prompt and efficient patient interventions.  © 2024 IEEE.","biomedical MRI; CNN; Deep learning; Inception v3; ResNet101; transfer learning; VGG16","Bottles; Convolutional neural networks; Deep learning; Diagnosis; Large datasets; Learning systems; Magnetic resonance imaging; Medical imaging; Network architecture; Patient treatment; Transfer learning; Biomedical MRI; Deep learning; Disease classification; Evaluation metrics; Healthcare systems; Inception v3; Neurodegenerative disorders; Resnet101; Transfer learning; VGG16; Neurodegenerative diseases","","","Institute of Electrical and Electronics Engineers Inc.",""
"Ammaiappan S.; Liang G.; Tan C.; Dong F.","Ammaiappan, Sathesh (56879130000); Liang, Guanghui (57190497743); Tan, Chao (35235699400); Dong, Feng (35721802600)","56879130000; 57190497743; 35235699400; 35721802600","A Priority-Based Adaptive Firefly Optimized Conv-BiLSTM Algorithm for Electrical Resistance Image Reconstruction","2024","24","1","","624","634","10","10.1109/JSEN.2023.3335321","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182031516&doi=10.1109%2fJSEN.2023.3335321&partnerID=40&md5=8e59fe48f66b5ff856b24e2b8aa0aef7","As a high-speed, noninvasive process measurement technology, electrical resistance tomography (ERT) is well suited for visualization of media distribution in industrial and biomedical fields. An innovative optimal hybrid deep-learning strategy utilizing a 1-D convolution neural network (CNN) and recurrent neural network (RNN) is proposed to solve the ERT inverse problem. In the proposed hybrid deep-learning model, the priority-based adaptive firefly algorithm (PAFA) optimizes the neuron structure by feature engineering and adaptively estimates the local optimum to accelerate convergence. The feature selection technique controls randomness through efficient local search and finding the optimal value fit. The input and output relation is enforced by local recurrent cells in the hybrid model feedback with a bidirectional long-short-term memory (BiLSTM) network. The proposed model extracts the latent features from the prior cells during the training period of the network architecture. Simulation and experimental tests are carried out, and the quantitative analysis shows that the proposed hybrid deep-learning model has better imaging accuracy than the traditional image reconstruction methods.  © 2001-2012 IEEE.","Bidirectional long-short term memory (BiLSTM); convolutional neural network (CNN); electrical resistance tomography (ERT); firefly algorithm (FA); image reconstruction; recurrent neural network (RNN)","Bioluminescence; Brain; Convolution; Electric resistance; Inverse problems; Learning algorithms; Long short-term memory; Network architecture; Optimization; Tomography; Bidirectional long-short term memory; Convolutional neural network; Electrical resistance tomography; Firefly algorithm; Firefly algorithms; Images reconstruction; Priority-based; Recurrent neural network; Image reconstruction","National Natural Science Foundation of China, NSFC, (51976137, 62201381); National Natural Science Foundation of China, NSFC","","Institute of Electrical and Electronics Engineers Inc.",""
"Nolke J.; Adler T.J.; Schellenberg M.; Dreher K.K.; Holzwarth N.; Bender C.J.; Tizabi M.D.; Seitel A.; Maier-Hein L.","Nolke, Jan-Hinrich (57209457194); Adler, Tim J. (57207918421); Schellenberg, Melanie (57219740778); Dreher, Kris K. (57220901243); Holzwarth, Niklas (57208643821); Bender, Christoph J. (59141741400); Tizabi, Minu D. (57193956328); Seitel, Alexander (22635486300); Maier-Hein, Lena (22634618600)","57209457194; 57207918421; 57219740778; 57220901243; 57208643821; 59141741400; 57193956328; 22635486300; 22634618600","Photoacoustic quantification of tissue oxygenation using conditional invertible neural networks","2024","","","","1","1","0","10.1109/TMI.2024.3403417","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194081763&doi=10.1109%2fTMI.2024.3403417&partnerID=40&md5=ac5a8991170251942ded6157351eac83","Intelligent systems in interventional healthcare depend on the reliable perception of the environment. In this context, photoacoustic tomography (PAT) has emerged as a non-invasive, functional imaging modality with great clinical potential. Current research focuses on converting the high-dimensional, not human-interpretable spectral data into the underlying functional information, specifically the blood oxygenation. One of the largely unexplored issues stalling clinical advances is the fact that the quantification problem is ambiguous, i.e. that radically different tissue parameter configurations could lead to almost identical photoacoustic spectra. In the present work, we tackle this problem with conditional Invertible Neural Networks (cINNs). Going beyond traditional point estimates, our network is used to compute an approximation of the conditional posterior density of tissue parameters given the measurement. To this end, an automatic mode detection algorithm extracts the plausible solution from the sample-based posterior. According to a comprehensive validation study based on both synthetic and real images, our approach is well-suited for exploring ambiguity in quantitative PAT. Authors","Biomedical optical imaging; Couplings; Deep learning; inverse problems; invertible networks; Optical imaging; Optical variables measurement; photoacoustic imaging; Standards; synthetic data; tissue oxygenation; Training; Vectors","Deep learning; Intelligent systems; Monte Carlo methods; Optical image storage; Oxygenation; Photoacoustic effect; Tissue; Biomedical optical imaging; Deep learning; Invertible network; Neural-networks; Optical imaging; Optical variable measurement; Photo-acoustic imaging; Photoacoustic tomography; Synthetic data; Tissue oxygenation; article; blood oxygenation; deep learning; detection algorithm; diagnosis; electric potential; fluorescence imaging; human; nerve cell network; optics; oxygen blood level; photoacoustic tomography; photoacoustics; tissue oxygenation; training; validation study; Inverse problems","","","Institute of Electrical and Electronics Engineers Inc.",""
"Wang Z.; Wu Y.; Xia Z.; Chen X.; Li X.; Bai Y.; Zhou Y.; Liang D.; Zheng H.; Yang Y.; Wang S.; Wang M.; Sun T.","Wang, Zhenguo (57444804400); Wu, Yaping (57195319814); Xia, Zeheng (58849534800); Chen, Xinyi (58378448100); Li, Xiaochen (57218467503); Bai, Yan (57077433300); Zhou, Yun (35291190000); Liang, Dong (57195152723); Zheng, Hairong (7403440733); Yang, Yongfeng (55719919600); Wang, Shanshan (36761739900); Wang, Meiyun (36609343900); Sun, Tao (54792272500)","57444804400; 57195319814; 58849534800; 58378448100; 57218467503; 57077433300; 35291190000; 57195152723; 7403440733; 55719919600; 36761739900; 36609343900; 54792272500","Non-Invasive Quantification of the Brain [¹F]FDG-PET Using Inferred Blood Input Function Learned From Total-Body Data With Physical Constraint","2024","43","7","","2563","2573","10","10.1109/TMI.2024.3368431","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186101097&doi=10.1109%2fTMI.2024.3368431&partnerID=40&md5=1c14cf189317e103230922cece66d600","Full quantification of brain PET requires the blood input function (IF), which is traditionally achieved through an invasive and time-consuming arterial catheter procedure, making it unfeasible for clinical routine. This study presents a deep learning based method to estimate the input function (DLIF) for a dynamic brain FDG scan. A long short-term memory combined with a fully connected network was used. The dataset for training was generated from 85 total-body dynamic scans obtained on a uEXPLORER scanner. Time-activity curves from 8 brain regions and the carotid served as the input of the model, and labelled IF was generated from the ascending aorta defined on CT image. We emphasize the goodness-of-fitting of kinetic modeling as an additional physical loss to reduce the bias and the need for large training samples. DLIF was evaluated together with existing methods in terms of RMSE, area under the curve, regional and parametric image quantifications. The results revealed that the proposed model can generate IFs that closer to the reference ones in terms of shape and amplitude compared with the IFs generated using existing methods. All regional kinetic parameters calculated using DLIF agreed with reference values, with the correlation coefficient being 0.961 (0.913) and relative bias being 1.68±8.74% (0.37±4.93%) for text{K}_{text {i}} (text{K}_{{1}}{)}. In terms of the visual appearance and quantification, parametric images were also highly identical to the reference images. In conclusion, our experiments indicate that a trained model can infer an image-derived IF from dynamic brain PET data, which enables subsequent reliable kinetic modeling.  © 1982-2012 IEEE.","blood input function; Brain imaging; deep learning; FDG-PET; kinetic modeling","Adult; Brain; Deep Learning; Female; Fluorodeoxyglucose F18; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Positron-Emission Tomography; Radiopharmaceuticals; Whole Body Imaging; Blood; Brain mapping; Computerized tomography; Deep learning; Image reconstruction; Kinetic theory; Kinetics; fluorodeoxyglucose f 18; fluorodeoxyglucose f 18; radiopharmaceutical agent; Biomedical imaging; Blood; Blood input function; Brain imaging; Brain modeling; Deep learning; FDG PET; Images reconstruction; Input functions; Kinetic models; adult; anterior cingulate; Article; ascending aorta; blood-to-plasma ratio; brain stem; carotid artery; cerebellum; compartment model; controlled study; deep learning; demographics; female; human; image analysis; image processing; image reconstruction; kinetic parameters; Levenberg Marquardt algorithm; lingual gyrus; long short term memory network; major clinical study; male; middle aged; middle temporal gyrus; neuroimaging; positron emission tomography; posterior cingulate; putamen; recurrent neural network; reference value; root mean squared error; standardized uptake value; thalamus; x-ray computed tomography; brain; diagnostic imaging; procedures; whole body imaging; Brain","","","Institute of Electrical and Electronics Engineers Inc.","38386580"
"Srujan Raju K.; Sharma A.; Reddy N.C.S.; Latha G.S.; Pavan Kumar G.; Vidyasagar G.","Srujan Raju, K. (57757923700); Sharma, Ashish (57210974694); Reddy, Nagu Chandra Sekhar (58919221400); Latha, Godisela Swarna (59041191800); Pavan Kumar, G. (58515735900); Vidyasagar, Gasiganti (58938566100)","57757923700; 57210974694; 58919221400; 59041191800; 58515735900; 58938566100","Prediction and Classification of Skin Diseases Using Convolution Neural Network Techniques","2024","898","","","403","411","8","10.1007/978-981-99-9707-7_38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187656518&doi=10.1007%2f978-981-99-9707-7_38&partnerID=40&md5=4160db0963d65dd2e02e0173956b5fc0","This research paper proposes the dermatological diseases are very predominant diseases around the world. Even though being general, treatment is very problematic and needs broad knowledge in subject. The skin illnesses are mainly caused by bacteria, fungal infection, viruses, allergy, etc. The Photonics-based medical technology and lasers advancement will be utilized for the treatment of skin illnesses which produce results rapidly and precisely. But the medical equipments for such diagnosis are limited and very costly. In such cases deep learning methods found to be helpful. The skin illness detection at an initial phase is a significant part in treatment. Deep learning technique like Convolution Neural Network (CNN) may help to find the problem at an initial stage. Computer vision and deep learning are dual stages which we used to identify diseases accurately. The utilization of deep learning methods has decreased the requirement for human supervision on a regular basis. A dataset of 5,633 images which are divided into five categories have been taken for skin diseases classification. They comprise acne, eczema, melanoma, psoriasis, and urticaria hives. The model also provides the precautions needed to be taken and some recommended medicines for the skin disease. By utilizing CNN algorithm, 83% accuracy is achieved in classification of skin disease. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","CNN; Deep learning; Skin disease","Biomedical engineering; Classification (of information); Convolution; Deep learning; Dermatology; Diagnosis; Learning systems; Convolution neural network; Deep learning; Dermatological disease; Fungal infection; Learning methods; Medical lasers; Medical technologies; Neural network techniques; Research papers; Skin disease; Diseases","","Devi B.R.; Raju M.; Kumar K.; Raju K.S.; Sellathurai M.","Springer Science and Business Media Deutschland GmbH",""
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","1964 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178598232&partnerID=40&md5=efc2e5f9beece0459200cd1145901a6d","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"Asif S.; Qurrat-ul-Ain; Awais M.; Khan S.U.R.","Asif, Sohaib (57221248320); Qurrat-ul-Ain (58179973500); Awais, Muhammad (59276254700); Khan, Saif Ur Rehman (58836834300)","57221248320; 58179973500; 59276254700; 58836834300","IR-CNN: Inception residual network for detecting kidney abnormalities from CT images","2023","12","1","35","","","","10.1007/s13721-023-00431-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171877377&doi=10.1007%2fs13721-023-00431-4&partnerID=40&md5=e700067af39abaad0cb7f9c0215ae2a6","Kidney abnormalities are a public health problem and a common disease with adverse effects such as kidney damage. Due to the shortage of nephrologists worldwide, detecting these abnormalities are expensive and time consuming. Thus, deep learning (DL) techniques can help clinicians to automate the diagnosis of kidney diseases. However, achieving better performance is still a challenge in kidney disease detection. In this study, we propose an efficient architecture “IR-CNN” based on the Inception residual network for the detection of three major kidney diseases, tumor, kidney stone and cyst, using CT images. We customized the top layer of InceptionResNetV2 and further added global average pooling (GAP), batch normalization (BN), dropout and dense layers with swish activation functions to extract robust features, avoid vanishing gradient problems and achieve better accuracy in detecting kidney disease. The proposed IR-CNN model was trained and tested on a publicly available kidney CT dataset with 4000 images using different optimizers (Adam, SGD, and RMSprop). Experimental results show that IR-CNN achieves 99.38%, 94.63%, 97.38% using Adam, SGD and RMSprop optimizers, respectively. In addition, IR-CNN with Adam optimizer achieved better performance with only 5 misclassifications out of 800 test images and performed better than existing methods in diagnosing kidney disease. The superior results of our IR-CNN architecture can help urologists diagnose kidney disease, thereby reducing human error. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.","Biomedical image analysis; Deep learning; Inception residual network; Kidney abnormalities; Kidney disease detection","Computerized tomography; Deep learning; Network architecture; Biomedical image analysis; CT Image; Deep learning; Disease detection; Inception residual network; Kidney abnormality; Kidney disease; Kidney disease detection; Optimizers; Performance; accuracy; Article; augmentation index; classification algorithm; computer assisted tomography; convolutional neural network; cyst; deep learning; feature extraction; global average pooling; human; image analysis; image segmentation; kidney disease; kidney injury; kidney malformation; learning; learning algorithm; machine learning; medical research; nephrolithiasis; network analysis; patient dropout; receiver operating characteristic; residual network; sensitivity and specificity; spatial discrimination; training; validation process; Diagnosis","","","Springer",""
"Habib A.; Vaniya S.N.; Khandoker A.; Karmakar C.","Habib, Ahsan (57211426409); Vaniya, Shruthi Narayanan (57205391248); Khandoker, Ahsan (23091108200); Karmakar, Chandan (57080550900)","57211426409; 57205391248; 23091108200; 57080550900","MDDBranchNet: A Deep Learning Model for Detecting Major Depressive Disorder Using ECG Signal","2024","28","7","","3798","3809","11","10.1109/JBHI.2024.3390847","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197716186&doi=10.1109%2fJBHI.2024.3390847&partnerID=40&md5=1119101db767154fdaffb7d94c3c7884","Major depressive disorder (MDD) is a chronic mental illness which affects people's well-being and is often detected at a later stage of depression with a likelihood of suicidal ideation. Early detection of MDD is thus necessary to reduce the impact, however, it requires monitoring vitals in daily living conditions. EEG is generally multi-channel and due to difficulty in signal acquisition, it is unsuitable for home-based monitoring, whereas, wearable sensors can collect single-channel ECG. Classical machine-learning based MDD detection studies commonly use various heart rate variability features. Feature generation, which requires domain knowledge, is often challenging, and requires computation power, often unsuitable for real time processing, MDDBranchNet is a proposed parallel-branch deep learning model for MDD binary classification from a single channel ECG which uses additional ECG-derived signals such as R-R signal and degree distribution time series of horizontal visibility graph. The use of derived branches was able to increase the model's accuracy by around 7%. An optimal 20-second overlapped segmentation of ECG recording was found to be beneficial with a 70% prediction threshold for maximum MDD detection with a minimum false positive rate. The proposed model evaluated MDD prediction from signal excerpts, irrespective of location (first, middle or last one-third of the recording), instead of considering the entire ECG signal with minimal performance variation stressing the idea that MDD phenomena are likely to manifest uniformly throughout the recording.  © 2013 IEEE.","convolutional network (CNN); deep learning; electrocardiogram; generalisation; Major depressive disorder (MDD); QRS-complex; temporal convolution","Adult; Algorithms; Deep Learning; Depressive Disorder, Major; Electrocardiography; Humans; Male; Signal Processing, Computer-Assisted; Biomedical signal processing; Convolution; Deep learning; Diseases; Domain Knowledge; Convolutional network; Convolutional networks; Deep learning; ECG signals; Generalisation; Learning models; Major depressive disorder; QRS complexes; Single channel ECG; Temporal convolution; Article; clinical article; controlled study; convolutional neural network; deep learning; diagnostic accuracy; electrocardiogram; electroencephalography; entropy; feature extraction; Hamilton Depression Rating Scale; heart rate; horizontal visibility graph; human; image segmentation; learning algorithm; machine learning; major depression; mathematical parameters; MDDBranchNet; neuropsychological assessment; prediction; recurrent neural network; sensitivity analysis; time series analysis; validation process; adult; algorithm; diagnosis; electrocardiography; male; pathophysiology; procedures; signal processing; Electrocardiograms","National Computational Infrastructure, NCI; Khalifa University of Science, Technology and Research, KU","","Institute of Electrical and Electronics Engineers Inc.","38954560"
"Wang Q.; Wang W.; Fang Y.; Yap P.-T.; Zhu H.; Li H.-J.; Qiao L.; Liu M.","Wang, Qianqian (57876786300); Wang, Wei (56948638900); Fang, Yuqi (57204673288); Yap, Pew-Thian (55985442900); Zhu, Hongtu (7404664018); Li, Hong-Jun (15035194300); Qiao, Lishan (34868503100); Liu, Mingxia (36677833300)","57876786300; 56948638900; 57204673288; 55985442900; 7404664018; 15035194300; 34868503100; 36677833300","Leveraging Brain Modularity Prior for Interpretable Representation Learning of fMRI","2024","71","8","","2391","2401","10","10.1109/TBME.2024.3370415","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187010276&doi=10.1109%2fTBME.2024.3370415&partnerID=40&md5=4fbe84dab5a1eea0eff6585fd5a6eb96","Resting-state functional magnetic resonance imaging (rs-fMRI) can reflect spontaneous neural activities in the brain and is widely used for brain disorder analysis. Previous studies focus on extracting fMRI representations using machine/deep learning methods, but these features typically lack biological interpretability. The human brain exhibits a remarkable modular structure in spontaneous brain functional networks, with each module comprised of functionally interconnected brain regions-of-interest (ROIs). However, existing learning-based methods cannot adequately utilize such brain modularity prior. In this paper, we propose a brain modularity-constrained dynamic representation learning framework for interpretable fMRI analysis, consisting of dynamic graph construction, dynamic graph learning via a novel modularity-constrained graph neural network (MGNN), and prediction and biomarker detection. The designed MGNN is constrained by three core neurocognitive modules (i.e., salience network, central executive network, and default mode network), encouraging ROIs within the same module to share similar representations. To further enhance discriminative ability of learned features, we encourage the MGNN to preserve network topology of input graphs via a graph topology reconstruction constraint. Experimental results on 534 subjects with rs-fMRI scans from two datasets validate the effectiveness of the proposed method. The identified discriminative brain ROIs and functional connectivities can be regarded as potential fMRI biomarkers to aid in clinical diagnosis. © 1964-2012 IEEE.","Biomarker; brain disorder; brain modularity; functional MRI","Adult; Algorithms; Brain; Brain Mapping; Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Neural Networks, Computer; Biomarkers; Biomedical engineering; Diagnosis; Learning systems; Magnetic resonance imaging; Topology; Autism; Brain disorders; Brain modeling; Brain modularity; Functional magnetic resonance imaging; Functional MRI; Network topology; Region-of-interest; Regions of interest; Representation learning; adolescent; adult; Article; autism; BOLD signal; brain region; comparative study; controlled study; cross validation; deep learning; deep neural network; default mode network; executive network; explainable machine learning; feature learning (machine learning); female; functional connectivity; functional magnetic resonance imaging; functional neuroimaging; human; major clinical study; male; nerve cell network; prediction; random forest; salience network; task performance; algorithm; artificial neural network; brain; brain mapping; diagnostic imaging; image processing; machine learning; nuclear magnetic resonance imaging; physiology; procedures; Brain","","","IEEE Computer Society","38412079"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","1968 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178625415&partnerID=40&md5=bb0a33ddf85aef908ebced83f2ea0b55","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"","","","27th European Conference on Applications of Evolutionary Computation, EvoApplications 2024 held as part of EvoStar 2024","2024","14635 LNCS","","","","","406","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189505583&partnerID=40&md5=a99d049463ba20c40d70daef7effb558","The proceedings contain 24 papers. The special focus in this conference is on Applications of Evolutionary Computation. The topics include: Evolving Reservoirs for Meta Reinforcement Learning; hybrid Surrogate Assisted Evolutionary Multiobjective Reinforcement Learning for Continuous Robot Control; towards Physical Plausibility in Neuroevolution Systems; leveraging More of Biology in Evolutionary Reinforcement Learning; a Hierarchical Dissimilarity Metric for Automated Machine Learning Pipelines, and Visualizing Search Behaviour; DeepEMO: A Multi-indicator Convolutional Neural Network-Based Evolutionary Multi-objective Algorithm; a Comparative Analysis of Evolutionary Adversarial One-Pixel Attacks; robust Neural Architecture Search Using Differential Evolution for Medical Images; Progressive Self-supervised Multi-objective NAS for Image Classification; genetic Programming with Aggregate Channel Features for Flower Localization Using Limited Training Data; evolutionary Multi-objective Optimization of Large Language Model Prompts for Balancing Sentiments; evolutionary Feature-Binning with Adaptive Burden Thresholding for Biomedical Risk Stratification; an Evolutionary Deep Learning Approach for Efficient Quantum Algorithms Transpilation; measuring Similarities in Model Structure of Metaheuristic Rule Set Learners; incremental Growth on Compositional Pattern Producing Networks Based Optimization of Biohybrid Actuators; hilbert Curves for Efficient Exploratory Landscape Analysis Neighbourhood Sampling; predicting Algorithm Performance in Constrained Multiobjective Optimization: A Tough Nut to Crack; on the Latent Structure of the bbob-biobj Test Suite; strategies for Evolving Diverse and Effective Behaviours in Pursuit Domains; using Evolution and Deep Learning to Generate Diverse Intelligent Agents; vision Transformers for Computer Go; integrating Bayesian and Evolutionary Approaches for Multi-objective Optimisation.","","","","Smith S.; Correia J.; Cintrano C.","Springer Science and Business Media Deutschland GmbH",""
"Wang J.; Zhang Z.; Wu M.; Ye Y.; Wang S.; Cao Y.; Yang H.","Wang, Juan (57216678183); Zhang, Zetao (58174824400); Wu, Minghu (55616993200); Ye, Yonggang (58175996000); Wang, Sheng (57204602398); Cao, Ye (57212556037); Yang, Hao (59045052400)","57216678183; 58174824400; 55616993200; 58175996000; 57204602398; 57212556037; 59045052400","Nuclei instance segmentation using a transformer-based graph convolutional network and contextual information augmentation","2023","167","","107622","","","","10.1016/j.compbiomed.2023.107622","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174825651&doi=10.1016%2fj.compbiomed.2023.107622&partnerID=40&md5=f0778771e3846cf10a909a41d721c3ad","Nucleus instance segmentation is an important task in medical image analysis involving cell-level pathological analysis and is of great significance for many biomedical applications, such as disease diagnosis and drug screening. However, the high-density and tight-contact between cells is a common feature of most cell images, which poses a great technical challenge for nuclei instance segmentation. The latest research focuses on CNN-based methods for nuclei instance segmentation, which typically rely on bounding box regression and non-maximum suppression to locate nuclei. However, this frequently results in poor local bounding boxes for nuclei that are adhered or clustered together. In response to the challenges of high-density and tight-contact in cellular images, we propose a novel end-to-end nuclei instance segmentation model. Specifically, we first employ the Swin Transformer as the backbone network of our model, which captures global multi-scale information by combining the global modelling capability of transformers and the local modelling capability of convolutional neural networks (CNNs). Additionally, we integrate a graph convolutional feature fusion module (GCFM), that combines deep and shallow features to learn an affinity matrix. The module also adopts graph convolution to guide the network in learning the object-level local information. Finally, we design a hybrid dilated convolution module (HDC) and insert it into the backbone network to enhance the contextual information over a large range. These components assist the network in extracting rich features. The experimental results demonstrate that our algorithm outperforms several state-of-the-art models on the DSB2018 and LIVECell datasets. © 2023 Elsevier Ltd","Graph convolution; Microscopic pathological images; Nuclei instance segmentation; Swin transformer","Convolutional neural networks; Diagnosis; Image segmentation; Medical applications; Medical imaging; Back-bone network; Bounding-box; Contextual information; Convolutional neural network; Graph convolution; Microscopic pathological image; Modelling capabilities; Nucleus instance segmentation; Pathological images; Swin transformer; Article; controlled study; convolutional neural network; extraction; image segmentation; Convolution","National Natural Science Foundation of China, NSFC, (62006073); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Hubei Province, (2022CFA007); Natural Science Foundation of Hubei Province; Key Research and Development Program of Jiangxi Province, (2021BGD013); Key Research and Development Program of Jiangxi Province; Science and Technology Program of Hubei Province, (2022BEC017); Science and Technology Program of Hubei Province","","Elsevier Ltd",""
"Banerjee A.; Pal O.; Mondal M.; Mukherjee A.; Chakrabarti P.P.; Pal S.K.; Misra S.; Chakravarty D.","Banerjee, Amardip (59007759600); Pal, Olivia (59008577900); Mondal, Mayukh (58064164200); Mukherjee, Avishek (57669886500); Chakrabarti, Partha Pratim (7101793021); Pal, Surjya Kanta (35570021100); Misra, Sudip (7401768547); Chakravarty, Debashish (7004526342)","59007759600; 59008577900; 58064164200; 57669886500; 7101793021; 35570021100; 7401768547; 7004526342","An Effective EEG-Based Image Classification Methodology Under Low Data and Resource Requirements Using Machine Learning","2024","","","","","","","10.1109/ICCECE58645.2024.10497204","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191739638&doi=10.1109%2fICCECE58645.2024.10497204&partnerID=40&md5=005008ed29ddf39124d7606ce3a89f01","Deep Learning (DL) methods such as Convolutional Neural Network (CNN) learning approaches are used to extract features from images through convolution operation. These features are widely used for image classification, object detection or segmentations tasks. But a high testing accuracy needs lot of input images for training, whereas a human brain can do similar tasks with a few training samples. Present study is aiming to establish the potential of extracted features from electroencephalogram (EEG) signals acquired from brain superior to CNN extracted features for image classification tasks. For this, EEG signals are collected while seeing an image and thinking about its attributes through a questionnaire. A five-channel EEG headset has been used for data collection. Four standard statistical features, namely mean, standard deviation, kurtosis and skewness have been extracted from signals emitted from each electrode. A total of twenty features extracted from five-channel EEG data have been used as input in training against the output labels through four different machine learning (ML) classifiers such as random forest (RF), support vector machine (SVM), multi-layer perceptron (MLP), extreme gradient boosting algorithm (XGBoost). Same images have been used for training, and inferenced through a CNN based binary classifier. Results show a lower performance metrics with CNN than EEG feature-based classifiers. Such concept can overcome the high data related constraint in areas like manufacturing. © 2024 IEEE.","CNN; Deep learning; EEG; Human brain; Image classification; Machine learning","Adaptive boosting; Biomedical signal processing; Brain; Brain mapping; Classification (of information); Convolution; Convolutional neural networks; Data mining; Deep learning; Electroencephalography; Higher order statistics; Image segmentation; Learning systems; Object detection; Support vector machines; Classification methodologies; Convolutional neural network; Data requirements; Deep learning; Electroencephalogram signals; Human brain; Images classification; Learning methods; Machine-learning; Resource requirements; Image classification","","","Institute of Electrical and Electronics Engineers Inc.",""
"Tseng C.; Chien S.; Wang P.; Lee S.; Pu B.; Zeng X.","Tseng, Ching-Hsun (57212460507); Chien, Shao-Ju (7201952328); Wang, Po-Shen (58553737500); Lee, Shin-Jye (34877262700); Pu, Bin (57217089123); Zeng, Xiao-Jun (7403248390)","57212460507; 7201952328; 58553737500; 34877262700; 57217089123; 7403248390","Real-time Automatic M-mode Echocardiography Measurement with Panel Attention","2024","","","","1","13","12","10.1109/JBHI.2024.3413628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196084124&doi=10.1109%2fJBHI.2024.3413628&partnerID=40&md5=e103717cdfd8a342219f6f93e7784b5c","Motion mode (M-mode) echocardiography is essential for measuring cardiac dimension and ejection fraction. However, the current diagnosis is time-consuming and suffers from diagnosis accuracy variance. This work resorts to building an automatic scheme through well-designed and well-trained deep learning to conquer the situation. That is, we proposed RAMEM, an automatic scheme of real-time M-mode echocardiography, which contributes three aspects to address the challenges: 1) provide MEIS, the first dataset of M-mode echocardiograms, to enable consistent results and support developing an automatic scheme; For detecting objects accurately in echocardiograms, it requires big receptive field for covering long-range diastole to systole cycle. However, the limited receptive field in the typical backbone of convolutional neural networks (CNN) and the losing information risk in non-local block (NL) equipped CNN risk the accuracy requirement. Therefore, we 2) propose panel attention embedding with updated UPANets V2, a convolutional backbone network, in a real-time instance segmentation (RIS) scheme for boosting big object detection performance; 3) introduce AMEM, an efficient algorithm of automatic M-mode echocardiography measurement, for automatic diagnosis; The experimental results show that RAMEM surpasses existing RIS schemes (CNNs with NL &amp; Transformers as the backbone) in PASCAL 2012 SBD and human performances in MEIS. The implemented code and dataset are available at <uri>https://github.com/hanktseng131415go/RAMEM</uri>. IEEE","Biomedical measurement; Deep learning; Echocardiography; Instance segmentation; Labeling; M-mode Echocardiography; Manuals; Real-time Instance Segmentation; Real-time systems; Ultrasound Images","Convolution; Deep learning; Echocardiography; Image segmentation; Interactive computer systems; Neural networks; Object detection; Biomedical measurements; Deep learning; Instance segmentation; Labelings; Manual; Motion mode echocardiography; Motion modes; Real - Time system; Real- time; Real-time instance segmentation; Time instances; Ultrasound images; Real time systems","","","Institute of Electrical and Electronics Engineers Inc.","38865231"
"Wang R.; Zhu J.; Meng Y.; Wang X.; Chen R.; Wang K.; Li C.; Shi J.","Wang, Ruofan (57208593580); Zhu, Jing (58365694000); Meng, Yuqian (58635283100); Wang, Xuanhao (57210445921); Chen, Ruimin (55276249100); Wang, Kaiyue (57226832551); Li, Chiye (55385819000); Shi, Junhui (56809809000)","57208593580; 58365694000; 58635283100; 57210445921; 55276249100; 57226832551; 55385819000; 56809809000","Adaptive machine learning method for photoacoustic computed tomography based on sparse array sensor data","2023","242","","107822","","","","10.1016/j.cmpb.2023.107822","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173500581&doi=10.1016%2fj.cmpb.2023.107822&partnerID=40&md5=ffd116ee9c6b2fd82cdc73084dca3c88","Background and objective: Photoacoustic computed tomography (PACT) is a non-invasive biomedical imaging technology that has developed rapidly in recent decades, especially has shown potential for small animal studies and early diagnosis of human diseases. To obtain high-quality images, the photoacoustic imaging system needs a high-element-density detector array. However, in practical applications, due to the cost limitation, manufacturing technology, and the system requirement in miniaturization and robustness, it is challenging to achieve sufficient elements and high-quality reconstructed images, which may even suffer from artifacts. Different from the latest machine learning methods based on removing distortions and artifacts to recover high-quality images, this paper proposes an adaptive machine learning method to firstly predict and complement the photoacoustic sensor channel data from sparse array sampling and then reconstruct images through conventional reconstruction algorithms. Methods: We develop an adaptive machine learning method to predict and complement the photoacoustic sensor channel data. The model consists of XGBoost and a neural network named SS-net. To handle data sets of different sizes and improve the generalization, a tunable parameter is used to control the weights of XGBoost and SS-net outputs. Results: The proposed method achieved superior performance as demonstrated by simulation, phantom experiments, and in vivo experiment results. Compared with linear interpolation, XGBoost, CAE, and U-net, the simulation results show that the SSIM value is increased by 12.83%, 6.78%, 21.46%, and 12.33%. Moreover, the median R2 is increased by 34.4%, 8.1%, 28.6%, and 84.1% with the in vivo data. Conclusions: This model provides a framework to predict the missed photoacoustic sensor data on a sparse ring-shaped array for PACT imaging and has achieved considerable improvements in reconstructing the objects. Compared with linear interpolation and other deep learning methods qualitatively and quantitatively, our proposed methods can effectively suppress artifacts and improve image quality. The advantage of our methods is that there is no need for preparing a large number of images as the training dataset, and the data for training is directly from the sensors. It has the potential to be applied to a wide range of photoacoustic imaging detector arrays for low-cost and user-friendly clinical applications. © 2023 The Author(s)","Machine learning; Photoacoustic imaging; Sensor data prediction; Sparse array","Algorithms; Artifacts; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks, Computer; Phantoms, Imaging; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Diagnosis; Image enhancement; Image reconstruction; Interpolation; Large dataset; Learning systems; Medical imaging; Photoacoustic effect; graphite; Adaptive machine learning; Data prediction; Machine learning methods; Machine-learning; Photo-acoustic imaging; Photoacoustic computed tomography; Photoacoustic sensors; Sensor data prediction; Sensors data; Sparse arrays; animal experiment; animal tissue; Article; artifact; artificial intelligence; artificial neural network; capillary; computer assisted tomography; controlled study; deep learning; feature extraction; image analysis; image quality; image reconstruction; in vivo study; machine learning; mouse; nonhuman; photoacoustic tomography; photoacoustics; prediction; reconstruction algorithm; recurrent neural network; algorithm; artificial neural network; human; image processing; machine learning; procedures; x-ray computed tomography; Forecasting","Youth Foundation Project of Zhejiang Lab, (K2023BA0AA04); Zhejiang Lab Research Funds, (2020MC0AD01); Key Research and Development Program of Zhejiang Province, (2021C0305); National Natural Science Foundation of China, NSFC, (T2293750, T2293752)","","Elsevier Ireland Ltd","37832425"
"Huang X.; Gong H.; Zhang J.","Huang, Xiaofei (57937815600); Gong, Hongfang (8276321500); Zhang, Jin (35771944500)","57937815600; 8276321500; 35771944500","HST-MRF: Heterogeneous Swin Transformer with Multi-Receptive Field for Medical Image Segmentation","2024","28","7","","4048","4061","13","10.1109/JBHI.2024.3397047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192740727&doi=10.1109%2fJBHI.2024.3397047&partnerID=40&md5=02cbb5ea994cb083b7456dd5008e8df2","The Transformer has been successfully used in medical image segmentation due to its excellent long-range modeling capabilities. However, patch segmentation is necessary when building a Transformer class model. This process ignores the tissue structure features within patch, resulting in the loss of shallow representation information. In this study, we propose a Heterogeneous Swin Transformer with Multi-Receptive Field (HST-MRF) model that fuses patch information from different receptive fields to solve the problem of loss of feature information caused by patch segmentation. The heterogeneous Swin Transformer (HST) is the core module, which achieves the interaction of multi-receptive field patch information through heterogeneous attention and passes it to the next stage for progressive learning, thus complementing the patch structure information. We also designed a two-stage fusion module, multimodal bilinear pooling (MBP), to assist HST in further fusing multi-receptive field information and combining low-level and high-level semantic information for accurate localization of lesion regions. In addition, we developed adaptive patch embedding (APE) and soft channel attention (SCA) modules to retain more valuable information when acquiring patch embedding and filtering channel features, respectively, thereby improving model segmentation quality. We evaluated HST-MRF on multiple datasets for polyp, skin lesion and breast ultrasound segmentation tasks. Experimental results show that our proposed method outperforms state-of-the-art models and can achieve superior performance. Furthermore, we verified the effectiveness of each module and the benefits of multi-receptive field segmentation in reducing the loss of structural information through ablation experiments and qualitative analysis.  © 2013 IEEE.","Heterogeneous attention; medical imaging segmentation; multi-receptive field; patch segmentation","Algorithms; Deep Learning; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Computer vision; Embeddings; Image segmentation; Information filtering; Job analysis; Semantics; Biomedical imaging; Computational modelling; Features extraction; Heterogeneous attention; Images segmentations; Medical imaging segmentation; Multi-receptive field; Patch segmentation; Receptive fields; Task analysis; Transformer; adaptive patch embedding; Article; artificial neural network; colon polyp; colonoscopy; convolutional neural network; cross validation; diagnostic imaging; echomammography; feature selection; heterogeneous swin transformer with multi receptive field; human; image quality; image segmentation; machine learning; multimodal bilinear pooling; receptive field; skin defect; soft channel attention module; task performance; algorithm; computer assisted diagnosis; deep learning; image processing; nuclear magnetic resonance imaging; procedures; Medical imaging","","","Institute of Electrical and Electronics Engineers Inc.","38709610"
"Sun J.; Portilla J.; Otero A.","Sun, Junjiao (59001471000); Portilla, Jorge (23005759600); Otero, Andres (35868116400)","59001471000; 23005759600; 35868116400","A Deep Learning Approach for Fear Recognition on the Edge Based on Two-Dimensional Feature Maps","2024","28","7","","3973","3984","11","10.1109/JBHI.2024.3392373","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191340041&doi=10.1109%2fJBHI.2024.3392373&partnerID=40&md5=421854330883b4eb2992035652cce98a","Applying affective computing techniques to recognize fear and combining them with portable signal monitors makes it possible to create real-time detection systems that could act as bodyguards when users are in danger. With this aim, this paper presents a fear recognition method based on physiological signals obtained from wearable devices. The procedure involves creating two-dimensional feature maps from the raw signals, using data augmentation and feature selection algorithms, followed by deep learning-based classification models, taking inspiration from those used in image processing. This proposal has been validated with two different datasets, achieving, in WEMAC, WESAD 3-classes, and WESAD 2-classes, F1-score results of 78.13%, 88.07%, and 99.60%, respectively, and 79.90%, 89.12%, and 99.60% in accuracy. Furthermore, the paper demonstrates the feasibility of implementing the proposed method on the Coral Edge TPU device, prepared to make inferences on the edge.  © 2013 IEEE.","Affective computing; deep learning; edge computing; fear recognition; feature selection; physiological signals","Adult; Algorithms; Deep Learning; Fear; Female; Humans; Male; Signal Processing, Computer-Assisted; Wearable Electronic Devices; Young Adult; Biomedical signal processing; Deep learning; Edge computing; Emotion Recognition; Image processing; Interactive computer systems; Physiology; Real time systems; Affective Computing; Anxiety disorder; Biomedical monitoring; Deep learning; Edge computing; Emotion recognition; Fear recognition; Features extraction; Features selection; Physiological signals; Real - Time system; Article; blood volume pulse; convolutional neural network; deep learning; deep neural network; electrocardiogram; electrodermal response; electroencephalography; fear; fear recognition; feature selection; gender based violence; heart rate variability; human; k nearest neighbor; long short term memory network; machine learning; mathematical computing; physiological signal; physiology; power spectrum; pulse wave; recursive feature elimination; skin conductance; skin temperature; support vector machine; adult; algorithm; female; male; physiology; signal processing; wearable computer; young adult; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.","38648140"
"Ahmed S.; Esha J.F.; Rahman M.S.; Kaiser M.S.; Hosen A.S.M.S.; Ghimire D.; Park M.J.","Ahmed, Samia (58534131700); Esha, Jannatul Ferdous (58951965500); Rahman, Md. Sazzadur (56297689700); Kaiser, M. Shamim (56446362000); Hosen, A. S. M. Sanwar (55354658100); Ghimire, Deepak (36835193600); Park, Mi Jin (57205500978)","58534131700; 58951965500; 56297689700; 56446362000; 55354658100; 36835193600; 57205500978","Exploring Deep Learning and Machine Learning Approaches for Brain Hemorrhage Detection","2024","12","","","45060","45093","33","10.1109/ACCESS.2024.3376438","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188428908&doi=10.1109%2fACCESS.2024.3376438&partnerID=40&md5=ed2e0620bccbd55be834c3d57a46cb9c","Brain hemorrhage refers to a potentially fatal medical disorder that affects millions of individuals. The percentage of patients who survive can be significantly raised with the prompt identification of brain hemorrhages, due to image-guided radiography, which has emerged as the predominant treatment modality in clinical practice. A Computed Tomography Image has frequently been employed for the purpose of identifying and diagnosing neurological disorders. The manual identification of anomalies in the brain region from the Computed Tomography Image demands the radiologist to devote a greater amount of time and dedication. In the most recent studies, a variety of techniques rooted in Deep learning and traditional Machine Learning have been introduced with the purpose of promptly and reliably detecting and classifying brain hemorrhage. This overview provides a comprehensive analysis of the surveys that have been conducted by utilizing Machine Learning and Deep Learning. This research focuses on the main stages of brain hemorrhage, which involve preprocessing, feature extraction, and classification, as well as their findings and limitations. Moreover, this in-depth analysis provides a description of the existing benchmark datasets that are utilized for the analysis of the detection process. A detailed comparison of performances is analyzed. Moreover, this paper addresses some aspects of the above-mentioned technique and provides insights into prospective possibilities for future research.  © 2013 IEEE.","Artificial intelligence; brain hemorrhage; convolutional neural network; deep learning; human health; intracranial hemorrhage; machine learning","Biomedical signal processing; Brain; Computerized tomography; Deep learning; Diagnosis; Extraction; Learning algorithms; Medical imaging; Neural networks; Neurology; Patient treatment; Radiography; Signal detection; Benchmark testing; Brain hemorrhage; Brain injury; Classification algorithm; Computed tomography; Convolutional neural network; Deep learning; Detection algorithm; Features extraction; Haemorrage; Hemorrhaging; Human health; Image preprocessing; Intracranial hemorrhages; Machine-learning; Medical treatment; Neurological disease; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.",""
"Lei W.; Su Q.; Jiang T.; Gu R.; Wang N.; Liu X.; Wang G.; Zhang X.; Zhang S.","Lei, Wenhui (57212008040); Su, Qi (57355122200); Jiang, Tianyu (58487451800); Gu, Ran (57208180217); Wang, Na (57702365000); Liu, Xinglong (56179970200); Wang, Guotai (55682589900); Zhang, Xiaofan (56352677000); Zhang, Shaoting (13605200100)","57212008040; 57355122200; 58487451800; 57208180217; 57702365000; 56179970200; 55682589900; 56352677000; 13605200100","One-Shot Weakly-Supervised Segmentation in 3D Medical Images","2024","43","1","","175","189","14","10.1109/TMI.2023.3294975","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164784068&doi=10.1109%2fTMI.2023.3294975&partnerID=40&md5=f654d433fc3bf8b5e1076c4c719c91fc","Deep neural networks typically require accurate and a large number of annotations to achieve outstanding performance in medical image segmentation. One-shot and weakly-supervised learning are promising research directions that reduce labeling effort by learning a new class from only one annotated image and using coarse labels instead, respectively. In this work, we present an innovative framework for 3D medical image segmentation with one-shot and weakly-supervised settings. Firstly a propagation-reconstruction network is proposed to propagate scribbles from one annotated volume to unlabeled 3D images based on the assumption that anatomical patterns in different human bodies are similar. Then a multi-level similarity denoising module is designed to refine the scribbles based on embeddings from anatomical- to pixel-level. After expanding the scribbles to pseudo masks, we observe the miss-classified voxels mainly occur at the border region and propose to extract self-support prototypes for the specific refinement. Based on these weakly-supervised segmentation results, we further train a segmentation model for the new class with the noisy label training strategy. Experiments on three CT and one MRI datasets show the proposed method obtains significant improvement over the state-of-the-art methods and performs robustly even under severe class imbalance and low contrast. Code is publicly available at https://github.com/LWHYC/OneShot_WeaklySeg. © 1982-2012 IEEE.","One-shot learning; self-supervision; weakly-supervised learning","Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Supervised Machine Learning; Computer vision; Computerized tomography; Deep neural networks; Image denoising; Image reconstruction; Image segmentation; Medical imaging; Supervised learning; Biomedical imaging; Images reconstruction; Images segmentations; Location awareness; Noise measurements; One-shot learning; Prototype; Self-supervision; Supervised segmentation; Weakly supervised learning; Article; autoencoder; brain stem; cardiovascular magnetic resonance; comparative study; controlled study; human; image reconstruction; image segmentation; internal consistency; learning algorithm; nuclear magnetic resonance imaging; target organ; three-dimensional imaging; artificial neural network; image processing; supervised machine learning; Noise abatement","","","Institute of Electrical and Electronics Engineers Inc.","37440388"
"Dai L.; Zhou M.; Liu H.","Dai, Ling (59116296100); Zhou, Mingming (57906850800); Liu, Haipeng (56874983500)","59116296100; 57906850800; 56874983500","Recent applications of convolutional neural networks in medical data analysis","2023","","","","119","131","12","10.4018/979-8-3693-1022-9.ch007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183676743&doi=10.4018%2f979-8-3693-1022-9.ch007&partnerID=40&md5=1672ad8bc8abfd182ee27bb03df73e7d","Cutting-edge artificial intelligence techniques especially deep learning algorithms have shown great potentials in data-driven diagnostics. Convolutional neural networks (CNNs) have been widely applied in image analysis, pattern recognition, and anomaly detection. CNNs can automatically learn features from images, avoiding human bias and improving the efficiency. The multi-layer deep network structure enables CNN to extract features at different abstraction levels in images, enhancing semantic informa¬tion in images and improving its performance in various tasks such as classification, segmentation, and detection. CNN exhibits great potentials in the diagnosis, prognosis and classification of various diseases. Whereas, there are some unmet challenges in data quality and quantity, data security and privacy, model interpretability, and ethical considerations. This chapter summarizes the advantages and challenges of the state of the art, and future directions under the context of healthcare 5.0, providing a reference for clinical researchers, data scientists, and biomedical engineers. © 2024, IGI Global. All rights reserved.","","","","","IGI Global",""
"Ahmed S.Z.; Kavya K.S.; Karthik R.L.; Mani S.H.","Ahmed, Sk. Zayeem (59134384800); Kavya, K. Sri (57209259621); Karthik, R. Lalitha (59134384900); Mani, S. Hemanth (59134515900)","59134384800; 57209259621; 59134384900; 59134515900","Dental Fluorosis Analysis: A Web-Based Dental Fluorosis Severity Detection","2024","","","","","","","10.1109/INOCON60754.2024.10511698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193569767&doi=10.1109%2fINOCON60754.2024.10511698&partnerID=40&md5=684bae4c95dbca202a531574b254fca8","The success of deep learning algorithms in biomedical applications is notable, yet their application to dental hard tissue conditions, including Dental Caries, Dental Abrasion, Dental Attrition, Erosive Tooth Wear (ETW), and Fluorosis, remains underexplored, particularly in analyzing photographic images. Traditional visual examination methods for clinical diagnostics are hindered by subjectivity. With the advancement of computer technology, there is growing interest in leveraging Artificial Intelligence (AI) for dental health. Our study in Vijayawada revealed a lack of oral health awareness among residents. Collaborating with Dr. Sandhya, we identified a significant issue - dental fluorosis affects nearly 45% of residents, with many cases going undiagnosed. Early detection and intervention could potentially reduce severity by up to 70%. This paper introduces a comprehensive solution for analyzing dental fluorosis. Utilizing Convolutional Neural Network (CNN) and You Only Look Once (YOLO) architecture, our web application swiftly detects severity. The CNN model, trained on diverse data, accurately classifies severity levels, and YOLO ensures real-time analysis. Users, including patients and dental professionals, interpret severity classifications through an interactive map interface. The final classification model achieves an impressive 96% accuracy in categorizing dental fluorosis severity and an 84% precision in object detection. This convergence of advanced image detection algorithms and user-friendly interfaces marks a significant stride in advancing dental health initiatives, fostering a healthier, more informed society in Vijayawada, and beyond. © 2024 IEEE.","Biomedical Applications; Convolutional Neural Network (CNN); Deep Learning Algorithms; Dental Hard Tissue Conditions; Photographic Image Analysis; You Only Look Once (YOLO)","Bioinformatics; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Imaging systems; Learning algorithms; Medical applications; Medical imaging; Photography; Tissue; Biomedical applications; Condition; Convolutional neural network; Deep learning algorithm; Dental hard tissue condition; Dental hard tissues; Image-analysis; Photographic image; Photographic image analyse; You only look once; Object detection","","","Institute of Electrical and Electronics Engineers Inc.",""
"K L.; J M.","K, Lalitha (57218902400); J, Manjula (55792613000)","57218902400; 55792613000","Dielectric Characterization of Dispersive Head Tissue for Detection and Classification of Tumour Using Microwave Imaging Technique and Deep Learning Model","2024","","","","","","","10.1007/s13369-023-08666-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182866227&doi=10.1007%2fs13369-023-08666-z&partnerID=40&md5=58967132391a718351fe495ad3ea6132","Microwave sensing is envisioned to be a reliable imaging technique for detecting and monitoring brain tumours. It uses low-power, nonionized microwave signals to visualize the interior of the living tissues. This study automatically exploits categorization of brain tumours using a deep neural network called the YOLOv5 l algorithm in non-invasive microwave images. A modified antipodal structure (including parasitic patch between flares) that operates over the wideband is proposed for the collection of scattering parameters. The staircase parasitic patch located at the centre of the radiator provides the improved radiation performance at low frequencies. Subsequently, a simulation environment was modelled using CST Microwave Studio 2020, which contained a data acquisition system using a designed microwave antenna and head phantom. Next, the image reconstruction is implemented MATLAB software. The detection and classification of tumours were performed using the YOLOv5l model. A dataset with 500 image samples was formed by pre-processing, which was divided into training (70%), testing (15%) and validation (15%). Then, augmentation is used to create final dataset with 1000 training images. The model was successful in locating an early-stage brain tumour with a size of 5 mm. The YOLOv5 model automatically detected tumour (s) and categorized them as benign tumour or malignant tumour based on a predicted bounding box with an accuracy of 91.5%. © 2024, King Fahd University of Petroleum & Minerals.","Antipodal Vivaldi antenna; Biomedical electromagnetic imaging; Brain tumour; Inverse scattering; Microwave head imaging","","","","Institute for Ionics",""
"Krylov A.S.; Nasonov A.V.; Sorokin D.V.; Khvostikov A.V.; Pavelyeva E.A.; Pchelintsev Y.A.","Krylov, A.S. (7202280261); Nasonov, A.V. (36939493000); Sorokin, D.V. (55631871400); Khvostikov, A.V. (57188856261); Pavelyeva, E.A. (55530981800); Pchelintsev, Ya. A. (57203130129)","7202280261; 36939493000; 55631871400; 57188856261; 55530981800; 57203130129","Image Analysis and Enhancement: General Methods and Biomedical Applications","2023","33","4","","1493","1514","21","10.1134/S1054661823040235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188236830&doi=10.1134%2fS1054661823040235&partnerID=40&md5=314a8b582c0a7d2e0b3f86388d2bf8f0","Abstract: General methods of image processing, analysis and enhancement and their biomedical applications developed by the scientific school of the Laboratory of Mathematical Methods of Image Processing of the Faculty of Computational Mathematics and Cybernetics of Lomonosov Moscow State University are reviewed. The suggested general methods and algorithms of image quality enhancement for image resampling and super-resolution, ringing artifact reduction, image sharpening, image denoising, and image registration are described. Image analysis methods based on Hermite projection method, Gauss-Laguerre functions and the use of phase information are presented. We describe and review the developed methods for medical imaging tasks solution, including problems in histology, color Doppler flow mapping, ultrasound liver fibrosis diagnostics, CT brain perfusion, Alzheimer’s disease diagnostics, dermatology, chest X-ray image analysis, live cell image registration, tracking, segmentation and synthesis. The paper illustrates the basic research idea of the effectiveness of the hybrid approach when we jointly use classical mathematical methods and deep learning approaches. © Pleiades Publishing, Ltd. 2023. ISSN 1054-6618, Pattern Recognition and Image Analysis, 2023, Vol. 33, No. 4, pp. 1493–1514. Pleiades Publishing, Ltd., 2023.","cell microscopy images; convolutional neural networks; hybrid methods; image analysis; image enhancement; image processing; mathematical methods; medical images","Brain mapping; Computerized tomography; Deep learning; Diagnosis; Image analysis; Image denoising; Image registration; Image segmentation; Medical applications; Medical problems; Biomedical applications; Cell microscopy image; Convolutional neural network; General method; Hybrid method; Image-analysis; Images processing; Mathematical method; Medical image; Microscopy images; Image enhancement","University of Tokyo; National Taiwan University of Science and Technology, NTUST; Zhejiang University, ZJU, (118); Russian Science Foundation, RSF, (22‑41‑02002)","","Pleiades Publishing",""
"Hu Z.; He L.; Wu H.","Hu, Zhangfang (7404211399); He, Lingxiao (58699912100); Wu, Haoze (57210186156)","7404211399; 58699912100; 57210186156","A Multi-feature Fusion Transformer Neural Network for Motor Imagery EEG Signal Classification","2023","31","4","","1822","1831","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177065852&partnerID=40&md5=033c7c33d6ae992f3f678fcbc69aae16","In recent years, the classification method of motor imagery(MI) electroencephalography(EEG) signals based on deep learning(DL) has become more and more mature in the field of brain-computer interface(BIC). However, most of the studies tend to use a single feature or two associated features when dealing with motor imagery EEG signal classification, while ignoring other features, resulting in poor classification performance. Therefore, this paper proposes a neural network feature fusion algorithm called Multi-feature Fusion Transformer(M-FFT). The network is built based on convolutional neural network (CNN) and Transformer. This method uses CNN and wavelet transform to extract the time-frequency and space-time features, and uses the converter to fuse the three feature domains contained in the two features to establish the information interaction between the three feature domains contained in the two features. Then, the global feature pooling is used to output the feature vector, and finally the softmax function is used to classify the feature vector. In the training process, we use cross entropy as the loss function. Finally, on the brain-computer interface competition IV data set 2a, the average classification accuracy is 85.66%, and the average kappa value is 0.833. The experimental results validate the algorithm performance. © 2023, International Association of Engineers. All rights reserved.","brain-computer interface; CNN; motor imagery; multi-feature fusion; Transformer","Biomedical signal processing; Brain computer interface; Classification (of information); Convolutional neural networks; Deep learning; Electrophysiology; Image classification; Wavelet transforms; Associated feature; Classification methods; Convolutional neural network; Feature domain; Features vector; Motor imagery; Multi-feature fusion; Neural-networks; Signal classification; Transformer; Electroencephalography","National Natural Science Foundation of China, NSFC, (61703067); Chongqing Municipal Education Commission, CQMEC, (KJ1704072); Chongqing Research Program of Basic Research and Frontier Technology, (Cstc2017jcyjAX0212)","","International Association of Engineers",""
"Sonneck J.; Zhou Y.; Chen J.","Sonneck, Justin (57892839100); Zhou, Yu (58488105700); Chen, Jianxu (56352708300)","57892839100; 58488105700; 56352708300","MMV_Im2Im: an open-source microscopy machine vision toolbox for image-to-image transformation","2024","13","","giad120","","","","10.1093/gigascience/giad120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183847155&doi=10.1093%2fgigascience%2fgiad120&partnerID=40&md5=436270eaa2e3acee493454ee3e8306a9","Over the past decade, deep learning (DL) research in computer vision has been growing rapidly, with many advances in DL-based image analysis methods for biomedical problems. In this work, we introduce MMV_Im2Im, a new open-source Python package for image-to-image transformation in bioimaging applications. MMV_Im2Im is designed with a generic image-to-image transformation framework that can be used for a wide range of tasks, including semantic segmentation, instance segmentation, image restoration, image generation, and so on. Our implementation takes advantage of state-of-the-art machine learning engineering techniques, allowing researchers to focus on their research without worrying about engineering details. We demonstrate the effectiveness of MMV_Im2Im on more than 10 different biomedical problems, showcasing its general potentials and applicabilities. For computational biomedical researchers, MMV_Im2Im provides a starting point for developing new biomedical image analysis or machine learning algorithms, where they can either reuse the code in this package or fork and extend this package to facilitate the development of new methods. Experimental biomedical researchers can benefit from this work by gaining a comprehensive view of the image-to-image transformation concept through diversified examples and use cases. We hope this work can give the community inspirations on how DL-based image-to-image transformation can be integrated into the assay development process, enabling new biomedical studies that cannot be done only with traditional experimental assays. To help researchers get started, we have provided source code, documentation, and tutorials for MMV_Im2Im at [https://github.com/MMV-Lab/mmv_im2im] under MIT license. © The Author(s) 2024.","deep learning; microscopy image analysis; open-source","Algorithms; Image Processing, Computer-Assisted; Machine Learning; Microscopy; Software; Article; artificial intelligence; cell structure; cellular neural network; computer simulation; computer vision; confocal microscopy; deep learning; fluorescence microscopy; image analysis; image reconstruction; image segmentation; immunofluorescence; immunohistochemistry; learning algorithm; machine learning; microscopy; prediction; stimulated emission depletion microscopy; article; controlled study; human; vision","Ministry of Culture and Science of the State of North Rhine-Westphalia; Bundesministerium für Bildung und Forschung, BMBF, (161L0272); Bundesministerium für Bildung und Forschung, BMBF; Ministerium für Kultur und Wissenschaft des Landes Nordrhein-Westfalen, MKW NRW","","Oxford University Press","38280188"
"Rajalakshmi S.; Almohimeed I.; Sikkandar M.Y.; Sabarunisha Begum S.","Rajalakshmi, S. (58321740200); Almohimeed, Ibrahim (37033387300); Sikkandar, Mohamed Yacin (57202716139); Sabarunisha Begum, S. (58344576000)","58321740200; 37033387300; 57202716139; 58344576000","Optimal Deep Learning-Based Recognition Model for EEG Enabled Brain-Computer Interfaces Using Motor-Imagery","2023","23","6","","248","253","5","10.2478/msr-2023-0031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178051693&doi=10.2478%2fmsr-2023-0031&partnerID=40&md5=088e5017cf0c7d9b32d0b76fa666d18a","Brain-Computer Interfaces (BCIs) facilitate the translation of brain activity into actionable commands and act as a crucial link between the human brain and the external environment. Electroencephalography (EEG)-based BCIs, which focus on motor imagery, have emerged as an important area of study in this domain. They are used in neurorehabilitation, neuroprosthetics, and gaming, among other applications. Optimal Deep Learning-Based Recognition for EEG Signal Motor Imagery (ODLR-EEGSM) is a novel approach presented in this article that aims to improve the recognition of motor imagery from EEG signals. The proposed method includes several crucial stages to improve the precision and effectiveness of EEG-based motor imagery recognition. The pre-processing phase starts with the Variation Mode Decomposition (VMD) technique, which is used to improve EEG signals. The EEG signals are decomposed into different oscillatory modes by VMD, laying the groundwork for subsequent feature extraction. Feature extraction is a crucial component of the ODLR-EEGSM method. In this study, we use Stacked Sparse Auto Encoder (SSAE) models to identify significant patterns in the pre-processed EEG data. Our approach is based on the classification model using Deep Wavelet Neural Network (DWNN) optimized with Chaotic Dragonfly Algorithm (CDFA). CDFA optimizes the weight and bias values of the DWNN, significantly improving the classification accuracy of motor imagery. To evaluate the efficacy of the ODLR-EEGSM method, we use benchmark datasets to perform rigorous performance validation. The results show that our approach outperforms current methods in the classification of EEG motor imagery, confirming its promising performance. This study has the potential to make brain-computer interface applications in various fields more accurate and efficient, and pave the way for brain-controlled interactions with external systems and devices.  © 2023 S. Rajalakshmi et al., published by Sciendo.","Brain-Computer Interface (BCI); classification; Deep Learning (DL); Dragonfly algorithm; EEG Motor Imagery (MI); feature extraction","Benchmarking; Biomedical signal processing; Brain; Brain computer interface; Classification (of information); Deep learning; Electroencephalography; Electrophysiology; Extraction; Image classification; Image enhancement; Brain-computer interface; Chaotics; Deep learning; Dragonfly algorithm; EEG signals; Electroencephalography motor imagery; Features extraction; Motor imagery; Neural-networks; Recognition models; Feature extraction","","","Sciendo",""
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","14450 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178556551&partnerID=40&md5=b0b91f9a575c994470ccc3db9fb3ab6e","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"Li Y.; Qian G.; Jiang X.; Jiang Z.; Wen W.; Zhang S.; Li K.; Lao Q.","Li, Yiyue (57673043000); Qian, Guangwu (57194707775); Jiang, Xiaoshuang (55326050600); Jiang, Zekun (57212001989); Wen, Wen (57421169100); Zhang, Shaoting (13605200100); Li, Kang (57445059900); Lao, Qicheng (36134454100)","57673043000; 57194707775; 55326050600; 57212001989; 57421169100; 13605200100; 57445059900; 36134454100","Hierarchical-Instance Contrastive Learning for Minority Detection on Imbalanced Medical Datasets","2024","43","1","","416","426","10","10.1109/TMI.2023.3310716","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170552526&doi=10.1109%2fTMI.2023.3310716&partnerID=40&md5=cfc0b7a18612ccbe0f9de73bd2b43abe","Deep learning methods are often hampered by issues such as data imbalance and data-hungry. In medical imaging, malignant or rare diseases are frequently of minority classes in the dataset, featured by diversified distribution. Besides that, insufficient labels and unseen cases also present conundrums for training on the minority classes. To confront the stated problems, we propose a novel Hierarchical-instance Contrastive Learning (HCLe) method for minority detection by only involving data from the majority class in the training stage. To tackle inconsistent intra-class distribution in majority classes, our method introduces two branches, where the first branch employs an auto-encoder network augmented with three constraint functions to effectively extract image-level features, and the second branch designs a novel contrastive learning network by taking into account the consistency of features among hierarchical samples from majority classes. The proposed method is further refined with a diverse mini-batch strategy, enabling the identification of minority classes under multiple conditions. Extensive experiments have been conducted to evaluate the proposed method on three datasets of different diseases and modalities. The experimental results show that the proposed method outperforms the state-of-the-art methods. © 1982-2012 IEEE.","Data imbalance; hierarchical instance; medical image analysis; minority detection","Anomaly detection; Deep learning; Diseases; Feature extraction; Medical imaging; Anomaly detection; Biomedical imaging; Cancer; Data imbalance; Features extraction; Hierarchical instance; Images reconstruction; Learning methods; Medical image analysis; Minority detection; Article; autoencoder; clinical practice; controlled study; deep learning; detection algorithm; diagnostic accuracy; diagnostic imaging; diagnostic test accuracy study; embedding; feature extraction; glaucoma; hierarchical instance contrastive learning; human; image reconstruction; malignant neoplasm; multilayer perceptron; noise; nuclear magnetic resonance imaging; outlier detection; rare disease; receiver operating characteristic; residual neural network; supervised machine learning; thorax radiography; Image reconstruction","","","Institute of Electrical and Electronics Engineers Inc.","37651492"
"Wu H.; Lu H.; Ping M.; Zhu W.; Li Z.","Wu, Hongli (57796712300); Lu, Huijuan (55729819200); Ping, Mingzhu (57796619100); Zhu, Wenjie (57217050076); Li, Zhao (57191700056)","57796712300; 55729819200; 57796619100; 57217050076; 57191700056","A Deep Learning Method for Pneumonia Detection Based on Fuzzy Non-Maximum Suppression","2024","21","4","","902","911","9","10.1109/TCBB.2023.3247483","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149418789&doi=10.1109%2fTCBB.2023.3247483&partnerID=40&md5=ac5ea2f2a002e4d56b6955c7593bde58","Pneumonia is one of the largest causes of death in the world. Deep learning techniques can assist doctors to detect the areas of pneumonia in the chest X-rays images. However, existing methods lack sufficient consideration for the large variation scale and the blurred boundary of the pneumonia area. Here, we present a deep learning method based on Retinanet for pneumonia detection. First, we introduce Res2Net into Retinanet to get the multi-scale feature of pneumonia. Then, we proposed a novel predicted boxes fusion algorithm, named Fuzzy Non-Maximum Suppression (FNMS), which gets a more robust predicted box by fusing the overlapping detection boxes. Finally, we get the performance outperforms than existing methods by integrating two models with different backbones. We report the experimental result in the single model case and the model ensemble case. In the single model case, RetinaNet with FNMS algorithm and Res2Net backbone is better than RetinaNet and other models. In the model ensemble case, the final score of predicted boxes that fused by the FNMS algorithm is better than NMS, Soft-NMS, and weighted boxes fusion. Experimental results on the pneumonia detection dataset verify the superiority of the FNMS algorithm and the proposed method in the pneumonia detection task.  © 2004-2012 IEEE.","Biomedical image; deep learning; model ensemble; pneumonia detection","Algorithms; Deep Learning; Fuzzy Logic; Humans; Pneumonia; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Bioinformatics; Deep neural networks; Job analysis; Biomedical images; Convolutional neural network; Deep learning; Features extraction; Model ensembles; Pneumonia detection; Prediction algorithms; Predictive models; Task analysis; algorithm; computer assisted diagnosis; deep learning; diagnosis; diagnostic imaging; fuzzy logic; human; pneumonia; procedures; thorax radiography; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.","37027655"
"Gupta K.; Bajaj V.; Jain D.K.; Hussain A.","Gupta, Kapil (57198261212); Bajaj, Varun (57209289122); Jain, Deepak Kumar (56206778300); Hussain, Amir (19734290900)","57198261212; 57209289122; 56206778300; 19734290900","Multi-model deep learning system for screening human monkeypox using skin images","2024","","","","","","","10.1111/exsy.13651","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195513858&doi=10.1111%2fexsy.13651&partnerID=40&md5=2acc0808aed8db5dfb2a71d421dcb4e9","Purpose: Human monkeypox (MPX) is a viral infection that transmits between individuals via direct contact with animals, bodily fluids, respiratory droplets, and contaminated objects like bedding. Traditional manual screening for the MPX infection is a time-consuming process prone to human error. Therefore, a computer-aided MPX screening approach utilizing skin lesion images to enhance clinical performance and alleviate the workload of healthcare providers is needed. The primary objective of this work is to devise an expert system that accurately classifies MPX images for the automatic detection of MPX subjects. Methods: This work presents a multi-modal deep learning system through the fusion of convolutional neural network (CNN) and machine learning algorithms, which effectively and autonomously detect MPX-infected subjects using skin lesion images. The proposed framework, termed MPXCN-Net is developed by fusing deep features of three pre-trained CNNs: MobileNetV2, DarkNet19, and ResNet18. Three classifiers—K-nearest neighbour, support vector machine (SVM), and ensemble classifier—with various kernel functions, are used to identify infected patients. To validate the efficacy of our proposed system, we employ a publicly accessible MPX skin lesion dataset. Results: By amalgamating features extracted from all three CNNs and utilizing the medium Gaussian kernel of the SVM classifier, our proposed system achieves an outstanding average classification accuracy of 90.4%. Conclusions: Developed MPXCN-Net is suitable for testing with a large diversified dataset before being used in clinical settings. © 2024 John Wiley & Sons Ltd.","biomedical image classification; convolutional neural network; machine learning algorithm; monkeypox infection","Bioinformatics; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Expert systems; Image classification; Image enhancement; Large datasets; Learning algorithms; Nearest neighbor search; Statistical tests; Support vector machines; Biomedical image classification; Biomedical images; Convolutional neural network; Images classification; Machine learning algorithms; Monkeypox infection; Multi-modelling; Skin images; Skin lesion images; Support vector machine classifiers; Learning systems","Engineering and Physical Sciences Research Council, EPSRC, (EP/T021063/1, EP/T024917/1)","","John Wiley and Sons Inc",""
"Thamilselvan R.; Kalpana T.; Natesan P.; Sheik Alaudeen Y.; Surendiran S.; Showket S.","Thamilselvan, R. (56683185600); Kalpana, T. (57921074200); Natesan, P. (56829436200); Sheik Alaudeen, Y. (59155407600); Surendiran, S. (59155307400); Showket, Sayeem (59155407700)","56683185600; 57921074200; 56829436200; 59155407600; 59155307400; 59155407700","Autism Spectrum Disorder Diagnosis using Deep Learning Techniques","2024","","","","402","407","5","10.1109/ICC-ROBINS60238.2024.10533978","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195123955&doi=10.1109%2fICC-ROBINS60238.2024.10533978&partnerID=40&md5=bef1a0ea8d420436151b6d91d7c4f7eb","Autism spectrum disorder (ASD) represents a neurological condition rather than a mental illness, characterized by atypical brain development that can subsequently manifest in distinct facial features. Children with ASD often exhibit unique facial landmarks that differentiate them from Typically Developed individuals. This pioneering research introduces a novel approach, focusing on the detection of ASD through the analysis of both social media data and biomedical images, specifically by harnessing the power of face recognition technology and Convolutional Neural Networks (CNN). Deep learning techniques are precise identification of these facial features. The research aims to benefit both communities and mental health professionals by providing an accessible web application based on a CNN with transfer learning and Flask integration. In this refined approach, two robust models are exclusively retained, DenseNet121 with an accuracy of 54% and EfficientNetB0 with an impressive 90% accuracy rate. These models are intended for improving the accuracy and convenience for determining ASD using face traits, which will simplify the process of early diagnosis and intervention for those who need it. The dataset contains 2,940 images of faces that were retrieved from the Kaggle platform. Standard evaluation metrics are used to evaluate the effectiveness of the two CNN models, including sensitivity, specificity and accuracy. This research hopes to help people with ASD by finding a way to identify it early. Early help is very important for making things better for people with autism. So, the study aims to create a useful tool that can tell if someone might have ASD when the patients are very young.  © 2024 IEEE.","accuracy; Autism; DenseNet121; EfficientNetB0; Facial expression","Convolutional neural networks; Deep learning; Diseases; Face recognition; Learning algorithms; Learning systems; Neural network models; Transfer learning; Accuracy; Autism; Autism spectrum disorders; Condition; Convolutional neural network; Densenet121; Efficientnetb0; Facial Expressions; Facial feature; Learning techniques; Diagnosis","","","Institute of Electrical and Electronics Engineers Inc.",""
"Al-Shahari E.A.; Obayya M.; Alotaibi F.A.; Alsafari S.; Salama A.S.; Assiri M.","Al-Shahari, Eman A. (57218120186); Obayya, Marwa (6505869929); Alotaibi, Faiz Abdullah (57217736578); Alsafari, Safa (57218956797); Salama, Ahmed S. (56480035100); Assiri, Mohammed (57219344932)","57218120186; 6505869929; 57217736578; 57218956797; 56480035100; 57219344932","Accelerating biomedical image segmentation using equilibrium optimization with a deep learning approach","2024","9","3","","5905","5924","19","10.3934/math.2024288","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183902386&doi=10.3934%2fmath.2024288&partnerID=40&md5=5e3b7178cfd3a22e5cb4a4ddde2303ce","Biomedical image segmentation is a vital task in the analysis of medical imaging, including the detection and delineation of pathological regions or anatomical structures within medical images. It has played a pivotal role in a variety of medical applications, involving diagnoses, monitoring of diseases, and treatment planning. Conventionally, clinicians or expert radiologists have manually conducted biomedical image segmentation, which is prone to human error, subjective, and time-consuming. With the advancement in computer vision and deep learning (DL) algorithms, automated and semi-automated segmentation techniques have attracted much research interest. DL approaches, particularly convolutional neural networks (CNN), have revolutionized biomedical image segmentation. With this motivation, we developed a novel equilibrium optimization algorithm with a deep learning-based biomedical image segmentation (EOADL-BIS) technique. The purpose of the EOADL-BIS technique is to integrate EOA with the Faster RCNN model for an accurate and efficient biomedical image segmentation process. To accomplish this, the EOADL-BIS technique involves Faster R-CNN architecture with ResNeXt as a backbone network for image segmentation. The region proposal network (RPN) proficiently creates a collection of a set of region proposals, which are then fed into the ResNeXt for classification and precise localization. During the training process of the Faster RCNN algorithm, the EOA was utilized to optimize the hyperparameter of the ResNeXt model which increased the segmentation results and reduced the loss function. The experimental outcome of the EOADL-BIS algorithm was tested on distinct benchmark medical image databases. The experimental results stated the greater efficiency of the EOADL-BIS algorithm compared to other DL-based segmentation approaches. © 2024 the Author(s).","biomedical image segmentation; computer vision; deep learning; equilibrium optimizer; image processing","","Abdulrahman University, (PNURSP2023R203); Prince Sattam bin Abdulaziz University, PSAU, (PSAU/2023/R/1444); King Saud University, KSU; Princess Nourah Bint Abdulrahman University, PNU, (RSPD2024R838); Deanship of Scientific Research, King Khalid University, (RGP2/ 242 /44); Future University in Egypt, FUE","","American Institute of Mathematical Sciences",""
"","","","2nd International Conference on Biomedical Engineering Science and Technology, ICBEST 2023","2024","2003 CCIS","","","","","432","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189549974&partnerID=40&md5=165a2379c0787f76e946443c8bffdbea","The proceedings contain 32 papers. The special focus in this conference is on Biomedical Engineering Science and Technology. The topics include: Performance Analysis of Recent Algorithms for Compression of Various Medical Images; smart Gaming System for Hand Rehabilitation; an Ample Review of Various Deep Learning Skills for Identifying the Stages of Sleep; Deep Transfer Learning for Schizophrenia Detection Using Brain MRI; an Efficient Approach for Early Prediction of Sudden Cardiac Death Using Two-Stage Feature Selection and Gradient Boosting Classification; malware Detection Framework Based on Iterative Neighborhood Component Analysis for Internet of Medical Things; an Artificial Intelligence-Driven Deep Learning Model for Chest X-ray Image Segmentation; Deep Learning Approaches for Early Detection of Obstructive Sleep Apnea Using Single-Channel ECG: A Systematic Literature Review; Performance Evaluation of Vanilla, Residual, and Dense 2D U-Net Architectures for Skull Stripping of Augmented 3D T1-Weighted MRI Head Scans; EEG Based Classification of Learning Disability in Children Using Pretrained Network and Support Vector Machine; a Two-Level Classifier for Prediction of Healthy and Unhealthy Lung Sounds Using Machine Learning and Convolutional Neural Network; Classification of Meditation Expertise from EEG Signals Using Shallow Neural Networks; efficient Model for Prediction of Parkinson's Disease Using Machine Learning Algorithms with Hybrid Feature Selection Methods; Classification of EEG Signals for Epilepsy Detection Using PCA Analysis; white Blood Cell Classification Using Deep Transfer Learning; A Novel Feature Selection Algorithm for the Detection of Obstructive Sleep Apnea by Using Heart Rate Variability and ECG Derived Respiratory Analysis; Apnea Controlled CPAP for Obstructuve Sleep Patient.","","","","Singh B.; Sinha G.R.; Pandey R.","Springer Science and Business Media Deutschland GmbH",""
"Sturekova J.; Kamencay P.; Skrvan A.; Hlavata R.","Sturekova, Jana (58061159200); Kamencay, Patrik (44261326300); Skrvan, Adam (57796329600); Hlavata, Roberta (59202904200)","58061159200; 44261326300; 57796329600; 59202904200","A Benchmark Study of Deep Learning Algorithms for PPG Signal Processing","2024","","","","","","","10.1109/ELEKTRO60337.2024.10557075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197447549&doi=10.1109%2fELEKTRO60337.2024.10557075&partnerID=40&md5=7a1c43ab1afc933afb7cd11adba34c8f","This study delves into extracting Photoplethysmography (PPG) signals from images using various neural network architectures. The research aims to assess the effectiveness of different models in capturing PPG values from snapshots of the dataset. Two training approaches were investigated: pretraining the model with only the fully connected part being trained or training the entire network. Results demonstrate that the models trained from scratch outperform their pretrained counterparts. Among the architectures, DenseNet121 shows the most promising results. The findings highlight the potential of utilising neural networks for PPG signal extraction, with applications ranging from surgical planning to personalised medical treatments. This research represents a significant stride in integrating advanced imaging techniques and neural networks in biomedical engineering. © 2024 IEEE.","biomedical data; neural network; non-contact vital sign detection; Photoplethysmography; Remote Photoplethymosgraphy","Biomedical engineering; Deep learning; Network architecture; Neural networks; Signal detection; Benchmark study; Biomedical data; Neural network architecture; Neural-networks; Non-contact; Non-contact vital sign detection; Pre-training; Remote photoplethymosgraphy; Signal-processing; Vital signs detections; Photoplethysmography","Slovak Research and Development Agency, (APVV-21-0502, PP-COVID-20-0100)","Hockicko P.; Dubovan J.","Institute of Electrical and Electronics Engineers Inc.",""
"Zhang Y.; Ye X.; Wu W.; Luo Y.; Chen M.; Du Y.; Wen Y.; Song H.; Liu Y.; Zhang G.; Wang L.","Zhang, Yinsheng (55265270900); Ye, Xin (58595037000); Wu, Wenhua (58087882900); Luo, Yingqun (58087883000); Chen, Miaohong (57190662583); Du, Yueshanyi (58028689800); Wen, Yu (57226441158); Song, Houbing (57199094588); Liu, Yaling (57963905900); Zhang, Guoming (55738989600); Wang, Li (57226450882)","55265270900; 58595037000; 58087882900; 58087883000; 57190662583; 58028689800; 57226441158; 57199094588; 57963905900; 55738989600; 57226450882","Morphological Rule-Constrained Object Detection of Key Structures in Infant Fundus Image","2024","21","4","","1031","1041","10","10.1109/TCBB.2023.3234100","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147275519&doi=10.1109%2fTCBB.2023.3234100&partnerID=40&md5=aa430a913f626276e2ff7d813411cf89","The detection of optic disc and macula is an essential step for ROP (Retinopathy of prematurity) zone segmentation and disease diagnosis. This paper aims to enhance deep learning-based object detection with domain-specific morphological rules. Based on the fundus morphology, we define five morphological rules, i.e., number restriction (maximum number of optic disc and macula is one), size restriction (e.g., optic disc width: 1.05 +/- 0.13 mm), distance restriction (distance between the optic disc and macula/fovea: 4.4 +/- 0.4 mm), angle/slope restriction (optic disc and macula should roughly be positioned in the same horizontal line), position restriction (In OD, the macula is on the left side of the optic disc; vice versa for OS). A case study on 2953 infant fundus images (with 2935 optic disc instances and 2892 macula instances) proves the effectiveness of the proposed method. Without the morphological rules, naïve object detection accuracies of optic disc and macula are 0.955 and 0.719, respectively. With the proposed method, false-positive ROIs (region of interest) are further ruled out, and the accuracy of the macula is raised to 0.811. The IoU (intersection over union) and RCE (relative center error) metrics are also improved.  © 2004-2012 IEEE.","deep learning; macula; Object detection; optic disc; retinopathy of prematurity","Algorithms; Deep Learning; Fundus Oculi; Humans; Image Interpretation, Computer-Assisted; Infant; Infant, Newborn; Macula Lutea; Optic Disk; Retinopathy of Prematurity; Adaptive optics; Deep learning; Diagnosis; Image segmentation; Integrated optics; Neural networks; Object recognition; Optical image storage; Biomedical optical imaging; Convolutional neural network; Fundus image; Key structures; Morphological rules; Objects detection; Optic disks; Optical imaging; Retina; Retinopathy of prematurity; algorithm; computer assisted diagnosis; deep learning; diagnosis; diagnostic imaging; eye fundus; human; infant; newborn; optic disk; procedures; retina macula lutea; retrolental fibroplasia; Object detection","","","Institute of Electrical and Electronics Engineers Inc.","37018340"
"Xing W.; Yang Y.; Zhou Y.; Jiang T.; Li Y.; Song Y.; Hou D.; Ta D.","Xing, Wenyu (57203964459); Yang, Yanping (58691087500); Zhou, Yannan (57208900261); Jiang, Tao (58377132300); Li, Yifang (57210346439); Song, Yuanlin (58885730900); Hou, Dongni (57190855710); Ta, Dean (6701758419)","57203964459; 58691087500; 57208900261; 58377132300; 57210346439; 58885730900; 57190855710; 6701758419","Weakly-Supervised Segmentation-Based Quantitative Characterization of Pulmonary Cavity Lesions in CT Scans","2024","12","","","457","467","10","10.1109/JTEHM.2024.3399261","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192734513&doi=10.1109%2fJTEHM.2024.3399261&partnerID=40&md5=c1960c726eab6fc3c5fa037f1a4996b0","Objective: Pulmonary cavity lesion is one of the commonly seen lesions in lung caused by a variety of malignant and non-malignant diseases. Diagnosis of a cavity lesion is commonly based on accurate recognition of the typical morphological characteristics. A deep learning-based model to automatically detect, segment, and quantify the region of cavity lesion on CT scans has potential in clinical diagnosis, monitoring, and treatment efficacy assessment. Methods: A weakly-supervised deep learning-based method named CSA2-ResNet was proposed to quantitatively characterize cavity lesions in this paper. The lung parenchyma was firstly segmented using a pretrained 2D segmentation model, and then the output with or without cavity lesions was fed into the developed deep neural network containing hybrid attention modules. Next, the visualized lesion was generated from the activation region of the classification network using gradient-weighted class activation mapping, and image processing was applied for post-processing to obtain the expected segmentation results of cavity lesions. Finally, the automatic characteristic measurement of cavity lesions (e.g., area and thickness) was developed and verified. Results: the proposed weakly-supervised segmentation method achieved an accuracy, precision, specificity, recall, and F1-score of 98.48%, 96.80%, 97.20%, 100%, and 98.36%, respectively. There is a significant improvement (P < 0.05) compared to other methods. Quantitative characterization of morphology also obtained good analysis effects. Conclusions: The proposed easily-trained and high-performance deep learning model provides a fast and effective way for the diagnosis and dynamic monitoring of pulmonary cavity lesions in clinic. Clinical and Translational Impact Statement: This model used artificial intelligence to achieve the detection and quantitative analysis of pulmonary cavity lesions in CT scans. The morphological features revealed in experiments can be utilized as potential indicators for diagnosis and dynamic monitoring of patients with cavity lesions  © 2013 IEEE.","CSAÂ²-ResNet; Grad-CAM; Pulmonary cavity lesion; quantitative characterization.; weakly-supervised segmentation","Algorithms; Deep Learning; Humans; Lung; Lung Diseases; Lung Neoplasms; Neural Networks, Computer; Radiographic Image Interpretation, Computer-Assisted; Supervised Machine Learning; Tomography, X-Ray Computed; Biological organs; Chemical activation; Computerized tomography; Deep neural networks; Diagnosis; Job analysis; Medical imaging; Biomedical imaging; Computed tomography; Features extraction; Grad-CAM; Images segmentations; Lesion; Lung; Pulmonary cavity lesion; Quantitative characterization; Supervised segmentation; Task analysis; Weakly-supervised segmentation; adult; aged; Article; aspergilloma; channel and spatial attention module residual neural network; clinical article; computer assisted tomography; deep neural network; diagnostic accuracy; human; image processing; image segmentation; intermethod comparison; lung abscess; lung cavity; lung parenchyma; lung tuberculosis; lung tumor; quantitative analysis; residual neural network; retrospective study; algorithm; artificial neural network; computer assisted diagnosis; deep learning; diagnostic imaging; lung; lung disease; pathology; procedures; supervised machine learning; x-ray computed tomography; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.","38899144"
"Wang C.; Liu X.; Zhang Y.; Sun Y.; Yu Z.; Zheng Z.","Wang, Chang (57192599956); Liu, Xinyu (57360447600); Zhang, Yang (58105146600); Sun, Yan (57214760526); Yu, Zeqing (57219626992); Zheng, Zhenrong (8293050600)","57192599956; 57360447600; 58105146600; 57214760526; 57219626992; 8293050600","Dual-Channel Switchable Metasurface Filters for Compact Spectral Imaging with Deep Compressive Reconstruction","2023","13","21","2854","","","","10.3390/nano13212854","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176603645&doi=10.3390%2fnano13212854&partnerID=40&md5=ca8a2c3db65640e39a5c66b1730721aa","Spectral imaging technology, which aims to capture images across multiple spectral channels and create a spectral data cube, has been widely utilized in various fields. However, conventional spectral imaging systems face challenges, such as slow acquisition speed and large size. The rapid development of optical metasurfaces, capable of manipulating light fields versatilely and miniaturizing optical components into ultrathin planar devices, offers a promising solution for compact hyperspectral imaging (HSI). This study proposes a compact snapshot compressive spectral imaging (SCSI) system by leveraging the spectral modulations of metasurfaces with dual-channel switchable metasurface filters and employing a deep-learning-based reconstruction algorithm. To achieve compactness, the proposed system integrates dual-channel switchable metasurface filters using twisted nematic liquid crystals (TNLCs) and anisotropic titanium dioxide (TiO2) nanostructures. These thin metasurface filters are closely attached to the image sensor, resulting in a compact system. The TNLCs possess a broadband linear polarization conversion ability, enabling the rapid switching of the incidence polarization state between x-polarization and y-polarization by applying different voltages. This polarization conversion facilitates the generation of two groups of transmittance spectra for wavelength-encoding, providing richer information for spectral data cube reconstruction compared to that of other snapshot compressive spectral imaging techniques. In addition, instead of employing classic iterative compressive sensing (CS) algorithms, an end-to-end residual neural network (ResNet) is utilized to reconstruct the spectral data cube. This neural network leverages the 2-frame snapshot measurements of orthogonal polarization channels. The proposed hyperspectral imaging technology demonstrates superior reconstruction quality and speed compared to those of the traditional compressive hyperspectral image recovery methods. As a result, it is expected that this technology will have substantial implications in various domains, including but not limited to object detection, face recognition, food safety, biomedical imaging, agriculture surveillance, and so on. © 2023 by the authors.","deep learning; hyperspectral imaging; optical metasurface","","National Key Research and Development Program of China, NKRDPC, (2022YFF0705500)","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Fu S.; Xu J.; Chang S.; Yang L.; Ling S.; Cai J.; Chen J.; Yuan J.; Cai Y.; Zhang B.; Huang Z.; Yang K.; Sui W.; Xue L.; Zhao Q.","Fu, Suzhong (58347547600); Xu, Jing (58409359800); Chang, Shilong (57219129497); Yang, Luyao (58349443700); Ling, Shuting (57863451000); Cai, Jinghan (58348179700); Chen, Jiayin (58296662600); Yuan, Jiacheng (58346902600); Cai, Ying (58350710100); Zhang, Bei (57224824489); Huang, Zicheng (57439391300); Yang, Kun (57190298844); Sui, Wenhai (55734549200); Xue, Linyan (56502906800); Zhao, Qingliang (55659267000)","58347547600; 58409359800; 57219129497; 58349443700; 57863451000; 58348179700; 58296662600; 58346902600; 58350710100; 57224824489; 57439391300; 57190298844; 55734549200; 56502906800; 55659267000","Robust Vascular Segmentation for Raw Complex Images of Laser Speckle Contrast Based on Weakly Supervised Learning","2024","43","1","","39","50","11","10.1109/TMI.2023.3287200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162884877&doi=10.1109%2fTMI.2023.3287200&partnerID=40&md5=3b12f7fac3846af9edbaf3847fd08842","Laser speckle contrast imaging (LSCI) is widely used for in vivo real-time detection and analysis of local blood flow microcirculation due to its non-invasive ability and excellent spatial and temporal resolution. However, vascular segmentation of LSCI images still faces a lot of difficulties due to numerous specific noises caused by the complexity of blood microcirculation's structure and irregular vascular aberrations in diseased regions. In addition, the difficulties of LSCI image data annotation have hindered the application of deep learning methods based on supervised learning in the field of LSCI image vascular segmentation. To tackle these difficulties, we propose a robust weakly supervised learning method, which selects the threshold combinations and processing flows instead of labor-intensive annotation work to construct the ground truth of the dataset, and design a deep neural network, FURNet, based on UNet++ and ResNeXt. The model obtained from training achieves high-quality vascular segmentation and captures multi-scene vascular features on both constructed and unknown datasets with good generalization. Furthermore, we intravital verified the availability of this method on a tumor before and after embolization treatment. This work provides a new approach for realizing LSCI vascular segmentation and also makes a new application-level advance in the field of artificial intelligence-assisted disease diagnosis. © 1982-2012 IEEE.","Blood flow; convolutional neural network (CNN); laser speckle contrast imaging (LSCI); vascular segmentation; weakly supervised learning","Artificial Intelligence; Image Processing, Computer-Assisted; Lasers; Microcirculation; Neural Networks, Computer; Supervised Machine Learning; Blood; Blood vessels; Complex networks; Deep neural networks; Diagnosis; Medical imaging; Microcirculation; Speckle; Supervised learning; Annotation; Biomedical imaging; Blood flow; Convolutional neural network; Images segmentations; Laser speckle contrast imaging; Speckle; Vascular segmentations; Weakly supervised learning; Article; artificial embolization; artificial intelligence; blood flow; blood flow velocity; body surface; cancer staging; cancer transplantation; controlled study; convolutional neural network; deep learning; deep neural network; image processing; image segmentation; k means clustering; laser speckle contrast imaging; Markov random field; microcirculation; morphology; noise reduction; nonhuman; prediction; segmentation algorithm; signal noise ratio; supervised machine learning; artificial intelligence; artificial neural network; physiology; procedures; supervised machine learning; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.","37335795"
"Zhang Y.; Yu Y.; Wang B.; Shen H.; Lu G.; Liu Y.; Zeng L.-L.; Hu D.","Zhang, Yifan (57223918168); Yu, Yang (55731519100); Wang, Bo (57282269900); Shen, Hui (35436091400); Lu, Gai (57759179600); Liu, Yingxin (57296548900); Zeng, Ling-Li (35147001500); Hu, Dewen (7402585423)","57223918168; 55731519100; 57282269900; 35436091400; 57759179600; 57296548900; 35147001500; 7402585423","Graph Learning With Co-Teaching for EEG-Based Motor Imagery Recognition","2023","15","4","","1722","1731","9","10.1109/TCDS.2022.3174660","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132528415&doi=10.1109%2fTCDS.2022.3174660&partnerID=40&md5=9f7aa5b83a05685d0ed06536cdb4927e","Previous studies have explored the use of deep neural networks for electroencephalography (EEG)-based motor imagery (MI) recognition, but most of the models focus on the recognition performance achieved for a single subject and are challenging to transfer due to individual differences and low signal-to-noise-ratio of EEG signals. To date, few studies have paid attention to the balance between generalizability and personalization across subjects. To this end, we propose a co-teaching graph learning method for cross-subject EEG-based MI recognition. First, A novel graph learning approach is designed to improve feature extraction from a typical graph structure containing raw EEG signals. Second, two graph learning models are constructed to filter noisy data by using a co-teaching training strategy, preventing overfitting on noisy samples obtained from different subjects. The proposed model shows a 5.4% and 3.2% increase in accuracy of single- and multisubject four-class MI recognition tasks compared to the previous best method, respectively. Experimental results also demonstrate that it is easy to derive a model that can represent generic knowledge of multiple MI subjects and can be fine-tuned efficiently for new subjects. © 2022 IEEE.","Co-teaching; electroencephalography (EEG); graph learning; motor imagery (MI)","Biomedical signal processing; Brain; Classification (of information); Deep neural networks; Electroencephalography; Electrophysiology; Extraction; Image recognition; Job analysis; Signal to noise ratio; Brain modeling; Classification algorithm; Co-teaching; Convolutional neural network; EEG signals; Features extraction; Graph learning; Motor imagery; Motor imagery.; Task analysis; Feature extraction","Defense Industrial Technology Development Program, (JCKY2020550B003, U19A2083); National Natural Science Foundation of China, NSFC, (61722313, 62006239); Fok Ying Tung Education Foundation, FYTEF, (161057); National Key Research and Development Program of China, NKRDPC, (2018YFB1305101)","","Institute of Electrical and Electronics Engineers Inc.",""
"Windarto A.P.; Yuhandri Y.; Bukhori S.","Windarto, Agus Perdana (57197780326); Yuhandri, Y. (57195139282); Bukhori, Saiful (37071915000)","57197780326; 57195139282; 37071915000","Bibliometric Analysis of Image Segmentation with Deep Learning: An Analytical Study","2024","845","","","61","79","18","10.1007/978-981-99-8498-5_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187794558&doi=10.1007%2f978-981-99-8498-5_6&partnerID=40&md5=000b9760c726c26ac9196219379f1add","This study presents a comprehensive bibliometric analysis of research pertaining to the utilization of deep learning techniques for image segmentation using CNN algorithms. A dataset comprising 1078 publications from journals and conference proceedings between 2018 and 2022 was examined through keyword search, co-occurrence network analysis, and keyphrase analysis. The study offers valuable insights into the present research landscape and identifies prominent areas of investigation, encompassing deep learning's application in medical imaging, disease detection, and object detection. Our analysis reveals China as a leading contributor to deep learning research for image segmentation, with 279 publications and 4,380 citations in Scopus. Advances in Biomedical Optics and Imaging—Proceedings of SPIE are pinpointed as the most productive source for deep learning research in image segmentation, with a specific emphasis on biomedical optics and imaging. The co-occurrence network analysis highlights the red cluster primarily focusing on methods and algorithms associated with deep learning in image segmentation. In contrast, the blue cluster demonstrates the application of these methods and algorithms to other objects or methods, with the “human” node standing out in terms of frequency and centrality. Our keyphrase analysis reveals the growing trend of Cellular Artificial Neural Networks over the past five years, indicating a shift in research focus toward this domain. Overall, this study's findings demonstrate the potential of deep learning to deliver precise and efficient segmentation of medical images, thereby enhancing clinical outcomes and patient care. Furthermore, our study contributes to an enhanced understanding of the current research landscape and identifies avenues for future exploration in deep learning techniques for image segmentation. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Bibliometric; Cellular Artificial Neural Networks; Convolutional neural networks; Deep learning; Image segmentation","Clustering algorithms; Convolutional neural networks; Deep neural networks; Image enhancement; Learning algorithms; Learning systems; Medical imaging; Object detection; Search engines; Bibliometric; Bibliometrics analysis; Cellular artificial neural network; Cellulars; Co-occurrence networks; Convolutional neural network; Deep learning; Images segmentations; Key-phrase; Learning techniques; Image segmentation","","Tan A.; Zhu F.; Jiang H.; Mostafa K.; Yap E.H.; Chen L.; Olule L.J.A.; Myung H.","Springer Science and Business Media Deutschland GmbH",""
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","1966 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178645226&partnerID=40&md5=cb77862583ffbc833416c3a13f9affec","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"Liu W.; Ni Z.; Chen Q.; Ni L.","Liu, Wentao (58608388100); Ni, Zhiwei (7102668071); Chen, Qian (57195062207); Ni, Liping (14033294200)","58608388100; 7102668071; 57195062207; 14033294200","Attention-Guided Partial Domain Adaptation for Automated Pneumonia Diagnosis From Chest X-Ray Images","2023","27","12","","5848","5859","11","10.1109/JBHI.2023.3313886","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171743399&doi=10.1109%2fJBHI.2023.3313886&partnerID=40&md5=2d828cb0563afbd66a4a546944bc19b7","Deep neural networks (DNN) supported by multicenter large-scale Chest X-Ray (CXR) datasets can efficiently perform tasks such as disease identification, lesion segmentation, and report generation. However, the non-ignorable inter-domain heterogeneity caused by different equipment, ethnic groups, and scanning protocols may lead to dramatic degradation in model performance. Unsupervised domain adaptation (UDA) methods help alleviate the cross-domain discrepancy for subsequent analysis. Nevertheless, they may be prone to: 1) spatial negative transfer: misaligning non-transferable regions which have inadequate knowledge, and 2) semantic negative transfer: failing to extend to scenarios where the label spaces of the source and target domain are partially shared. In this work, we propose a classification-based framework named attention-guided partial domain adaptation (AGPDA) network for overcoming these two negative transfer challenges. AGPDA is composed of two key modules: 1) a region attention discrimination block (RADB) to generate fine-grained attention value via lightweight region-wise multi-adversarial networks. 2) a residual feature recalibration block (RFRB) trained with class-weighted maximum mean discrepancy (MMD) loss for down-weighing the irrelevant source samples. Extensive experiments on two publicly available CXR datasets containing a total of 8598 pneumonia (viral, bacterial, and COVID-19) cases, 7163 non-pneumonia or healthy cases, demonstrate the superior performance of our AGPDA. Especially on three partial transfer tasks, AGPDA significantly increases the accuracy, sensitivity, and F1 score by 4.35%, 4.05%, and 1.78% compared to recently strong baselines.  © 2023 IEEE.","adversarial learning; domain adaptation; negative transfer; Pneumonia diagnosis","COVID-19; COVID-19 Testing; Health Status; Humans; Pneumonia; Thorax; X-Rays; COVID-19; Deep neural networks; Diagnosis; Image segmentation; Job analysis; Medical imaging; Pulmonary diseases; X ray analysis; Adversarial learning; Biomedical imaging; Chest X-ray image; Domain adaptation; Lesion; Lung; Negative transfer; Pneumonia diagnose; Task analysis; X-ray imaging; algorithm; Article; attention; clinical article; coronavirus disease 2019; deep neural network; entropy; ethnic group; human; learning; lung disease; machine learning; nerve cell network; pneumonia; semantics; sensitivity and specificity; thorax radiography; training; clinical trial; coronavirus disease 2019; COVID-19 testing; diagnostic imaging; health status; multicenter study; thorax; X ray; Semantics","Anhui Provincial Science and Technology, (201903a05020020); National Natural Science Foundation of China, NSFC, (91546108); Ministry of Education of the People's Republic of China, MOE; Natural Science Foundation of Anhui Province, (1908085QG298); Fundamental Research Funds for the Central Universities, (PA2023IISL0093); Hefei University of Technology, HFUT","","Institute of Electrical and Electronics Engineers Inc.","37695960"
"Chen T.; Wang C.; Chen Z.; Lei Y.; Shan H.","Chen, Tao (57192810199); Wang, Chenhui (58221208100); Chen, Zhihao (58739646800); Lei, Yiming (57212474679); Shan, Hongming (57191481929)","57192810199; 58221208100; 58739646800; 57212474679; 57191481929","HiDiff: Hybrid Diffusion Framework for Medical Image Segmentation","2024","","","","1","1","0","10.1109/TMI.2024.3424471","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198234442&doi=10.1109%2fTMI.2024.3424471&partnerID=40&md5=82504c651f0cf215dbd3e008b27410f7","Medical image segmentation has been significantly advanced with the rapid development of deep learning (DL) techniques. Existing DL-based segmentation models are typically discriminative; <italic>i.e</italic>., they aim to learn a mapping from the input image to segmentation masks. However, these discriminative methods neglect the underlying data distribution and intrinsic class characteristics, suffering from unstable feature space. In this work, we propose to complement discriminative segmentation methods with the knowledge of underlying data distribution from generative models. To that end, we propose a novel hybrid diffusion framework for medical image segmentation, termed HiDiff, which can synergize the strengths of existing discriminative segmentation models and new generative diffusion models. HiDiff comprises two key components: discriminative segmentor and diffusion refiner. First, we utilize any conventional trained segmentation models as discriminative segmentor, which can provide a segmentation mask prior for diffusion refiner. Second, we propose a novel binary Bernoulli diffusion model (BBDM) as the diffusion refiner, which can effectively, efficiently, and interactively refine the segmentation mask by modeling the underlying data distribution. Third, we train the segmentor and BBDM in an alternate-collaborative manner to mutually boost each other. Extensive experimental results on abdomen organ, brain tumor, polyps, and retinal vessels segmentation datasets, covering four widely-used modalities, demonstrate the superior performance of HiDiff over existing medical segmentation algorithms, including the state-of-the-art transformer- and diffusion-based ones. In addition, HiDiff excels at segmenting small objects and generalizing to new datasets. Source codes are made available at https://github.com/takimailto/HiDiff. IEEE","alternate training; binary neural network; Biomedical imaging; Data models; diffusion model; Diffusion models; hybrid framework; Image segmentation; Medical image segmentation; Task analysis; Training; Transformers","Deep learning; Diffusion; Job analysis; Medical imaging; Refining; Alternate training; Binary neural networks; Biomedical imaging; Diffusion model; Hybrid framework; Images segmentations; Medical image segmentation; Task analysis; Transformer; Image segmentation","ZJLab; National Natural Science Foundation of China, NSFC, (62101136, 62306075); Natural Science Foundation of Shanghai Municipality, (21ZR1403600); Science and Technology Commission of Shanghai Municipality, STCSM, (2018SHZDZX01)","","Institute of Electrical and Electronics Engineers Inc.","38976467"
"Murad N.; Pan M.-C.; Hsu Y.-F.","Murad, Nazish (57657064700); Pan, Min-Chun (55580008800); Hsu, Ya-Fen (42961708900)","57657064700; 55580008800; 42961708900","Optimizing diffuse optical imaging for breast tissues with a dual-encoder neural network to preserve small structural information and fine features","2023","10","6","066003","","","","10.1117/1.JMI.10.6.066003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182349964&doi=10.1117%2f1.JMI.10.6.066003&partnerID=40&md5=fa0ab31d8a96c3e33e8a40827d4cc908","Purpose: Various laboratory sources have recently achieved progress in implementing deep learning models on biomedical optical imaging of soft biological tissues. The highly scattered nature of tissues at specific optical wavelengths results in poor spatial resolution. This opens up opportunities for diffuse optical imaging to improve the spatial resolution of obtained optical properties suffering from artifacts. This study aims to investigate a dual-encoder deep learning model for successfully detecting tumors in different phantoms w.r.t tumor size on diffuse optical imaging. Approach: Our proposed dual-encoder network extends U-net by adding a parallel branch of signal data to get information directly from the base source. This allows the trained network to localize the inclusions without degrading or merging with the background. The signals from the forward model and the images from the inverse problem are combined in a single decoder, filling the gap between existing direct processing and post-processing. Results: Absorption and reduced scattering coefficients are well reconstructed in both simulation and phantom test datasets. The proposed and implemented dualencoder networks characterize better optical-property images than the signalencoder and image-encoder networks, and the contrast-and-size detail resolution of the dual-encoder networks outperforms the other two approaches. From the measures of performance evaluation, the structural similarity and peak signal-to-noise ratio of the reconstructed images obtained by the dual-encoder networks remain the highest values. Conclusions: In this study, we synthesized the advantages of boundary data direct reconstruction, namely the extracted signals and iterative methods, from the obtained images into a unified network architecture.  © 2023 Society of Photo-Optical Instrumentation Engineers (SPIE).","breast cancer; diffusion light; image reconstruction; inverse problem; machine learning; optical tissue coefficients; optical tomography","Brain; Deep learning; Histology; Image resolution; Inverse problems; Iterative methods; Learning systems; Medical imaging; Network architecture; Optical image storage; Optical properties; Optical tomography; Phantoms; Signal to noise ratio; Tumors; Breast Cancer; Diffuse optical; Diffusion light; Images reconstruction; Learning models; Machine-learning; Optical imaging; Optical tissue coefficient; Optical-; Spatial resolution; algorithm; Article; breast tissue; cancer diagnosis; computer language; deep learning; diffuse optical imaging; diffuse optical tomography; dual-encoder deep learning; experimental test; human; human tissue; image processing; image quality; image reconstruction; information processing; reconstruction algorithm; ridge regression; signal noise ratio; tumor volume; Image reconstruction","Landseed Hospital International, (LSH-2023-01); NCU-LSH Research and Development Office, (NCU-LSH-111-B-02); National Science and Technology Council, NSTC, (NSTC 112-2221-E-008-080); National Science and Technology Council, NSTC","","SPIE",""
"Li L.; Chen W.; Qi J.","Li, Lichuan (58984759200); Chen, Wei (57218450196); Qi, Jie (35206045300)","58984759200; 57218450196; 35206045300","VB-SOLO: Single-Stage Instance Segmentation of Overlapping Epithelial Cells","2024","12","","","52555","52564","9","10.1109/ACCESS.2024.3387832","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190354791&doi=10.1109%2fACCESS.2024.3387832&partnerID=40&md5=ba60589c8a87b03d4a0e36fc925e880a","The instance segmentation of overlapping cells in smear images of epithelial cells is challenging due to the significant overlap and adhesion between the cells' translucent cytoplasm. In this paper, an improved single-stage instance segmentation network called VoVNet-BiFPN-SOLO (VB-SOLO) is proposed to address this problem. The model takes SOLOv2 model as its main frame. Firstly, the backbone network uses Efficient Channel Attention (ECA) to optimize the VoVNetv2 network to increase the information interaction across channels and enhance the extraction of cell instance features. Secondly, the bi-directional feature pyramid network (BiFPN) is introduced to connect with the new backbone. BiFPN can achieve the weighted fusion of features with different resolutions from bottom to top and keep more shallow semantic information in the network. Finally, the Convolutional Block Attention Module (CBAM) is added to the mask branch to improve cell segmentation results in feature maps. Experimental results on the publicly available datasets CISD and Cx22 demonstrate the effectiveness of the VB-SOLO model, achieving a DCP of 0.966 and 0.940 and a FNRO of 0.055 and 0.03. Compared to the original SOLOv2 algorithm, the proposed method achieved improvements in DCP of 1.3% and 1.1% respectively. Additionally, comparative tests with multiple instance segmentation networks have shown that the proposed improved network can achieve a better balance between segmentation accuracy and efficiency. The experimental results demonstrate the effectiveness of the proposed network improvements and the potential of single-stage instance segmentation networks in overlapping cell image segmentation.  © 2013 IEEE.","Biomedical imaging; cervical cancer; convolutional neural networks; deep learning; image segmentation; instance segmentation; SOLOv2","Bioinformatics; Bismuth compounds; Cells; Classification (of information); Cytology; Deep neural networks; Extraction; Feature extraction; Image classification; Image enhancement; Medical imaging; Semantic Segmentation; Semantics; Biomedical imaging; Cervical cancers; Classification algorithm; Convolutional neural network; Deep learning; Features extraction; Images segmentations; Instance segmentation; Kernel; Proposal; Semantic segmentation; SOLOv2; Convolution","","","Institute of Electrical and Electronics Engineers Inc.",""
"Chechekhina E.; Voloshin N.; Kulebyakin K.; Tyurin-Kuzmin P.","Chechekhina, Elizaveta (58665835100); Voloshin, Nikita (57226867584); Kulebyakin, Konstantin (54400164600); Tyurin-Kuzmin, Pyotr (36646806400)","58665835100; 57226867584; 54400164600; 36646806400","Code-Free Machine Learning Solutions for Microscopy Image Processing: Deep Learning","2024","","","","","","","10.1089/ten.tea.2024.0014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190736316&doi=10.1089%2ften.tea.2024.0014&partnerID=40&md5=a29d3d1e89288c5758d85034853be31f","In recent years, there has been a significant expansion in the realm of processing microscopy images, thanks to the advent of machine learning techniques. These techniques offer diverse applications for image processing. Currently, numerous methods are used for processing microscopy images in the field of biology, ranging from conventional machine learning algorithms to sophisticated deep learning artificial neural networks with millions of parameters. However, a comprehensive grasp of the intricacies of these methods usually necessitates proficiency in programming and advanced mathematics. In our comprehensive review, we explore various widely used deep learning approaches tailored for the processing of microscopy images. Our emphasis is on algorithms that have gained popularity in the field of biology and have been adapted to cater to users lacking programming expertise. In essence, our target audience comprises biologists interested in exploring the potential of deep learning algorithms, even without programming skills. Throughout the review, we elucidate each algorithm’s fundamental concepts and capabilities without delving into mathematical and programming complexities. Crucially, all the highlighted algorithms are accessible on open platforms without requiring code, and we provide detailed descriptions and links within our review. It’s essential to recognize that addressing each specific problem demands an individualized approach. Consequently, our focus is not on comparing algorithms but on delineating the problems they are adept at solving. In practical scenarios, researchers typically select multiple algorithms suited to their tasks and experimentally determine the most effective one. It is worth noting that microscopy extends beyond the realm of biology; its applications span diverse fields such as geology and material science. Although our review predominantly centers on biomedical applications, the algorithms and principles outlined here are equally applicable to other scientific domains. Furthermore, a number of the proposed solutions can be modified for use in entirely distinct computer vision cases. Copyright 2024, Mary Ann Liebert, Inc., publishers","artificial intelligence; deep learning; open-source code-free microscopy image analysis","Bioinformatics; Image processing; Learning algorithms; Learning systems; Medical applications; Neural networks; Open source software; Open systems; Conventional machines; Deep learning; Diverse applications; Images processing; Machine learning techniques; Machine-learning; Microscopy image analysis; Microscopy images; Open-source code; Open-source code-free microscopy image analyse; Deep learning","Moscow State University of Geodesy and Cartography, MIIGAiK; Russian Science Foundation, RSF, (19–75-30007)","","Mary Ann Liebert Inc.","38556835"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","14448 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178549397&partnerID=40&md5=cd53510390634e0e25fb8bc1b0bfb5e0","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"Zilaie M.; Mohammadkhani Z.; Asrari K.A.; Noghabi S.","Zilaie, Morteza (58864725600); Mohammadkhani, Zohreh (58864809100); Asrari, Keyvan Azimi (58864809200); Noghabi, Sadaf (58864725700)","58864725600; 58864809100; 58864809200; 58864725700","Investigating and Importance of Fetal Monitoring Methods and Presenting a New Method According to Convolutional Deep Learning Based on Image Processing to Separate Fetal Heart Signal from Mother","2024","1110 LNEE","","","457","467","10","10.1007/978-3-031-48121-5_66","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184112554&doi=10.1007%2f978-3-031-48121-5_66&partnerID=40&md5=b5775f0e91655e45ecc372f299f4ca91","This Fetal electrocardiogram is a standard method to identify and diagnose fetal diseases. Therefore, effective techniques are needed to monitor fetal conditions during pregnancy and delivery. Meanwhile, obtaining the fetal electrocardiogram (FECG) signal, which contains the electrical activity of the fetal heart, has great importance, Of course, this signal is contaminated with many noises and disturbances and the most important of them is the mother's electrocardiogram signal. Inherently, the NI-ECG signal contains the maternal ECG signal, which has a larger amplitude than the fetal ECG signal. Therefore, it is not easy to detect the fetal QRS complex in order to control the condition of the fetus and prevent congenital defects. According to the above explanations, in this article, a deep learning approach based on a convolutional neural network is proposed to separate the electrocardiogram signals of the mother from the fetus without separating the mother's ECG signal. The proposed algorithm is able to reliably detect the fetal QRS complex. Also, in addition to not needing feature extraction steps, it has been able to show more suitable performance than the best methods proposed in previous research in terms of detection accuracy. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Convolutional neural network; Deep learning; Electrocardiogram; Fetal heart signal; QRS complex","Biomedical signal processing; Complex networks; Convolution; Deep learning; Feature extraction; Image processing; Condition; Convolutional neural network; Deep learning; ECG signals; Electrocardiogram signal; Fetal electrocardiograms; Fetal heart; Fetal heart signal; Heart signal; QRS complexes; Electrocardiograms","","Bellotti F.; Grammatikakis M.D.; Mansour A.; Ruo Roch M.; Seepold R.; Solanas A.; Berta R.","Springer Science and Business Media Deutschland GmbH",""
"","","","2nd International Conference on Advances in Information and Communication Technology, ICTA 2023","2024","848","","","","","340","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182008382&partnerID=40&md5=9f5f2ce61d1c75fb95fc41317c4da1bc","The proceedings contain 35 papers. The special focus in this conference is on Advances in Information and Communication Technology. The topics include: A Real-time Crowd Density Level Detection System; an Architecture for More Fine-Grained Hidden Representation in Named Entity Recognition for Biomedical Texts; application of Deep Learning Methods for Forest Fire Intelligent Image Processing; choosing Data Points to Label for Semi-supervised Learning Based on Neighborhood; classification of Fermentation Levels of Cacao Beans (Theobroma cacao L.) Using Sensing Technology and Neural Networks; DCDynUnet: Deep Supervision Attention Context for Brain Segmentation; enhancing Wildfire Detection Using Semi-supervised Fuzzy Clustering on Satellite Imagery; Evaluating the Performance of Some Deep Learning Model for the Problem of Emotion Recognition Based on EEG Signal; a Novel Arm Bone Fracture Detection Using Deep Learning; feature Reduction for Interpretability of Neuro-Fuzzy Classifier; improved Accuracy of Path System on Creating Intelligence Base; the Vehicle Routing Problem with Drones for Fresh Agricultural Products; ViT-SigNet: Combining Deep CNN and Vision Transformer for Enhanced Signature Verification; combining Local Search and Multi-objective Optimization Algorithm in Signalized Intersection Optimization; Comparative Evaluation of PRR and PODA Methods for Model Order Reduction in Electrical Circuits; data-Driven Narratives: Unleashing the Potential of R for Journalistic Storytelling; dynamic Analysis of Capsubot Model in Liquid Environment by Numerical Method; genetic Programming–A Preliminary Study of Knowledge Transfer in Mutation; improvement of Spectral Clustering Method in Social Network Community Detection; a Systematic Review of Artificial Intelligence in Geographic Information Systems; probable Characteristics of Multi-channel Queuing Systems with “Impatient” and “Patient” Claims.","","","","Nghia P.T.; Thai V.D.; Thuy N.T.; Son L.H.; Huynh V.-N.","Springer Science and Business Media Deutschland GmbH",""
"Kim S.-J.; Lee D.-H.; Kwak H.-G.; Lee S.-W.","Kim, Sung-Jin (57223342592); Lee, Dae-Hyeok (57214143052); Kwak, Heon-Gyu (57221774348); Lee, Seong-Whan (7601390519)","57223342592; 57214143052; 57221774348; 7601390519","Toward Domain-Free Transformer for Generalized EEG Pre-Training","2024","32","","","482","492","10","10.1109/TNSRE.2024.3355434","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182950583&doi=10.1109%2fTNSRE.2024.3355434&partnerID=40&md5=33b90a80877fa31a91048ef9215d7725","Electroencephalography (EEG) signals are the brain signals acquired using the non-invasive approach. Owing to the high portability and practicality, EEG signals have found extensive application in monitoring human physiological states across various domains. In recent years, deep learning methodologies have been explored to decode the intricate information embedded in EEG signals. However, since EEG signals are acquired from humans, it has issues with acquiring enormous amounts of data for training the deep learning models. Therefore, previous research has attempted to develop pre-trained models that could show significant performance improvement through fine-tuning when data are scarce. Nonetheless, existing pre-trained models often struggle with constraints, such as the necessity to operate within datasets of identical configurations or the need to distort the original data to apply the pre-trained model. In this paper, we proposed the domain-free transformer, called DFformer, for generalizing the EEG pre-trained model. In addition, we presented the pre-trained model based on DFformer, which is capable of seamless integration across diverse datasets without necessitating architectural modification or data distortion. The proposed model achieved competitive performance across motor imagery and sleep stage classification datasets. Notably, even when fine-tuned on datasets distinct from the pre-training phase, DFformer demonstrated marked performance enhancements. Hence, we demonstrate the potential of DFformer to overcome the conventional limitations in pre-trained model development, offering robust applicability across a spectrum of domains.  © 2001-2011 IEEE.","autoencoder; Electroencephalogram; motor imagery; sleep stage classification; transformer","Algorithms; Brain; Brain-Computer Interfaces; Electric Power Supplies; Electroencephalography; Humans; Biomedical signal processing; Classification (of information); Deep learning; Electrophysiology; Image classification; Job analysis; Sleep research; Auto encoders; Brain modeling; Domain free; Motor imagery; Pre-training; Sleep; Sleep stages classifications; Task analysis; Transformer; Article; cardiovascular disease; convolutional neural network; cross validation; data accuracy; data analysis; data base; deep learning; Deep sleepnet; electroencephalography; electroencephalography phase synchronization; embedding; evaluation research; evaluation study; frequency modulation; heart; human; model; monitoring; polysomnography; Robust sleepnet; sine wave; sleep; sleep apnea syndromes; sleep heart health study; spatial analysis; training; U sleepnet; algorithm; brain; electroencephalography; physiology; power supply; procedures; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.","38236672"
"Lin Y.; Liang Z.; He Y.; Huang W.; Guan T.","Lin, Yuanhua (58556669500); Liang, Zhendong (57963206100); He, Yonghong (7404941330); Huang, Wenting (57488200300); Guan, Tian (7006929546)","58556669500; 57963206100; 7404941330; 57488200300; 7006929546","End-to-end affine registration framework for histopathological images with weak annotations","2023","241","","107763","","","","10.1016/j.cmpb.2023.107763","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169299165&doi=10.1016%2fj.cmpb.2023.107763&partnerID=40&md5=1fb902796ebe9648e81415a57f0e3287","Background and Objective: Histopathological image registration is an essential component in digital pathology and biomedical image analysis. Deep-learning-based algorithms have been proposed to achieve fast and accurate affine registration. Some previous studies assume that the pairs are free from sizeable initial position misalignment and large rotation angles before performing the affine transformation. However, large-rotation angles are often introduced into image pairs during the production process in real-world pathology images. Reliable initial alignment is important for registration performance. The existing deep-learning-based approaches often use a two-step affine registration pipeline because convolutional neural networks (CNNs) cannot correct large-angle rotations. Methods: In this manuscript, a general framework ARoNet is developed to achieve end-to-end affine registration for histopathological images. We use CNNs to extract global features of images and fuse them to construct correspondent information for affine transformation. In ARoNet, a rotation recognition network is implemented to eliminate great rotation misalignment. In addition, a self-supervised learning task is proposed to assist the learning of image representations in an unsupervised manner. Results: We applied our model to four datasets, and the results indicate that ARoNet surpasses existing affine registration algorithms in alignment accuracy when large angular misalignments (e.g., 180 rotation) are present, providing accurate affine initialization for subsequent non-rigid alignments. Besides, ARoNet shows advantages in execution time (0.05 per pair), registration accuracy, and robustness. Conclusion: We believe that the proposed general framework promises to simplify and speed up the registration process and has the potential for clinical applications. © 2023 Elsevier B.V.","Affine estimation; ANHIR; Histopathological image registration","Algorithms; Image Processing, Computer-Assisted; Neural Networks, Computer; Alignment; Convolutional neural networks; Deep learning; Image annotation; Large dataset; Learning systems; Pathology; Rotation; Affine estimations; Affine registration; Affine transformations; ANHIR; Convolutional neural network; End to end; Histopathological image registration; Histopathological images; Images registration; Large rotation angles; affine transform; article; convolutional neural network; deep learning; histopathology; image registration; learning; pipeline; rotation; velocity; algorithm; artificial neural network; image processing; Image registration","Science and Technology Research Program of Shenzhen City, (JCYJ20200109110606054, WDZC20200821141349001); National Natural Science Foundation of China, NSFC, (61875102); National Natural Science Foundation of China, NSFC","","Elsevier Ireland Ltd","37634308"
"Alanazi A.A.; Abaker A.O.I.; Abdel-Khalek S.; Alhomayani F.M.; Aripov M.","Alanazi, Adwan A. (57212021340); Abaker, Abdelgalal O. I. (58817476400); Abdel-Khalek, Sayed (6506630609); Alhomayani, Fahad Mohammed (57218996816); Aripov, M. (8880099100)","57212021340; 58817476400; 6506630609; 57218996816; 8880099100","Neutrosophic Logic Empowered Machine Learning Algorithm with Salp Swarm Optimization for Biomedical Image Analysis","2024","23","4","","104","116","12","10.54216/IJNS.230408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193495422&doi=10.54216%2fIJNS.230408&partnerID=40&md5=e69f6bc87ebd3a1cf5560d89ffcd8151","Leukemia recognition and classification contain the identification of dissimilar kinds of leukemia, a group of blood cancers that affects the bone marrow and blood. A classical model containing microscopic analysis of blood smears to classify abnormal cells analytic of leukemia. Leukemia recognition employing a united technique of neutrosophic logic and deep learning (DL) signifies a new and complete approach to handling uncertainty and difficulty in medical data. Neutrosophic logic permits the representation of unstated or imperfect data, which is general in medical analyses. DL mainly convolutional neural networks (CNN) or recurrent neural networks (RNN), which can mechanically remove difficult patterns from medicinal imageries, improving the accuracy of leukemia recognition. The neutrosophic logic module accommodates the characteristic uncertainty in medicinal data, offering a formalism to manage imperfect or inaccurate data linked with the analysis procedure. The combination of these dual techniques generates a robust structure which capable of leveraging both the control of DL in image analysis and the flexibility of neutrosophic logic in dealing with uncertainties, contributing to more trustworthy and interpretable leukemia recognition methods. This study develops a new Salp Swarm Algorithm with a Neutrosophic Logic SVM (SSA-NSVM) model for Leukemia Detection and Classification. The SSA-NSVM technique mainly exploits Neutrosophic Logic (NL) concepts with the DL model for the detection of leukemia. To attain this, the SSA-NSVM model uses bilateral filtering (BF) based image pre-processing. In addition, the SSA-NSVM approach applies a modified densely connected networks (DenseNet) technique for learning complex and intrinsic feature patterns. Besides, the hyperparameter range of the modified DenseNet system takes place utilizing a SSA. At last, the NSVM technique is employed for the detection and identification of leukemia. The performance validation of the SSA-NSVM algorithm is verified utilizing a benchmark medicinal image dataset. The simulation values emphasized that the SSA-NSVM model reaches better detection outcomes than other existing approaches. © 2024, American Scientific Publishing Group (ASPG). All rights reserved.","Blood Cancer; Bone Marrow; Leukemia Detection; Neutrosophic Logic; Salp Swarm Algorithm","","Deanship of Scientific Research, King Khalid University, (RGP2/462/44); Deanship of Scientific Research, King Khalid University","","American Scientific Publishing Group (ASPG)",""
"Long B.; Chen Z.; Liu T.; Wu X.; He C.; Wang L.","Long, Bofeng (58925473900); Chen, Zhong (57216117954); Liu, Tongzhe (58925322800); Wu, Ximei (58925178300); He, Chenchen (58026720300); Wang, Lujie (58026795000)","58925473900; 57216117954; 58925322800; 58925178300; 58026720300; 58026795000","A Novel Medical Image Encryption Scheme Based on Deep Learning Feature Encoding and Decoding","2024","12","","10453520","38382","38398","16","10.1109/ACCESS.2024.3371888","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186963736&doi=10.1109%2fACCESS.2024.3371888&partnerID=40&md5=144d3990b4da7665c9984244a5730f87","Medical image encryption is essential to protect the privacy and confidentiality of patients' medical records. Deep learning-based encryption, which leverages the nonlinear characteristics of neural networks, has emerged as a promising new method for protecting medical images. In this paper, we present insights into deep learning-based medical image encryption and propose a novel end-to-end medical image encryption scheme based on these insights that leverages feature encoding and decoding for encrypting and decrypting images. Firstly, we explore a method that combines keys generated by the Logistic Map with encoded plaintext image features to improve network diffusion performance. Secondly, we employ a reversible neural network to enhance plaintext image reconstruction while maintaining encryption effectiveness. Finally, we propose a series of novel loss functions to measure the cost with the ideal cryptographic algorithm and continuously optimize our network. Experimental results demonstrate that our scheme improves the performance of image encryption and decryption and resists brute force attacks, statistical attacks, noise and cropping attacks.  © 2013 IEEE.","convolutional neural network (CNN); deep learning; feature encoding and decoding; feature fusion; logistic map; Medical image encryption","Decoding; Deep learning; Encoding (symbols); Generative adversarial networks; Image coding; Image enhancement; Image reconstruction; Medical imaging; Network coding; Neural networks; Biomedical imaging; Convolutional neural network; Decoding; Deep learning; Encoding and decoding; Feature encoding and decoding; Features fusions; Generator; Logistic maps; Medical image encryptions; Cryptography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Amiri Y.; Omranpour H.","Amiri, Youkabed (58648699800); Omranpour, Hesam (26423137100)","58648699800; 26423137100","Efficient space learning based on kernel trick and dimension reduction technique for multichannel motor imagery EEG signals classification","2024","36","3","","1199","1214","15","10.1007/s00521-023-09090-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174185382&doi=10.1007%2fs00521-023-09090-y&partnerID=40&md5=6b71b5ebd35f73e1d33a216588c533cd","Electroencephalogram (EEG) signals show the electrical activity of the brain, which are one of the inputs of the brain–computer interface (BCI). The BCI provides the communication path between the brain and the computer. One of the critical applications of BCI is Motor imagery (MI). MI is a mental process that a person practices or simulates a particular movement without physically acting. BCI allows the person to communicate with their environment independently of peripheral muscles and nerves, using EEG brain signals by assistive devices such as wheelchairs, robotic arms, and computers. In this paper, a space learning concept is proposed for EEG motor imagery signal classification. Our innovation in the proposed method is to increase and then, reduce the data dimensions, which has led to learning the efficient space for signals classification. It is based on two techniques: Multi-Kernel Learning (MKL) and dimension reduction. The composite kernel is made of a combination of four kernels by The Heuristic MKL Algorithm. This algorithm uses heuristic rules to estimate the weight of kernels with high accuracy and very little computational complexity. The weight associated with each base kernel and its parameters is calculated by the Equilibrium Optimizer. Dimensions of data are reduced to avoid the curse of dimensions. In this step, the number of dimensions of reduced space and the mapping matrix are learned to reduce the dimensions of data linearly. We selected ELM, KNN, and SVM classifiers for classification. The BCI Competition dataset was used for evaluation, which consists of five subsets aa, al, ay, aw, av, and two classes of the right hand and right foot. The proposed method with the ELM was improved the average classification accuracy and standard deviation by 3.9% and 2.28, respectively, and achieved 91.4% accuracy. The lower standard deviation than other methods shows that our method is more robust than all other methods to subject variety. The proposed method is compared with twelve state-of-the-art methods and has shown higher accuracy than other methods such as the deep convolutional neural networks. The results show the superiority of the proposed method over other methods in the Wilcoxon signed test. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","BCI system; EEG; Kernel tricks; Optimization; Space learning","Biomedical signal processing; Brain; Brain computer interface; Convolutional neural networks; Data reduction; Deep neural networks; Image classification; Learning systems; Optimization; Statistics; Support vector machines; Brain–computer interface system; Electroencephalogram signals; Interface system; Kernel dimension; Kernel trick; Motor imagery; Multi-kernel learning; Optimisations; Signal classification; Space learning; Electroencephalography","","","Springer Science and Business Media Deutschland GmbH",""
"Jagadesh T.; Kamalesh P.; Kishore A.; Lokin V.; Jaiprakash B.","Jagadesh, T. (56582511400); Kamalesh, P. (57643418800); Kishore, A. (57190295631); Lokin, V. (59223702400); Jaiprakash, B. (59223702500)","56582511400; 57643418800; 57190295631; 59223702400; 59223702500","Oral Cancer Detection Using Convolutional Neural Networks","2024","","","","","","","10.1109/ICONSTEM60960.2024.10568599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198842931&doi=10.1109%2fICONSTEM60960.2024.10568599&partnerID=40&md5=06ba3e9726a885247d2fb4f3b6c22a93","In developing nation oral cancer makes the significant threat to human life. The existing system uses deep learning technique for detection of oral cancer in medical imaging. The two powerful tools of deep learning techniques are Convolutional Neural Networks and Deep Belief Network [1]. PSOBER- Particle Swarm Optimization and AI-Biruni Earth Radius a hybrid optimization algorithm is used to optimize the CNN and DBN. To overcome the outperformance of the existing method standard dataset of biomedical images are used for demonstration of the promising results. To test and validate the significance and stability one-way ANOVA and Wilcoxon signed-rank is used. For screening oral cancer detection in clinical setting this technique is used. However, the accuracy and to find the early detection of oral cancer and to make the less suffering of the patients the further research is needed. The proposed method of oral cancer detection using deep learning technique includes the enhancement of the images. In this method salt and pepper noise detection is used to find the accurate results using segmentation of the cells for thresholding. Back Propagation Neural Networks (BPNN) is used for the classification of the oral cancer. Tumor partition and features extraction are done in the proposed method. Feeding the loss backward through neural networks layers to fine tune the weights and the BPNN involves the error rate of forward propagation. Back propagation neural networks contain two signals. They are Error signal and Back signal.  © 2024 IEEE.","Back propagation; back signal; deep learning; detection; error signal; hybrid optimization; Medical imaging; neural networks; oral cancer; standard dataset; tumor partition","Backpropagation; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Diseases; Image enhancement; Learning systems; Multilayer neural networks; Network layers; Particle swarm optimization (PSO); Salt and pepper noise; Tumors; Back Propagation; Back signal; Deep learning; Detection; Error signal; Hybrid optimization; Neural-networks; Oral cancer; Standard dataset; Tumor partition; Medical imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","3rd International Conference on Emergent Converging Technologies and Biomedical Systems, ETBS 2023","2024","1116","","","","","725","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188001176&partnerID=40&md5=aeef7d46018741e55c433f5ea0319e2c","The proceedings contain 56 papers. The special focus in this conference is on Emergent Converging Technologies and Biomedical Systems. The topics include: Smart Health Monitoring System for Elderly People; impact of Covid-19 and Subsequent Usage of IoT; design of Battery Monitoring System for Converted Electric Cycles; image Denoising Framework Employing Auto Encoders for Image Reconstruction; server Access Pattern Analysis Based on Weblogs Classification Methods; multilingual Emotion Recognition from Continuous Speech Using Transfer Learning; Violence Detection Using DenseNet and LSTM; financial Technology and Competitive Landscape in the Banking Industry of Bangladesh: An Exploratory Focus; on Parameterized Picture Fuzzy Discriminant Information Measure in Medical Diagnosis Problem; review on Deep Learning-Based Classification Techniques for Cocoa Quality Testing; a Curated Study on Machine Learning Based Algorithms and Sensors for Drone Technology in Various Application; automatic Detection of Coagulation of Blood in Brain Using Deep Learning Approach; deepPose: A 2D Image Based Automated Framework for Human Pose Detection and a Trainer App Using Deep Learning; Phylogenetic Study of Surface Glycoprotein (S1 Spike Protein) Sequence of SARS-CoV-2 Virus; pervasive and Wearable Computing and Networks; power of Image-Based Digit Recognition with Machine Learning; open-Source Gesture-Powered Augmented Reality-Based Remote Assistance Tool for Industrial Application: Challenges and Improvisation; enhancing Biometric Performance Through Mitigation of Sleep-Related Breaches; Neural Network Based CAD System for the Classification of Textures in Liver Ultrasound Images; fuzzy Vendor–Buyer Trade Credit Inventory Model-Pentagonal Numbers in Permissible Limits Delay in Account Settlement with Supervised Learning; a Comparative Survey on Histogram Equalization Techniques for Image Contrast Enhancement.","","","","Jain S.; Marriwala N.; Singh P.; Tripathi C.C.; Kumar D.","Springer Science and Business Media Deutschland GmbH",""
"Weng L.; Zhu Z.; Dai K.; Zheng Z.; Zhu J.; Wu H.","Weng, Li (25643440200); Zhu, Zhoule (57216586589); Dai, Kaixin (58882766700); Zheng, Zhe (57206699578); Zhu, Junming (35779636700); Wu, Hemmings (55264662200)","25643440200; 57216586589; 58882766700; 57206699578; 35779636700; 55264662200","Reduced-Reference Learning for Target Localization in Deep Brain Stimulation","2024","43","7","","2434","2447","13","10.1109/TMI.2024.3363425","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184821989&doi=10.1109%2fTMI.2024.3363425&partnerID=40&md5=5650a8137cb82ed064119105edff21ea","This work proposes a supervised machine learning method for target localization in deep brain stimulation (DBS). DBS is a recognized treatment for essential tremor. The effects of DBS significantly depend on the precise implantation of electrodes. Recent research on diffusion tensor imaging shows that the optimal target for essential tremor is related to the dentato-rubro-thalamic tract (DRTT), thus DRTT targeting has become a promising direction. The tractography-based targeting is more accurate than conventional ones, but still too complicated for clinical scenarios, where only structural magnetic resonance imaging (sMRI) data is available. In order to improve efficiency and utility, we consider target localization as a non-linear regression problem in a reduced-reference learning framework, and solve it with convolutional neural networks (CNNs). The proposed method is an efficient two-step framework, and consists of two image-based networks: one for classification and the other for localization. We model the basic workflow as an image retrieval process and define relevant performance metrics. Using DRTT as pseudo groundtruths, we show that individualized tractography-based optimal targets can be inferred from sMRI data with high accuracy. For two datasets of {280}times {220}/{272}times {227} (0.7/0.8 mm slice thickness) sMRI input, our model achieves an average posterior localization error of 2.3/1.2 mm, and a median of 1.7/1.02 mm. The proposed framework is a novel application of reduced-reference learning, and a first attempt to localize DRTT from sMRI. It significantly outperforms existing methods using 3D-CNN, anatomical and DRTT atlas, and may serve as a new baseline for general target localization problems.  © 1982-2012 IEEE.","Deep brain stimulation; diffusion tensor imaging; essential tremor; machine learning; magnetic resonance imaging; neural network; target localization","Algorithms; Brain; Deep Brain Stimulation; Diffusion Tensor Imaging; Essential Tremor; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Supervised Machine Learning; Diffusion; Diffusion tensor imaging; Electrodes; Image retrieval; Neural networks; Neurosurgery; Supervised learning; Tensors; Biomedical imaging; Complexity theory; Deep brain stimulation; Essential tremor; Location awareness; Machine-learning; Neural-networks; Satellite broadcasting; Target localization; algorithm; Article; binary classification; brain depth stimulation; controlled study; convolutional neural network; correlation coefficient; cross validation; dentato rubo thalamic tract; diffusion tensor imaging; diffusion weighted imaging; essential tremor; gray matter volume; human; image retrieval; mean squared error; nuclear magnetic resonance imaging; performance indicator; supervised machine learning; thalamus; tractography; artificial neural network; brain; diagnostic imaging; diffusion tensor imaging; essential tremor; image processing; procedures; supervised machine learning; therapy; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.","38324428"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","14452 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190366951&partnerID=40&md5=6ebabd485ea61c047f43d7f7d7fde660","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"Johari L.; Ramya P.; Suganya M.; Praveena H.D.; Lathamageshwari P.S.; Rajendiran M.","Johari, Lalit (57832455200); Ramya, P. (57203940941); Suganya, M. (59223443700); Praveena, Hirald Dwaraka (57195507519); Lathamageshwari, P.S. (59223533800); Rajendiran, M. (57451399100)","57832455200; 57203940941; 59223443700; 57195507519; 59223533800; 57451399100","Deep Learning-Based Noise Reduction Techniques in Electronic Signal Processing","2024","","","","","","","10.1109/ICONSTEM60960.2024.10568634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198844395&doi=10.1109%2fICONSTEM60960.2024.10568634&partnerID=40&md5=34f565aa3d6c38d1c65cc3be0847579b","This paper explores the operation of deep literacy- grounded noise reduction ways in electronic signal processing. Noise hindrance poses a significant challenge in colorful signal processing operations, impacting the delicacy and trustability of data analysis and interpretation. Traditional noise reduction styles frequently calculate on heuristic approaches or signal processing algorithms, which may have limited effectiveness, especially in complex and dynamic surroundings. In discrepancy, deep literacy algorithms, similar as convolutional neural networks(CNNs) and intermittent neural networks(RNNs), offer promising results for noise reduction by learning complex patterns and connections directly from data. This paper determines the state- of- the- art deep literacy- grounded noise reduction ways, including denoising autoencoders, generative inimical networks(GANs), and intermittent neural network- grounded models. Case studies and experimental results demonstrate the effectiveness and performance of these ways in colorful signal processing tasks, similar as audio denoising, image restoration, and biomedical signal processing. The integration of deep literacy- grounded noise reduction styles into electronic signal processing systems shows significant eventuality for perfecting signal quality and enhancing the delicacy of data analysis in different operations.  © 2024 IEEE.","Convolutional neural networks; Deep learning; Denoising techniques; Electronic signal processing; Noise reduction; Recurrent neural networks; Signal enhancement","Complex networks; Convolutional neural networks; Data reduction; E-learning; Heuristic methods; Image reconstruction; Information analysis; Noise abatement; Quality control; Signal analysis; Signal denoising; Convolutional neural network; De-noising techniques; Deep learning; Electronic signal processing; Heuristics approaches; Neural-networks; Noise reduction technique; Processing operations; Signal enhancement; Signal-processing; Recurrent neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Salimi M.; Roshanfar M.; Tabatabaei N.; Mosadegh B.","Salimi, Mohammadhossein (57216746350); Roshanfar, Majid (57302682100); Tabatabaei, Nima (55871406500); Mosadegh, Bobak (31967759100)","57216746350; 57302682100; 55871406500; 31967759100","Machine Learning-Assisted Short-Wave InfraRed (SWIR) Techniques for Biomedical Applications: Towards Personalized Medicine","2024","14","1","33","","","","10.3390/jpm14010033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183117984&doi=10.3390%2fjpm14010033&partnerID=40&md5=6e5b361ddfd11f40b9b6681c79177924","Personalized medicine transforms healthcare by adapting interventions to individuals’ unique genetic, molecular, and clinical profiles. To maximize diagnostic and/or therapeutic efficacy, personalized medicine requires advanced imaging devices and sensors for accurate assessment and monitoring of individual patient conditions or responses to therapeutics. In the field of biomedical optics, short-wave infrared (SWIR) techniques offer an array of capabilities that hold promise to significantly enhance diagnostics, imaging, and therapeutic interventions. SWIR techniques provide in vivo information, which was previously inaccessible, by making use of its capacity to penetrate biological tissues with reduced attenuation and enable researchers and clinicians to delve deeper into anatomical structures, physiological processes, and molecular interactions. Combining SWIR techniques with machine learning (ML), which is a powerful tool for analyzing information, holds the potential to provide unprecedented accuracy for disease detection, precision in treatment guidance, and correlations of complex biological features, opening the way for the data-driven personalized medicine field. Despite numerous biomedical demonstrations that utilize cutting-edge SWIR techniques, the clinical potential of this approach has remained significantly underexplored. This paper demonstrates how the synergy between SWIR imaging and ML is reshaping biomedical research and clinical applications. As the paper showcases the growing significance of SWIR imaging techniques that are empowered by ML, it calls for continued collaboration between researchers, engineers, and clinicians to boost the translation of this technology into clinics, ultimately bridging the gap between cutting-edge technology and its potential for personalized medicine. © 2023 by the authors.","biomedical optics; deep learning; individualized bioinstruments; machine learning; personalized medicine; short-wave infrared (SWIR) techniques","artificial intelligence; artificial neural network; atherosclerosis; biomedical engineering; cancer diagnosis; cardiovascular disease; controlled study; decision tree; deep learning; deep neural network; diabetic retinopathy; diagnostic test accuracy study; elastography; fibroatheroma; fluorescence imaging; fluorescence molecular tomography; heart infarction; human; illumination; image segmentation; infrared radiation; interferometry; k nearest neighbor; learning algorithm; light scattering; machine learning; nuclear magnetic resonance imaging; optical coherence tomography; optical coherence tomography angiography; patient compliance; personalized medicine; Review; sensitivity and specificity; short wave infrared; spectroscopy; support vector machine; tomography","Natural Sciences and Engineering Research Council of Canada, NSERC, (RGPIN-2022-04605)","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Zhang X.; Li W.; Gao C.; Yang Y.; Chang K.","Zhang, Xueyu (58748157300); Li, Wei (56215159000); Gao, Chenzhong (57223972852); Yang, Yue (56498892300); Chang, Kan (15520748200)","58748157300; 56215159000; 57223972852; 56498892300; 15520748200","Hyperspectral pathology image classification using dimension-driven multi-path attention residual network","2023","230","","120615","","","","10.1016/j.eswa.2023.120615","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161019211&doi=10.1016%2fj.eswa.2023.120615&partnerID=40&md5=bd2db7f74675f9023334e54b3a857e39","Hyperspectral imaging technology (HSI) can capture pathological tissue's spatial and spectral information simultaneously, with wide coverage and high accuracy characteristics, and is widely used in biomedical imaging. As an image-spectrum merging technology, HSI can obtain more practical information in disease diagnosis, which is helpful for pathological analysis. Focusing on the characteristics of scattered distribution of pathological areas, and combined with the advantages of HSI technology, a dimension-driven multi-path attention residual network (DDMARN) is proposed to pixel-level classification for membranous nephropathy (MN). To make full use of the space-spectrum information of hyperspectral data, dimension-driven multi-path attention residual block (DDMARB) is developed to effectively obtain the multi-scale features and differently treats these features containing different amounts of information through the channel attention (CA) mechanism, which makes the data depth features better expressed. The experimental results demonstrate that the proposed DDMARN performs very competitively in the PMN and HBV-MN classification tasks. The average of OA (%) ± standard deviation (%), AA (%) ± standard deviation (%), and Kappa coefficient ± standard deviation of 10 experiments results are 96.23 ± 0.17, 90.24 ± 0.18, and 0.8654 ± 0.0056, respectively, the optimal values in the comparison algorithm, and the model parameter is only 700K. © 2023","Classification; Convolutional neural networks; Deep learning; Medical hyperspectral images; Membranous nephropathy","Convolutional neural networks; Deep neural networks; Diagnosis; Hyperspectral imaging; Medical imaging; Statistics; Convolutional neural network; Deep learning; Dimension-driven; Hyperspectral imaging technologies; Medical hyperspectral; Medical hyperspectral image; Membranoi nephropathy; Multipath; Nephropathy; Standard deviation; Image classification","National Natural Science Foundation of China, NSFC, (61922013, 62171145); Natural Science Foundation of Beijing Municipality, (JQ20021)","","Elsevier Ltd",""
"Sun J.; Zhu Q.; Fang H.; Wang J.; Zhou W.; Liu Z.; Yang Y.","Sun, Jingyu (57215688856); Zhu, Qidi (59208134300); Fang, Hao (58564988400); Wang, Jiazheng (58515919400); Zhou, Wei (56939509600); Liu, Zhe (57221282423); Yang, Yunjie (41961701200)","57215688856; 59208134300; 58564988400; 58515919400; 56939509600; 57221282423; 41961701200","Multi-Modal EIT Image Reconstruction Using Deep Similarity Prior","2024","","","","","","","10.1109/I2MTC60896.2024.10560635","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197789663&doi=10.1109%2fI2MTC60896.2024.10560635&partnerID=40&md5=99cf266ac38eb28ae59b993212061076","Electrical Impedance Tomography (EIT) is a promising imaging technique with diverse applications from biomedical engineering to industrial process monitoring. Despite its potential, the practical utility of EIT is often limited by low spatial resolution due to the ill-posed nature of its inverse problem. This paper presents a novel multi-modal EIT image reconstruction algorithm that leverages neural network regularization to address this limitation. We first design a self-supervised Siamese network consisting of a dual Structure Encoding Network (abbreviated as SEN) with shared weights. Then, we construct the multi-modal EIT reconstruction with the network regularization, utilizing the learned similarity prior of the trained SEN. We compare our approach with conventional single-modal and multi-modal EIT image reconstruction algorithms to evaluate its effectiveness. Numerical simulations and real-world experiments demonstrate the superior performance of our approach over other algorithms by effectively integrating structural information from the auxiliary image to enhance the quality of the EIT image. © 2024 IEEE.","Electrical Impedance Tomography; multi-modal image reconstruction; neural network regularization; self-supervised learning","Biomedical engineering; Deep learning; Electric impedance; Electric impedance measurement; Electric impedance tomography; Image enhancement; Inverse problems; Medical imaging; Process monitoring; Electrical impe dance tomography (EIT); Image reconstruction algorithm; Images reconstruction; Multi-modal; Multi-modal image reconstruction; Multimodal images; Neural network regularization; Neural-networks; Regularisation; Self-supervised learning; Image reconstruction","","","Institute of Electrical and Electronics Engineers Inc.",""
"Wang X.; Liesaputra V.; Liu Z.; Wang Y.; Huang Z.","Wang, Xianheng (57205725603); Liesaputra, Veronica (23009373500); Liu, Zhaobin (12785692100); Wang, Yi (58855517700); Huang, Zhiyi (7406222769)","57205725603; 23009373500; 12785692100; 58855517700; 7406222769","An in-depth survey on Deep Learning-based Motor Imagery Electroencephalogram (EEG) classification","2024","147","","102738","","","","10.1016/j.artmed.2023.102738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180408277&doi=10.1016%2fj.artmed.2023.102738&partnerID=40&md5=a5c60d7a24cdc634efa16e870072c33a","Electroencephalogram (EEG)-based Brain–Computer Interfaces (BCIs) build a communication path between human brain and external devices. Among EEG-based BCI paradigms, the most commonly used one is motor imagery (MI). As a hot research topic, MI EEG-based BCI has largely contributed to medical fields and smart home industry. However, because of the low signal-to-noise ratio (SNR) and the non-stationary characteristic of EEG data, it is difficult to correctly classify different types of MI-EEG signals. Recently, the advances in Deep Learning (DL) significantly facilitate the development of MI EEG-based BCIs. In this paper, we provide a systematic survey of DL-based MI-EEG classification methods. Specifically, we first comprehensively discuss several important aspects of DL-based MI-EEG classification, covering input formulations, network architectures, public datasets, etc. Then, we summarize problems in model performance comparison and give guidelines to future studies for fair performance comparison. Next, we fairly evaluate the representative DL-based models using source code released by the authors and meticulously analyse the evaluation results. By performing ablation study on the network architecture, we found that (1) effective feature fusion is indispensable for multi-stream CNN-based models. (2) LSTM should be combined with spatial feature extraction techniques to obtain good classification performance. (3) the use of dropout contributes little to improving the model performance, and that (4) adding fully connected layers to the models significantly increases their parameters but it might not improve their performance. Finally, we raise several open issues in MI-EEG classification and provide possible future research directions. © 2023 The Authors","Deep learning; Motor imagery electroencephalogram classification; Survey","Brain; Brain-Computer Interfaces; Communication; Deep Learning; Electroencephalography; Humans; Automation; Biomedical signal processing; Brain computer interface; Electroencephalography; Image classification; Long short-term memory; Network architecture; Signal to noise ratio; Communication path; Deep learning; Depth surveys; Hot research topics; Human brain; Low signal-to-noise ratio; Medical fields; Motor imagery; Motor imagery electroencephalogram classification; Smart homes; algorithm; binary classification; classification; comparative study; convolutional neural network; deep belief network; deep learning; deep neural network; drug formulation; electroencephalogram; event related potential; health care survey; human; long short term memory network; machine learning; natural language processing; performance; Review; short term memory; short time Fourier transform; signal noise ratio; steady state; support vector machine; visual evoked potential; brain; electroencephalography; interpersonal communication; Classification (of information)","","","Elsevier B.V.","38184362"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","1961 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178608466&partnerID=40&md5=1667dbcda5df4e45fc3ea5633ada31fb","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"Subasi A.","Subasi, Abdulhamit (8327241200)","8327241200","Medical image segmentation using artificial intelligence","2024","","","","377","400","23","10.1016/B978-0-443-22308-2.00004-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193360200&doi=10.1016%2fB978-0-443-22308-2.00004-4&partnerID=40&md5=a1d159a6c188aa5ac0196dc8dc0c2c60","A fundamental problem in medical image analysis, biomedical image segmentation, is essential to many therapeutic applications. To facilitate quantitative analysis and support disease diagnosis, treatment planning, and disease monitoring, it requires partitioning images into different regions or objects of interest. Artificial intelligence (AI) methods, in particular deep learning algorithms, have become effective tools for biomedical picture segmentation in recent years. This chapter presents a biomedical image segmentation application of AI, emphasizing its potential to enhance precision, effectiveness, and therapeutic results. It examines several AI techniques, such as generative models and convolutional neural networks, and how they might be used to tackle the difficulties associated with image segmentation. It emphasizes how using AI algorithms can produce precise and reliable segmentation results. We go over the difficulties with biomedical image segmentation as well as the improvements made feasible by AI methods. We also implement a medical image segmentation example with TransResUNet. The impact of AI on biomedical image segmentation and its promise to alter medical imaging and customized healthcare are highlighted in the chapter's conclusion. © 2024 Elsevier Inc. All rights reserved.","Artificial intelligence; Biomedical image segmentation; Clinical applications; Deep learning; TransResUNet","","","","Elsevier",""
"Chen G.; Shi T.; Xie B.; Zhao Z.; Meng Z.; Huang Y.; Dong J.","Chen, Guanyu (57221151524); Shi, Tianyi (57885828500); Xie, Baoxing (58609579400); Zhao, Zhicheng (56029227100); Meng, Zhu (57209882355); Huang, Yadong (58609065100); Dong, Jin (58609065200)","57221151524; 57885828500; 58609579400; 56029227100; 57209882355; 58609065100; 58609065200","SwinDAE: Electrocardiogram Quality Assessment Using 1D Swin Transformer and Denoising AutoEncoder","2023","27","12","","5779","5790","11","10.1109/JBHI.2023.3314698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171791725&doi=10.1109%2fJBHI.2023.3314698&partnerID=40&md5=f3bef06e69387b5203f139d4a776efe0","Objective: Electrocardiogram (ECG) signals have wide-ranging applications in various fields, and thus it is crucial to identify clean ECG signals under different sensors and collection scenarios. Despite the availability of a variety of deep learning algorithms for ECG quality assessment, these methods still lack generalization across different datasets, hindering their widespread use. Methods: In this paper, an effective model named Swin Denoising AutoEncoder (SwinDAE) is proposed. Specifically, SwinDAE uses a DAE as the basic architecture, and incorporates a 1D Swin Transformer during the feature learning stage of the encoder and decoder. SwinDAE was first pre-trained on the public PTB-XL dataset after data augmentation, with the supervision of signal reconstruction loss and quality assessment loss. Specially, the waveform component localization loss is proposed in this paper and used for joint supervision, guiding the model to learn key information of signals. The model was then fine-tuned on the finely annotated BUT QDB dataset for quality assessment. Results: SwinDAE achieved 0.02-0.13 mean F1 score improvement on the BUT QDB dataset compared to multiple deep learning methods, and demonstrated applicability on two other datasets. Conclusion: The proposed SwinDAE shows strong generalization ability on different datasets, and surpasses other state-of-the-art deep learning methods on multiple evaluation metrics. In addition, the statistical analysis for SwinDAE prove the significance of the performance and the rationality of the prediction. Significance: SwinDAE can learn the commonality between high-quality ECG signals, exhibiting excellent performance in the application of cross-sensors and cross-collection scenarios.  © 2013 IEEE.","Denoising AutoEncoder; ECG quality assessment; swin Transfromer; transfer learning; waveform component localization","Algorithms; Benchmarking; Electric Power Supplies; Electrocardiography; Humans; Research Design; Biomedical signal processing; Deep learning; Feature extraction; Learning algorithms; Signal reconstruction; Auto encoders; De-noising; Deep learning; Denoising autoencoder; Electrocardiogram quality assessment; Features extraction; Localisation; Machine-learning; Quality assessment; Sensitivity; Swin transfrome; Transfer learning; Waveform component localization; Waveform components; accuracy; algorithm; Article; artificial intelligence; artificial neural network; autoencoder; body movement; deep learning; denoising autoencoder; diagnostic accuracy; electrocardiogram; electrocardiography; entropy; feature extraction; gait; heart arrhythmia; heart contraction; heart rate; heart rate variability; homeostasis model assessment; human; image segmentation; learning algorithm; machine learning; mitochondrial respiration; natural language processing; perimetry; physical activity; QRS complex; quality control; signal noise ratio; signal processing; sinus rhythm; speckle tracking echocardiography; speech intelligibility; support vector machine; total quality management; transfer of learning; waveform; algorithm; benchmarking; methodology; power supply; Electrocardiograms","","","Institute of Electrical and Electronics Engineers Inc.","37698969"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","1962 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178564254&partnerID=40&md5=3829318325536acdf7d9f46a8439ef86","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"Zheng W.; Chen J.; Zhang K.; Yan J.; Wang J.; Cheng Y.; Du B.; Chen D.Z.; Gao H.; Wu J.; Xu H.","Zheng, Wenhao (57559381700); Chen, Jintai (57211999917); Zhang, Kai (59041130000); Yan, Jiahuan (58023227100); Wang, Jinhong (57407142300); Cheng, Yi (57750482400); Du, Bang (58739979700); Chen, Danny Z. (7405453271); Gao, Honghao (36442463200); Wu, Jian (56197228100); Xu, Hongxia (57222187378)","57559381700; 57211999917; 59041130000; 58023227100; 57407142300; 57750482400; 58739979700; 7405453271; 36442463200; 56197228100; 57222187378","Polygonal Approximation Learning for Convex Object Segmentation in Biomedical Images with Bounding Box Supervision","2024","28","8","","4522","4533","11","10.1109/JBHI.2023.3341699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180309620&doi=10.1109%2fJBHI.2023.3341699&partnerID=40&md5=cadb113a49e750624b7d19918644bbd8","As a common and critical medical image analysis task, deep learning based biomedical image segmentation is hindered by the dependence on costly fine-grained annotations. To alleviate this data dependence, in this article, a novel approach, called Polygonal Approximation Learning (PAL), is proposed for convex object instance segmentation with only bounding-box supervision. The key idea behind PAL is that the detection model for convex objects already contains the necessary information for segmenting them since their convex hulls, which can be generated approximately by the intersection of bounding boxes, are equivalent to the masks representing the objects. To extract the essential information from the detection model, a repeated detection approach is employed on biomedical images where various rotation angles are applied and a dice loss with the projection of the rotated detection results is utilized as a supervised signal in training our segmentation model. In biomedical imaging tasks involving convex objects, such as nuclei instance segmentation, PAL outperforms the known models (e.g., BoxInst) that rely solely on box supervision. Furthermore, PAL achieves comparable performance with mask-supervised models including Mask R-CNN and Cascade Mask R-CNN. Interestingly, PAL also demonstrates remarkable performance on non-convex object instance segmentation tasks, for example, surgical instrument and organ instance segmentation.  © 2013 IEEE.","Biomedical object segmentation; nuclei segmentation; weakly-supervised segmentation","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Supervised Machine Learning; Biological systems; Image segmentation; Medical imaging; Object detection; Annotation; Biological system modeling; Biomedical imaging; Biomedical object segmentation; Biomedical objects; Instance segmentation; Nucleus segmentation; Objects segmentation; Shape; Supervised segmentation; Weakly-supervised segmentation; ablation study of predicting oval segmentation masks from detection models; ablation study on detection models; Article; artificial neural network; biomedical images; biomedical object segmentation; bounding box supervision; box supervised instance segmentation; computer vision; convex object instance segmentation; convolutional neural network; deep learning; human; image analysis; image segmentation; learning algorithm; mask supervised instance segmentation; medical image analysis task; minimum rotating angle ablation study; nuclei segmentation; polygonal approximation learning; segmentation algorithm; segmentation of non-convex objects; transformer-based detector; weakly supervised segmentation; algorithm; deep learning; image processing; procedures; supervised machine learning; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.","38090818"
"Soufiene B.O.; Chakraborty C.","Soufiene, Ben Othman (56993845900); Chakraborty, Chinmay (7005340424)","56993845900; 7005340424","Machine learning and deep learning techniques for medical image recognition","2023","","","","1","257","256","10.1201/9781003366249","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177094418&doi=10.1201%2f9781003366249&partnerID=40&md5=d43695aba86ae64d79a59dd7c0679a17","Machine Learning and Deep Learning Techniques for Medical Image Recognition comprehensively reviews deep learning-based algorithms in medical image analysis problems including medical image processing. It includes a detailed review of deep learning approaches for semantic object detection and segmentation in medical image computing and large-scale radiology database mining. A particular focus is placed on the application of convolutional neural networks with the theory and varied selection of techniques for semantic segmentation using deep learning principles in medical imaging supported by practical examples. Features: • Offers important key aspects in the development and implementation of machine learning and deep learning approaches toward developing prediction tools and models and improving medical diagnosis • Teaches how machine learning and deep learning algorithms are applied to a broad range of application areas, including chest X-ray, breast computer-aided detection, lung and chest, microscopy, and pathology • Covers common research problems in medical image analysis and their challenges • Focuses on aspects of deep learning and machine learning for combating COVID-19 • Includes pertinent case studies This book is aimed at researchers and graduate students in computer engineering, artificial intelligence and machine learning, and biomedical imaging. © 2024, Ben Othman Soufiene and Chinmay Chakraborty.","","","","","CRC Press",""
"Lee J.Y.; Lee Y.S.; Tae J.H.; Chang I.H.; Kim T.-H.; Myung S.C.; Nguyen T.T.; Lee J.H.; Choi J.; Kim J.H.; Kim J.W.; Choi S.Y.","Lee, Ju Young (59202047900); Lee, Yong Seong (36068330000); Tae, Jong Hyun (56678417400); Chang, In Ho (57203614272); Kim, Tae-Hyoung (57212837594); Myung, Soon Chul (7005796823); Nguyen, Tuan Thanh (57214889585); Lee, Jae Hyeok (57195838934); Choi, Joongwon (57208742789); Kim, Jung Hoon (57207437054); Kim, Jin Wook (57207437351); Choi, Se Young (57209856147)","59202047900; 36068330000; 56678417400; 57203614272; 57212837594; 7005796823; 57214889585; 57195838934; 57208742789; 57207437054; 57207437351; 57209856147","Selection of Convolutional Neural Network Model for Bladder Tumor Classification of Cystoscopy Images and Comparison with Humans","2024","","","","","","","10.1089/end.2024.0250","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197385681&doi=10.1089%2fend.2024.0250&partnerID=40&md5=baf48212e3fed8e0edade970e9d0f0eb","Purpose: An investigation of various convolutional neural network (CNN)-based deep learning algorithms was conducted to select the appropriate artificial intelligence (AI) model for calculating the diagnostic performance of bladder tumor classification on cystoscopy images, with the performance of the selected model to be compared against that of medical students and urologists. Methods: A total of 3,731 cystoscopic images that contained 2,191 tumor images were obtained from 543 bladder tumor cases and 219 normal cases were evaluated. A total of 17 CNN models were trained for tumor classification with various hyperparameters. The diagnostic performance of the selected AI model was compared with the results obtained from urologists and medical students by using the receiver operating characteristic (ROC) curve graph and metrics. Results: EfficientNetB0 was selected as the appropriate AI model. In the test results, EfficientNetB0 achieved a balanced accuracy of 81%, sensitivity of 88%, specificity of 74%, and an area under the curve (AUC) of 92%. In contrast, human-derived diagnostic statistics for the test data showed an average balanced accuracy of 75%, sensitivity of 94%, and specificity of 55%. Specifically, urologists had an average balanced accuracy of 91%, sensitivity of 95%, and specificity of 88%, while medical students had an average balanced accuracy of 69%, sensitivity of 94%, and specificity of 44%. Conclusions: Among the various AI models, we suggest that EfficientNetB0 is an appropriate AI classification model for determining the presence of bladder tumors in cystoscopic images. EfficientNetB0 showed the highest performance among several models and showed high accuracy and specificity compared to medical students. This AI technology will be helpful for less experienced urologists or nonurologists in making diagnoses. Image-based deep learning classifies bladder cancer using cystoscopy images and shows promise for generalized applications in biomedical image analysis and clinical decision making. Copyright 2024, Mary Ann Liebert, Inc., publishers.","artificial intelligence; bladder cancer; convolutional neural network; cystoscopy; deep learning","","National Research Foundation of Korea, NRF; Ministry of Science, ICT and Future Planning, MSIP, (NRF-2022R1F1A1076502); Ministry of Science, ICT and Future Planning, MSIP; Korean Neurological Association, KNA, (KUOS 21-06); Korean Neurological Association, KNA","","Mary Ann Liebert Inc.","38877795"
"","","","46th Mexican Conference on Biomedical Engineering, CNIB 2023","2024","96","","","","","676","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177176594&partnerID=40&md5=904640d21862d5465d90edd50e842297","The proceedings contain 70 papers. The special focus in this conference is on Biomedical Engineering. The topics include: Tumor Tissue Classification in Hyperspectral Histopathology Images Through Individual and Ensemble of Machine Learning Algorithms; Classification of COVID-19 Mortality Risk: A Neural Network-Based Approach Using Mexican Healthcare Sector Data; design of a Convolutional Neural Network for Hippocampal Segmentation in Epileptics and Healthy Patients; Development and Evaluation of a Diagnostic Exam for Undergraduate Biomedical Engineering Students Using GPT Language Model-Based Virtual Agents; transcriptional Expression of Bioactive Antimicrobial Peptides with Biomedical Potential in Diverse Organs of the Mexican Axolotl; drugs and Therapeutic Targets in Breast Cancer: Physicochemical Analysis by Computational Chemistry; automatic Cluster Selection in K-Means Lung Segmentation; muscle Activation Patterns Differentiate Post-stroke and Healthy Population; heterogeneous Behavior in the Iowa Gambling Task: A Clustering Approach; skinSight: A Melanoma Detection App Based on Deep Learning Models with On-Device Inference; vision Algorithm to Compute Pupil Parameters: Towards Non-invasive Estimation of Intracranial Pressure; sex-Based Speech Pattern Recognition for Post-traumatic Stress Disorder; Analysis of EEG Signals Recorded from Persons with Neuronal Alterations due to Covid-19 with Respect to the Cases Considered Normal; automated Segmentation of Breast Skin for Early Cancer Diagnosis: A Multi-otsu Region Growing Approach for Detecting Skin Thickness Variations; towards Fluid Intake Quantification in Older Adults: An Algorithm for Movement Detection Using Accelerometry and Gyroscope Sensors; Optimizing fMRI Techniques for Post-stroke Motor Rehabilitation: Preliminary Protocol Standardization; Recommendations for ICA Denoising of Task-Based Functional MRI Data of Stroke Patients; EOG Signal Classification Based on Blink-to-Speak Language; computation of Human-Sperm Local Flagellar Instantaneous Velocity.","","","","Flores Cuautle J.d.; Benítez-Mata B.; Salido-Ruiz R.A.; Vélez-Pérez H.A.; Alonso-Silverio G.A.; Dorantes-Méndez G.; Mejía-Rodríguez A.R.; Zúñiga-Aguilar E.; Hierro-Gutiérrez E.D.","Springer Science and Business Media Deutschland GmbH",""
"Das A.; Nayak S.R.; Mohanty M.N.; Shukla P.K.","Das, Abhishek (57198696302); Nayak, Soumya Ranjan (57188876957); Mohanty, Mihir Narayan (57211009173); Shukla, Piyush Kumar (56599752300)","57198696302; 57188876957; 57211009173; 56599752300","Biomedical signal to image conversion and classification using flexible deep learning techniques","2024","24","2","","183","202","19","10.1504/IJBIDM.2024.136439","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183947326&doi=10.1504%2fIJBIDM.2024.136439&partnerID=40&md5=016d476b047bf846d27f63d3d0bb6293","Most diseases are diagnosed from image data like CT scans, MRIs, and X-rays. Gene data carries vital information related to the diseases that needs to be analysed for diagnosis. Both the logics are combined and a flexible deep ensemble learning-based model is proposed for the classification of images generated from one-dimensional (1D) data. Earlier works in the detection of brain tumours and epileptic seizures have been developed either directly providing 1D data or images to the classification model, whereas the proposed method utilises the effectiveness of two-dimensional (2D) convolutional neural networks (CNNS) to analyse 1D data like gene expressions and EEG signals after effective conversion to images. The data conversion is performed using three data reduction techniques, i.e., locally linearly embedding (LL-Embedding), multi-dimensional scaling (MDS), and t-distributed stochastic neighbour embedding (t-SNE) with convex hull algorithm to wrap all the data points. Multilayer perceptron is used for second-stage training. The proposed method is verified using brain tumour gene data collected from the genomic data commons (GDC) data portal and the EEG data for epileptic seizures detection provided by the University of Bonn (UoB dataset) and provided 97.38% and 97.33% accuracies respectively. © 2024 Inderscience Enterprises Ltd.. All rights reserved.","Brain tumour; Convex hull.; Convolution neural network; EEG to image; Ensemble learning; Epileptic; Gene to image; Multilayer perception; Seizure","Brain; Computerized tomography; Convolution; Convolutional neural networks; Data handling; Deep learning; Diagnosis; Embeddings; Gene expression; Image classification; Multilayer neural networks; Multilayers; Neurophysiology; Tumors; Brain tumors; Convex hull; Convex hull.; Convolution neural network; EEG to image; Ensemble learning; Epileptic; Gene to image; Multi-layer perception; Seizure; Stochastic systems","","","Inderscience Publishers",""
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","1963 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178637916&partnerID=40&md5=586fffd2441e9387dc354a41897227bc","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"Qi X.; Wu Z.; Zou W.; Ren M.; Gao Y.; Sun M.; Zhang S.; Shan C.; Sun Z.","Qi, Xingqun (57200316444); Wu, Zhuojie (57243840600); Zou, Wenxuan (57247979700); Ren, Min (57196329305); Gao, Yifan (58973612800); Sun, Muyi (57200658411); Zhang, Shanghang (57054535400); Shan, Caifeng (13605743800); Sun, Zhenan (57218404238)","57200316444; 57243840600; 57247979700; 57196329305; 58973612800; 57200658411; 57054535400; 13605743800; 57218404238","Exploring Generalizable Distillation for Efficient Medical Image Segmentation","2024","28","7","","4170","4183","13","10.1109/JBHI.2024.3385098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189638738&doi=10.1109%2fJBHI.2024.3385098&partnerID=40&md5=3f2139e3806276e12410132ec9211eb2","Efficient medical image segmentation aims to provide accurate pixel-wise predictions with a lightweight implementation framework. However, existing lightweight networks generally overlook the generalizability of the cross-domain medical segmentation tasks. In this paper, we propose Generalizable Knowledge Distillation (GKD), a novel framework for enhancing the performance of lightweight networks on cross-domain medical segmentation by generalizable knowledge distillation from powerful teacher networks. Considering the domain gaps between different medical datasets, we propose the Model-Specific Alignment Networks (MSAN) to obtain the domain-invariant representations. Meanwhile, a customized Alignment Consistency Training (ACT) strategy is designed to promote the MSAN training. Based on the domain-invariant vectors in MSAN, we propose two generalizable distillation schemes, Dual Contrastive Graph Distillation (DCGD) and Domain-Invariant Cross Distillation (DICD). In DCGD, two implicit contrastive graphs are designed to model the intra-coupling and inter-coupling semantic correlations. Then, in DICD, the domain-invariant semantic vectors are reconstructed from two networks (i.e., teacher and student) with a crossover manner to achieve simultaneous generalization of lightweight networks, hierarchically. Moreover, a metric named Fréchet Semantic Distance (FSD) is tailored to verify the effectiveness of the regularized domain-invariant features. Extensive experiments conducted on the Liver, Retinal Vessel and Colonoscopy segmentation datasets demonstrate the superiority of our method, in terms of performance and generalization ability on lightweight networks.  © 2013 IEEE.","Contrastive Graph; Knowledge Distillation; Medical Image Segmentation; Model Generalization","Algorithms; Databases, Factual; Deep Learning; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Distillation; Job analysis; Medical imaging; Personnel training; Semantic Segmentation; Biomedical imaging; Contrastive graph; Cross-domain; Images segmentations; Knowledge distillation; Medical image segmentation; Medical segmentations; Model generalization; Performance; Task analysis; article; colonoscopy; controlled study; distillation; human; image segmentation; prediction; retina blood vessel; semantics; training; algorithm; artificial neural network; deep learning; factual database; image processing; procedures; Semantics","","","Institute of Electrical and Electronics Engineers Inc.","38954557"
"Zhao P.; Song X.; Xi X.; Nie X.; Meng X.; Qu Y.; Yin Y.","Zhao, Peng (58485224200); Song, Xian (57873921600); Xi, Xiaoming (55034799700); Nie, Xiushan (35327663300); Meng, Xianjing (55510664400); Qu, Yi (26635577100); Yin, Yilong (8981026100)","58485224200; 57873921600; 55034799700; 35327663300; 55510664400; 26635577100; 8981026100","Biomarkers-Aware Asymmetric Bibranch GAN with Adaptive Memory Batch Normalization for Prediction of Anti-VEGF Treatment Response in Neovascular Age-Related Macular Degeneration","2024","28","1","","557","568","11","10.1109/JBHI.2023.3302989","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167802891&doi=10.1109%2fJBHI.2023.3302989&partnerID=40&md5=960baaeb396a8b0f2444deeb93f2422e","The emergence of anti-vascular endothelial growth factor (anti-VEGF) therapy has revolutionized neovascular age-related macular degeneration (nAMD). Post-therapeutic optical coherence tomography (OCT) imaging facilitates the prediction of therapeutic response to anti-VEGF therapy for nAMD. Although the generative adversarial network (GAN) is a popular generative model for post-therapeutic OCT image generation, it is realistically challenging to gather sufficient pre- and post-therapeutic OCT image pairs, resulting in overfitting. Moreover, the available GAN-based methods ignore local details, such as the biomarkers that are essential for nAMD treatment. To address these issues, a Biomarkers-aware Asymmetric Bibranch GAN (BAABGAN) is proposed to efficiently generate post-therapeutic OCT images. Specifically, one branch is developed to learn prior knowledge with a high degree of transferability from large-scale data, termed the source branch. Then, the source branch transfer knowledge to another branch, which is trained on small-scale paired data, termed the target branch. To boost the transferability, a novel Adaptive Memory Batch Normalization (AMBN) is introduced in the source branch, which learns more effective global knowledge that is impervious to noise via memory mechanism. Also, a novel Adaptive Biomarkers-aware Attention (ABA) module is proposed to encode biomarkers information into latent features of target branches to learn finer local details of biomarkers. The proposed method outperforms traditional GAN models and can produce high-quality post-treatment OCT pictures with limited data sets, as shown by the results of experiments.  © 2013 IEEE.","generative adversarial network; Neovascular age-related macular degeneration; post-therapeutic image prediction; transfer learning","Biomarkers; Forecasting; Generative adversarial networks; Medical imaging; Ophthalmology; biological marker; vasculotropin antibody; Age-related macular degeneration; Biological system modeling; Biomedical imaging; Image prediction; Medical treatment; Neovascular age-related macular degeneration; Post-therapeutic image prediction; Retina; Task analysis; Transfer learning; age related macular degeneration; aged; Article; artificial neural network; deep learning; eye fundus; female; fluorescence angiography; human; image analysis; image quality; indocyanine green angiography; laser coagulation; learning algorithm; machine learning; major clinical study; male; multimodal imaging; neuroimaging; optic disk; optical coherence tomography; perimetry; prediction; retinal nerve fiber layer thickness; retinal outer plexiform layer; sensitivity and specificity; spectral domain optical coherence tomography; transfer of learning; treatment response; visual acuity; visual field; Optical tomography","","","Institute of Electrical and Electronics Engineers Inc.","37549082"
"Lai P.; Zhao Q.; Zhou Y.; Cheng S.; Chi M.W.; Li H.; Yu Z.; Huang X.; Yao J.; Pang W.; Li H.; Huang H.; Li W.; Zheng Y.; Wang Z.; Yuan C.; Zhong T.","Lai, Puxiang (26639352000); Zhao, Qi (57224130880); Zhou, Yingying (57193263686); Cheng, Shengfu (57211430971); Chi, Man Woo (58888692600); Li, Huanhao (57193457233); Yu, Zhipeng (57199835329); Huang, Xiazi (57211916912); Yao, Jing (57219726342); Pang, Weiran (57208307320); Li, Haoran (57202729561); Huang, Haofan (57220035895); Li, Wenzhao (57225041323); Zheng, Yuandong (58606345400); Wang, Zhiyuan (57349258400); Yuan, Chuqi (57764116100); Zhong, Tianting (57200560004)","26639352000; 57224130880; 57193263686; 57211430971; 58888692600; 57193457233; 57199835329; 57211916912; 57219726342; 57208307320; 57202729561; 57220035895; 57225041323; 58606345400; 57349258400; 57764116100; 57200560004","Deep-Tissue Optics: Technological Development and Applications (Invited); [深 层 生 物 组 织 光 学 技 术 发 展 及 其 应 用（特 邀）]","2024","51","1","","","","","10.3788/CJL231318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185192537&doi=10.3788%2fCJL231318&partnerID=40&md5=9dc5ea9868b96ef2637e1b48e7f32667","Significance Optics, which is a significant sub-discipline of physics, focuses on the study of the phenomena, properties, and applications of light. Optics has evolved into an independent discipline over time. Optical imaging plays a crucial role in optical research by utilizing the phenomena and properties of light to record images of objects. Optical imaging has extensive applications in diverse fields, including astronomy, medicine, communication, and photography. For example, with the ongoing advancements in biomedical research, optical imaging has progressively showcased its distinctive advantages. First, optical imaging offers high resolution that is free from ionizing radiation, making it safer than X-rays or gamma rays that pose the potential risk of cancer. In addition, optical imaging can be flexibly configured to provide rich biomedical information based on the amplitude, phase, wavelength, polarization, and other characteristics of light. Another advantage of optics is their exceptional sensitivity, which enables the precise and sensitive detection of interactions between light and tissue components or molecules. Finally, the application of contrast agents further enhances the imaging specificity and contrast, thereby improving the visualization of desired targets and opening new avenues for disease diagnosis and treatment. These have spurred the development of a vast range of high-resolution optical imaging technologies, such as confocal microscope, multiphoton microscope, and super-resolution imaging, which have been achieved by exciting fluorescence signals and/ or utilizing gating or nonlinear optical effects in tissue samples. However, these implementations without exception have encountered fundamental challenges in thick biological tissues. This limitation stems from the strong scattering of light in tissue due to the inherent inhomogeneous spatial distribution of the refractive index of the medium encompassing diverse tissue constituents and functions. As a result, when light propagates within biological tissues, the light beam spreads quickly and is accompanied by the accumulated scattering of light (approximately one scattering event per 0.1-mm optical path length at visible wavelengths), which also rapidly weakens the intensity of non-scattered light in situ. In combination, these result in an intrinsic trade-off between spatial resolution and penetration depth for optics in biological tissues. This is also why optical techniques that utilize ballistic or quasi-ballistic photons typically have an effective penetration depth of less than or approximately 1 mm beneath the skin, which corresponds to 10 times the transport mean free path in the visible and near-infrared regimes. Excessive laser power may further enhance tissue penetration depths, but it also poses a risk of damaging biological tissues, particularly the skin and subsurface. In the past two decades, numerous studies have been conducted to address these challenges, including switching to longer wavelengths to obtain lower tissue scattering coefficients, converting diffused light into non-scattered ultrasound at the signal detection side, and creating a minimally invasive optical path via ultrathin fibers to deep tissue regions. We believe that summarizing these advancements is not only worthwhile, but also critical for inspiring further research aimed at greater penetration depths and faster speeds toward wider applications. Progress In this review, we summarize the recent efforts in deep-tissue optics from various perspectives based on the mechanism of operation, including physical, computational, learning, and fiber optics. Note that this is not a complete list but only an empirical one. Regarding physical-optics-based efforts, relevant research has primarily focused on the three aspects of wavelength engineering, energy conversion, and phase compensation. Wavelength engineering, such as multiphoton imaging and up-conversion imaging, involves the transformation of the input light wavelength into a different output wavelength to enhance the penetration depth. In multiphoton fluorescence imaging, two or more photons with longer wavelengths but lower energies are absorbed almost simultaneously before exciting the target fluorescent molecules at depth, generating one photon with shorter wavelength but higher energy. The longer wavelength in excitation and elevated photon energy in emission both contribute positively to the increased penetration depth for imaging. Up-conversion imaging entails the sequential absorption of multiple low-energy photons and their conversion into a single high-energy photon, thereby increasing the penetration depth. Among approaches based on energy conversion, the photoacoustic (PA) effect, which converts input pulsed light into ultrasonic waves, has been extensively studied. When a biological tissue absorbs light energy, it undergoes thermal transformation, leading to localized expansion in the region of interest. Conversely, when the optical illumination is switched off, the local temperature decreases, causing the tissue region to contract. When the activation and deactivation of optical illumination (such as pulsed light) are manipulated, the expansion and contraction of tissues can be controlled, generating periodic mechanical waves in the ultrasonic frequency (MHz) range. These are usually referred to as photoacoustic or optoacoustic signals and are detected by one or an array of ultrasound transducers positioned outside the tissue sample. Because the generation of PA signals relies on the optical absorption of light, optical absorption contrast is obtained in PA imaging. However, the generation of signals does not distinguish between ballistic or diffused photons, and the detection of signals is based on ultrasound, which scatters much less (~1/1000) than light in the tissue. In combination, these features lead to a considerably boosted balance between imaging resolution and penetration depth and enable many exciting applications that are not possible with pure optical technologies. In phase compensation, optical devices are utilized to measure and compensate for the optical phase distortion induced by light scattering. One representative example of phase compensation is optical phase conjugation, which captures the phase distortion of the wavefront emitted by a guide star within the scattering medium and compensates for it by conjugately adjusting the incident wavefronts and then refocusing light onto the position of the guide star. The phase-conjugation mirror, which is typically a photorefractive material, is responsible for recording the incident wavefront pattern and generating conjugated light that propagates along the optical path opposite the original transmission path. Computational optics is an interdisciplinary field that merges optics and computers to leverage physics and algorithms, thereby enabling applications beyond those that can be achieved using traditional optical systems. The primary computational optics-based efforts in deep-tissue optics include digital optical phase conjugation (DOPC), iterative wavefront shaping, and transmission and reflection matrices. In DOPC, the phase-conjugation mirror previously discussed is replaced by the integration of a digital camera, computer, spatial light modulator, and algorithms for determining and generating the phase-conjugated wavefront. In iterative wavefront shaping, the phase of the incident light wavefront is adjusted based on feedback signals and the focusing performance is iteratively optimized. Feedback signals can take various forms, such as focal intensity, peak-to-background ratio (PBR) in the captured pattern, and photoacoustic signal strength. In the transmission matrix, a linear mathematical model is used to describe the relationship between the incident and scattered output wavefronts to characterize the scattering medium. If we denote the input wavefront as ein and the output wavefront as eout, the transmission matrix (MTM) can be characterized as eout = MTM • ein. By measuring the transmission matrix, we can focus the diffused light, project specific patterns through a scattering medium, or retrieve images from speckles. The reflection matrix establishes the relationship between the incident and reflected wavefronts from a scattering medium. In deep tissues, it is typically impractical to define or position guidestars or obtain guidestar signals within or on the opposite side of a tissue sample. Thus, applications of transmission matrices are limited. The introduction of a reflection matrix addresses this challenge by utilizing a reflected wavefront instead of a transmitted wavefront. In this scenario, both the incident and reflected light detectors are present on the same side of the scattering medium, thereby circumventing the need for guidestars to be placed on the opposite side of the scattering medium. These computational optics-based efforts typically rely on intricate physical models to achieve the focusing or imaging of simple targets, such as letters, numbers, and other basic patterns, through scattering media. With recent advances in artificial intelligence, complicated problems involving speckles can now be addressed using deep learning. For example, deep-learning-based speckle imaging has powerful learning capabilities and data-driven characteristics. Deep neural networks can be trained using known data pairs, including ground-truth images and corresponding speckles, to extract various dimensions of information features. This can enable the high-fidelity reconstruction of target images, such as human face images. In addition, by training the speckle patterns obtained under different states of perturbed scattering media, the generalization capabilities of deep neural networks can be further improved, and the robustness of handling perturbed scattering media exceeds that of transmission-matrix-based methods. In addition to these endeavors, which are all aimed at noninvasive deep-tissue optics, minimally invasive solutions that employ ultrathin optical multimode fibers as light guides into the tissue are also attractive and have seen promising advancements in recent years. Multimode fiber-based imaging is advantageous due to its minimally invasive nature, flexibility, and affordability. However, because of mode dispersion and coupling within multimode fibers, the optical field output from the fiber appears to be similar to a speckle pattern from tissue-like scattering media, making it infeasible to directly interpret the transmitted spatial information. Nevertheless, if multimode fibers are treated as scattering media, the aforementioned wavefront shaping approaches can be applied to multimode fibers. Thus, with the integration of wavefront shaping, the speckled output from a lensless multimode fiber can be focused onto a single optical mode, and then the raster can scan at a high speed within the field of view of the fiber. The excited or responding signals can also be detected and relayed using the same fiber for further use. This creates a scenario very similar to laser confocal microscope, except that the probe is inserted deep into the tissue. As a result, spatially and/or temporally resolving optical signals from deep tissues can be excited and detected with high resolution, which opens avenues for exciting new optical practices that require high resolution at depths in tissue. This capability can also be extended beyond imaging, such as for optogenetics, where wavefront shaping-empowered multimode fibers can deliver light precisely to targeted neurons within deep tissues and pick up fluorescence signals reflecting neuronal activities, enabling precise activation or inhibition of neurons to study brain functions. Conclusions and Prospects Optics have gained significant attention in the study of deep biological tissues due to their non-ionizing radiation, exceptional contrast, exquisite specificity, and heightened sensitivity. In addition, the integration of computational optics and deep learning with conventional optics has substantially enhanced penetration depths while preserving moderate resolution in deep biological tissues. Despite these remarkable advancements, the practical implementation of deep-tissue optics still encounters critical challenges that must be addressed before moving forward. The first is the penetration depth. With photoacoustic efforts and wavefront shaping techniques, which are sometimes further aided by computational optics and deep learning, current practices have achieved high-resolution optical focusing and/or imaging far beyond the optical diffraction limit. While most experimental research efforts to date still concentrate on small animal models such as mice, future studies are anticipated to improve the depth capability and extend to large animal models such as rabbits and monkeys. This transition is necessary for assessing the practicality, safety, and reliability of clinical diagnostics and therapeutic applications before working with human patients. © 2024 Science Press. All rights reserved.","bio-optics; biomedical optics; deep tissue; optical imaging; optical wavefront shaping; photoacoustic imaging","Diagnosis; Diseases; Fluorescence; Gamma rays; Histology; Infrared devices; Medical imaging; Optical image storage; Photons; Refractive index; Biological tissues; Biomedical optics; Biooptics; Deep tissue; Optical imaging; Optical wavefront; Optical wavefront shaping; Photo-acoustic imaging; Scattering medium; Wave front shaping; Tissue","","","Science Press",""
"Sonawane P.S.; Helonde J.B.","Sonawane, Pratibha S (58205077200); Helonde, Jagdish B. (35145609900)","58205077200; 35145609900","Smart Societal Optimization-based Deep Learning Convolutional Neural Network Model for Epileptic Seizure Prediction","2024","12","1","2280551","","","","10.1080/21681163.2023.2280551","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177478285&doi=10.1080%2f21681163.2023.2280551&partnerID=40&md5=4bda0ddd00231d0b1a608f1e4b01aa3b","Epilepsy is a long-term neurological condition that disrupts brain function in people of all ages, epilepsy is a condition that is analysed through the brain signals via electroencephalogram (EEG) signal. To analyse epilepsy using spatial and temporal data, various machine-learning-based techniques are used. However, most of the techniques suffer from inaccuracy issues in dealing with the dynamic and raw EEG signal. In this research, an intelligent societal optimisation-driven classifier is introduced based on convolutional neural networks (CNN) for epileptic seizure prediction using EEG signals. To boost predictive accuracy, we extract frequency band features from the EEG signal utilising wavelet decomposition. The frequency band features form the feature vector, is provided smart societal optimisation- CNN such that the prediction performance is enhanced through the optimal tuning of the CNN with the smart societal optimisation. Smart societal optimisation is proposed by integrating the behaviour of the Lobos wolf and the Moggie. The smart societal optimisation-based CNN attains 87.673% accuracy, 84.949% sensitivity91.274%specificity for the K-Fold-10 for CHB-MIT scalp EEG database. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Deep learning classification; EEG signals; epileptic seizure prediction; frequency band features; optimisation algorithm","Biomedical signal processing; Convolution; Convolutional neural networks; Deep learning; Electroencephalography; Neurodegenerative diseases; Neurophysiology; Wavelet decomposition; Brain functions; Condition; Convolutional neural network; Deep learning classification; Electroencephalogram signals; Epileptic seizure prediction; Frequency band feature; Neural network model; Optimisations; Optimization algorithms; adolescent; adult; Article; child; convolutional neural network; deep learning; diagnostic test accuracy study; electroencephalogram; epilepsy; female; human; image processing; k nearest neighbor; male; mathematical model; mathematical parameters; prediction; recurrent neural network; sensitivity and specificity; smart societal optimization; Forecasting","","","Taylor and Francis Ltd.",""
"Zhi S.; Wang Y.; Xiao H.; Bai T.; Li B.; Tang Y.; Liu C.; Li W.; Li T.; Ge H.; Cai J.","Zhi, Shaohua (57192655243); Wang, Yinghui (58611324700); Xiao, Haonan (57222711088); Bai, Ti (57994072100); Li, Bing (57447068000); Tang, Yunsong (58486660800); Liu, Chenyang (57329805500); Li, Wen (58399445600); Li, Tian (57216658368); Ge, Hong (57226450976); Cai, Jing (35067810800)","57192655243; 58611324700; 57222711088; 57994072100; 57447068000; 58486660800; 57329805500; 58399445600; 57216658368; 57226450976; 35067810800","Coarse-Super-Resolution-Fine Network (CoSF-Net): A Unified End-to-End Neural Network for 4D-MRI With Simultaneous Motion Estimation and Super-Resolution","2024","43","1","","162","174","12","10.1109/TMI.2023.3294245","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164744059&doi=10.1109%2fTMI.2023.3294245&partnerID=40&md5=0d6b1f27cf3924478f1ace128dcba052","Four-dimensional magnetic resonance imaging (4D-MRI) is an emerging technique for tumor motion management in image-guided radiation therapy (IGRT). However, current 4D-MRI suffers from low spatial resolution and strong motion artifacts owing to the long acquisition time and patients' respiratory variations. If not managed properly, these limitations can adversely affect treatment planning and delivery in IGRT. In this study, we developed a novel deep learning framework called the coarse-super-resolution-fine network (CoSF-Net) to achieve simultaneous motion estimation and super-resolution within a unified model. We designed CoSF-Net by fully excavating the inherent properties of 4D-MRI, with consideration of limited and imperfectly matched training datasets. We conducted extensive experiments on multiple real patient datasets to assess the feasibility and robustness of the developed network. Compared with existing networks and three state-of-the-art conventional algorithms, CoSF-Net not only accurately estimated the deformable vector fields between the respiratory phases of 4D-MRI but also simultaneously improved the spatial resolution of 4D-MRI, enhancing anatomical features and producing 4D-MR images with high spatiotemporal resolution. © 1982-2012 IEEE.","Coarse-to-fine registration; deep learning; four-dimensional magnetic resonance imaging; super-resolution","Humans; Magnetic Resonance Imaging; Motion; Neural Networks, Computer; Radiotherapy, Image-Guided; Deep learning; Image enhancement; Image resolution; Medical imaging; Motion estimation; Radiotherapy; Tumors; Biomedical imaging; Coarse to fine; Coarse-to-fine registration; Deep learning; End to end; Four-dimensional magnetic resonance imaging; Image-guided radiation therapy; Neural-networks; Spatial resolution; Superresolution; Article; artificial neural network; breathing mechanics; breathing pattern; coarse super resolution fine network; convolutional neural network; cross correlation; deep learning; feasibility study; feature extraction; four-dimensional imaging; human; image enhancement; image quality; image registration; image registration algorithm; intermethod comparison; measurement accuracy; measurement error; motion; nuclear magnetic resonance imaging; performance indicator; quantitative analysis; root mean squared error; signal noise ratio; spatiotemporal analysis; total quality management; artificial neural network; image guided radiotherapy; motion; nuclear magnetic resonance imaging; procedures; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.","37432808"
"Pal S.C.; Toumpanakis D.; Wikstrom J.; Ahuja C.K.; Strand R.; Dhara A.K.","Pal, Subhash Chandra (58179329500); Toumpanakis, Dimitrios (57671205700); Wikstrom, Johan (7006375844); Ahuja, Chirag Kamal (23048455900); Strand, Robin (57214766927); Dhara, Ashis Kumar (54897503900)","58179329500; 57671205700; 7006375844; 23048455900; 57214766927; 54897503900","Multi-Level Residual Dual Attention Network for Major Cerebral Arteries Segmentation in MRA Toward Diagnosis of Cerebrovascular Disorders","2024","23","1","","167","175","8","10.1109/TNB.2023.3298444","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165867079&doi=10.1109%2fTNB.2023.3298444&partnerID=40&md5=762c32aa22849d39e4004898d0e68316","Segmentation of major brain vessels is very important for the diagnosis of cerebrovascular disorders and subsequent surgical planning. Vessel segmentation is an important preprocessing step for a wide range of algorithms for the automatic diagnosis or treatment of several vascular pathologies and as such, it is valuable to have a well-performing vascular segmentation pipeline. In this article, we propose an end-to-end multiscale residual dual attention deep neural network for resilient major brain vessel segmentation. In the proposed network, the encoder and decoder blocks of the U-Net are replaced with the multi-level atrous residual blocks to enhance the learning capability by increasing the receptive field to extract the various semantic coarse- and fine-grained features. Dual attention block is incorporated in the bottleneck to perform effective multiscale information fusion to obtain detailed structure of blood vessels. The methods were evaluated on the publicly available TubeTK data set. The proposed method outperforms the state-of-the-art techniques with dice of 0.79 on the whole-brain prediction. The statistical and visual assessments indicate that proposed network is robust to outliers and maintains higher consistency in vessel continuity than the traditional U-Net and its variations.  © 2002-2011 IEEE.","deep neural networks; Intracranial aneurysms; magnetic resonance angiography (MRA); major brain vessels; volumetric segmentation","Algorithms; Brain; Cerebral Arteries; Cerebrovascular Disorders; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Blood vessels; Brain; Computer architecture; Deep neural networks; Diagnosis; Magnetic resonance; Medical imaging; Semantics; Aneurysm; Biomedical imaging; Brain modeling; Brain vessels; Images segmentations; Intracranial aneurysms; Magnetic resonance angiography; Major brain vessel; Volumetric segmentations; algorithm; artificial neural network; brain; brain artery; cerebrovascular disease; diagnostic imaging; human; image processing; Image segmentation","Department of Biotechnology, Ministry of Science and Technology, India, DBT, (BT/PR41121/Swdn/135/7/2020); VINNOVA, (2020-03616)","","Institute of Electrical and Electronics Engineers Inc.","37486852"
"Song H.; Wang Z.","Song, Huihui (58964894600); Wang, Zheng (59156960300)","58964894600; 59156960300","Automatic Classification of White Blood Cells Using a Semi-Supervised Convolutional Neural Network","2024","12","","","44972","44983","11","10.1109/ACCESS.2024.3380896","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189137184&doi=10.1109%2fACCESS.2024.3380896&partnerID=40&md5=c6d42f1772878efa3291293968d7d8fc","The correct classification of white blood cell subtypes is critical in the diagnosis of blood disease. However, the performance of classical computer vision-based classification methods is heavily dependent on the features that should be carefully designed by trial and error. The machine learning-based classifier outperforms the traditional classifiers but suffers from sample labeling, which is labor intensive and time consuming. This paper presents a semi-supervised convolutional neural network that can maintain a similarly high accuracy of classification as deep learning approaches with only 10% labeled data or less. A Visual Geometry Group (VGG) network model was pre-trained with a small amount of labeled data and then used to predict unlabeled data. After implementing entropy filtering and confidence filtering processes, high-quality pseudo label data were obtained and served as input for the final mean teacher model training. The proposed methodology was validated on a dataset of 9069 synthetic images that correspond to five different subtypes of white blood cells. The model yielded an overall average accuracy of 94.4% with only 500 labeled samples, which is slightly lower than that of the fully supervised model with 9069 labeled samples (97.9%) but much higher than that of the fully supervised model with 500 labeled samples (86.5%). With such results, the proposed model demonstrates promising prospects for developing clinically useful solutions that are able to detect white blood cells based on blood cell images. © 2013 IEEE.","deep learning; medical imaging; semi-supervision; White blood cell classification","Bioinformatics; Blood; Cells; Classification (of information); Computer aided diagnosis; Convolution; Cytology; Deep learning; Feature extraction; Medical imaging; Neural networks; Personnel training; Supervised learning; Teaching; Biomedical imaging; Classification algorithm; Convolutional neural network; Deep learning; Features extraction; Images segmentations; Semi supervisions; Semi-supervised learning; White blood cell classification; White blood cells; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","14451 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178583888&partnerID=40&md5=007ceaaaf0db55b4cc3502c42b9f5b5c","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"Fan Y.-L.; Hsu F.-R.; Wang Y.; Liao L.-D.","Fan, Yi-Ling (58527908900); Hsu, Fang-Rong (7202881024); Wang, Yuhling (57212035932); Liao, Lun-De (15065570200)","58527908900; 7202881024; 57212035932; 15065570200","Unlocking the Potential of Zebrafish Research with Artificial Intelligence: Advancements in Tracking, Processing, and Visualization","2023","61","11","","2797","2814","17","10.1007/s11517-023-02903-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167357922&doi=10.1007%2fs11517-023-02903-1&partnerID=40&md5=787ca397ca516e4a31ff080eb82fd176","Zebrafish have become a widely accepted model organism for biomedical research due to their strong cortisol stress response, behavioral strain differences, and sensitivity to both drug treatments and predators. However, experimental zebrafish studies generate substantial data that must be analyzed through objective, accurate, and repeatable analysis methods. Recently, advancements in artificial intelligence (AI) have enabled automated tracking, image recognition, and data analysis, leading to more efficient and insightful investigations. In this review, we examine key AI applications in zebrafish research, including behavior analysis, genomics, and neuroscience. With the development of deep learning technology, AI algorithms have been used to precisely analyze and identify images of zebrafish, enabling automated testing and analysis. By applying AI algorithms in genomics research, researchers have elucidated the relationship between genes and biology, providing a better basis for the development of disease treatments and gene therapies. Additionally, the development of more effective neuroscience tools could help researchers better understand the complex neural networks in the zebrafish brain. In the future, further advancements in AI technology are expected to enable more extensive and in-depth medical research applications in zebrafish, improving our understanding of this important animal model. This review highlights the potential of AI technology in achieving the full potential of zebrafish research by enabling researchers to efficiently track, process, and visualize the outcomes of their experiments. Graphical Abstract: [Figure not available: see fulltext.] © 2023, International Federation for Medical and Biological Engineering.","Data analysis; Deep learning; Image recognition; Machine learning; Trajectory tracking; Zebrafish","Behavioral research; Data handling; Data visualization; Deep learning; Disease control; Image analysis; Information analysis; Learning systems; Neurology; Analysis method; Artificial intelligence algorithms; Artificial intelligence technologies; Biomedical research; Deep learning; Machine-learning; Model organisms; Stresses response; Trajectory-tracking; Zebrafish; animal behavior; artificial intelligence; automation; behavioral science; cell motion; deep learning; genomics; image processing; large scale production; learning algorithm; machine learning; medical research; microinjection; movement (physiology); neuroscience; nonhuman; Review; zebra fish; Image recognition","National Health Research Institutes of Taiwan, (NHRI-EX108-10829EI, NHRI-EX111-11111EI, NHRI-EX111-11129EI); Ministry of Health and Welfare, MOHW, (113-0324-01-30-11, MOHW 112-0324-01-30-06); National Science and Technology Council, NSTC, (110-2221-E-400-003-MY3, 111-2218-E-007-019, 111-2221-E-035-015, 111-2314-B-075-006, 111-3114-8-400-001)","","Springer Science and Business Media Deutschland GmbH",""
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","1969 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178557826&partnerID=40&md5=c23286954f90d2afc18b7ed624564f69","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"","","","46th Mexican Conference on Biomedical Engineering, CNIB 2023","2024","97","","","","","676","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177423911&partnerID=40&md5=4ea194c933e3cc261441f49bb3ac8a75","The proceedings contain 70 papers. The special focus in this conference is on Biomedical Engineering. The topics include: Tumor Tissue Classification in Hyperspectral Histopathology Images Through Individual and Ensemble of Machine Learning Algorithms; Classification of COVID-19 Mortality Risk: A Neural Network-Based Approach Using Mexican Healthcare Sector Data; design of a Convolutional Neural Network for Hippocampal Segmentation in Epileptics and Healthy Patients; Development and Evaluation of a Diagnostic Exam for Undergraduate Biomedical Engineering Students Using GPT Language Model-Based Virtual Agents; transcriptional Expression of Bioactive Antimicrobial Peptides with Biomedical Potential in Diverse Organs of the Mexican Axolotl; drugs and Therapeutic Targets in Breast Cancer: Physicochemical Analysis by Computational Chemistry; automatic Cluster Selection in K-Means Lung Segmentation; muscle Activation Patterns Differentiate Post-stroke and Healthy Population; heterogeneous Behavior in the Iowa Gambling Task: A Clustering Approach; skinSight: A Melanoma Detection App Based on Deep Learning Models with On-Device Inference; vision Algorithm to Compute Pupil Parameters: Towards Non-invasive Estimation of Intracranial Pressure; sex-Based Speech Pattern Recognition for Post-traumatic Stress Disorder; Analysis of EEG Signals Recorded from Persons with Neuronal Alterations due to Covid-19 with Respect to the Cases Considered Normal; automated Segmentation of Breast Skin for Early Cancer Diagnosis: A Multi-otsu Region Growing Approach for Detecting Skin Thickness Variations; towards Fluid Intake Quantification in Older Adults: An Algorithm for Movement Detection Using Accelerometry and Gyroscope Sensors; Optimizing fMRI Techniques for Post-stroke Motor Rehabilitation: Preliminary Protocol Standardization; Recommendations for ICA Denoising of Task-Based Functional MRI Data of Stroke Patients; EOG Signal Classification Based on Blink-to-Speak Language; computation of Human-Sperm Local Flagellar Instantaneous Velocity.","","","","Flores Cuautle J.d.; Benítez-Mata B.; Salido-Ruiz R.A.; Vélez-Pérez H.A.; Alonso-Silverio G.A.; Dorantes-Méndez G.; Mejía-Rodríguez A.R.; Zúñiga-Aguilar E.; Hierro-Gutiérrez E.D.","Springer Science and Business Media Deutschland GmbH",""
"Mittal R.; Jeribi F.; Martin R.J.; Malik V.; Menachery S.J.; Singh J.","Mittal, Ruchi (57210932810); Jeribi, Fathe (57204498461); Martin, R. John (57118175700); Malik, Varun (57220515306); Menachery, Santhosh Joseph (57203816885); Singh, Jaiteg (26422494700)","57210932810; 57204498461; 57118175700; 57220515306; 57203816885; 26422494700","DermCDSM: Clinical Decision Support Model for Dermatosis Using Systematic Approaches of Machine Learning and Deep Learning","2024","12","","","47319","47337","18","10.1109/ACCESS.2024.3373539","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187358012&doi=10.1109%2fACCESS.2024.3373539&partnerID=40&md5=f56114534ef226a56b245bba212b482d","Skin disorders encompass a wide range of conditions that affect the skin, a vital organ of the human body. Early detection of skin diseases is difficult due to a lack of awareness, subtle symptoms, similarities, inter-individual heterogeneity in symptoms, limited access to dermatologists, and difficulties in imaging techniques. In this article, we propose a clinical decision support model for detection and classification of skin diseases (DermCDSM) through productive improvement of division capabilities and a cross-breed profound learning procedure. The division cycle is expected to be further developed using an improved chameleon swarm optimization (ICSO) method that takes into account a more accurate and proficient identification of the main cause of the disease. By employing the ICSO algorithm, we aim to enhance the overall accuracy and reliability of disease detection methods. Multi-strategy seeking optimization (MSSO), which is used to optimize feature selection by identifying the most significant features for the task at hand, has been introduced to handle the tests connected to data dimensionality. Convolutional deep spiking neural networks (CD-SNN), a deep learning method, have been implemented to improve the precision of skin cancer diagnosis and multi-class classification. The benchmark ISIC 2017 dataset is utilized to validate the efficacy of our proposed framework, DermCDSM, and its superiority over existing approaches in terms of accuracy, dependability, and efficiency is demonstrated. © 2013 IEEE.","Decision support system; deep learning; digital healthcare; eczema; image segmentation","Computer aided diagnosis; Deep neural networks; Dermatology; Diseases; E-learning; Feature extraction; Health care; Image segmentation; Medical imaging; Oncology; Biomedical imaging; Clinical diagnosis; Deep learning; Digital healthcare; Eczema; Electronic healthcare; Features extraction; Images segmentations; Optimisations; Skin cancers; Decision support systems","","","Institute of Electrical and Electronics Engineers Inc.",""
"Güler M.; Namlı E.","Güler, Mustafa (58984022900); Namlı, Ersin (55499104800)","58984022900; 55499104800","Brain Tumor Detection with Deep Learning Methods’ Classifier Optimization Using Medical Images","2024","14","2","642","","","","10.3390/app14020642","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192528413&doi=10.3390%2fapp14020642&partnerID=40&md5=257d5f684d2698f674ea73f7946980ed","It is known that, with the development of artificial intelligence science in recent years, it has started to be used in all areas of life. Due to the increase in diseases that threaten human life, such as epidemics and cancer, more attention has been paid to research in this field. Especially in the field of biomedical image processing, very successful results have been obtained in recent years with the use of deep learning methods. For this study, MR images are utilized to diagnose brain tumors. To assist doctors and radiologists in automatic brain tumor diagnosis and to overcome the need for manual diagnosis, a brain MR image automated classification system is being developed. The data used in the study are open access data obtained from the Kaggle library. This paper presents a novel approach for classifying brain MR images utilizing a dataset of 7022 MR images. To give an unbiased evaluation of the dataset, it is divided into a 40% test and 60% training set. Respectively, VGG, ResNet, DenseNet and SqueezeNet architectures are trained and used for feature extraction from brain MRI images. In order to classify the extracted features, machine learning methods (Support Vector Machines, K-Nearest Neighbors, Naive Bayes, Decision Tree, Linear Regression Analysis) are applied first, then an ensemble learning method is applied and the best validation method is selected. In addition, parameter optimization is applied to the trained CNN algorithms. In order to develop the proposed methods, the Python software program was used in the training and testing phases of the models, and the classification success rates were mutually evaluated. Among the results found, it can see that the ResNet architecture reached 100% accuracy. The data obtained as a result of the study were compared with the results of similar studies. In conclusion, the techniques and methods applied highlight their effectiveness in accurately classifying brain MRI images and their potential to improve diagnostic capabilities. © 2024 by the authors.","brain tumor; classification; convolutional neural networks; deep learning; image processing","","Istanbul University-Cerrahpaşa Scientific Research Projects Coordination Unit, (35916)","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Nkengue M.J.; Zeng X.; Koehl L.; Tao X.","Nkengue, Marc Junior (57227976100); Zeng, Xianyi (55512876800); Koehl, Ludovic (17434471300); Tao, Xuyuan (15840482500)","57227976100; 55512876800; 17434471300; 15840482500","X-RCRNet: An explainable deep-learning network for COVID-19 detection using ECG beat signals","2024","87","","105424","","","","10.1016/j.bspc.2023.105424","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171610916&doi=10.1016%2fj.bspc.2023.105424&partnerID=40&md5=cafe57bf0dffb5afd8b27a4795a17834","Wearable systems measuring human physiological indicators with integrated sensors and supervised learning-based medical image analysis (e.g. ECG, X-ray, CT or ultrasound images for lung or the chest) have been considered relevant tools for COVID-19 monitoring and diagnosis. However, these two technical roadmaps have their respective advantages and drawbacks. The current wearable systems enable to realize real-time monitoring of COVID-19 but are limited to its basic symptoms only, neither allowing to distinguish it from other diseases nor performing deep analysis. Current medical image analysis can provide accurate decision support for diagnosis but rarely deals with real-time data processing. In this context, we propose a new wearable system by combining the advantages of these two technical roadmaps. Considering that electrocardiogram (ECG) has been proved relevant to evolution of COVID-19 symptoms, the proposed wearable system will integrate an explainable Deep Neural Network to realize online monitoring of COVID-19 gravity by using ECG beat signal. This paper will focus on the Deep Neural Network model named X-RCRNet. The network is based on ResNet18 but with few enhancements: 1) LSTM Layers for regenerating the backpropagation error and further extracting the involved time-varying features; 2) LeakyReLU for increasing the performances of the model. With an accuracy of 96.48 % after experiments, our model has not only outperformed the existing methods in terms of accuracy and robustness, but also originally identify the ST interval of the ECG pattern, as the most prominent key features affected by the virus. © 2023 The Authors","COVID-19; Explainable artificial intelligence; Multilabel classification; Signal processing","Biomedical signal processing; Computerized tomography; Decision support systems; Deep neural networks; Electrocardiograms; Image analysis; Learning systems; Long short-term memory; Medical imaging; Multilayer neural networks; Neural network models; Real time systems; Ultrasonic applications; Viruses; 'current; Beat signals; Explainable artificial intelligence; Learning network; Medical image analysis; Multi-label classifications; Physiological indicators; Roadmap; Signal-processing; Wearable systems; algorithm; Article; artificial intelligence; back propagation; benchmarking; body temperature; comparative study; computer assisted tomography; controlled study; coronavirus disease 2019; cross validation; data accuracy; data processing; decision support system; deep learning; deep neural network; ECG abnormality; electrocardiogram; electrocardiography; feature extraction; health status; heart beat; heart infarction; human; image analysis; image segmentation; information processing; long short term memory network; model; multilabel classification; online monitoring; P wave; patient monitoring; PR interval; QRS interval; QT interval; residual neural network; signal processing; T wave; X ray; COVID-19","Agence Nationale de la Recherche, ANR; National Radio Research Agency, RRA","","Elsevier Ltd",""
"Wang J.; Tang Y.; Xiao Y.; Zhou J.T.; Fang Z.; Yang F.","Wang, Jinting (58038820500); Tang, Yujiao (57211429352); Xiao, Yang (56452028600); Zhou, Joey Tianyi (56335714100); Fang, Zhiwen (55966629200); Yang, Feng (57198992554)","58038820500; 57211429352; 56452028600; 56335714100; 55966629200; 57198992554","GREnet: Gradually REcurrent Network With Curriculum Learning for 2-D Medical Image Segmentation","2024","35","7","","10018","10032","14","10.1109/TNNLS.2023.3238381","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148420817&doi=10.1109%2fTNNLS.2023.3238381&partnerID=40&md5=8665492551e9c35dd05f1c85ef76ce5e","Medical image segmentation is a vital stage in medical image analysis. Numerous deep-learning methods are booming to improve the performance of 2-D medical image segmentation, owing to the fast growth of the convolutional neural network. Generally, the manually defined ground truth is utilized directly to supervise models in the training phase. However, direct supervision of the ground truth often results in ambiguity and distractors as complex challenges appear simultaneously. To alleviate this issue, we propose a gradually recurrent network with curriculum learning, which is supervised by gradual information of the ground truth. The whole model is composed of two independent networks. One is the segmentation network denoted as GREnet, which formulates 2-D medical image segmentation as a temporal task supervised by pixel-level gradual curricula in the training phase. The other is a curriculum-mining network. To a certain degree, the curriculum-mining network provides curricula with an increasing difficulty in the ground truth of the training set by progressively uncovering hard-to-segmentation pixels via a data-driven manner. Given that segmentation is a pixel-level dense-prediction challenge, to the best of our knowledge, this is the first work to function 2-D medical image segmentation as a temporal task with pixel-level curriculum learning. In GREnet, the naive UNet is adopted as the backbone, while ConvLSTM is used to establish the temporal link between gradual curricula. In the curriculum-mining network, UNet++ supplemented by transformer is designed to deliver curricula through the outputs of the modified UNet++ at different layers. Experimental results have demonstrated the effectiveness of GREnet on seven datasets, i.e., three lesion segmentation datasets in dermoscopic images, an optic disc and cup segmentation dataset and a blood vessel segmentation dataset in retinal images, a breast lesion segmentation dataset in ultrasound images, and a lung segmentation dataset in computed tomography (CT).  © 2012 IEEE.","Curriculum learning; data-driven curriculum; gradually recurrent network; medical image segmentation","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Blood vessels; Computerized tomography; Diagnosis; Image analysis; Image enhancement; Image segmentation; Job analysis; Medical imaging; Personnel training; Pixels; Recurrent neural networks; Biomedical imaging; Curriculum learning; Data driven; Data-driven curriculum; Gradually recurrent network; Images segmentations; Lesion; Medical diagnostic imaging; Medical image segmentation; Recurrent networks; Task analysis; algorithm; artificial neural network; deep learning; human; image processing; procedures; Curricula","","","Institute of Electrical and Electronics Engineers Inc.","37022080"
"Abidi M.H.; Moiduddin K.; Ayub R.; Mohammed M.K.; Shankar A.; Shiaeles S.","Abidi, Mustufa Haider (55582207400); Moiduddin, Khaja (56238278500); Ayub, Rashid (58101166900); Mohammed, Muneer Khan (56637824500); Shankar, Achyut (58987767600); Shiaeles, Stavros (55258443400)","55582207400; 56238278500; 58101166900; 56637824500; 58987767600; 55258443400","EEGDepressionNet: A Novel Self Attention-Based Gated DenseNet With Hybrid Heuristic Adopted Mental Depression Detection Model Using EEG Signals","2024","","","","1","12","11","10.1109/JBHI.2024.3401389","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193257456&doi=10.1109%2fJBHI.2024.3401389&partnerID=40&md5=e9b5becc3588479f2ec776af9c6b7876","World Health Organization (WHO) has identified depression as a significant contributor to global disability, creating a complex thread in both public and private health. Electroencephalogram (EEG) can accurately reveal the working condition of the human brain, and it is considered an effective tool for analyzing depression. However, manual depression detection using EEG signals is time-consuming and tedious. To address this, fully automatic depression identification models have been designed using EEG signals to assist clinicians. In this study, we propose a novel automated deep learning-based depression detection system using EEG signals. The required EEG signals are gathered from publicly available databases, and three sets of features are extracted from the original EEG signal. Firstly, spectrogram images are generated from the original EEG signal, and 3-dimensional Convolutional Neural Networks (3D-CNN) are employed to extract deep features. Secondly, 1D-CNN is utilized to extract deep features from the collected EEG signal. Thirdly, spectral features are extracted from the collected EEG signal. Following feature extraction, optimal weights are fused with the three sets of features. The selection of optimal features is carried out using the developed Chaotic Owl Invasive Weed Search Optimization (COIWSO) algorithm. Subsequently, the fused features undergo analysis using the Self-Attention-based Gated Densenet (SA-GDensenet) for depression detection. The parameters within the detection network are optimized with the assistance of the same COIWSO. Finally, implementation results are analyzed in comparison to existing detection models. The experimentation findings of the developed model show 96&#x0025; of accuracy. Throughout the empirical result, the findings of the developed model show better performance than traditional approaches. IEEE","Chaotic Owl Invasive Weed Search Optimization; Convolutional Neural Networks; Depression Analysis; Electroencephalogram; Mental Depression Detection; Self-Attention-based Gated Densenet; Spectral Features","Biomedical signal processing; Birds; Convolution; Deep learning; Feature extraction; Neural networks; Optimization; Signal detection; Chaotic owl invasive weed search optimization; Chaotics; Convolutional neural network; Depression analyse; Electroencephalogram signals; Invasive weed; Mental depression detection; Search optimization; Self-attention-based gated densenet; Spectral feature; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Wang Y.; Huang K.; Fang J.; Yan M.; Wu E.; Zeng H.","Wang, Yinqi (57216911729); Huang, Kun (56681588300); Fang, Jianan (57221081077); Yan, Ming (35103947200); Wu, E. (57204914778); Zeng, Heping (7401472015)","57216911729; 56681588300; 57221081077; 35103947200; 57204914778; 7401472015","Mid-infrared single-pixel imaging at the single-photon level","2023","14","1","1073","","","","10.1038/s41467-023-36815-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149053968&doi=10.1038%2fs41467-023-36815-3&partnerID=40&md5=ae5a71486a061d0a19405e1a0d07c300","Single-pixel cameras have recently emerged as promising alternatives to multi-pixel sensors due to reduced costs and superior durability, which are particularly attractive for mid-infrared (MIR) imaging pertinent to applications including industry inspection and biomedical diagnosis. To date, MIR single-pixel photon-sparse imaging has yet been realized, which urgently calls for high-sensitivity optical detectors and high-fidelity spatial modulators. Here, we demonstrate a MIR single-photon computational imaging with a single-element silicon detector. The underlying methodology relies on nonlinear structured detection, where encoded time-varying pump patterns are optically imprinted onto a MIR object image through sum-frequency generation. Simultaneously, the MIR radiation is spectrally translated into the visible region, thus permitting infrared single-photon upconversion detection. Then, the use of advanced algorithms of compressed sensing and deep learning allows us to reconstruct MIR images under sub-Nyquist sampling and photon-starving illumination. The presented paradigm of single-pixel upconversion imaging is featured with single-pixel simplicity, single-photon sensitivity, and room-temperature operation, which would establish a new path for sensitive imaging at longer infrared wavelengths or terahertz frequencies, where high-sensitivity photon counters and high-fidelity spatial modulators are typically hard to access. © 2023, The Author(s).","","silicon; algorithm; imaging method; learning; pixel; sensor; Article; computer model; convolutional neural network; crystal; deep learning; illumination; imaging and display; infrared radiation; mid infrared single-pixel imaging; nonlinear system; optics; photon; room temperature; terahertz imaging","National Natural Science Foundation of China, NSFC, (11621404, 11727812, 62175064); Science and Technology Commission of Shanghai Municipality, STCSM, (2019SHZDZX01); National Key Research and Development Program of China, NKRDPC, (2021YFB2801100); Fundamental Research Funds for the Central Universities","","Nature Research","36841860"
"Parihar S.; Kukker A.; Dhar S.; Amitabh V.; Singh V.; Krishna V.","Parihar, Sushma (57211908398); Kukker, Amit (57200143782); Dhar, Supriyo (58765446700); Amitabh, Varun (58765639800); Singh, Varun (58830446400); Krishna, Vamsi (59267164900)","57211908398; 57200143782; 58765446700; 58765639800; 58830446400; 59267164900","Biomedical Image Classification using Deep Reinforcement Learning","2024","","","","","","","10.1109/ICAECT60202.2024.10468733","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190115796&doi=10.1109%2fICAECT60202.2024.10468733&partnerID=40&md5=c62b01c01c27c8eb54bdf91b6d5b771f","The amalgamated tool of two renowned tools deep learning and reinforcement learning is a powerful representation for deep neural networks that improves the basic reinforcement learning framework. With the use of deep learning's representational power, it learns from the agent's activities on how to increase the expected reward. Recent work has shown a lot of success of deep reinforcement learning in different domains such as video games, robotics, finance, medical and computer vision. In this project, various DRL models and methods for planning medical image analysis are discussed. This study covers the fundamentals of reinforcement learning. DRL algorithms can address the problems with limited and inconsistent annotated medical imaging data, which has been a major obstacle to the implementation of deep learning models in clinical settings. DRL algorithms support these models for the reward function, interactions between agents, and the environment. There has been an extensive amount of research being done in this area, and it has the potential to enhance the utilisation of deep learning in medical imaging.  © 2024 IEEE.","Convolutional neural network; Deep learning; Machine learning; Reinforcement learning","Computer games; Convolutional neural networks; Deep neural networks; Image classification; Learning systems; Medical imaging; Medical problems; Agent activities; Biomedical images; Convolutional neural network; Deep learning; Images classification; Learn+; Learning frameworks; Machine-learning; Power; Reinforcement learnings; Reinforcement learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Kode H.; Elleithy K.; Almazaydeh L.","Kode, Hepseeba (58451555100); Elleithy, Khaled (35576221100); Almazaydeh, Laiali (55321047600)","58451555100; 35576221100; 55321047600","Epileptic Seizure Detection in EEG Signals Using Machine Learning and Deep Learning Techniques","2024","12","","","80657","80668","11","10.1109/ACCESS.2024.3409581","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195417750&doi=10.1109%2fACCESS.2024.3409581&partnerID=40&md5=9d6354fc8892ef62b24ddae6cb69bab1","This research presents a novel approach to detecting epileptic seizures leveraging the strengths of Machine Learning (ML) and Deep Learning (DL) algorithms in EEG signals. Epileptic seizures are neurological events with distinctive features found in Electroencephalography (EEG) that lend considerable credibility to researchers. Machine Learning (ML) and Deep learning (DL) algorithms have emerged as powerful feature extraction and classification tools in EEG signal analysis. Many studies have converted the EEG signals into either images and /or calculated time-frequency domain features and performed classification. This study focuses on classifying time-series data representation of EEG signals with machine learning-based classifiers by tuning parameters and deep learning-based One-Dimensional Convolutional Neural Network (1D CNN) methods. The primary objective is not only to determine the optimal classifier but also to emphasize critical metrics such as sensitivity, precision, and accuracy, which are critical in medical investigations, particularly for the early detection of diseases and patient care optimization. The UCI Epileptic Seizure Recognition dataset used in this study consists of time-series data points extracted from the EEG signals. The dataset has been preprocessed and fed to the classifiers, namely Extreme Gradient Boosting (XGBoost), TabNet, Random Forest (RF), One Dimensional Convolutional Neural Network, and achieved encouraging accuracies of 98%, 96%, 98%, and 99%, respectively. The proposed 1D-CNN model performed better than other state-of-the-art models concerning accuracy, sensitivity, precision, and recall.  © 2013 IEEE.","1D CNN; data points; deep learning (DL); epileptic seizures; machine learning (ML); random forest (RF); TabNet; time series; XGBoost","Biomedical signal processing; Brain; Classification (of information); Convolution; Deep learning; Electroencephalography; Electrophysiology; Feature extraction; Frequency domain analysis; Learning algorithms; Neural networks; Neurodegenerative diseases; Neurophysiology; Time series; 1d CNN; Brain modeling; Classification algorithm; Convolutional neural network; Datapoints; Deep learning; Epileptic seizures; Features extraction; Machine learning; Machine learning algorithms; Machine-learning; Random forest; Random forests; Tabnet; Times series; Xgboost; Extraction","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","14447 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182011176&partnerID=40&md5=895edbcfa16594160d146efaa02e87d0","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH",""
"McConnell N.; Ndipenoch N.; Cao Y.; Miron A.; Li Y.","McConnell, Niccolò (57472609800); Ndipenoch, Nchongmaje (58064883400); Cao, Yu (58730971100); Miron, Alina (57214473917); Li, Yongmin (56717319800)","57472609800; 58064883400; 58730971100; 57214473917; 56717319800","Exploring advanced architectural variations of nnUNet","2023","560","","126837","","","","10.1016/j.neucom.2023.126837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173447520&doi=10.1016%2fj.neucom.2023.126837&partnerID=40&md5=fd1e645613616dfe30af7bdec3983364","The nnUNet is a state-of-the-art deep learning based segmentation framework which automatically and systematically configures the entire network training pipeline. We extend the network architecture component of the nnUNet framework by newly integrating mechanisms from advanced U-Net variations including residual, dense, and inception blocks as well as three forms of the attention mechanism. We propose the following extensions to nnUNet, namely Residual-nnUNet, Dense-nnUNet, Inception-nnUNet, Spatial-Single-Attention-nnUNet, Spatial- Multi-Attention-nnUNet, and Channel-Spatial-Attention-nnUNet. Furthermore, within Channel-Spatial- Attention-nnUNet we integrate our newly proposed variation of the channel-attention mechanism. We demonstrate that use of the nnUNet allows for consistent and transparent comparison of U-Net architectural modifications, while maintaining network architecture as the sole independent variable across experiments with respect to a dataset. The proposed variants are evaluated on eight medical imaging datasets consisting of 20 anatomical regions which is the largest collection of datasets on which attention U-Net variants have been compared in a single work. Our results suggest that attention variants are effective at improving performance when applied to tumour segmentation tasks consisting of two or more target anatomical regions, and that segmentation performance is influenced by use of the deep supervision architectural feature. © 2023 Elsevier B.V.","Attention; Biomedical image segmentation; Dense; Inception; nnUnet; Residual","Deep learning; Image segmentation; Medical imaging; Anatomical regions; Attention; Attention mechanisms; Biomedical image segmentation; Dense; Inception; Nnunet; Residual; Spatial attention; State of the art; Article; artificial neural network; automation; deep learning; image analysis; image processing; information processing; mathematical model; segmentation algorithm; Network architecture","","","Elsevier B.V.",""
"Nour M.; Senturk U.; Polat K.","Nour, Majid (54783088200); Senturk, Umit (57203169526); Polat, Kemal (8945093900)","54783088200; 57203169526; 8945093900","Diagnosis and classification of Parkinson's disease using ensemble learning and 1D-PDCovNN","2023","161","","107031","","","","10.1016/j.compbiomed.2023.107031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159607650&doi=10.1016%2fj.compbiomed.2023.107031&partnerID=40&md5=e59d607c2d6a3abd76b56429e86c774b","In this paper, we proposed a novel approach to diagnose and classify Parkinson's Disease (PD) using ensemble learning and 1D-PDCovNN, a novel deep learning technique. PD is a neurodegenerative disorder; early detection and correct classification are essential for better disease management. The primary aim of this study is to develop a robust approach to diagnosing and classifying PD using EEG signals. As the dataset, we have used the San Diego Resting State EEG dataset to evaluate our proposed method. The proposed method mainly consists of three stages. In the first stage, the Independent Component Analysis (ICA) method has been used as the pre-processing method to filter out the blink noises from the EEG signals. Also, the effect of the band showing motor cortex activity in the 7–30 Hz frequency band of EEG signals in diagnosing and classifying Parkinson's disease from EEG signals has been investigated. In the second stage, the Common Spatial Pattern (CSP) method has been used as the feature extraction to extract useful information from EEG signals. Finally, an ensemble learning approach, Dynamic Classifier Selection (DCS) in Modified Local Accuracy (MLA), has been employed in the third stage, consisting of seven different classifiers. As the classifier method, DCS in MLA, XGBoost, and 1D-PDCovNN classifier has been used to classify the EEG signals as the PD and healthy control (HC). We first used dynamic classifier selection to diagnose and classify Parkinson's disease (PD) from EEG signals, and promising results have been obtained. The performance of the proposed approach has been evaluated using the classification accuracy, F-1 score, kappa score, Jaccard score, ROC curve, recall, and precision values in the classification of PD with the proposed models. In the classification of PD, the combination of DCS in MLA achieved an accuracy of 99,31%. The results of this study demonstrate that the proposed approach can be used as a reliable tool for early diagnosis and classification of PD. © 2023 Elsevier Ltd","1D CNN algoritm; Classification; Common spatial pattern; Deep learning; EEG signals; Ensemble learning; Parkinson's disease (PD)","Algorithms; Cerebral Cortex; Electroencephalography; Humans; Parkinson Disease; Support Vector Machine; Biomedical signal processing; Computer aided diagnosis; Deep learning; Learning systems; Neurodegenerative diseases; 1d CNN algoritm; Common spatial patterns; Deep learning; Dynamic classifier selection; EEG signals; Ensemble learning; Learning techniques; Neurodegenerative disorders; Parkinson disease; Parkinson's disease; adult; Article; clinical article; controlled study; convolutional neural network; diagnostic accuracy; disease classification; electroencephalogram; feature extraction; female; frequency; human; image segmentation; independent component analysis; male; middle aged; motor activity; motor cortex; one dimensional convolutional neural network; Parkinson disease; algorithm; brain cortex; electroencephalography; procedures; support vector machine; Independent component analysis","Ministry of Education in Saudi Arabia, (1040-135-1443)","","Elsevier Ltd","37211002"
"Qiu L.; Zhao L.; Hou R.; Zhao W.; Zhang S.; Lin Z.; Teng H.; Zhao J.","Qiu, Lu (57404727100); Zhao, Lu (57405705100); Hou, Runping (57205322120); Zhao, Wangyuan (57214918354); Zhang, Shunan (58074078900); Lin, Zefan (57405343900); Teng, Haohua (23499770800); Zhao, Jun (57037151500)","57404727100; 57405705100; 57205322120; 57214918354; 58074078900; 57405343900; 23499770800; 57037151500","Hierarchical multimodal fusion framework based on noisy label learning and attention mechanism for cancer classification with pathology and genomic features","2023","104","","102176","","","","10.1016/j.compmedimag.2022.102176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146694783&doi=10.1016%2fj.compmedimag.2022.102176&partnerID=40&md5=86111b4f889113b18d084af1517986f0","Classification of subtype and grade is imperative in the clinical diagnosis and prognosis of cancer. Many deep learning-based studies related to cancer classification are based on pathology and genomics. However, most of them are late fusion-based and require full supervision in pathology image analysis. To address these problems, we present an integrated framework for cancer classification with pathology and genomics data. This framework consists of two major parts, a weakly supervised model for extracting patch features from whole slide images (WSIs), and a hierarchical multimodal fusion model. The weakly supervised model can make full use of WSI labels, and mitigate the effects of label noises by the self-training strategy. The generic multimodal fusion model is capable of capturing deep interaction information through multi-level attention mechanisms and controlling the expressiveness of each modal representation. We validate our approach on glioma and lung cancer datasets from The Cancer Genome Atlas (TCGA). The results demonstrate that the proposed method achieves superior performance compared to state-of-the-art methods, with the competitive AUC of 0.872 and 0.977 on these two datasets respectively. This paper establishes insight on how to build deep networks on multimodal biomedical data and proposes a more general framework for pathology image analysis without pixel-level annotation. © 2022 Elsevier Ltd","Cancer classification; Multimodal fusion; Weakly supervised learning; Whole-slide image analysis","Genomics; Glioma; Humans; Image Processing, Computer-Assisted; Lung Neoplasms; Classification (of information); Computer aided diagnosis; Deep learning; Diseases; Genes; Genome; Image classification; Image fusion; Modal analysis; Pathology; Attention mechanisms; Cancer classification; Fusion model; Genomics; Image-analysis; Multi-modal fusion; Noisy labels; Weakly supervised learning; Whole slide images; Whole-slide image analyse; Article; attention based hierarchical multimodal fusion model; cancer classification; cancer grading; classification algorithm; cross validation; deep learning; feature extraction; feature learning (machine learning); genomics; glioma; human; image analysis; intermethod comparison; lung carcinoma; malignant neoplasm; measurement accuracy; measurement precision; multiple instance learning; noise; pathological instance encoder based on noisy label learning; pathology; performance indicator; qualitative analysis; quantitative analysis; recurrent neural network; sensitivity and specificity; spiking neural network; supervised machine learning; validation study; genomics; glioma; image processing; lung tumor; Image analysis","","","Elsevier Ltd","36682215"
"Wang Y.; Huang Z.; Wang X.; Yang F.; Yao X.; Pan T.; Li B.; Chu J.","Wang, Yiming (57287692900); Huang, Ziwei (58511848100); Wang, Xiaojie (57212145769); Yang, Fengrui (57205234526); Yao, Xuebiao (7402530401); Pan, Tingrui (7202203165); Li, Baoqing (55698666900); Chu, Jiaru (55554255900)","57287692900; 58511848100; 57212145769; 57205234526; 7402530401; 7202203165; 55698666900; 55554255900","Real-time fluorescence imaging flow cytometry enabled by motion deblurring and deep learning algorithms","2023","23","16","","3615","3627","12","10.1039/d3lc00194f","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166211972&doi=10.1039%2fd3lc00194f&partnerID=40&md5=486d2236e6e8fa5db6b5ef2931ca0525","Fluorescence imaging flow cytometry (IFC) has been demonstrated as a crucial biomedical technique for analyzing specific cell subpopulations from heterogeneous cellular populations. However, the high-speed flow of fluorescent cells leads to motion blur in cell images, making it challenging to identify cell types from the raw images. In this study, we present a real-time single-cell imaging and classification system based on a fluorescence microscope and deep learning algorithm, which is able to directly identify cell types from motion-blur images. To obtain annotated datasets of blurred images for deep learning model training, we developed a motion deblurring algorithm for the reconstruction of blur-free images. To demonstrate the ability of this system, deblurred images of HeLa cells with various fluorescent labels and HeLa cells at different cell cycle stages were acquired. The trained ResNet achieved a high accuracy of 96.6% for single-cell classification of HeLa cells in three different mitotic stages, with a short processing time of only 2 ms. This technology provides a simple way to realize single-cell fluorescence IFC and real-time cell classification, offering significant potential in various biological and medical applications. © 2023 The Royal Society of Chemistry.","","Algorithms; Deep Learning; Flow Cytometry; HeLa Cells; Humans; Image Processing, Computer-Assisted; Optical Imaging; Cytology; Deep learning; Flow cytometry; Image enhancement; Lanthanum compounds; Learning algorithms; Medical applications; fluorescent dye; polystyrene; Cell classification; Cell subpopulations; Cell types; Fluorescence imaging; HeLa cell; Motion blur; Motion deblurring; Real- time; Real-time fluorescence imaging; Single cells; algorithm; Article; cell cycle; cells by body anatomy; classification; comparative study; controlled study; data accuracy; deep learning; exposure; feature extraction algorithm; flow cytometry; fluorescence imaging; HeLa cell line; human; human cell; image processing; image reconstruction; learning algorithm; mitosis; morphological trait; motion deblurring algorithm; proof of concept; residual neural network; software; algorithm; flow cytometry; fluorescence imaging; procedures; Fluorescence imaging","USTC Experimental Center of Engineering and Material Sciences; Chinese Academy of Sciences, CAS, (XDC07040200); Natural Science Foundation of Anhui Province, (2208085ME136); Joint Research Fund for Overseas Chinese Scholars and Scholars in Hong Kong and Macao, (51929501); National Key Research and Development Program of China, NKRDPC, (2022YFA1303100, 2022YFF0705002)","","Royal Society of Chemistry","37458395"
"Kaczmarzyk J.R.; Gupta R.; Kurc T.M.; Abousamra S.; Saltz J.H.; Koo P.K.","Kaczmarzyk, Jakub R. (57204394276); Gupta, Rajarsi (55783928600); Kurc, Tahsin M. (6701424615); Abousamra, Shahira (55000680700); Saltz, Joel H. (7004423034); Koo, Peter K. (55924625400)","57204394276; 55783928600; 6701424615; 55000680700; 7004423034; 55924625400","ChampKit: A framework for rapid evaluation of deep neural networks for patch-based histopathology classification","2023","239","","107631","","","","10.1016/j.cmpb.2023.107631","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163413654&doi=10.1016%2fj.cmpb.2023.107631&partnerID=40&md5=64f6c19e046fc1552656c9abdad41703","Background and Objective: Histopathology is the gold standard for diagnosis of many cancers. Recent advances in computer vision, specifically deep learning, have facilitated the analysis of histopathology images for many tasks, including the detection of immune cells and microsatellite instability. However, it remains difficult to identify optimal models and training configurations for different histopathology classification tasks due to the abundance of available architectures and the lack of systematic evaluations. Our objective in this work is to present a software tool that addresses this need and enables robust, systematic evaluation of neural network models for patch classification in histology in a light-weight, easy-to-use package for both algorithm developers and biomedical researchers. Methods: Here we present ChampKit (Comprehensive Histopathology Assessment of Model Predictions toolKit): an extensible, fully reproducible evaluation toolkit that is a one-stop-shop to train and evaluate deep neural networks for patch classification. ChampKit curates a broad range of public datasets. It enables training and evaluation of models supported by timm directly from the command line, without the need for users to write any code. External models are enabled through a straightforward API and minimal coding. As a result, Champkit facilitates the evaluation of existing and new models and deep learning architectures on pathology datasets, making it more accessible to the broader scientific community. To demonstrate the utility of ChampKit, we establish baseline performance for a subset of possible models that could be employed with ChampKit, focusing on several popular deep learning models, namely ResNet18, ResNet50, and R26-ViT, a hybrid vision transformer. In addition, we compare each model trained either from random weight initialization or with transfer learning from ImageNet pretrained models. For ResNet18, we also consider transfer learning from a self-supervised pretrained model. Results: The main result of this paper is the ChampKit software. Using ChampKit, we were able to systemically evaluate multiple neural networks across six datasets. We observed mixed results when evaluating the benefits of pretraining versus random intialization, with no clear benefit except in the low data regime, where transfer learning was found to be beneficial. Surprisingly, we found that transfer learning from self-supervised weights rarely improved performance, which is counter to other areas of computer vision. Conclusions: Choosing the right model for a given digital pathology dataset is nontrivial. ChampKit provides a valuable tool to fill this gap by enabling the evaluation of hundreds of existing (or user-defined) deep learning models across a variety of pathology tasks. Source code and data for the tool are freely accessible at https://github.com/SBU-BMI/champkit. © 2023","Benchmarks; Classification; Computational pathology; Deep learning; Histopathology","Algorithms; Histological Techniques; Humans; Neoplasms; Neural Networks, Computer; Software; Bioinformatics; Classification (of information); Codes (symbols); Computer aided diagnosis; Computer vision; Deep neural networks; Learning systems; Network architecture; Benchmark; Computational pathology; Deep learning; Gold standards; Histopathology; Learning models; Model prediction; Patch based; Systematic evaluation; Transfer learning; article; artificial neural network; body mass; body weight; computer vision; controlled study; deep learning; deep neural network; digital pathology; histology; histopathology; human; human tissue; prediction; residual neural network; software; transfer of learning; vision; algorithm; histology; neoplasm; Pathology","National Institutes of Health, NIH, (T32GM008444); National Institutes of Health, NIH; National Human Genome Research Institute, NHGRI, (R01HG012131); National Human Genome Research Institute, NHGRI; National Cancer Institute, NCI, (U24CA215109, UH3CA225021); National Cancer Institute, NCI; National Institute of General Medical Sciences, NIGMS; Cold Spring Harbor Laboratory, CSHL, (5P30CA045508); Cold Spring Harbor Laboratory, CSHL; Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory, SCQB, (S10OD028632-01); Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory, SCQB","","Elsevier Ireland Ltd","37271050"
"Ein Shoka A.A.; Dessouky M.M.; El-Sayed A.; El-Din Hemdan E.","Ein Shoka, Athar A. (6507194277); Dessouky, Mohamed M. (57222103128); El-Sayed, Ayman (57204547379); El-Din Hemdan, Ezz (57190733374)","6507194277; 57222103128; 57204547379; 57190733374","An efficient CNN based epileptic seizures detection framework using encrypted EEG signals for secure telemedicine applications","2023","65","","","399","412","13","10.1016/j.aej.2022.10.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145249618&doi=10.1016%2fj.aej.2022.10.014&partnerID=40&md5=4d6c6938b3302e7efc64f7e9f853e23f","Recently, the rapid development of Artificial Intelligence (AI) applied in the Medical Internet of Things (MIoT) for the diagnosis of diseases such as epilepsy based on the investigation of electroencephalography (EEG) signals. Thanks to AI-based deep learning models, the procedure of epileptic seizure detection can be performed professionally in Smart Healthcare. However, the security issues for protecting sensitive medical EEG signals from disclosure and unauthorized operations from severe attacks over open networks. Therefore, there is a serious need for providing an effective method for encrypted EEG classification and prediction. In this paper, a new and efficient encrypted EEG data classification and recognition system using Chaotic Baker Map and Arnold Transform algorithms with Convolutional Neural Networks (CNNs). In this system, the channel's EEG time series is first converted into a 2D spectrogram image and then encrypted using Chaotic Baker Map and Arnold Transform algorithms, and finally fed to CNNs-based Transfer Learning (TL) models. From the experimental results, the proposed approach is validated and evaluated on a public CHB-MIT dataset and the googlenet with encrypted EEG images provides satisfactory performance by outperforming the models of other CNN like Alexnet, Resnet50, and squeezenet. © 2022 THE AUTHORS","And Chaotic Baker Map; Arnold Transform; Convolutional Neural Networks (CNNs); Electroencephalography (EEG) signals; Epileptic seizures; Transfer Learning (TL)","Biomedical signal processing; Convolution; Convolutional neural networks; Cryptography; Deep learning; Electrophysiology; Neurophysiology; Transfer learning; And chaotic baker map; Arnold transform; Baker maps; Chaotics; Convolutional neural network; Electroencephalography  signal; Epileptic seizures; Transfer learning; Electroencephalography","","","Elsevier B.V.",""
"Sahu G.; Karnati M.; Gupta A.; Seal A.","Sahu, Geet (57216222698); Karnati, Mohan (57224313309); Gupta, Abhishek (57214416996); Seal, Ayan (54898238300)","57216222698; 57224313309; 57214416996; 54898238300","SCZ-SCAN: An automated Schizophrenia detection system from electroencephalogram signals","2023","86","","105206","","","","10.1016/j.bspc.2023.105206","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163859962&doi=10.1016%2fj.bspc.2023.105206&partnerID=40&md5=6fa2e540b5e071c39fd401280b99812e","Schizophrenia (SCZ) is a severe neurological and physiological syndrome that perverts a patient's perception of reality. SCZ exhibits several symptoms, including hallucinations, delusions, aberrant behavior, and thinking. It affects their professional, academic, personal, and social lives. Neurologists use a variety of verbal and visual tests to determine SCZ. However, these methods are laborious, time-consuming, superficial, and vulnerable to mistakes. Therefore, it is necessary to create an automated model for SCZ detection. Convolutional neural networks have swiftly established themselves in the field of mental health care due to the growth of deep learning in recent decades. Electroencephalogram (EEG) data records the variations in the neural dynamics of human memory. Using EEG data, this study proposes an automatic SCZ detection method using separable convolution attention network (SCZ-SCAN). The proposed network employs depth-wise separable convolution and attention networks on high-level and low-level to aggregate characteristics of 2-D scalogram images acquired from the continuous wavelet transform. The depth-wise separable convolutions help to create a lightweight framework, while attention techniques concentrate on significant features and reduce futile computations by removing the transmission of irrelevant features. The proposed approach has an average classification accuracy of 99% and 95% on the IBIB-PAN and EEG data from the basic sensory task in SZ dataset. Moreover, statistical hypothesis testing is performed using Wilcoxon's Rank-Sum test to signify the model performance and it proves that SCZ-SCAN is statistically efficient to nine cutting-edge methods. Experimental results show that the PSFAN statistically defeats 11 contemporary methods, proving its effectiveness for medical industrial applications. © 2023 Elsevier Ltd","Continuous wavelet transform; Convolutional neural network; Electroencephalography; Scalogram; Schizophrenia","Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Diseases; Electrophysiology; Statistical tests; Wavelet transforms; Automated modelling; Continuous Wavelet Transform; Convolutional neural network; Detection system; Electroencephalogram signals; Personal lives; Professional life; Scalogram; Schizophrenia; Social life; Article; attention network; automation; calculation; classification algorithm; comparative study; continuous wavelet transform; convolutional neural network; cross validation; electroencephalography; feature extraction algorithm; human; mental health care; schizophrenia; separable convolution attention network; validation study; Electroencephalography","","","Elsevier Ltd",""
"Pradhan A.K.; Das K.; Mishra D.; Chithaluru P.","Pradhan, Ashwini Kumar (57223054673); Das, Kaberi (57210528390); Mishra, Debahuti (35070028500); Chithaluru, Premkumar (57201708482)","57223054673; 57210528390; 35070028500; 57201708482","Optimizing CNN-LSTM hybrid classifier using HCA for biomedical image classification","2023","40","5","e13235","","","","10.1111/exsy.13235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147220372&doi=10.1111%2fexsy.13235&partnerID=40&md5=1adc130c8bfea14dd807c881a0b1023a","In medical science, imaging is the most effective diagnostic and therapeutic tool. Almost all modalities have transitioned to direct digital capture devices, which have emerged as a major future healthcare option. Three diseases such as Alzheimer's (AD), Haemorrhage (HD), and COVID-19 have been used in this manuscript for binary classification purposes. Three datasets (AD, HD, and COVID-19) were used in this research out of which the first two, that is, AD and HD belong to brain Magnetic Resonance Imaging (MRI) and the last one, that is, COVID-19 belongs to Chest X-Ray (CXR) All of the diseases listed above cannot be eliminated, but they can be slowed down with early detection and effective medical treatment. This paper proposes an intelligent method for classifying brain (MRI) and CXR images into normal and abnormal classes for the early detection of AD, HD, and COVID-19 based on an ensemble deep neural network (DNN). In the proposed method, the convolutional neural network (CNN) is used for automatic feature extraction from images and long-short term memory (LSTM) is used for final classification. Moreover, the Hill-Climbing Algorithm (HCA) is implemented for finding the best possible value for hyper parameters of CNN and LSTM, such as the filter size of CNN and the number of units of LSTM while fixing the other parameters. The data-set is pre-processed (resized, cropped, and noise removed) before feeding the train images to the proposed models for accurate and fast learning. Forty-five MR images of AD, Sixty MR images of HD, and 600 CXR images of COVID-19 were used for testing the proposed model ‘CNN-LSTM-HCA’. The performance of the proposed model is evaluated using six types of statistical assessment metrics such as; Accuracy, Sensitivity, Specificity, F-measure, ROC, and AUC. The proposed model compared with the other three types of hybrid models such as CNN-LSTM-PSO, CNN-LSTM-Jaya, and CNN-LSTM-GWO and also with state-of-art techniques. The overall accuracy of the proposed model received was 98.87%, 85.75%, and 99.1% for COVID-19, Haemorrhage, and Alzheimer's data sets, respectively. © 2023 John Wiley & Sons Ltd.","Alzheimer disease; CNN; COVID-19; CXR; deep learning; Haemorrhage disease; LSTM","Biomedical signal processing; Convolutional neural networks; Deep neural networks; Diagnosis; Digital devices; Image classification; Long short-term memory; Magnetic resonance imaging; Medical imaging; Neurodegenerative diseases; Optimization; Alzheimer; Alzheimers disease; Chest X-ray; Chest X-ray image; Convolutional neural network; Data set; Deep learning; Haemorrage; Hemorrhage disease; Hill-Climbing algorithm; COVID-19","","","John Wiley and Sons Inc",""
"Havaei P.; Zekri M.; Mahmoudzadeh E.; Rabbani H.","Havaei, Pedram (57301989000); Zekri, Maryam (23981791800); Mahmoudzadeh, Elham (56733081000); Rabbani, Hossein (16643769100)","57301989000; 23981791800; 56733081000; 16643769100","An efficient deep learning framework for P300 evoked related potential detection in EEG signal","2023","229","","107324","","","","10.1016/j.cmpb.2022.107324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145255613&doi=10.1016%2fj.cmpb.2022.107324&partnerID=40&md5=6013c004881596597176c2c76462da86","Background: Incorporating the time-frequency localization properties of Gabor transform (GT), the complexity understandings of convolutional neural network (CNN), and histogram of oriented gradients (HOG) efficacy in distinguishing positive peaks can exhibit their characteristics to reveal an effective solution in the detection of P300 evoked related potential (ERP). By applying a drastic number of convolutional layers, the majority of deep networks elicit sufficient properties for the output determination, leading to gigantic and time-consuming structures. In this paper, we propose a novel deep learning framework by the combination of tuned GT, and modified HOG with the CNN as “TGT-MHOG-CNN” for detection of P300 ERP in EEG signal. Method: In the proposed method, GT is tuned based on triangular function for EEG signals, and then spectrograms including time-frequency information are captured. The function's parameters are justified to differentiate the signals with the P300 component. Furthermore, HOG is modified (MHOG) for the 2-D EEG signal, and consequently, gradients patterns are extracted for the target potentials. MHOG is potent in distinguishing the positive peak in the general waveform; however, GT unravels time-frequency information, which is ignored in the gradient histogram. These outputs of GT and MHOG do not share the same nature in the images nor overlap. Therefore, more extensive information is reached without redundancy or excessive information by fusing them. Combining GT and MHOG provides different patterns which benefit CNN for more precise detection. Consequently, TGT-MHOG-CNN ends in a more straightforward structure than other networks, and therefore, the whole performance is acceptable with faster rates and very high accuracy. Results: BCI Competition II and III datasets are used to evaluate the performance of the proposed method. These datasets include a complete record for P300 ERP with BCI2000 using a paradigm, and it has numerous noises, including power and muscle-based noises. The objective is to predict the correct character in each provided character selection epochs. Compared to state-of-the-art methods, simulation results indicate striking abilities of the proposed framework for P300 ERP detection. Our best record reached the P300 ERP classification rates of over 98.7% accuracy and 98.7% precision for BCI Competition II and 99% accuracy and 100% precision for BCI Competition III datasets, with superiority in execution time for the mentioned datasets. © 2022 Elsevier B.V.","Convolutional neural network; Gabor transform; Modified histogram of oriented gradients; P300 detection","Algorithms; Brain-Computer Interfaces; Deep Learning; Electroencephalography; Evoked Potentials; Neural Networks, Computer; Biomedical signal processing; Classification (of information); Convolution; Deep learning; Graphic methods; Signal detection; Convolutional neural network; EEG signals; Gabor transform; Histogram of oriented gradients; Learning frameworks; Modified histogram of oriented gradient; P300 detection; Performance; Time frequency information; Time-frequency localization; article; competition; convolutional neural network; deep learning; electroencephalogram; Gabor transform; histogram; muscle; noise; simulation; waveform; algorithm; brain computer interface; electroencephalography; evoked response; physiology; procedures; Convolutional neural networks","Medical Image and Signal Processing Research Center; Iran University of Medical Sciences, IUMS","","Elsevier Ireland Ltd","36586179"
"Sharma A.; Sengar S.S.; Singh P.","Sharma, Ashok (57204889340); Sengar, Sandeep Singh (57062849000); Singh, Parveen (57730991300)","57204889340; 57062849000; 57730991300","Meta-Learning Frameworks for Imaging Applications","2023","","","","1","253","252","10.4018/978-1-6684-7659-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175277768&doi=10.4018%2f978-1-6684-7659-8&partnerID=40&md5=d606221403c7303dcf5aad6d9c865bb5","Meta-learning, or learning to learn, has been gaining popularity in recent years to adapt to new tasks systematically and efficiently in machine learning. In the book, Meta-Learning Frameworks for Imaging Applications, experts from the fields of machine learning and imaging come together to explore the current state of meta-learning and its application to medical imaging and health informatics. The book presents an overview of the meta-learning framework, including common versions such as model-agnostic learning, memory augmentation, prototype networks, and learning to optimize. It also discusses how meta-learning can be applied to address fundamental limitations of deep neural networks, such as high data demand, computationally expensive training, and limited ability for task transfer. One critical topic in imaging is image segmentation, and the book explores how a meta-learning-based framework can help identify the best image segmentation algorithm, which would be particularly beneficial in the healthcare domain. This book is relevant to healthcare institutes, e-commerce companies, and educational institutions, as well as professionals and practitioners in the intelligent system, computational data science, network applications, and biomedical applications fields. It is also useful for domain developers and project managers from diagnostic and pharmacy companies involved in the development of medical expert systems. Additionally, graduate and master students in intelligent systems, big data management, computational intelligent approaches, computer vision, and biomedical science can use this book for their final projects and specific courses. © 2023 by IGI Global. All rights reserved.","","","","","IGI Global",""
"Wölfl A.-M.; Schützenberger A.; Breininger K.; Kist A.M.","Wölfl, Anna-Maria (58538578400); Schützenberger, Anne (26655068600); Breininger, Katharina (56536987700); Kist, Andreas M. (57204454654)","58538578400; 26655068600; 56536987700; 57204454654","Towards image-based laryngeal videostroboscopy using deep learning-enabled compressed sensing","2023","86","","105335","","","","10.1016/j.bspc.2023.105335","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168138304&doi=10.1016%2fj.bspc.2023.105335&partnerID=40&md5=73e5798735dbe68e1f21ffa6a1de296f","Laryngeal videostroboscopy is an audio-mediated imaging technique allowing the visualization of vocal fold oscillation behavior: the audio signal is used to determine the fundamental frequency F0, which represents the vocal fold oscillation frequency. Knowing F0 allows to trigger the strobe illumination unit to provide a still image or slow-motion view of the vocal fold oscillation. However, this procedure involves several hardware components, noisy audio signals, and a chain of complex, error-prone algorithms that have to be orchestrated. We hypothesize that endoscopic images suffice to determine F0 with a view towards providing an alternative, image-based approach for estimating F0 during laryngeal videoendoscopy. In this study, we show that we are able to predict the relative glottal opening state to create sample points on the glottal area waveform, an endoscopic image-derived signal capable of deriving F0. As imaging frame rates from ordinary endoscopic cameras do not fulfill the Shannon–Nyquist criterion, we solve this problem with compressed sensing. We developed and evaluated the proposed approach using high-speed videoendoscopy (HSV) to simulate different, realistic low frame rates that are similar to those used in videostroboscopy. We show that we are able to predict F0 with over 95% accuracy using at most 75 sample points of a 600 ms long footage. Using endoscopic images and our algorithm only, we showcase that we can achieve a stroboscopic effect. This shows, that our proposed method in combination with the developed algorithm may be considered in the future to be integrated into clinical videostroboscopy. © 2023 Elsevier Ltd","Biomedical imaging; Compressed sensing; Deep learning; Endoscopy; Laryngology; Point of care","Compressed sensing; Deep learning; Medical imaging; Audio signal; Biomedical imaging; Compressed-Sensing; Deep learning; Endoscopic image; Image-based; Laryngology; Point of care; Sample point; Vocal folds; algorithm; Article; controlled study; convolutional neural network; deep learning; discrete cosine transform; endoscopy; Fourier transform; glottis; hearing; human; laryngoscopy; mean absolute error; measurement accuracy; oscillation; otorhinolaryngology; phonation; power spectrum; prediction; random sample; signal processing; stochastic model; stroboscopy; videoendoscopy; vocal cord; waveform; Endoscopy","d.hip campus - Bavarian; Deutsche Forschungsgemeinschaft, DFG, (SCHU 3441/3-2)","","Elsevier Ltd",""
"Zhang D.; Li H.; Xie J.","Zhang, Dongxue (58024064600); Li, Huiying (36552872000); Xie, Jingmeng (58024857600)","58024064600; 36552872000; 58024857600","MI-CAT: A transformer-based domain adaptation network for motor imagery classification","2023","165","","","451","462","11","10.1016/j.neunet.2023.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162147840&doi=10.1016%2fj.neunet.2023.06.005&partnerID=40&md5=851d630cf56e2ec603d4d70b1bc4c271","Due to its convenience and safety, electroencephalography (EEG) data is one of the most widely used signals in motor imagery (MI) brain–computer interfaces (BCIs). In recent years, methods based on deep learning have been widely applied to the field of BCIs, and some studies have gradually tried to apply Transformer to EEG signal decoding due to its superior global information focusing ability. However, EEG signals vary from subject to subject. Based on Transformer, how to effectively use data from other subjects (source domain) to improve the classification performance of a single subject (target domain) remains a challenge. To fill this gap, we propose a novel architecture called MI-CAT. The architecture innovatively utilizes Transformer's self-attention and cross-attention mechanisms to interact features to resolve differential distribution between different domains. Specifically, we adopt a patch embedding layer for the extracted source and target features to divide the features into multiple patches. Then, we comprehensively focus on the intra-domain and inter-domain features by stacked multiple Cross-Transformer Blocks (CTBs), which can adaptively conduct bidirectional knowledge transfer and information exchange between domains. Furthermore, we also utilize two non-shared domain-based attention blocks to efficiently capture domain-dependent information, optimizing the features extracted from the source and target domains to assist in feature alignment. To evaluate our method, we conduct extensive experiments on two real public EEG datasets, Dataset IIb and Dataset IIa, achieving competitive performance with an average classification accuracy of 85.26% and 76.81%, respectively. Experimental results demonstrate that our method is a powerful model for decoding EEG signals and facilitates the development of the Transformer for brain–computer interfaces (BCIs). © 2023 Elsevier Ltd","Brain–computer interfaces (BCIs); Domain adaptation; Electroencephalograph (EEG); Motor imagery (MI); Transformer","Algorithms; Brain-Computer Interfaces; Electroencephalography; Imagination; Biomedical signal processing; Brain computer interface; Classification (of information); Decoding; Deep learning; Electroencephalography; Image classification; Knowledge management; Network architecture; Brain–computer interface; Domain adaptation; Electroencephalograph; Electroencephalograph signals; Global informations; Motor imagery; Motor imagery classification; Target domain; Transformer; Article; artificial neural network; classification algorithm; electroencephalogram; feature extraction; human; imagery; measurement accuracy; motor imagery; algorithm; electroencephalography; imagination; procedures; Electrophysiology","Jilin Provincial Scientific and Technological Development Program, (20210201138GX, 20230201089GX)","","Elsevier Ltd","37336030"
"Sun H.; Plawinski J.; Subramaniam S.; Jamaludin A.; Kadir T.; Readie A.; Ligozio G.; Ohlssen D.; Baillie M.; Coroller T.","Sun, Hanxi (57225209807); Plawinski, Jason (57225216403); Subramaniam, Sajanth (57225214766); Jamaludin, Amir (57190343259); Kadir, Timor (6603957764); Readie, Aimee (36543033500); Ligozio, Gregory (24179023300); Ohlssen, David (16177998400); Baillie, Mark (15043575500); Coroller, Thibaud (56141905700)","57225209807; 57225216403; 57225214766; 57190343259; 6603957764; 36543033500; 24179023300; 16177998400; 15043575500; 56141905700","A deep learning approach to private data sharing of medical images using conditional generative adversarial networks (GANs)","2023","18","7 JULY","e0280316","","","","10.1371/journal.pone.0280316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164269263&doi=10.1371%2fjournal.pone.0280316&partnerID=40&md5=78bfd3da70fc330e89c05087e606d4c7","Clinical data sharing can facilitate data-driven scientific research, allowing a broader range of questions to be addressed and thereby leading to greater understanding and innovation. However, sharing biomedical data can put sensitive personal information at risk. This is usually addressed by data anonymization, which is a slow and expensive process. An alternative to anonymization is construction of a synthetic dataset that behaves similar to the real clinical data but preserves patient privacy. As part of a collaboration between Novartis and the Oxford Big Data Institute, a synthetic dataset was generated based on images from COSENTYX® (secukinumab) ankylosing spondylitis (AS) clinical studies. An auxiliary classifier Generative Adversarial Network (ac-GAN) was trained to generate synthetic magnetic resonance images (MRIs) of vertebral units (VUs), conditioned on the VU location (cervical, thoracic and lumbar). Here, we present a method for generating a synthetic dataset and conduct an in-depth analysis on its properties along three key metrics: image fidelity, sample diversity and dataset privacy. Copyright: © 2023 Sun et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Academies and Institutes; Benchmarking; Big Data; Deep Learning; Humans; Image Processing, Computer-Assisted; Information Dissemination; algorithm; Article; artificial neural network; cervical vertebra; clinical effectiveness; data privacy; data processing; data quality; deep learning; diagnostic imaging; generative adversarial network; human; image fidelity; image morphing; imaging; lumbar vertebra; nuclear magnetic resonance imaging; parameters; private data sharing; sample diversity; thoracic vertebra; benchmarking; big data; image processing; information dissemination; organization","","","Public Library of Science","37410795"
"Smolders A.; Lomax A.; Weber D.C.; Albertini F.","Smolders, A. (57212110146); Lomax, A. (35596133400); Weber, D.C. (7402029492); Albertini, F. (36008103200)","57212110146; 35596133400; 7402029492; 36008103200","Patient-specific neural networks for contour propagation in online adaptive radiotherapy","2023","68","9","095010","","","","10.1088/1361-6560/accaca","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153803344&doi=10.1088%2f1361-6560%2faccaca&partnerID=40&md5=6649d44df63088c0c377db717aa2ea4a","Objective. fast and accurate contouring of daily 3D images is a prerequisite for online adaptive radiotherapy. Current automatic techniques rely either on contour propagation with registration or deep learning (DL) based segmentation with convolutional neural networks (CNNs). Registration lacks general knowledge about the appearance of organs and traditional methods are slow. CNNs lack patient-specific details and do not leverage the known contours on the planning computed tomography (CT). This works aims to incorporate patient-specific information into CNNs to improve their segmentation accuracy. Approach. patient-specific information is incorporated into CNNs by retraining them solely on the planning CT. The resulting patient-specific CNNs are compared to general CNNs and rigid and deformable registration for contouring of organs-at-risk and target volumes in the thorax and head-and-neck regions. Results. patient-specific fine-tuning of CNNs significantly improves contour accuracy compared to standard CNNs. The method further outperforms rigid registration and a commercial DL segmentation software and yields similar contour quality as deformable registration (DIR). It is additionally 7-10 times faster than DIR. Significance. patient-specific CNNs are a fast and accurate contouring technique, enhancing the benefits of adaptive radiotherapy. © 2023 The Author(s). Published on behalf of Institute of Physics and Engineering in Medicine by IOP Publishing Ltd.","adaptive radiotherapy; biomedical image segmentation; contour propagation; deep learning","Algorithms; Cone-Beam Computed Tomography; Head and Neck Neoplasms; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Radiotherapy Planning, Computer-Assisted; Backpropagation; Convolutional neural networks; Deep learning; E-learning; Image segmentation; Radiotherapy; Adaptive radiotherapy; Biomedical image segmentation; Contour propagation; Contouring; Convolutional neural network; Deep learning; Online adaptive radiotherapies; Patient specific; Rigid registration; Specific information; algorithm; artificial neural network; cone beam computed tomography; head and neck tumor; human; image processing; procedures; Computerized tomography","Barbara Bachtiary; European Union’s Horizon 2020 Marie Skłodowska-Curie Actions, (955956); Reinhardt Krcek","","Institute of Physics","37019120"
"Keshta I.; Deshpande P.S.; Shabaz M.; Soni M.; Bhadla M.; Muhammed Y.","Keshta, Ismail (56444410400); Deshpande, Pallavi Sagar (56591984200); Shabaz, Mohammad (57202955007); Soni, Mukesh (57202986134); Bhadla, Mohit kumar (57666121300); Muhammed, Yasser (57705952100)","56444410400; 56591984200; 57202955007; 57202986134; 57666121300; 57705952100","Multi-stage biomedical feature selection extraction algorithm for cancer detection","2023","5","5","131","","","","10.1007/s42452-023-05339-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152771079&doi=10.1007%2fs42452-023-05339-2&partnerID=40&md5=87f215eb76631e8895e4ba4ef5c6135d","Cancer is a significant cause of death worldwide. Early cancer detection is greatly aided by machine learning and artificial intelligence (AI) to gene microarray data sets (microarray data). Despite this, there is a significant discrepancy between the number of gene features in the microarray data set and the number of samples. Because of this, it is crucial to identify markers for gene array data. Existing feature selection algorithms, however, generally use long-standing, are limited to single-condition feature selection and rarely take feature extraction into account. This work proposes a Multi-stage algorithm for Biomedical Deep Feature Selection (MBDFS) to address this issue. In the first, three feature selection techniques are combined for thorough feature selection, and feature subsets are obtained; in the second, an unsupervised neural network is used to create the best representation of the feature subset to enhance final classification accuracy. Using a variety of metrics, including a comparison of classification results before and after feature selection and the performance of alternative feature selection methods, we evaluate MBDFS's efficacy. The experiments demonstrate that although MBDFS uses fewer features, classification accuracy is either unchanged or enhanced. © 2023, The Author(s).","Artificial intelligence; Artificial Intelligence; Biomedical Image; Cancer Detection; Deep Feature Selection; Feature Selection; Machine Learning","Bioinformatics; Classification (of information); Deep learning; Diseases; Extraction; Genes; Learning systems; Biomedical images; Cancer detection; Deep feature selection; Feature subset; Features selection; Machine-learning; Microarray dataset; Multi-stages; STAGE algorithm; Feature Selection","","","Springer Nature",""
"Sharma P.; Gautam A.; Maji P.; Pachori R.B.; Balabantaray B.K.","Sharma, Pallabi (57207939401); Gautam, Anmol (57795500200); Maji, Pallab (55606994400); Pachori, Ram Bilas (14632337000); Balabantaray, Bunil Kumar (56178407400)","57207939401; 57795500200; 55606994400; 14632337000; 56178407400","Li-SegPNet: Encoder-Decoder Mode Lightweight Segmentation Network for Colorectal Polyps Analysis","2023","70","4","","1330","1339","9","10.1109/TBME.2022.3216269","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140774288&doi=10.1109%2fTBME.2022.3216269&partnerID=40&md5=4b67bfc75199382fcbcc3951efc76d65","Objective: One of the fundamental and crucial tasks for the automated diagnosis of colorectal cancer is the segmentation of the acute gastrointestinal lesions, most commonly colorectal polyps. Therefore, in this work, we present a novel lightweight encoder-decoder mode of architecture with the attention mechanism to address this challenging task. Methods: The proposed Li-SegPNet architecture harnesses cross-dimensional interaction in feature maps with novel encoder block with modified triplet attention. We have used atrous spatial pyramid pooling to handle the problem of segmenting objects at multiple scales. We also address the semantic gap between the encoder and decoder through a modified skip connection using attention gating. Results: We applied our model to colonoscopy still images and trained and validated it on two publicly available datasets, Kvasir-SEG and CVC-ClinicDB. We achieve mean Intersection-Over-Union (mIoU) and dice scores of 0.88, 0.9058 and 0.8969, 0.9372 on Kvasir-SEG and CVC-ClinicDB, respectively. We analyze the generalizability of Li-SegPNet by testing it on two independent previously unseen datasets, Hyper-Kvasir and EndoTect 2020, and establish the model efficiency in cross-dataset evaluation. We employ multi-scale testing to examine the model performance on different sizes of polyps. Li-SegPNet performs best on medium-sized polyps with a mIoU and dice score of 0.9086 and 0.9137, respectively on the Kvasir-SEG dataset and 0.9425, 0.9434 of mIoU and dice score, respectively on CVC-ClinicDB. Conclusion: The experimental results convey that we establish a new benchmark on these four datasets for the segmentation of polyps. Significance: The proposed model can be used as a new benchmark model for polyps segmentation. Lesser parameters in comparison to other models give the edge in the applicability of the proposed Li-SegPNet model in real-time clinical analysis. © 2022 IEEE.","attention; colon cancer; Deep learning; polyps segmentation","Colonic Polyps; Humans; Image Processing, Computer-Assisted; Lithium; Decoding; Deep learning; Diseases; Job analysis; Medical imaging; Network architecture; Semantic Segmentation; Signal encoding; Statistical tests; lithium; Attention; Biomedical imaging; Cancer; Colon cancer; Decoding; Deep learning; Encoder-decoder; Images segmentations; Polyp segmentation; Task analysis; Article; benchmarking; colonoscopy; colorectal polyp; convolution algorithm; deep learning; deep neural network; encoder decoder mode lightweight segmentation network; feature extraction; hold out cross validation; image analysis; image segmentation; intermethod comparison; measurement precision; residual convolutional block; residual neural network; segmentation algorithm; semantics; colon polyp; diagnostic imaging; human; image processing; Semantics","NVIDIA Higher Education and Research Team; Nvidia","","IEEE Computer Society","36269902"
"Zaid Y.; Sah M.; Direkoglu C.","Zaid, Yazan (57671782900); Sah, Melike (22836158400); Direkoglu, Cem (13006002500)","57671782900; 22836158400; 13006002500","Pre-processed and combined EEG data for epileptic seizure classification using deep learning","2023","84","","104738","","","","10.1016/j.bspc.2023.104738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149874099&doi=10.1016%2fj.bspc.2023.104738&partnerID=40&md5=57566ca69d9c124345ed60bb563b2299","Epilepsy is a neurological disease that affects nearly 60 million people around the world. Electroencephalography (EEG) and Machine Learning (ML) can be used to detect epileptic seizures, where ML algorithms depend on hand crafted features. Recently, deep learning (DL) methods became popular due to automatic feature learning. However, current DL based approaches mainly focuses on different DL architecture design, especially deeper DL networks. Only few works experiment modified EEG data as an input to DL models. In this work, we propose modified, pre-processed and combined EEG signals as an input to different DL models for epilepsy seizure classification rather than using raw EEG signals. A variety of pre-processed and combined EEG signals have been evaluated with three different DL architectures: A simple Deep Neural Network (DNN) model and a moderately complex 1D-Convolutional Neural Network (CNN) model and a complex 1D-CNN model. We perform several experiments for two-class and three-class epileptic seizure classification on UCI-Bonn dataset using the proposed EEG signals: (1)Original EEG signal of UCI-Bonn dataset, (2)standardized EEG signal, (3)original EEG signal combined with squared EEG signal, and then standardized, (4)original EEG signal combined with differentiated EEG signal, and then standardized, and (5)original EEG signal combined with magnitude of Fast Fourier Transform (FFT) of EEG signal, and then standardized (original + FFT). Extensive evaluations and comparisons show that the best results are achieved with original + FFT combination on all DL architectures. Using original + FFT EEG signal, competitive results can be achieved with simple and moderately complex DL models, by utilizing less computational resources. © 2023 Elsevier Ltd","Deep learning; Deep neural networks; EEG; Epileptic seizure classification; Pre-processing","Biomedical signal processing; Complex networks; Convolution; Convolutional neural networks; Deep neural networks; Electroencephalography; Electrophysiology; Fast Fourier transforms; Learning systems; Network architecture; Neurodegenerative diseases; Neurophysiology; Convolutional neural network; Deep learning; Epileptic seizure classification; Epileptic seizures; Learning architectures; Learning models; Neural network model; Neurological disease; Pre-processing; Simple++; abnormal behavior; Article; clinical classification; clinical evaluation; comparative study; continuous wavelet transform; controlled study; convolutional neural network; deep learning; deep neural network; diagnostic accuracy; electroencephalogram; electroencephalography; epilepsy; feature extraction; feature selection; Fourier transform; human; image processing; outcome assessment; standardization; Classification (of information)","","","Elsevier Ltd",""
"Altun S.; Alkan A.; Altun I.","Altun, Sinan (57482139300); Alkan, Ahmet (56261391700); Altun, İdiris (55975679200)","57482139300; 56261391700; 55975679200","LSS-VGG16: Diagnosis of Lumbar Spinal Stenosis with Deep Learning","2023","36","5","","E180","E190","10","10.1097/BSD.0000000000001418","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160969409&doi=10.1097%2fBSD.0000000000001418&partnerID=40&md5=ad05ba3d2030aa119b22766cd58a0911","Study Design: This was a retrospective study. Objection: Lumbar Spinal Stenosis (LSS) is a disease that causes chronic low back pain and can often be confused with herniated disk. In this study, a deep learning-based classification model is proposed to make LSS diagnosis quickly and automatically with an objective tool. Summary of Background Data: LSS is a disease that causes negative consequences such as low back pain, foot numbness, and pain. Diagnosis of this disease is difficult because it is confused with herniated disk and requires serious expertise. The shape and amount of this stenosis are very important in deciding the surgery and the surgical technique to be applied in these patients. When the spinal canal narrows, as a result of compression on these nerves and/or pressure on the vessels feeding the nerves, poor nutrition of the nerves causes loss of function and structure. Image processing techniques are applied in biomedical images such as MR and CT and high classification success is achieved. In this way, computer-aided diagnosis systems can be realized to help the specialist in the diagnosis of different diseases. Methods: To demonstrate the success of the proposed model, different deep learning methods and traditional machine learning techniques have been studied. Results: The highest classification success was obtained in the VGG16 method, with 87.70%. Conclusions: The proposed LSS-VGG16 model reveals that a computer-aided diagnosis system can be created for the diagnosis of spinal canal stenosis. In addition, it was observed that higher classification success was achieved compared with similar studies in the literature. This shows that the proposed LSS-VGG16 model will be an important resource for scientists who will work in this field. © 2023 Lippincott Williams and Wilkins. All rights reserved.","deep learning; image processing; lumbar spinal stenosis; VGG16","Constriction, Pathologic; Deep Learning; Humans; Intervertebral Disc Displacement; Low Back Pain; Lumbar Vertebrae; Retrospective Studies; Spinal Stenosis; accuracy; adult; aged; algorithm; area under the curve; Article; artificial intelligence; artificial neural network; backache; cerebrospinal fluid; cervical spine; classification algorithm; compression; controlled study; decision tree; decompression surgery; deep learning; diagnostic test accuracy study; feeding; female; histogram; human; image processing; image quality; image reconstruction; intervertebral disk degeneration; intervertebral disk hernia; knee; learning algorithm; loss of function mutation; low back pain; lumbar spinal stenosis; machine learning; major clinical study; male; natural language processing; nerve; nuclear magnetic resonance imaging; operation duration; random forest; receiver operating characteristic; retrospective study; sensitivity and specificity; spine surgery; structure activity relation; support vector machine; surgical technique; three-dimensional imaging; vertebral canal; VGG16; complication; diagnostic imaging; intervertebral disk hernia; low back pain; lumbar vertebra; stenosis, occlusion and obstruction; surgery; vertebral canal stenosis","Türkiye Bilimsel ve Teknolojik Araştırma Kurumu, TÜBİTAK, (122E042)","","Lippincott Williams and Wilkins","36727890"
"Vijendran A.S.; Ramasamy K.","Vijendran, Anna Saro (55512939900); Ramasamy, Kalaivani (58446007000)","55512939900; 58446007000","Optimal segmentation and fusion of multi-modal brain images using clustering based deep learning algorithm","2023","27","","100691","","","","10.1016/j.measen.2023.100691","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151285850&doi=10.1016%2fj.measen.2023.100691&partnerID=40&md5=de78bd706e5931b311d07859cf4cfd2a","In the last several years, the world of medical technology has seen a boom in multimodal picture fusion. Information is constrained since a single medical instrument can only acquire single modal pictures. Doctors often need a large number of multimodal pictures to get the complete information necessary for disease diagnosis. The burden associated with illness diagnosis will significantly rise when multimodal pictures are employed directly, and errors and interference are likely to occur. Fusion algorithms, which have been extensively employed in the medical industry, may very effectively combine a lot of information in multimodal pictures. However, the existing method has an issue with the earlier stages of brain tumor prediction in white images and inaccuracy image results. To overcome the above-mentioned problems, in this work, Adaptive Firefly Optimization based Convolutional Neural Network (AFFOCNN) and Modified Fully Connected Layer (MFCL) scheme is proposed. This work contains main steps such as noise removal, segmentation, feature extraction, image fusion, and image classification process. Initially, noise removal is done for improving the image quality by removing the noise. Then the modality MRI images are segmented and it is used for subdividing an image into its constituent regions or object. It segments the image into black and white images. After that, feature extraction is applied through the AFFOCNN algorithm which extracts the more informative image features. Image fusion of multi-modal images derived the lower-level, middle-level, and higher-level image contents. It can be viewed in multiple directions and fused in all directions. Finally, image classification is performed by using a Modified Fully Connected Layer (MFCL) which improves the training and testing features efficiently. It was determined from the results that the suggested combination of AFFOCN and MFCL algorithm performs improved than the current algorithms with the increased accuracy, precision, recall, and mean square error (MSE), as well as execution time with the values of 99.00%, 98.00%, 96.00%, 12.00% and 2.40 seconds respectively. © 2023","Adaptive FireFly Optimization based Convolutional Neural Network (AFFOCNN); clustering; Computed Tomography (CT); Magnetic Resonance Imaging (MRI); Modified Fully Connected Layer (MFCL); Multimodal images; Segmentation","Bioluminescence; Biomedical signal processing; Brain mapping; Clustering algorithms; Computerized tomography; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Extraction; Feature extraction; Image classification; Image enhancement; Image fusion; Image segmentation; Mean square error; Multilayer neural networks; Optimization; Adaptive firefly optimization based convolutional neural network; Clusterings; Computed tomography; Convolutional neural network; Magnetic resonance imaging; Modified fully connected layer; Multi-modal; Multimodal images; Optimisations; Segmentation; Magnetic resonance imaging","","","Elsevier Ltd",""
"Maity A.; Pathak A.; Saha G.","Maity, Arnab (57208319888); Pathak, Akanksha (57206265005); Saha, Goutam (35766944200)","57208319888; 57206265005; 35766944200","Transfer learning based heart valve disease classification from Phonocardiogram signal","2023","85","","104805","","","","10.1016/j.bspc.2023.104805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150352863&doi=10.1016%2fj.bspc.2023.104805&partnerID=40&md5=ecafd589aea2dc1b61e3e177efefc9e0","Physiological conditions that prevent heart valves from functioning precisely to ensure proper blood circulation are known as heart valve disorder (HVD). Detection of HVD is critical as untreated heart valve disease often develops life-threatening cardiac diseases. Typical HVD detection methods, like echocardiography, MRI, and cardiac CT, are costly, complex, and require robust healthcare infrastructure. Although, by simple non-invasive listening to heart sound irregularities, an expert physician can anticipate the signs of HVD from ancient times. Contemporary development suggests that with machine learning-based algorithms, a graphical representation of heart sound, known as the phonocardiogram (PCG), can effectively predict the anomaly in the valvular activity. In recent studies, deep learning-based strategies showed promising results in the PCG classification task but demand extensive resources and training data. This work investigates the merits of transfer learning (TL) using pre-trained convolution neural networks for the automatic PCG classification when data is scarce. With standard time–frequency representations (i.e., spectrogram, log-Mel spectrogram, and scalogram) as input features, audio and image-based pre-trained lightweight models are fine-tuned to categorize the PCG. The proposed YAMNet-based TL method classifies four types of HVD data collected from public heart sound databases and achieves overall accuracy, sensitivity, and specificity of 99.83%, 99.59%, and 99.90%, respectively. Alongside, it classifies the PhysioNet/CinC Challenge 2016 dataset into binary classes with 92.23% accuracy. The study achieves high classification metrics despite data scarcity. It also investigates the proposed method's computational efficiency and robustness against practical noise contamination for performance evaluation in a possible real-life scenario. © 2023 Elsevier Ltd","Heart valve disease; PCG; Spectrogram; Time–frequency representation; Transfer learning; YAMNet","Biomedical signal processing; Cardiology; Computational efficiency; Computerized tomography; Deep learning; Echocardiography; Heart; Phonocardiography; Disease classification; Heart sounds; Heart valve disease; Heart valves; Phonocardiograms; Physiological condition; Spectrograms; Time-frequency representations; Transfer learning; YAMNet; aortic valve stenosis; Article; artifact; continuous wavelet transform; convolutional neural network; diagnostic accuracy; diagnostic test accuracy study; disease classification; feature extraction; heart cycle; heart sound; human; major clinical study; mitral valve prolapse; mitral valve regurgitation; mitral valve stenosis; phonocardiography; sensitivity and specificity; short time Fourier transform; transfer of learning; valvular heart disease; Classification (of information)","","","Elsevier Ltd",""
"Anand A.B.; Michael A.; Biju A.; Chacko D.J.; Darsana P.","Anand, Abin B. (58909360400); Michael, Alent (58909486600); Biju, Aneesha (58909579100); Chacko, Deryck Joseph (58909360500); Darsana, P. (56405608600)","58909360400; 58909486600; 58909579100; 58909360500; 56405608600","Computer Aided Diagnosis of Depression Using EEG Signal Processing","2023","","","","","","","10.1109/AICERA/ICIS59538.2023.10420346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186139901&doi=10.1109%2fAICERA%2fICIS59538.2023.10420346&partnerID=40&md5=4fd0c6c7432d586d873b21c5458f359c","Major depressive disorder (MDD) emerges as a prominent factor leading to disability on a global scale and contributes significantly to the global burden of illness overall. The traditional method of detecting MDD is by continuous medical examination by a psychologist or psychiatrist. Our objective is to develop a non-invasive device which collects brain signals from the head and gets interfaced with a computer. The purpose of this paper is to develop a computer-aided diagnosis system that can identify depression in real time. The proposed system comprises three main components: the ADS1299 Front-End (FE) Printed Development Kit (PDK) evaluation board, a wearable electrode, and a desktop application. The primary approach involves the utilization of electroencephalogram (EEG) signal processing, along with the ADS1299 FE PDK evaluation board and deep learning techniques. This paper involves the utilisation of a publicly available dataset for training the deep learning model. The convolutional Neural Network (CNN) algorithm is used for the classification process. Absolute and relative powers are computed, and an asymmetry image matrix is generated based on the relative power values. By analysing the image matrix, the system can classify a patient as healthy or suffering from major depression based on higher or lower relative power, respectively. This paper seeks to make a valuable contribution to the academic sphere of the study of mental health diagnosis by leveraging advanced signal processing techniques and deep learning models for more accurate and efficient detection of depression.  © 2023 IEEE.","Asymmetry matrix; Depression; Electroencephalogram; MDD","Biomedical signal processing; Computer aided diagnosis; Convolutional neural networks; Deep learning; Learning systems; Asymmetry matrix; Depression; Electroencephalogram signals; Evaluation board; Front end; Learning models; Major depressive disorder; matrix; Power; Signal-processing; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Körber N.","Körber, Nils (57471196000)","57471196000","MIA is an open-source standalone deep learning application for microscopic image analysis","2023","3","7","100517","","","","10.1016/j.crmeth.2023.100517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166029536&doi=10.1016%2fj.crmeth.2023.100517&partnerID=40&md5=f1360aec357bd3ba04de6a3b2ba72d41","In recent years, the amount of data generated by imaging techniques has grown rapidly, along with increasing computational power and the development of deep learning algorithms. To address the need for powerful automated image analysis tools for a broad range of applications in the biomedical sciences, the Microscopic Image Analyzer (MIA) was developed. MIA combines a graphical user interface that obviates the need for programming skills with state-of-the-art deep-learning algorithms for segmentation, object detection, and classification. It runs as a standalone, platform-independent application and uses open data formats, which are compatible with commonly used open-source software packages. The software provides a unified interface for easy image labeling, model training, and inference. Furthermore, the software was evaluated in a public competition and performed among the top three for all tested datasets. © 2023 The Author(s)","classification; CP: Imaging; deep learning; image analysis; microscopy; object detection; segmentation; tracking","Algorithms; Deep Learning; Image Processing, Computer-Assisted; Software; Article; artificial neural network; benchmarking; Caenorhabditis elegans; classification; controlled study; deep learning; female; human; human cell; human experiment; human tissue; image analysis; image segmentation; information processing; male; Microscopic Image Analyzer; microscopy; model; nonhuman; normal human; software; statistical analysis; algorithm; image processing; procedures; software","","","Cell Press","37533647"
"Rasheed A.; Shirazi S.H.; Umar A.I.; Shahzad M.; Yousaf W.; Khan Z.","Rasheed, Assad (57743035700); Shirazi, Syed Hamad (56275849800); Umar, Arif Iqbal (56497586200); Shahzad, Muhammad (57530488700); Yousaf, Waqas (57214821240); Khan, Zakir (57188803233)","57743035700; 56275849800; 56497586200; 57530488700; 57214821240; 57188803233","Cervical cell's nucleus segmentation through an improved UNet architecture","2023","18","10 October","e0283568","","","","10.1371/journal.pone.0283568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173044134&doi=10.1371%2fjournal.pone.0283568&partnerID=40&md5=3af5778db0f19d92aaafecdac9d0dffa","Precise segmentation of the nucleus is vital for computer-aided diagnosis (CAD) in cervical cytology. Automated delineation of the cervical nucleus has notorious challenges due to clumped cells, color variation, noise, and fuzzy boundaries. Due to its standout performance in medical image analysis, deep learning has gained attention from other techniques. We have proposed a deep learning model, namely C-UNet (Cervical-UNet), to segment cervical nuclei from overlapped, fuzzy, and blurred cervical cell smear images. Cross-scale features integration based on a bi-directional feature pyramid network (BiFPN) and wide context unit are used in the encoder of classic UNet architecture to learn spatial and local features. The decoder of the improved network has two inter-connected decoders that mutually optimize and integrate these features to produce segmentation masks. Each component of the proposed C-UNet is extensively evaluated to judge its effectiveness on a complex cervical cell dataset. Different data augmentation techniques were employed to enhance the proposed model's training. Experimental results have shown that the proposed model outperformed extant models, i.e., CGAN (Conditional Generative Adversarial Network), DeepLabv3, Mask-RCNN (Region-Based Convolutional Neural Network), and FCN (Fully Connected Network), on the employed dataset used in this study and ISBI-2014 (International Symposium on Biomedical Imaging 2014), ISBI-2015 datasets. The C-UNet achieved an objectlevel accuracy of 93%, pixel-level accuracy of 92.56%, object-level recall of 95.32%, pixellevel recall of 92.27%, Dice coefficient of 93.12%, and F1-score of 94.96% on complex cervical images dataset.  © 2023 Rasheed et al.","","Diagnosis, Computer-Assisted; Female; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Papanicolaou Test; Vaginal Smears; accuracy; Article; artificial neural network; Cervical cells nucleus segmentation; comparative effectiveness; computer vision; convolutional neural network; cytology; deep learning; fuzzy system; hierarchical clustering; human; illumination; image analysis; image segmentation; learning algorithm; Markov random field; nerve cell network; noise; recall; signal noise ratio; support vector machine; training; uterine cervix; artificial neural network; computer assisted diagnosis; female; image processing; Papanicolaou test; procedures; vagina smear","","","Public Library of Science","37788295"
"Tas N.P.; Kaya O.; Macin G.; Tasci B.; Dogan S.; Tuncer T.","Tas, Nevsun Pihtili (57213019087); Kaya, Oguz (57581235700); Macin, Gulay (56344605200); Tasci, Burak (57213686441); Dogan, Sengul (25653093400); Tuncer, Turker (37062172100)","57213019087; 57581235700; 56344605200; 57213686441; 25653093400; 37062172100","ASNET: A Novel AI Framework for Accurate Ankylosing Spondylitis Diagnosis from MRI","2023","11","9","2441","","","","10.3390/biomedicines11092441","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172483650&doi=10.3390%2fbiomedicines11092441&partnerID=40&md5=b3af38844bd1ee5aa798248dfcbb8fc6","Background: Ankylosing spondylitis (AS) is a chronic, painful, progressive disease usually seen in the spine. Traditional diagnostic methods have limitations in detecting the early stages of AS. The early diagnosis of AS can improve patients’ quality of life. This study aims to diagnose AS with a pre-trained hybrid model using magnetic resonance imaging (MRI). Materials and Methods: In this research, we collected a new MRI dataset comprising three cases. Furthermore, we introduced a novel deep feature engineering model. Within this model, we utilized three renowned pretrained convolutional neural networks (CNNs): DenseNet201, ResNet50, and ShuffleNet. Through these pretrained CNNs, deep features were generated using the transfer learning approach. For each pretrained network, two feature vectors were generated from an MRI. Three feature selectors were employed during the feature selection phase, amplifying the number of features from 6 to 18 (calculated as 6 × 3). The k-nearest neighbors (kNN) classifier was utilized in the classification phase to determine classification results. During the information phase, the iterative majority voting (IMV) algorithm was applied to secure voted results, and our model selected the output with the highest classification accuracy. In this manner, we have introduced a self-organized deep feature engineering model. Results: We have applied the presented model to the collected dataset. The proposed method yielded 99.80%, 99.60%, 100%, and 99.80% results for accuracy, recall, precision, and F1-score for the collected axial images dataset. The collected coronal image dataset yielded 99.45%, 99.20%, 99.70%, and 99.45% results for accuracy, recall, precision, and F1-score, respectively. As for contrast-enhanced images, accuracy of 95.62%, recall of 80.72%, precision of 94.24%, and an F1-score of 86.96% were attained. Conclusions: Based on the results, the proposed method for classifying AS disease has demonstrated successful outcomes using MRI. The model has been tested on three cases, and its consistently high classification performance across all cases underscores the model’s general robustness. Furthermore, the ability to diagnose AS disease using only axial images, without the need for contrast-enhanced MRI, represents a significant advancement in both healthcare and economic terms. © 2023 by the authors.","ankylosing spondylitis; ASNet; biomedical image classification; deep feature engineering; information fusion","","","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Liu H.-M.; Peng C.-J.; Han F.; Zhang Y.","Liu, Hong-Mei (58223020700); Peng, Cai-Jing (57555798900); Han, Fang (57225658899); Zhang, Yuan (55971560500)","58223020700; 57555798900; 57225658899; 55971560500","Multi-view hybrid neural network for spatiotemporal semi-supervised sleep staging; [基于脑电多视图混合神经网络的时空半监督睡眠分期]","2023","45","5","","797","806","9","10.13374/j.issn2095-9389.2022.03.22.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156219354&doi=10.13374%2fj.issn2095-9389.2022.03.22.005&partnerID=40&md5=b65b1bc4e7ae3d345cff733680443606","Sleep takes approximately 1/3 of a person’s lifetime; therefore, its quality profoundly affects learning, physical recovery, and metabolism. Clinically relevant human physiological data are collected using polysomnography, which is analyzed by sleep technologists to determine sleep stages. However, the manual method is prone to having a cumbersome workload due to a large amount of data analysis and different data formats. Simultaneously, manually analyzed results are influenced by doctors’ medical clinical experience, which may cause inconsistent diagnoses. Recently, with the development of artificial intelligence, computer science, other technologies, and their interdisciplinarity, a series of typical achievements have been accomplished in intelligent diagnosis, laying the foundation for medical artificial intelligence in the sleep medicine field. In sleep research, realizing automatic sleep signal analysis and recognition assists doctors in diagnosis and reduces their workload, thus having important clinical significance and application value. Although deep neural networks are becoming popular for automatic sleep stage classification with supervised learning, large-scale, labeled datasets remain difficult to acquire. Learning from raw polysomnography signals and derived time-frequency image representations has been an interesting solution. However, extracting features from only a single dimension leads to inadequate feature extraction and, thus, limited accuracy. Hence, this paper aims to learn multi-view representations for physiological signals with semi-supervised learning. Specifically, we make the following contributions: (1) We propose a multi-view, hybrid neural network model containing a multichannel view time-frequency domain feature extraction mechanism, an attention mechanism, and a feature fusion module. Among these aspects, the multichannel view time-frequency domain mechanism extracts time domain and frequency domain signal features to achieve multi-view feature extraction. The attention mechanism module enhances salience features and achieves interclass feature extraction in the frequency domain. The feature fusion module fuses and classifies the above features. (2) A semi-supervised learning strategy is used to learn unlabeled electroencephalogram (EEG) data, which solves the problem of sleep data underutilization due to insufficient labeling of EEG signals in clinical practice. (3) Extensive experiments conducted on sleep stage classification demonstrate state-of-the-art performance compared with supervised learning and a semi-supervised baseline. Experimental results on three public databases (Sleep−EDF, DOD−H, and DOD−O) and one private database show that our semi-supervised method achieves accuracies of 81.6%, 81.5%, 79.2%, and 75.4%. The results show that our proposed model is comparable to a fully supervised sleep staging model while substantially reducing the technician’s workload in data labeling. © 2023 Science Press. All rights reserved.","electroencephalograph; hybrid neural network; multi-view; semi-supervised; sleep stage classification","Biomedical signal processing; Classification (of information); Clinical research; Deep neural networks; Electroencephalography; Extraction; Frequency domain analysis; Large dataset; Learning algorithms; Sleep research; Supervised learning; Electroencephalograph; Features extraction; Hybrid neural networks; Learn+; Multi-views; Polysomnography; Semi-supervised; Semi-supervised learning; Sleep stages classifications; Sleep staging; Feature extraction","","","Science Press",""
"Liu Y.-H.; Qin T.-X.; Wang Y.-C.; Kang X.-W.; Liu J.; Wu J.-C.; Cao L.-C.","Liu, You-Hai (58257975700); Qin, Tian-Xiang (58257603400); Wang, Ying-Ce (58260260400); Kang, Xing-Wang (57536692700); Liu, Jun (58415316500); Wu, Jia-Chen (56597056200); Cao, Liang-Cai (8502158000)","58257975700; 58257603400; 58260260400; 57536692700; 58415316500; 56597056200; 8502158000","Research advances in simple and compact optical imaging techniques; [简单光学成像技术及其研究进展]","2023","72","8","084205","","","","10.7498/aps.72.20230092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159613550&doi=10.7498%2faps.72.20230092&partnerID=40&md5=8ebe32d4adc6e344c5c83851ea431d33","Computational imaging enables optical imaging systems to acquire more information with miniaturized setups. Computational imaging can avoid the object-image conjugate limitation of the imaging system, and introduce encoding and decoding processes based on physical optics to achieve more efficient information transmission. It can simultaneously increase the amount of information and reduce the complexity of the system, thereby paving the way for miniaturizing imaging systems. Based on computational imaging, the simple and compact optical imaging techniques are developed, which is also called simple optics. To develop miniaturized optical imaging elements and integrated systems, simple optics utilizes the joint design of optical system and image processing algorithms, thereby realizing high-quality imaging that is comparable to complex optical systems. The imaging systems are of small-size, low-weight, and low-power consumption. With the development of micro-nano manufacturing, the optical elements have evolved from a single lens or a few lenses, to flat/planar optical elements, such as diffractive optical elements and metasurface optical elements. As a result, various lensless and metalens imaging systems have emerged. Owing to the introduction of encoding process and decoding process, an optical imaging model is developed to represent the relationship between the target object and the acquired signal, from which the computational reconstruction is used to restore the image. In the image restoration part, the algorithms are discussed in three categories, i.e. the classic algorithm, the model-based optimization iterative algorithm, and the deep learning (neural network) algorithm. Besides, the end-to-end optimization is highlighted because it introduces a new frame to minimize the complexity of optical system. In this review, the imaging techniques realized by simple optics are also discussed, such as depth imaging, high-resolution and super-resolution imaging, large field of view imaging, and extended depth of field imaging, as well as their important roles in developing consumer electronics, unmanned driving, machine vision, security monitoring, biomedical devices and metaverse. Last but not least, the challenges and future developments are prospected. © 2023 Chinese Physical Society.","computational imaging; lensless; metalens; simple optics","Complex networks; Computational Imaging; Decoding; Deep learning; Encoding (symbols); Image reconstruction; Imaging systems; Lenses; Optical data processing; Optical systems; Restoration; Signal encoding; Computational imaging; Decoding process; Encoding process; Lensless; MetaLens; Optical imaging; Optical imaging technique; Research advances; Simple optic; Simple++; Iterative methods","National Natural Science Foundation of China, NSFC, (62235009); National Natural Science Foundation of China, NSFC","","Institute of Physics, Chinese Academy of Sciences",""
"Tang R.; Xia L.; Gutierrez B.; Gagne I.; Munoz A.; Eribez K.; Jagnandan N.; Chen X.; Zhang Z.; Waller L.; Alaynick W.; Cho S.H.; An C.; Lo Y.-H.","Tang, Rui (57209586673); Xia, Lin (57222399699); Gutierrez, Bien (57225089437); Gagne, Ivan (57216163518); Munoz, Adonary (57800080100); Eribez, Korina (57204900048); Jagnandan, Nicole (57742358200); Chen, Xinyu (57212611742); Zhang, Zunming (57216150682); Waller, Lauren (57216147661); Alaynick, William (8944294000); Cho, Sung Hwan (55487931900); An, Cheolhong (23566358600); Lo, Yu-Hwa (7401935349)","57209586673; 57222399699; 57225089437; 57216163518; 57800080100; 57204900048; 57742358200; 57212611742; 57216150682; 57216147661; 8944294000; 55487931900; 23566358600; 7401935349","Low-latency label-free image-activated cell sorting using fast deep learning and AI inferencing","2023","220","","114865","","","","10.1016/j.bios.2022.114865","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141497447&doi=10.1016%2fj.bios.2022.114865&partnerID=40&md5=7f7f319781dedbbda5e14d3c5c4ceed4","Classification and sorting of cells using image-activated cell sorting (IACS) systems can bring significant insight to biomedical sciences. Incorporating deep learning algorithms into IACS enables cell classification and isolation based on complex and human-vision uninterpretable morphological features within a heterogeneous cell population. However, the limited capabilities and complicated implementation of deep learning–assisted IACS systems reported to date hinder the adoption of the systems for a wide range of biomedical research. Here, we present image-activated cell sorting by applying fast deep learning algorithms to conduct cell sorting without labeling. The overall sorting latency, including signal processing and AI inferencing, is less than 3 ms, and the training time for the deep learning model is less than 30 min with a training dataset of 20,000 images. Both values set the record for IACS with sorting by AI inference. We demonstrated our system performance through a 2-part polystyrene beads sorting experiment with 96.6% sorting purity, and a 3-part human leukocytes sorting experiment with 89.05% sorting purity for monocytes, 92.00% sorting purity for lymphocytes, and 98.24% sorting purity for granulocytes. The above performance was achieved with simple hardware containing only 1 FPGA, 1 PC and GPU, as a result of an optimized custom CNN UNet and efficient use of computing power. The system provides a compact, sterile, low-cost, label-free, and low-latency cell sorting solution based on real-time AI inferencing and fast training of the deep learning model. © 2022 The Authors","AI inferencing; Artificial intelligence; Image-activated cell sorting; Imaging flow cytometry","Algorithms; Biosensing Techniques; Deep Learning; Humans; Image Processing, Computer-Assisted; Signal Processing, Computer-Assisted; Cell culture; Cell proliferation; Computing power; Image processing; Learning algorithms; Learning systems; AI inferencing; Biomedical science; Cell isolation; Cell sorting; Image-activated cell sorting; Imaging flow cytometry; Label free; Learning models; Low latency; Sorting system; accuracy; Article; artificial intelligence; cell selection; convolutional neural network; deep learning; flow cytometry; granulocyte; human; human cell; image analysis; imaging; latent period; learning algorithm; leukocyte; lymphocyte; microfluidic analysis; monocyte; algorithm; genetic procedures; image processing; procedures; signal processing; Deep learning","National Science Foundation, NSF, (ECCS-1542148)","","Elsevier Ltd","36368140"
"Li J.; Wang Q.","Li, Jingjing (57259164100); Wang, Qiang (57221577479)","57259164100; 57221577479","Comparison of the representational ability in individual difference analysis using 2-D time-series image and time-series feature patterns","2023","215","","119429","","","","10.1016/j.eswa.2022.119429","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144015719&doi=10.1016%2fj.eswa.2022.119429&partnerID=40&md5=7ea876b937d79a6f2757cb462d0d1564","Physiological signals, as crucial indicators for measuring physical health, must be acquired by model learning, but the modeling and analysis performance is strongly affected by different representation patterns and feature extraction methods, even for the same data. This work investigated the capacity of the 2-D time-series image patterns on the weakening of individual differences and compared them with the time-series feature patterns. First, the time-series features of electrocardiograph (ECG) were extracted using the permutation conditional mutual information (PCMI), principal component analysis (PCA), power spectral density (PSD), and compactly supported sym-5 orthogonal wavelets with approximate symmetry (CSOWAS); the time-series coupling features of electroencephalogram (EEG) and SEED were extracted using PCMI. Then, the features of ECG, EEG, and SEED were reconstructed into 2-dimensional (2-D) time-series images using Gradient Angle Difference Field (GADF) algorithm. Finally, the classification performance of the 2-D time-series images and time-series features on the ECG, EEG, and SEED data sets are analyzed using the backpropagation (BP) neural network, LeNet 5, convolutional neural network (CNN), Deep Residual Shrinkage Networks (DRSN), ResNet 18, and VGG 16 models and compared to each other. The results show that 1) the representation ability of the 2-D time-series image pattern is better than that of the time-series feature pattern in physiological data (ECG, EEG, and SEED) analysis; 2) the Gamma band is a stabler in the classification task of individual differences (best accuracy: 100%), which can be used as the first choice for the analysis of similarity features between individuals; 3) the classification performance of the 2-D time-series images in Theta, Alpha 1, Beta 1, and Beta 2 bands on EEG datasets are greatly improved. This work shows that the 2-D time-series image patterns of the ECG, EEG, and SEED are an effective method for distinguishing individual differences. © 2022 Elsevier Ltd","Image patterns; Individual differences; Physiological signals; Time-series image","Biomedical signal processing; Classification (of information); Electrocardiography; Image analysis; Image enhancement; Physiological models; Physiology; Principal component analysis; Spectral density; Time series; Time series analysis; Classification performance; Conditional mutual information; Feature pattern; Image patterns; Images series; Individual Differences; Physiological signals; Time series features; Time-series image; Times series; Electroencephalography","","","Elsevier Ltd",""
"Kaba Ş.; Haci H.; Isin A.; Ilhan A.; Conkbayir C.","Kaba, Şerife (57204771029); Haci, Huseyin (35299632200); Isin, Ali (57192176371); Ilhan, Ahmet (57192176613); Conkbayir, Cenk (54794823600)","57204771029; 35299632200; 57192176371; 57192176613; 54794823600","The Application of Deep Learning for the Segmentation and Classification of Coronary Arteries","2023","13","13","2274","","","","10.3390/diagnostics13132274","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164705364&doi=10.3390%2fdiagnostics13132274&partnerID=40&md5=664753a894c5621fa415b433a38b9630","In recent years, the prevalence of coronary artery disease (CAD) has become one of the leading causes of death around the world. Accurate stenosis detection of coronary arteries is crucial for timely treatment. Cardiologists use visual estimations when reading coronary angiography images to diagnose stenosis. As a result, they face various challenges which include high workloads, long processing times and human error. Computer-aided segmentation and classification of coronary arteries, as to whether stenosis is present or not, significantly reduces the workload of cardiologists and human errors caused by manual processes. Moreover, deep learning techniques have been shown to aid medical experts in diagnosing diseases using biomedical imaging. Thus, this study proposes the use of automatic segmentation of coronary arteries using U-Net, ResUNet-a, UNet++, models and classification using DenseNet201, EfficientNet-B0, Mobilenet-v2, ResNet101 and Xception models. In the case of segmentation, the comparative analysis of the three models has shown that U-Net achieved the highest score with a 0.8467 Dice score and 0.7454 Jaccard Index in comparison with UNet++ and ResUnet-a. Evaluation of the classification model’s performances has shown that DenseNet201 performed better than other pretrained models with 0.9000 accuracy, 0.9833 specificity, 0.9556 PPV, 0.7746 Cohen’s Kappa and 0.9694 Area Under the Curve (AUC). © 2023 by the authors.","angiography; coronary arteries; coronary artery disease (CAD); pretrained models; U-Net","Article; automation; cardiologist; clinical article; comparative study; computer aided design; controlled study; convolutional neural network; coronary angiography; coronary artery; coronary artery disease; coronary stenosis; correlation coefficient; cross validation; deep learning; deep residual U net; densenet; diagnostic accuracy; digital imaging and communications in medicine; disease classification; efficientnet; evaluation study; false positive result; human; image processing; image segmentation; k fold cross validation; kappa statistics; machine learning; mobilenet; positivity rate; predictive value; radiological technologist; receiver operating characteristic; residual neural network; segmentation algorithm; sensitivity and specificity","","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Bhattacharya A.; Saha B.; Chattopadhyay S.; Sarkar R.","Bhattacharya, Agnish (58103768500); Saha, Biswajit (58329445300); Chattopadhyay, Soham (57219971529); Sarkar, Ram (13607482600)","58103768500; 58329445300; 57219971529; 13607482600","Deep feature selection using adaptive β-Hill Climbing aided whale optimization algorithm for lung and colon cancer detection","2023","83","","104692","","","","10.1016/j.bspc.2023.104692","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148098944&doi=10.1016%2fj.bspc.2023.104692&partnerID=40&md5=61f10e6281c06e8ef9f6f53fa2c4ee2c","One of the most frightening and talked-about diseases in the modern world is cancer. Huge amounts of research are conducted worldwide to make this ailment less fearsome, be it by finding its cure, discovering ways to detect it in much earlier stages to reduce the mortality rate, or identifying precautions for humans to avoid it. The availability of large collections of biomedical and clinical data has ushered in the use of computer vision for cancer detection, especially for two of its most common types, lung and colon carcinomas. In this work, we present a framework wherein both deep learning and meta-heuristic approaches have been used for the prediction of colon or lung cancer, or both, from histopathological images with near-perfect precision. Initially, deep learning models, namely ResNet-18 for 2-class classification and EfficientNet-b4-widese for 3-class and 5-class classification, have been trained on the LC25000 dataset, followed by the extraction of deep features. The feature vector obtained from a deep learning model may have some redundancy. Hence, the selection of the most useful features has been done with the application of our proposed hybrid meta-heuristic optimization algorithm, AdBet-WOA (Whale optimization algorithm with integrated Adaptive β-Hill Climbing local search), utilizing which the Support Vector Machine (SVM) classifier classifies the colon cancer test data, lung cancer test data, and both combined with an accuracy of 99.99%, 99.97%, and 99.96%, respectively, matching the benchmark results comprehensively. For comparison, we have used a few independent as well as hybrid optimization algorithms. Our proposed approach succeeds greatly in reducing the number of features and also leads to better classification performance, as indicated by the obtained results. The relevant codes for our proposed approach are publicly available at: https://github.com/raj-1411/AdBet-WOA © 2023 Elsevier Ltd","Colon cancer; Feature selection; Histopathology images; Lung cancer; Medical image analysis; Whale optimization algorithm","Biological organs; Deep learning; Diseases; Feature Selection; Heuristic algorithms; Heuristic methods; Learning systems; Medical imaging; Optimization; Support vector machines; Cancer detection; Colon cancer; Features selection; Hill climbing; Histopathology image; Learning models; Lung Cancer; Medical image analysis; Optimization algorithms; Whale optimization algorithm; adaptive beta hill climbing algorithm; Article; cancer diagnosis; classification algorithm; classifier; colon adenocarcinoma; colon cancer; colon tissue; colorectal squamous cell carcinoma; computer assisted diagnosis; computer prediction; deep learning; diagnostic accuracy; false positive result; feature extraction; feature selection; feature selection algorithm; genetic algorithm; histopathology; human; human tissue; image analysis; intermethod comparison; lung adenocarcinoma; lung cancer; lung parenchyma; metaheuristics; particle swarm optimization; receiver operating characteristic; residual neural network; squamous cell lung carcinoma; support vector machine; whale optimization algorithm; Classification (of information)","Centre for Microprocessor Applications for Training Applications and Research","","Elsevier Ltd",""
"Tong G.; Wang X.; Jiang H.; Wu A.; Cheng W.; Cui X.; Bao L.; Cai R.; Cai W.","Tong, Guoyu (57821373500); Wang, Xi (57829472100); Jiang, Huiyan (14628756900); Wu, Anhua (55725686800); Cheng, Wen (56457139700); Cui, Xiao (57352679500); Bao, Long (57193427302); Cai, Ruikai (58339196500); Cai, Wei (56449914800)","57821373500; 57829472100; 14628756900; 55725686800; 56457139700; 57352679500; 57193427302; 58339196500; 56449914800","A Deep Learning Model for Automatic Segmentation of Intraparenchymal and Intraventricular Hemorrhage for Catheter Puncture Path Planning","2023","27","9","","4454","4465","11","10.1109/JBHI.2023.3285809","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162704055&doi=10.1109%2fJBHI.2023.3285809&partnerID=40&md5=9a4b7d398f717321f95915ca62517b3a","Intracerebral hemorrhage is the subtype of stroke with the highest mortality rate, especially when it also causes secondary intraventricular hemorrhage. The optimal surgical option for intracerebral hemorrhage remains one of the most controversial areas of neurosurgery. We aim to develop a deep learning model for the automatic segmentation of intraparenchymal and intraventricular hemorrhage for clinical catheter puncture path planning. First, we develop a 3D U-Net embedded with a multi-scale boundary aware module and a consistency loss for segmenting two types of hematoma in computed tomography images. The multi-scale boundary aware module can improve the model's ability to understand the two types of hematoma boundaries. The consistency loss can reduce the probability of classifying a pixel into two categories at the same time. Since different hematoma volumes and locations have different treatments. We also measure hematoma volume, estimate centroid deviation, and compare with clinical methods. Finally, we plan the puncture path and conduct clinical validation. We collected a total of 351 cases, and the test set contained 103 cases. For intraparenchymal hematomas, the accuracy can reach 96 % when the proposed method is applied for path planning. For intraventricular hematomas, the proposed model's segmentation efficiency and centroid prediction are superior to other comparable models. Experimental results and clinical practice show that the proposed model has potential for clinical application. In addition, our proposed method has no complicated modules and improves efficiency, with generalization ability.  © 2013 IEEE.","Catheter routing; Deep learning; Intracerebral hemorrhage segmentation; Intraparenchymal hemorrhage; Intraventricular hemorrhage","Cerebral Hemorrhage; Deep Learning; Hematoma; Humans; Image Processing, Computer-Assisted; Punctures; Stroke; Catheters; Computerized tomography; Deep learning; Efficiency; Medical imaging; Motion planning; Neurosurgery; Tumors; Biomedical imaging; Catheter routing; Computed tomography; Deep learning; Haemorrage; Hemorrhaging; Images segmentations; Intra-ventricular haemorrhage; Intracerebral hemorrhage segmentation; Intraparenchymal hemorrhage; Routings; Solid modelling; ablation therapy; algorithm; Article; artificial neural network; brain depth stimulation; brain hemorrhage; catheter puncture path planning; cerebrovascular accident; computer assisted tomography; deep learning; entropy; hematoma; human; image analysis; image segmentation; intensive care unit; intraparenchyma hemorrhage; major clinical study; mortality rate; neurosurgery; nuclear magnetic resonance imaging; puncture; receptive field; retrospective study; brain hemorrhage; cerebrovascular accident; complication; image processing; procedures; Image segmentation","345 talent Project of Shengjing Hospital; Shenyang Medical-Industry Integration Collaborative Innovation Research Project, (21-172-9-02); National Natural Science Foundation of China, NSFC, (61872075); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Liaoning Province, (2021-YGJC-07); Natural Science Foundation of Liaoning Province; National Key Research and Development Program of China, NKRDPC, (2020AAA0109400); National Key Research and Development Program of China, NKRDPC; Science and Technology Planning Project of Guangdong Province, (2021JH1/10400049, 2022JH1/10400004); Science and Technology Planning Project of Guangdong Province","","Institute of Electrical and Electronics Engineers Inc.","37310835"
"Liu X.; Xiong S.; Wang X.; Liang T.; Wang H.; Liu X.","Liu, Xiaoguang (57219874219); Xiong, Shicheng (58026788600); Wang, Xiaodong (58027053900); Liang, Tie (55230288100); Wang, Hongrui (9736821600); Liu, Xiuling (35115326500)","57219874219; 58026788600; 58027053900; 55230288100; 9736821600; 35115326500","A compact multi-branch 1D convolutional neural network for EEG-based motor imagery classification","2023","81","","104456","","","","10.1016/j.bspc.2022.104456","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144557234&doi=10.1016%2fj.bspc.2022.104456&partnerID=40&md5=1c165ee8baf0787bc01fa96d440c0f1c","Motor imagery (MI) EEG signals are considered a promising paradigm for BCI systems that enable humans to communicate with the outside world through the brain and have a wide range of applications to improve patients' quality of life with muscle or nerve damage. Due to the low signal-to-noise ratio of the acquired EEG signals, it is challenging to decode the intent accurately and even more challenging to decode the raw EEG signals. Currently, there is no deep learning method to achieve high classification performance in decoding raw EEG signals. We propose a new end-to-end network for decoding MI EEG signals, Compact Multi-Branch One-dimensional Convolutional Neural Network (CMO-CNN), without some pre-processing such as filtering, using the original EEG signals. The 1D convolution is used as the feature extractor to extract diverse and multi-level features for fusion using different filter scales and depths of different branches. 1D Squeeze-and-Excitation blocks (SE-blocks) and shortcut connections are added to further improve the generalization and robustness of the network. 83.92% and 87.19% classification accuracies were achieved in the BCI Competition IV-2a and the BCI Competition IV-2b datasets. An 8% improvement to 63.34% was achieved in the cross-subject test, demonstrating that our proposed CMO-CNN outperforms the current state-of-the-art methods. Visual analysis of the network shows that the proposed model can accurately learn the event-related desynchronization/synchronization (ERD/ERS) phenomenon in the signal, and 1D convolution is actively used for feature extraction suitable for feature extraction of the original EEG signal. © 2022 Elsevier Ltd","1D convolution; 1D squeeze-and-excitation blocks; Brain-computer interface; Deep learning; Motor imagery; Shortcut connections","Biomedical signal processing; Brain computer interface; Classification (of information); Convolutional neural networks; Decoding; Deep learning; Extraction; Feature extraction; Image classification; Image enhancement; Learning systems; Signal to noise ratio; 1d convolution; 1d squeeze-and-excitation block; Convolutional neural network; Deep learning; EEG signals; Features extraction; Motor imagery; Motor imagery EEG; One-dimensional; Short-cut connection; Article; classification algorithm; convolutional neural network; cross validation; deep learning; electroencephalogram; evoked response; feature extraction; feature selection; human; machine learning; motor imagery signal; residual neural network; signal noise ratio; Convolution","Key Research and Development Program of Baoding Science and Technology Bureau, (1911Q001); Postdoctoral Scientific Research Project of Hebei Province, (B2019005001); Science and Technology Project of Hebei Education Department, (ZD2020146)","","Elsevier Ltd",""
"Shah S.J.H.; Albishri A.; Kang S.S.; Lee Y.; Sponheim S.R.; Shim M.","Shah, Syed Jawad H. (57216702570); Albishri, Ahmed (57201686114); Kang, Seung Suk (57352727300); Lee, Yugyung (57293981900); Sponheim, Scott R. (6701769226); Shim, Miseon (55172770200)","57216702570; 57201686114; 57352727300; 57293981900; 6701769226; 55172770200","ETSNet: A deep neural network for EEG-based temporal–spatial pattern recognition in psychiatric disorder and emotional distress classification","2023","158","","106857","","","","10.1016/j.compbiomed.2023.106857","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151791639&doi=10.1016%2fj.compbiomed.2023.106857&partnerID=40&md5=1e74af9ea369693f43052e5356a01d26","The use of EEG for evaluating and diagnosing neurological abnormalities related to psychiatric diseases and identifying human emotions has been improved by deep learning advancements. This research aims to categorize individuals with schizophrenia (SZ), their biological relatives (REL), and healthy controls (HC) using resting EEG brain source signal data defined by regions of interest (ROIs). The proposed solution is a deep neural network for the cortical source signals of the ROIs, incorporating a Squeeze-and-Excitation Block and multiple CNNs designed for eyes-open and closed resting states. The model, called EEG Temporal Spatial Network (ETSNet), has two variants: ETSNets and ETSNetf. Two evaluations were conducted to show the effectiveness of the proposed model. The average accuracy for the classification of SZ, REL, and HC using EEG resting data was 99.57% (ETSNetf), and the average accuracy for the classification of eyes-open (EO) and eyes-closed (EC) resting states was 93.15% (ETSNets). An ablation study was also conducted using two public datasets for intellectual and developmental disorders and emotional states, showing improved classification accuracy compared to advanced EEG classification algorithms when using ETSNets. © 2023 Elsevier Ltd","Brain source signals; Convolutional neural networks; Deep learning; Emotional distress; Multi-class classification; Psychiatric disorders; Region of interest; Schizophrenia, biological relatives, and healthy controls; Spatiotemporal features","Electroencephalography; Emotions; Humans; Mental Disorders; Neural Networks, Computer; Psychological Distress; Biomedical signal processing; Classification (of information); Convolutional neural networks; Deep neural networks; Diagnosis; Emotion Recognition; Image segmentation; Pattern recognition; Brain source signal; Convolutional neural network; Deep learning; Emotional distress; Healthy controls; Multi-class classification; Psychiatric disorders; Region-of-interest; Regions of interest; Schizophrenia, biological relative, and healthy control; Source signals; Spatiotemporal feature; adult; Article; auditory stimulation; brain region; classification algorithm; clinical article; comparative study; controlled study; convolutional neural network; cross validation; deep neural network; developmental disorder; diagnostic accuracy; diagnostic test accuracy study; eeg temporal spatial network; electroencephalogram; emotional stress; false positive result; female; human; intellectual impairment; male; mental disease; pattern recognition; resting state network; schizophrenia; sensitivity and specificity; spatiotemporal analysis; distress syndrome; electroencephalography; emotion; mental disease; Diseases","","","Elsevier Ltd","37044046"
"Pankaj; Kumar A.; Komaragiri R.; Kumar M.","Pankaj (57223622541); Kumar, Ashish (58527206900); Komaragiri, Rama (9845916000); Kumar, Manjeet (56352531500)","57223622541; 58527206900; 9845916000; 56352531500","A novel CS-NET architecture based on the unification of CNN, SVM and super-resolution spectrogram to monitor and classify blood pressure using photoplethysmography","2023","240","","107716","","","","10.1016/j.cmpb.2023.107716","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166740947&doi=10.1016%2fj.cmpb.2023.107716&partnerID=40&md5=958316cb621368d96d439488499f4402","Context: Continuous blood pressure (BP) monitoring plays an important role while treating various cardiovascular diseases and hypertension. A high correlation between arterial blood pressure (ABP) and Photoplethysmogram (PPG) signal enables using a PPG signal to monitor and classify BP continuously. Control of BP in realtime is the basis for the prevention of hypertension. Proposed approach: This work proposes a CS-NET architecture by unifying CNN and SVM approaches to classify BP using PPG signals. The main objective of the CS-NET method is to establish an accurate and reliable algorithm for the ABP classification. Methodology: ABP signals are labeled normal and abnormal using the hypertension criteria the American College of Cardiology (ACC)/American Heart Association (AHA) laid down. The proposed CS-NET model incorporates three critical steps in three successive stages. The first stage includes converting a preprocessed PPG signal into a time-frequency (TF) representation called a super-resolution spectrogram by superlet transform. The second stage uses a convolutional neural network (CNN) model with several hidden layers to extract morphological features from every PPG super-resolution spectrogram. The third stage uses a support vector machine (SVM) classifier to classify the PPG signal. Results: PPG signals are used to train and test the proposed model. The performance of the proposed CS-NET method is tested using MIMIC-II, MIMIC-III, and PPG-BP-figshare database in terms of accuracy and F1 score. Moreover, the CS-NET method achieves better results with high accuracy when compared with other benchmark approaches that require an electrocardiogram signal for reference. Conclusions: The proposed model achieved an aggregate classification accuracy of 98.21% across a five-fold cross-validation technique, making it a reliable approach for BP classification in clinical settings and realtime monitoring. © 2023 Elsevier B.V.","Arterial blood pressure (ABP); Deep learning; Hypertension; Photoplethysmography (PPG); Superlet transform, Convolutional neural network (CNN); Support vector machine (SVM)","Blood Pressure; Blood Pressure Determination; Humans; Hypertension; Neural Networks, Computer; Photoplethysmography; Support Vector Machine; Biomedical signal processing; Blood; Blood pressure; Cardiology; Convolution; Convolutional neural networks; Deep learning; Glucose; Image enhancement; Multilayer neural networks; Network architecture; Optical resolving power; Photoplethysmography; Arterial blood pressure; Convolutional neural network; Deep learning; Hypertension; Photoplethysmography; Superlet transform, convolutional neural network; Superresolution; Support vector machine; Support vectors machine; Article; blood pressure monitoring; classifier; controlled study; convolutional neural network; diagnostic accuracy; diagnostic test accuracy study; disease classification; feature extraction; human; hypertension; intermethod comparison; k fold cross validation; learning algorithm; major clinical study; model; multilayer perceptron; photoelectric plethysmography; prehypertension; support vector machine; wavelet transform; artificial neural network; blood pressure; blood pressure measurement; hypertension; photoelectric plethysmography; procedures; Support vector machines","","","Elsevier Ireland Ltd","37542944"
"Bhosale Y.H.; Patnaik K.S.","Bhosale, Yogesh H. (57772765000); Patnaik, K. Sridhar (24438167800)","57772765000; 24438167800","PulDi-COVID: Chronic obstructive pulmonary (lung) diseases with COVID-19 classification using ensemble deep convolutional neural network from chest X-ray images to minimize severity and mortality rates","2023","81","","104445","","","","10.1016/j.bspc.2022.104445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144056056&doi=10.1016%2fj.bspc.2022.104445&partnerID=40&md5=498cb1874b19fecd0eb936eae2701b23","Background and Objective: In the current COVID-19 outbreak, efficient testing of COVID-19 individuals has proven vital to limiting and arresting the disease's accelerated spread globally. It has been observed that the severity and mortality ratio of COVID-19 affected patients is at greater risk because of chronic pulmonary diseases. This study looks at radiographic examinations exploiting chest X-ray images (CXI), which have become one of the utmost feasible assessment approaches for pulmonary disorders, including COVID-19. Deep Learning(DL) remains an excellent image classification method and framework; research has been conducted to predict pulmonary diseases with COVID-19 instances by developing DL classifiers with nine class CXI. However, a few claim to have strong prediction results; because of noisy and small data, their recommended DL strategies may suffer from significant deviation and generality failures. Methods: Therefore, a unique CNN model(PulDi-COVID) for detecting nine diseases (atelectasis, bacterial-pneumonia, cardiomegaly, covid19, effusion, infiltration, no-finding, pneumothorax, viral-Pneumonia) using CXI has been proposed using the SSE algorithm. Several transfer-learning models: VGG16, ResNet50, VGG19, DenseNet201, MobileNetV2, NASNetMobile, ResNet152V2, DenseNet169 are trained on CXI of chronic lung diseases and COVID-19 instances. Given that the proposed thirteen SSE ensemble models solved DL's constraints by making predictions with different classifiers rather than a single, we present PulDi-COVID, an ensemble DL model that combines DL with ensemble learning. The PulDi-COVID framework is created by incorporating various snapshots of DL models, which have spearheaded chronic lung diseases with COVID-19 cases identification process with a deep neural network produced CXI by applying a suggested SSE method. That is familiar with the idea of various DL perceptions on different classes. Results: PulDi-COVID findings were compared to thirteen existing studies for nine-class classification using COVID-19. Test results reveal that PulDi-COVID offers impressive outcomes for chronic diseases with COVID-19 identification with a 99.70% accuracy, 98.68% precision, 98.67% recall, 98.67% F1 score, lowest 12 CXIs zero-one loss, 99.24% AUC-ROC score, and lowest 1.33% error rate. Overall test results are superior to the existing Convolutional Neural Network(CNN). To the best of our knowledge, the observed results for nine-class classification are significantly superior to the state-of-the-art approaches employed for COVID-19 detection. Furthermore, the CXI that we used to assess our algorithm is one of the larger datasets for COVID detection with pulmonary diseases. Conclusion: The empirical findings of our suggested approach PulDi-COVID show that it outperforms previously developed methods. The suggested SSE method with PulDi-COVID can effectively fulfill the COVID-19 speedy detection needs with different lung diseases for physicians to minimize patient severity and mortality. © 2022 Elsevier Ltd","Biomedical engineering; Chronic Obstructive Pulmonary Diseases (COPD); Convolution neural networks (CNN); COVID-19; Diagnosis & Classification; Ensemble deep learning; Medical Imaging; Transfer learning","Biological organs; Biomedical engineering; Classification (of information); Computer aided diagnosis; Convolution; Convolutional neural networks; Deep neural networks; Forecasting; Image classification; Learning systems; Medical imaging; Pulmonary diseases; Transfer learning; Chest X-ray image; Chronic obstructive pulmonary disease; Convolution neural network; Convolutional neural network; Diagnose & classification; Ensemble deep learning; Learning models; Transfer learning; accuracy; algorithm; Article; atelectasis; bacterial pneumonia; cardiomegaly; chronic disease; chronic lung disease; chronic obstructive lung disease; convolutional neural network; coronavirus disease 2019; deep neural network; disease classification; disease severity; effusion; human; mortality rate; performance indicator; pneumothorax; prediction; sensitivity and specificity; thorax radiography; transfer of learning; virus pneumonia; COVID-19","","","Elsevier Ltd",""
"Pankaj; Kumar A.; Kumar M.; Komaragiri R.","Pankaj (57223622541); Kumar, Ashish (58527206900); Kumar, Manjeet (56352531500); Komaragiri, Rama (9845916000)","57223622541; 58527206900; 56352531500; 9845916000","Optimized deep neural network models for blood pressure classification using Fourier analysis-based time–frequency spectrogram of photoplethysmography signal","2023","13","4","","739","750","11","10.1007/s13534-023-00296-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163143972&doi=10.1007%2fs13534-023-00296-6&partnerID=40&md5=1ebcf3830efc8c18ba744eb280368e85","Appropriate blood pressure (BP) management through continuous monitoring and rapid diagnosis helps to take preventive care against cardiovascular diseases (CVD). As hypertension is one of the leading causes of CVDs, keeping hypertension under control by a timely screening of subjects becomes lifesaving. This work proposes estimating BP from motion artifact-affected photoplethysmography signals (PPG) by applying signal processing techniques in realtime. This paper proposes a deep neural network-based methodology to accurately classify PPG signals using a Fourier theory-based time–frequency (TF) spectrogram. This work uses the Fourier decomposition method (FDM) to transform a PPG signal into a TF spectrogram. In the proposed work, the last three layers of the pre-trained deep neural network, namely, GoogleNet, DenseNet, and AlexNet, are modified and then used to classify the PPG signal into normotension, pre-hypertension, and hypertension. The proposed framework is trained and tested using the MIMIC-III and PPG–BP databases using five-fold training and testing. Out of the three deep neural networks, the proposed framework with the DenseNet-201 network performs best, with a test accuracy of 96.5%. The proposed work uses FDM to compute the TF spectrogram to accurately separate the motion artifacts and noise components from a noise-corrupted PPG signal. Capturing more frequency components that contain more information from PPG signals makes the deep neural networks extract better and more meaningful features. Thus, training a deep neural network model with clean PPG signal features improves the generalized capability of a BP classification model when tested in realtime. © 2023, Korean Society of Medical and Biological Engineering.","Arterial blood pressure; Deep learning; Fourier decomposition method; Hypertension; Photoplethysmography; Time–frequency spectrogram; Transfer learning","Biomedical signal processing; Blood pressure; Deep neural networks; Fourier analysis; Learning systems; Multilayer neural networks; Photoplethysmography; Arterial blood pressure; Decomposition methods; Deep learning; Fourier decomposition; Fourier decomposition method; Hypertension; Motion artifact; Neural network model; Time-frequency spectrogram; Transfer learning; accuracy; adult; aged; AlexNet; algorithm; Article; artifact; blood pressure measurement; classifier; controlled study; convolutional neural network; cross validation; data base; decision tree; decomposition; deep learning; deep neural network; DenseNet; diagnostic test accuracy study; diastolic blood pressure; false negative result; false positive result; Fourier analysis; GoogLeNet; human; hypertension; image processing; information processing; learning; learning algorithm; measurement precision; MIMIC-III; motion; nerve cell network; noise; performance bias; performance metrics; photoelectric plethysmography; prehypertension; sensitivity and specificity; signal processing; simulation; spectroscopy; support vector machine; systolic blood pressure; theoretical study; time frequency spectrogram; training; transfer of learning; validation process; Blood","","","Springer Verlag",""
"Bagwan F.; Pise N.","Bagwan, Faraz (57227123200); Pise, Nitin (26029495600)","57227123200; 26029495600","IsoCore–An efficient model to aid rapid forecasting of SARS-CoV-2 infection from biomedical imagery","2023","9","3","","140","157","17","10.24840/2183-6493_009-003_001636","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160413867&doi=10.24840%2f2183-6493_009-003_001636&partnerID=40&md5=583cc1e1960b5c5b1f6f3d1bead2841a","Combating the covid19 scourge is a prime concern for the human race today. Rapid diagnosis is critical to identify the infection accurately. Due to the prevalence of public health crisis, reaction-based blood tests are the customary approach for identifying covid19. As a result, scientists are analyzing screening methods like deep layered machine learning on chest radiographs. Despite their usefulness, these approaches have large computational costs, rendering them unworkable in practice. This study's main goal is to establish an accurate yet efficient method for predicting SARS-CoV-2 infection (Severe Acute Respiratory Syndrome CoronaVirus 2) using chest radiography pictures. We utilized and enhanced the graph-based family of neural networks to achieve the stated goal. The IsoCore algorithm is trained on a collection of X-ray images separated into four categories: healthy, Covid19, viral pneumonia, and bacterial pneumonia. The IsoCore model has 5 to 10 times fewer parameters than the other tested designs. It attains an overall accuracy of 99.79%. We believe the acquired results are the most ideal in the deep inference domain at this time. This proposed model might be employed by doctors via phones. © The Authors.","Chest Radiography; Covid19; Deep Learning; IsoCore; Pneumonia","","","","Universidade do Porto - Faculdade de Engenharia",""
"Kumar T.; Ponnusamy R.","Kumar, Thirugnanam (58399213600); Ponnusamy, Ramasamy (58537073700)","58399213600; 58537073700","Robust Medical X-Ray Image Classification by Deep Learning with Multi-Versus Optimizer","2023","13","4","","11406","11411","5","10.48084/etasr.6127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167995870&doi=10.48084%2fetasr.6127&partnerID=40&md5=a3d3c0feee49c104b1696b455353da6c","Classification of medical images plays an indispensable role in medical treatment and training tasks. Much effort and time are required in the extraction and selection of classification features of medical images. Deep Neural Networks (DNNs) are an evolving Machine Learning (ML) method that has proved its ability in various classification tasks. Convolutional Neural Networks (CNNs) present the optimal results for changing image classification tasks. In this regard, this study focused on developing a Multi-versus Optimizer with Deep Learning Enabled Robust Medical X-ray Image Classification (MVODL-RMXIC) method, aiming to identify abnormalities in medical X-ray images. The MVODL-RMXIC model used the Cross Bilateral Filtering (CBF) technique for noise removal, a MixNet feature extractor with an MVO algorithm based on hyperparameter optimization, and Bidirectional Long-Short-Term Memory (BiLSTM) for image classification. The proposed MVODL-RMXIC model was simulated and evaluated, showing its efficiency over other current methods. © by the authors.","biomedical imaging; deep learning; image classification; medical X-ray images; multi-versus optimizer","","","","Dr D. Pylarinos",""
"Pei R.; Yao K.; Xu X.; Zhang X.; Yang X.; Fu W.; Zhang Y.","Pei, Ronghao (57202691051); Yao, Kang (57211110694); Xu, Xiaobin (56427119400); Zhang, Xin (36622009600); Yang, Xiaodong (55265540400); Fu, Weiwei (57199403057); Zhang, Yang (57840371300)","57202691051; 57211110694; 56427119400; 36622009600; 55265540400; 57199403057; 57840371300","TransFusion-net for multifocus microscopic biomedical image fusion","2023","240","","107688","","","","10.1016/j.cmpb.2023.107688","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165534150&doi=10.1016%2fj.cmpb.2023.107688&partnerID=40&md5=2ee972e7e1f7de02660f164337ba8a87","Background and objective: Due to the depth of focus (DOF) limitations of the optical systems of microscopes, it is often difficult to achieve full clarity from microscopic biomedical images under high-magnification microscopy. Multifocus microscopic biomedical image fusion (MFBIF) can effectively solve this problem. Considering both information richness and visual authenticity, this paper proposes a transformer network for MFBIF called TransFusion-Net. Methods: TransFusion-Net consists of two modules. One module is an interlayer cross-attention module, which is used to obtain feature mappings under the long-range dependencies observed among multiple nonfocus source images. The other module is a spatial attention upsampling network (SAU-Net) module, which is used to obtain global semantic information after further spatial attention is applied. Thus, TransFusion-Net can simultaneously receive multiple input images from a nonfull-focus microscope and make full use of the strong correlations between the source images to output accurate fusion results in an end-to-end manner. Results: The fusion results were quantitatively and qualitatively compared with those of eight state-of-the-art algorithms. In the quantitative experiments, five evaluation metrics, QAB/F, QMI, QAVG, QCB, and PSNR, were used to evaluate the performance of each method, and the proposed method achieved values of 0.6574, 8.4572, 5.6305, 0.7341, and 89.5685, respectively, which are higher than those of the current state-of-the-art algorithms. In the qualitative experiments, a differential image was used for further validation, and the near-zero residuals visually verified the adequacy of the proposed method for fusion. Furthermore, we showed some fusion results of multifocused biomedical microscopy images to verify the reliability of the proposed method, which shows high-quality fusion results. Conclusion: Multifocus biomedical microscopic image fusion can be accurately and effectively achieved by devising a deep convolutional neural network with joint cross-attention and spatial attention mechanisms. © 2023","Deep learning; End-to-end transformer network; Hybrid attention mechanism; Microscopic image fusion","Algorithms; Benchmarking; Electric Power Supplies; Image Processing, Computer-Assisted; Microscopy; Reproducibility of Results; Convolutional neural networks; Deep neural networks; Semantics; Attention mechanisms; Biomedical images; Deep learning; End to end; End-to-end transformer network; Hybrid attention mechanism; Microscopic image; Microscopic image fusion; Multi-focus; Spatial attention; Article; controlled study; convolutional neural network; deep learning; depth of focus; discrete wavelet transform; dual tree complex wavelet transform; genetic algorithm; human; imaging algorithm; intestine cancer; invasive ductal breast carcinoma; lung cancer; microscopy; multifocus microscopic biomedical image fusion; qualitative analysis; quantitative analysis; spatial analysis; stomach adenocarcinoma; transfusion; wavelet analysis; algorithm; benchmarking; image processing; microscopy; power supply; reproducibility; Image fusion","Natural Science Foundation of Shandong Province, (ZR2021QE205); Natural Science Foundation of Shandong Province","","Elsevier Ireland Ltd","37487310"
"Lei T.; Sun R.; Du X.; Fu H.; Zhang C.; Nandi A.K.","Lei, Tao (36602820500); Sun, Rui (58598642400); Du, Xiaogang (55264003900); Fu, Huazhu (35317209500); Zhang, Changqing (56313466500); Nandi, Asoke K. (7101896474)","36602820500; 58598642400; 55264003900; 35317209500; 56313466500; 7101896474","SGU-Net: Shape-Guided Ultralight Network for Abdominal Image Segmentation","2023","27","3","","1431","1442","11","10.1109/JBHI.2023.3238183","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147296672&doi=10.1109%2fJBHI.2023.3238183&partnerID=40&md5=ac678fdce422464a5422bf1bbafbfd11","Convolutional neural networks (CNNs) have achieved significant success in medical image segmentation. However, they also suffer from the requirement of a large number of parameters, leading to a difficulty of deploying CNNs to low-source hardwares, e.g., embedded systems and mobile devices. Although some compacted or small memory-hungry models have been reported, most of them may cause degradation in segmentation accuracy. To address this issue, we propose a shape-guided ultralight network (SGU-Net) with extremely low computational costs. The proposed SGU-Net includes two main contributions: it first presents an ultralight convolution that is able to implement double separable convolutions simultaneously, i.e., asymmetric convolution and depthwise separable convolution. The proposed ultralight convolution not only effectively reduces the number of parameters but also enhances the robustness of SGU-Net. Secondly, our SGU-Net employs an additional adversarial shape-constraint to let the network learn shape representation of targets, which can significantly improve the segmentation accuracy for abdomen medical images using self-supervision. The SGU-Net is extensively tested on four public benchmark datasets, LiTS, CHAOS, NIH-TCIA and 3Dircbdb. Experimental results show that SGU-Net achieves higher segmentation accuracy using lower memory costs, and outperforms state-of-the-art networks. Moreover, we apply our ultralight convolution into a 3D volume segmentation network, which obtains a comparable performance with fewer parameters and memory usage. © 2013 IEEE.","adversarial shape-constraint; deep lear- ning; Medical image segmentation; ultralight convolution","Deep learning; Embedded systems; Image enhancement; Image segmentation; Medical imaging; Neural networks; Three dimensional displays; Adversarial shape-constraint; Biomedical imaging; Computational modelling; Deep learning; Images segmentations; Medical image segmentation; Shape; Shape constraints; Three-dimensional display; Ultra-light; Ultralight convolution; abdomen; accuracy; Article; autoencoder; computer model; convolutional neural network; health care cost; image reconstruction; image segmentation; learning algorithm; liver; machine learning; memory; nonhuman; process optimization; receptive field; shape guided ultralight network; Convolution","Huazhu Fu’s A*STAR, (AISG2-TC-2021-003); Shaanxi Joint Laboratory of Artificial Intelligence, (2020SS-03); National Natural Science Foundation of China, NSFC, (61861024, 61871259, 62271296); Key Research and Development Projects of Shaanxi Province, (2021ZDLGY08-07, 2022GY-436, 2022JQ-018, 2022JQ-634); Natural Science Basic Research Program of Shaanxi Province, (2021JC-47)","","Institute of Electrical and Electronics Engineers Inc.",""
"Sangha V.; Nargesi A.A.; Dhingra L.S.; Khunte A.; Mortazavi B.J.; Ribeiro A.H.; Banina E.; Adeola O.; Garg N.; Brandt C.A.; Miller E.J.; Ribeiro A.L.P.; Velazquez E.J.; Giatti L.; Barreto S.M.; Foppa M.; Yuan N.; Ouyang D.; Krumholz H.M.; Khera R.","Sangha, Veer (57223591923); Nargesi, Arash A. (57440412400); Dhingra, Lovedeep S. (57205440989); Khunte, Akshay (57219020562); Mortazavi, Bobak J. (42761875000); Ribeiro, Antônio H. (57191699148); Banina, Evgeniya (58179224500); Adeola, Oluwaseun (57224698911); Garg, Nadish (57200592009); Brandt, Cynthia A. (35513998400); Miller, Edward J. (7404492750); Ribeiro, Antonio Luiz P. (57204577960); Velazquez, Eric J. (57203216327); Giatti, Luana (7801515595); Barreto, Sandhi M. (8097600700); Foppa, Murilo (6602625647); Yuan, Neal (55479611800); Ouyang, David (55211726800); Krumholz, Harlan M. (55152053200); Khera, Rohan (55974983700)","57223591923; 57440412400; 57205440989; 57219020562; 42761875000; 57191699148; 58179224500; 57224698911; 57200592009; 35513998400; 7404492750; 57204577960; 57203216327; 7801515595; 8097600700; 6602625647; 55479611800; 55211726800; 55152053200; 55974983700","Detection of Left Ventricular Systolic Dysfunction From Electrocardiographic Images","2023","148","9","","765","777","12","10.1161/CIRCULATIONAHA.122.062646","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169184779&doi=10.1161%2fCIRCULATIONAHA.122.062646&partnerID=40&md5=81f2893e0b58a11949a96fa45533281d","BACKGROUND: Left ventricular (LV) systolic dysfunction is associated with a >8-fold increased risk of heart failure and a 2-fold risk of premature death. The use of ECG signals in screening for LV systolic dysfunction is limited by their availability to clinicians. We developed a novel deep learning-based approach that can use ECG images for the screening of LV systolic dysfunction. METHODS: Using 12-lead ECGs plotted in multiple different formats, and corresponding echocardiographic data recorded within 15 days from the Yale New Haven Hospital between 2015 and 2021, we developed a convolutional neural network algorithm to detect an LV ejection fraction <40%. The model was validated within clinical settings at Yale New Haven Hospital and externally on ECG images from Cedars Sinai Medical Center in Los Angeles, CA; Lake Regional Hospital in Osage Beach, MO; Memorial Hermann Southeast Hospital in Houston, TX; and Methodist Cardiology Clinic of San Antonio, TX. In addition, it was validated in the prospective Brazilian Longitudinal Study of Adult Health. Gradient-weighted class activation mapping was used to localize class-discriminating signals on ECG images. RESULTS: Overall, 385 601 ECGs with paired echocardiograms were used for model development. The model demonstrated high discrimination across various ECG image formats and calibrations in internal validation (area under receiving operation characteristics [AUROCs], 0.91; area under precision-recall curve [AUPRC], 0.55); and external sets of ECG images from Cedars Sinai (AUROC, 0.90 and AUPRC, 0.53), outpatient Yale New Haven Hospital clinics (AUROC, 0.94 and AUPRC, 0.77), Lake Regional Hospital (AUROC, 0.90 and AUPRC, 0.88), Memorial Hermann Southeast Hospital (AUROC, 0.91 and AUPRC 0.88), Methodist Cardiology Clinic (AUROC, 0.90 and AUPRC, 0.74), and Brazilian Longitudinal Study of Adult Health cohort (AUROC, 0.95 and AUPRC, 0.45). An ECG suggestive of LV systolic dysfunction portended >27-fold higher odds of LV systolic dysfunction on transthoracic echocardiogram (odds ratio, 27.5 [95% CI, 22.3-33.9] in the held-out set). Class-discriminative patterns localized to the anterior and anteroseptal leads (V2 and V3), corresponding to the left ventricle regardless of the ECG layout. A positive ECG screen in individuals with an LV ejection fraction ≥40% at the time of initial assessment was associated with a 3.9-fold increased risk of developing incident LV systolic dysfunction in the future (hazard ratio, 3.9 [95% CI, 3.3-4.7]; median follow-up, 3.2 years). CONCLUSIONS: We developed and externally validated a deep learning model that identifies LV systolic dysfunction from ECG images. This approach represents an automated and accessible screening strategy for LV systolic dysfunction, particularly in low-resource settings. © 2023 Lippincott Williams and Wilkins. All rights reserved.","artificial intelligence; biomedical technology; electrocardiography; heart failure; machine learning; ventricular dysfunction, left","Adult; Electrocardiography; Humans; Longitudinal Studies; Prospective Studies; Ventricular Dysfunction, Left; Ventricular Function, Left; adult; aged; area under the curve; Article; artificial intelligence; calibration; California; cardiology; convolutional neural network; deep learning; discrimination learning; electrocardiography; female; follow up; hazard ratio; heart failure; heart left ventricle ejection fraction; human; left ventricular systolic dysfunction; machine learning; major clinical study; male; medical technology; Methodist; middle aged; outpatient; recall; receiver operating characteristic; risk assessment; risk factor; seashore; transthoracic echocardiography; validation process; diagnostic imaging; heart left ventricle failure; heart left ventricle function; longitudinal study; physiology; prospective study","Blavatnik Foundation; National Institutes of Health, NIH, (K23HL153775); National Institutes of Health, NIH; U.S. Department of Defense, DOD, (US20180315507A1); U.S. Department of Defense, DOD; U.S. Food and Drug Administration, FDA; National Heart, Lung, and Blood Institute, NHLBI; National Institute of Biomedical Imaging and Bioengineering, NIBIB; Doris Duke Charitable Foundation, DDCF, (2022060); Doris Duke Charitable Foundation, DDCF; Johnson and Johnson, J&J; Centers for Medicare and Medicaid Services, CMS; Yale University; Yale School of Medicine, YSM; Shenzhen Center for Health Information; Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq, (310790/2021-2, 409604/2022-4, 465518/2014-1); Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq; Fundação de Amparo à Pesquisa do Estado de Minas Gerais, FAPEMIG, (PPE-00030-21, PPM-00428-17, RED-00081-16); Fundação de Amparo à Pesquisa do Estado de Minas Gerais, FAPEMIG; Kjell och Märta Beijers Stiftelse","","Lippincott Williams and Wilkins","37489538"
"Fu Z.; Li J.; Hua Z.; Fan L.","Fu, Zhaojin (57931603300); Li, Jinjiang (25638923500); Hua, Zhen (7101891559); Fan, Linwei (57200248389)","57931603300; 25638923500; 7101891559; 57200248389","Deep supervision feature refinement attention network for medical image segmentation","2023","125","","106666","","","","10.1016/j.engappai.2023.106666","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164213513&doi=10.1016%2fj.engappai.2023.106666&partnerID=40&md5=e728be6eb8bcec2b63935524b708b141","The improvement of medical technology is closely related to the development of computers. Deep learning methods have become an important means for medical image processing, and their accuracy in processing lesions will have a significant impact on the final diagnosis result. Currently, some traditional algorithms and classical deep learning methods are no longer able to meet the increasing demand for higher accuracy in medical image processing. In order to achieve better performance in handling the edge and detail features of lesions, we create the Deep Supervision Feature Refinement Attention Network (DSFRA-Net) through extensive experiments. In DSFRA-Net, the Depth Feature Attention Block is created to enhance the long-range dependency between pixels in deep neural networks. The Feature Refinement Block is developed to enhance the details in shallow features. The Adaptive Feature Extraction Block is created to strengthen the fusion of semantic information and detail information. A deep supervision mechanism is used to supervise each layer of the feature reconstruction process, feeding back the training in the form of a loss function to optimize the training. DSFRA-Net experiments on four datasets, all of which show better performance than the current mainstream networks. It shows superior capabilities in areas such as feature continuity and detailed feature processing. © 2023 Elsevier Ltd","Attention mechanism; Deep supervision; Feature refinement; Medical image segmentation","Biomedical engineering; Deep neural networks; Learning systems; Medical imaging; Semantic Segmentation; Semantics; Attention mechanisms; Deep supervision; Depth features; Feature refinement; High-accuracy; Learning methods; Medical image segmentation; Medical images processing; Medical technologies; Performance; Diagnosis","Yantai science and technology innovation development plan, China, (2022JCYJ031); National Natural Science Foundation of China, NSFC, (61772319, 61972235, 62002200, 62202268); Natural Science Foundation of Shandong Province, (ZR2022MA076, ZR2022QF151)","","Elsevier Ltd",""
"Zhang Z.; Ye S.; Liu Z.; Wang H.; Ding W.","Zhang, Zuowei (57204673080); Ye, Songtao (57491404000); Liu, Zechao (58019216300); Wang, Hao (57202273307); Ding, Weiping (57193448087)","57204673080; 57491404000; 58019216300; 57202273307; 57193448087","Deep Hyperspherical Clustering for Skin Lesion Medical Image Segmentation","2023","27","8","","3770","3781","11","10.1109/JBHI.2023.3240297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148463433&doi=10.1109%2fJBHI.2023.3240297&partnerID=40&md5=9e471fe5b4b6c8468ed1f4b926399a28","Diagnosis of skin lesions based on imaging techniques remains a challenging task because data (knowledge) uncertainty may reduce accuracy and lead to imprecise results. This paper investigates a new deep hyperspherical clustering (DHC) method for skin lesion medical image segmentation by combining deep convolutional neural networks and the theory of belief functions (TBF). The proposed DHC aims to eliminate the dependence on labeled data, improve segmentation performance, and characterize the imprecision caused by data (knowledge) uncertainty. First, the SLIC superpixel algorithm is employed to group the image into multiple meaningful superpixels, aiming to maximize the use of context without destroying the boundary information. Second, an autoencoder network is designed to transform the superpixels' information into potential features. Third, a hypersphere loss is developed to train the autoencoder network. The loss is defined to map the input to a pair of hyperspheres so that the network can perceive tiny differences. Finally, the result is redistributed to characterize the imprecision caused by data (knowledge) uncertainty based on the TBF. The proposed DHC method can well characterize the imprecision between skin lesions and non-lesions, which is particularly important for the medical procedures. A series of experiments on four dermoscopic benchmark datasets demonstrate that the proposed DHC yields better segmentation performance, increasing the accuracy of the predictions while can perceive imprecise regions compared to other typical methods. © 2013 IEEE.","belief functions; clustering; deep learning; image segmentation; imprecision; Melanoma; skin lesion","Algorithms; Cluster Analysis; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Skin Diseases; Benchmarking; Deep neural networks; Dermatology; Diagnosis; Feature extraction; Medical imaging; Superpixels; Uncertainty analysis; Belief function; Biomedical imaging; Clusterings; Deep learning; Features extraction; Images segmentations; Imprecision; Lesion; Medical diagnostic imaging; Melanoma; Optimisations; Skin lesion; accuracy; algorithm; Article; artificial neural network; autoencoder; belief decision; benchmarking; classification algorithm; convolutional neural network; deep belief network; deep hyperspherical clustering; deep learning; diagnostic imaging; entropy; feature extraction; human; hypersphere loss; hypersphere optimization; image segmentation; information; k means clustering; knowledge; learning algorithm; machine learning; mathematical model; melanoma; prediction; receptive field; sensitivity analysis; skin defect; superpixel segmentation; uncertainty; cluster analysis; image processing; procedures; skin disease; Image segmentation","Natural Science Key Foundation of Jiangsu Education Department, (21KJA510004); National Natural Science Foundation of China, NSFC, (61300167, 61976120); National Natural Science Foundation of China, NSFC","","Institute of Electrical and Electronics Engineers Inc.","37022227"
"Borghouts M.; Ambrosanio M.; Franceschini S.; Autorino M.M.; Pascazio V.; Baselice F.","Borghouts, Marijn (58675969800); Ambrosanio, Michele (56198620800); Franceschini, Stefano (57210950263); Autorino, Maria Maddalena (57483413000); Pascazio, Vito (7003486376); Baselice, Fabio (57204648639)","58675969800; 56198620800; 57210950263; 57483413000; 7003486376; 57204648639","Microwave Breast Sensing via Deep Learning for Tumor Spatial Localization by Probability Maps","2023","10","10","1153","","","","10.3390/bioengineering10101153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175454467&doi=10.3390%2fbioengineering10101153&partnerID=40&md5=822affeb50f14a32ee28d364dabdbd29","Background: microwave imaging (MWI) has emerged as a promising modality for breast cancer screening, offering cost-effective, rapid, safe and comfortable exams. However, the practical application of MWI for tumor detection and localization is hampered by its inherent low resolution and low detection capability. Methods: this study aims to generate an accurate tumor probability map directly from the scattering matrix. This direct conversion makes the probability map independent of specific image formation techniques and thus potentially complementary to any image formation technique. An approach based on a convolutional neural network (CNN) is used to convert the scattering matrix into a tumor probability map. The proposed deep learning model is trained using a large realistic numerical dataset of two-dimensional (2D) breast slices. The performance of the model is assessed through visual inspection and quantitative measures to assess the predictive quality at various levels of detail. Results: the results demonstrate a remarkably high accuracy (0.9995) in classifying profiles as healthy or diseased, and exhibit the model’s ability to accurately locate the core of a single tumor (within 0.9 cm for most cases). Conclusion: overall, this research demonstrates that an approach based on neural networks (NN) for direct conversion from scattering matrices to tumor probability maps holds promise in advancing state-of-the-art tumor detection algorithms in the MWI domain. © 2023 by the authors.","biomedical engineering; breast cancer; early detection; microwave imaging; neural networks; tumor localization","","","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Tyagi P.K.; Agarwal D.","Tyagi, Praveen Kumar (57865229700); Agarwal, Dheeraj (57193869522)","57865229700; 57193869522","Systematic review of automated sleep apnea detection based on physiological signal data using deep learning algorithm: a meta-analysis approach","2023","13","3","","293","312","19","10.1007/s13534-023-00297-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163826832&doi=10.1007%2fs13534-023-00297-5&partnerID=40&md5=e5aad7caa7089002774b943b4ce022ba","Sleep apnea (SLA) is a respiratory-related sleep disorder that affects a major proportion of the population. The gold standard in sleep testing, polysomnography, is costly, inconvenient, and unpleasant, and it requires a skilled professional to score. Multiple researchers have suggested and developed automated scoring processes with less detectors and automated classification algorithms to resolve these problems. An automatic detection system will allow for a high diagnosis rate and the analysis of additional patients. Deep learning (DL) is achieving high priority due to the availability of databases and recently developed methods. As the most up-and-coming technique for classification and generative tasks, DL has shown its significant potential in 2-dimensional clinical image processing studies. However, physiological information collected as 1-dimensional data has yet to be effectively extracted from this new approach to achieve the needed medical goals. So, in this study, we review the most recent studies in the field of DL applied to physiological data based on pulse oxygen saturation, electrocardiogram, airflow, and sound signal. A total of 47 articles from different journals and publishing houses that were published between 2012 and 2022 were identified. The primary objective of this work is to perform a comprehensive analysis to analyze, classify, and compare the main characteristics of deep-learning algorithms applied in physiological data processing for SLA detection. Overall, our analysis provides comprehensive and detailed information for researchers looking to add to this field. The data input source, objective, DL network, training framework, and database references are the critical factors of the DL approach examined. These are the most critical variables that influence system performance. We categorized the relevant research studies in physiological sensor data analysis using the DL approach based on (1) Physiological sensor data aspects, like signal types, sampling frequency, and window size; and (2) DL model perspectives, such as learning structure and input data types. © 2023, Korean Society of Medical and Biological Engineering.","CNN; DBN; Deep learning; GRU; LSTM; Sleep apnea","Automation; Biomedical signal processing; Data handling; Deep learning; Diagnosis; Learning algorithms; Physiological models; Physiology; Sleep research; DBN; Deep learning; GRU; Learning approach; LSTM; Physiological data; Physiological sensors; Sleep apnea; Sleep apnea detection; Systematic Review; apnea hypopnea index; artificial intelligence; artificial neural network; brain depth stimulation; breathing pattern; cerebrovascular disease; classification algorithm; classifier; deep learning; electrocardiogram; electrocardiography; electroencephalogram; electroencephalography; electrophysiology; entropy; Fourier transform; heart arrhythmia; heart rate; human; image processing; learning algorithm; meta analysis; nuclear magnetic resonance imaging; oxygen desaturation; oxygen saturation; parasympathetic tone; physiology; polysomnography; predictive value; pulse oximetry; QRS complex; Review; sensitivity and specificity; signal processing; sinus rhythm; sleep apnea syndromes; spectroscopy; speech perception; support vector machine; T wave; Unified Parkinson Disease Rating Scale; Image processing","","","Springer Verlag",""
"Ozaltin O.; Yeniay O.","Ozaltin, Oznur (57251139900); Yeniay, Ozgur (8949828400)","57251139900; 8949828400","A novel proposed CNN–SVM architecture for ECG scalograms classification","2023","27","8","","4639","4658","19","10.1007/s00500-022-07729-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144154508&doi=10.1007%2fs00500-022-07729-x&partnerID=40&md5=5e6407232351d442cf25893fb423c1c6","Nowadays, the number of sudden deaths due to heart disease is increasing with the coronavirus pandemic. Therefore, automatic classification of electrocardiogram (ECG) signals is crucial for diagnosis and treatment. Thanks to deep learning algorithms, classification can be performed without manual feature extraction. In this study, we propose a novel convolutional neural networks (CNN) architecture to detect ECG types. In addition, the proposed CNN can automatically extract features from images. Here, we classify a real ECG dataset using our proposed CNN which includes 34 layers. While this dataset is one-dimensional signals, these are transformed into images (scalograms) using continuous wavelet transform (CWT). In addition, the proposed CNN is compared to known architectures: AlexNet and SqueezeNet for classifying ECG images, and we find it more effective than others. This study, which not only performed CWT but also implemented short-time Fourier transform, examines the success in recognizing ECG types for the proposed CNN. Besides, different split methods: training and testing, and cross-validation are applied in this study. Eventually, CWT and cross-validation are the best pre-processing and split methods for the proposed CNN, respectively. Although the results are quite good, we benefit from support vector machines (SVM) to obtain the best algorithm and for detecting ECG types. Essentially, the main aim of the study increases classification results. In this way, the proposed CNN is utilized as deep feature extractor and combined with SVM. As a conclusion of this study, we achieve the highest accuracy of 99.21% from the proposed CNN–SVM when using CWT. Therefore, we can express that this framework can be used as an aid to clinicians for ECG-type identification. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Continuous wavelet transform (CWT); Convolutional neural networks (CNN); Feature extraction; Scalogram; Support vector machine (SVM)","Biomedical signal processing; Classification (of information); Computer aided diagnosis; Convolution; Convolutional neural networks; Deep learning; Extraction; Feature extraction; Network architecture; Support vector machines; Wavelet transforms; Continuous wavelet transform; Convolutional neural network; Cross validation; Features extraction; Network support; Scalogram; Support vector machine; Support vectors machine; Electrocardiograms","","","Springer Science and Business Media Deutschland GmbH",""
"Hamzehei S.; Bai J.; Raimondi G.; Tripp R.; Ostroff L.; Nabavi S.","Hamzehei, Sahand (58074812700); Bai, Jun (57221616470); Raimondi, Gianna (57653961200); Tripp, Rebecca (58176501400); Ostroff, Linnaea (6506542847); Nabavi, Sheida (56229091400)","58074812700; 57221616470; 57653961200; 58176501400; 6506542847; 56229091400","3D Biological/Biomedical Image Registration with enhanced Feature Extraction and Outlier Detection","2023","","","1","","","","10.1145/3584371.3612965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175838560&doi=10.1145%2f3584371.3612965&partnerID=40&md5=4d91e845806c9386dec23c04b76eb04f","In various applications, such as computer vision, medical imaging, and robotics, three-dimensional (3D) image registration is a significant step. It enables the alignment of various datasets into a single coordinate system, consequently providing a consistent perspective that allows further analysis. By precisely aligning images, we can compare, analyze, and combine data collected in different situations. This paper presents a novel approach for 3D or z-stack microscopy and medical image registration, utilizing a combination of conventional and deep learning techniques for feature extraction and adaptive likelihood-based methods for outlier detection. The proposed method uses the Scale-invariant Feature Transform (SIFT) and the Residual Network (ResNet50) deep neural learning network to extract effective features and obtain precise and exhaustive representations of image contents. The registration approach also employs the adaptive Maximum Likelihood Estimation SAmple Consensus (MLESAC) method that optimizes outlier detection and increases noise and distortion resistance to improve the efficacy of these combined extracted features. This integrated approach demonstrates robustness, flexibility, and adaptability across a variety of imaging modalities, enabling the registration of complex images with higher precision. Experimental results show that the proposed algorithm outperforms state-of-the-art image registration methods, including conventional SIFT, SIFT with Random Sample Consensus (RANSAC), and Oriented FAST and Rotated BRIEF (ORB) methods, as well as registration software packages such as bUnwrapJ and TurboReg, in terms of Mutual Information (MI), Phase Congruency-Based (PCB) metrics, and Gradiant-based metrics (GBM), using 3D MRI and 3D serial sections of multiplex microscopy images. © 2023 ACM.","3D biomedical images; deep learning; feature extraction; image registration; maximum likelihood estimation sample consensus (MLESAC); scale-invariant feature transform (SIFT); z-stack microscopy images","Anomaly detection; Data handling; Deep neural networks; Extraction; Image enhancement; Image registration; Learning systems; Magnetic resonance imaging; Maximum likelihood estimation; Medical imaging; Polychlorinated biphenyls; Statistics; 3d biomedical image; Biomedical images; Deep learning; Features extraction; Images registration; Invariant feature transforms; Maximum likelihood estimation sample consensus; Maximum-likelihood estimation; Microscopy images; Sample consensus; Scale invariant features; Scale-invariant feature transform; Z-stack microscopy image; Feature extraction","Computer Science and Engineering departmental at UConn; National Institutes of Health, NIH, (RF1MH130472); National Institutes of Health, NIH","","Association for Computing Machinery, Inc",""
"Sankara Narayanan S.; Meena L.C.; Thanu K.C.; Chandrasekar P.","Sankara Narayanan, S. (57204862284); Meena, L.C. (57216944184); Thanu, K. Chidambara (57199506981); Chandrasekar, P. (56083276700)","57204862284; 57216944184; 57199506981; 56083276700","Enhancing Glioma Brain Tumor Detection from MRI using Deep Learning Techniques","2023","","","","","","","10.1109/ICDSAAI59313.2023.10452496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187782064&doi=10.1109%2fICDSAAI59313.2023.10452496&partnerID=40&md5=15f7065e186f74019a039b2da8185e8a","Brain tumor classification from MRI image is one of the important areas in biomedical research. However, the interpretation of these images is subjective, and automated detection methods can improve diagnostic accuracy. This study proposes a hybrid model that combines deep learning, machine learning, and traditional image processing techniques to detect brain tumors from MRI images. The proposed model is based on a convolutional neural network (CNN) algorithm and a machine learning model. The first stage is employing the histogram equalisation approach to enhance the image. In the second stage, features of the grey level co-occurrence matrix are extracted from the improved image. Convolutional neural networks are utilised in the third stage to categorise as normal or abnormal. The abnormal brain tumor is segmented using a morphological segmentation algorithm. This study suggests a number of performance criteria, such as accuracy, sensitivity, and specificity, to evaluate the efficacy of the proposeed method. Our proposes algorithm demonstrates superior performance compared to existing methods regarding accuracy, sensitivity, and specificity. © 2023 IEEE.","Convolutional neural network; Glioma brain tumor; Grey level co-occurrence matrix; Histogram equalization; Morphological segmentation","Brain; Convolution; Deep learning; Diagnosis; Equalizers; Graphic methods; Image enhancement; Image segmentation; Learning systems; Magnetic resonance imaging; Tumors; Brain tumors; Convolutional neural network; Glioma brain tumor; Gray-level co-occurrence matrix; Grey-level co-occurrence matrixes; Histogram equalizations; Morphological segmentation; MRI Image; Sensitivity and specificity; Tumour detection; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Qiao L.; Gao Y.; Xiao B.; Bi X.; Li W.; Gao X.","Qiao, Lihong (36919115400); Gao, Yonghao (58031031000); Xiao, Bin (57201773066); Bi, Xiuli (56704346000); Li, Weisheng (36067507500); Gao, Xinbo (57305287800)","36919115400; 58031031000; 57201773066; 56704346000; 36067507500; 57305287800","HS-Vectors: Heart Sound Embeddings for Abnormal Heart Sound Detection Based on Time-Compressed and Frequency-Expanded TDNN With Dynamic Mask Encoder","2023","27","3","","1364","1374","10","10.1109/JBHI.2022.3227585","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144763428&doi=10.1109%2fJBHI.2022.3227585&partnerID=40&md5=5349099f19c71e23f8455a32c7f43e3c","In recent years, auxiliary diagnosis technology for cardiovascular disease based on abnormal heart sound detection has become a research hotspot. Heart sound signals are promising in the preliminary diagnosis of cardiovascular diseases. Previous studies have focused on capturing the local characteristics of heart sounds. In this paper, we investigate a method for mapping heart sound signals with complex patterns to fixed-length feature embedding called HS-Vectors for abnormal heart sound detection. To get the full embedding of the complex heart sound, HS-Vectors are obtained through the Time-Compressed and Frequency-Expanded Time-Delay Neural Network(TCFE-TDNN) and the Dynamic Masked-Attention (DMA) module. HS-Vectors extract and utilize the global and critical heart sound characteristics by masking out irreverent information. Based on the TCFE-TDNN module, the heart sound signal within a certain time is projected into fixed-length embedding. Then, with a learnable mask attention matrix, DMA stats pooling aggregates multi-scale hidden features from different TCFE-TDNN layers and masks out irrelevant frame-level features. Experimental evaluations are performed on a 10-fold cross-validation task using the 2016 PhysioNet/CinC Challenge dataset and the new publicly available pediatric heart sound dataset we collected. Experimental results demonstrate that the proposed method excels the state-of-the-art models in abnormality detection.  © 2013 IEEE.","Abnormal heart sound detection; Dynamic Masked-Attention statistics pooling; HS-vectors; Time-Compressed and Frequency-Expanded Time-Delay Neural Network","Aggregates; Biomedical signal processing; Cardiology; Complex networks; Data mining; Diagnosis; Diseases; Feature extraction; Heart; Neural networks; Time delay; Abnormal heart sound detection; Dynamic masked-attention statistic pooling; Features extraction; Heart sounds; HS-vector; Sound detection; Task analysis; Time delay neural networks; Time-compressed and frequency-expanded time-delay neural network; Time-frequency Analysis; abnormal heart sound; aortic stenosis; Article; artificial neural network; classification algorithm; convolutional neural network; cross validation; data processing; deep learning; dynamic masked attention; embedding; Fallot tetralogy; feature extraction; frequency analysis; heart atrium septum defect; heart rate variability; heart sound; heart ventricle septum defect; hidden Markov model; image segmentation; learning algorithm; masking; measurement accuracy; mitral valve regurgitation; phonocardiography; pulmonary valve stenosis; recurrent neural network; sensitivity and specificity; signal processing; sound detection; support vector machine; time compressed and frequency expanded time delay neural network; time delay neural network; wavelet transform; Vectors","Scientific and Technological Key Research Program of Chongqing Municipal Education Commission, (KJQN202200624); National Natural Science Foundation of China, NSFC, (61976031, 62027827, 62276040); National Key Research and Development Program of China, NKRDPC, (2019YFE0110800)","","Institute of Electrical and Electronics Engineers Inc.",""
"Wang L.; Li M.; Zhang L.","Wang, Linlin (57573364900); Li, Mingai (55388854300); Zhang, Liyuan (57195397648)","57573364900; 55388854300; 57195397648","Recognize enhanced temporal-spatial-spectral features with a parallel multi-branch CNN and GRU","2023","61","8","","2013","2032","19","10.1007/s11517-023-02857-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161436709&doi=10.1007%2fs11517-023-02857-4&partnerID=40&md5=98659c84f856d2365f099eefffd1c09f","Deep learning has been applied to the recognition of motor imagery electroencephalograms (MI-EEG) in brain-computer interface, and the performance results depend on data representation as well as neural network structure. Especially, MI-EEG is so complex with the characteristics of non-stationarity, specific rhythms, and uneven distribution; however, its multidimensional feature information is difficult to be fused and enhanced simultaneously in the existing recognition methods. In this paper, a novel channel importance (NCI) based on time–frequency analysis is proposed to develop an image sequence generation method (NCI-ISG) for enhancing the integrity of data representation and highlighting the contribution inequalities of different channels as well. Each electrode of MI-EEG is converted to a time–frequency spectrum by utilizing short-time Fourier transform; the corresponding part to 8–30 Hz is combined with random forest algorithm for computing NCI; and it is further divided into three sub-images covered by α (8–13 Hz), β 1 (13–21 Hz), and β 2 (21–30 Hz) bands; their spectral powers are further weighted by NCI and interpolated to 2-dimensional electrode coordinates, producing three main sub-band image sequences. Then, a parallel multi-branch convolutional neural network and gate recurrent unit (PMBCG) is designed to successively extract and identify the spatial-spectral and temporal features from the image sequences. Two public four-class MI-EEG datasets are adopted; the proposed classification method respectively achieves the average accuracies of 98.26% and 80.62% by 10-fold cross-validation experiment; and its statistical performance is also evaluated by multi-indexes, such as Kappa value, confusion matrix, and ROC curve. Extensive experiment results show that NCI-ISG + PMBCG can yield great performance on MI-EEG classification compared to state-of-the-art methods. The proposed NCI-ISG can enhance the feature representation of time–frequency-space domains and match well with PMBCG, which improves the recognition accuracies of MI tasks and demonstrates the preferable reliability and distinguishable ability. Graphical Abstract: This paper proposes a novel channel importance (NCI) based on time–frequency analysis to develop an image sequences generation method (NCI-ISG) for enhancing the integrity of data representation and highlighting the contribution inequalities of different channels as well. Then, a parallel multi-branch convolutional neural network and gate recurrent unit (PMBCG) is designed to successively extract and identify the spatial-spectral and temporal features from the image sequences. [Figure not available: see fulltext.] © 2023, International Federation for Medical and Biological Engineering.","Brain computer interface; Convolutional neural network; Gate recurrent unit; Motor imagery electroencephalogram; Novel channel importance","Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Electrodes; Electrophysiology; Image analysis; Image enhancement; Recurrent neural networks; Convolutional neural network; Data representations; Gate recurrent unit; Image sequence; Motor imagery; Motor imagery electroencephalogram; Novel channel importance; Performance; Spectral feature; Time-frequency Analysis; Article; convolutional neural network; diagnostic accuracy; electroencephalogram; frequency analysis; motor performance; nonhuman; random forest; short time Fourier transform; Electroencephalography","National Natural Science Foundation of China, NSFC, (11832003, 62173010); National Key Research and Development Program of China, NKRDPC, (2021YFA1000200)","","Springer Science and Business Media Deutschland GmbH",""
"Kim D.H.; Lee G.; Kim S.H.","Kim, Do Hoon (57273857700); Lee, Gwangjin (58055273900); Kim, Seong Han (57215692773)","57273857700; 58055273900; 57215692773","An ECG Stitching Scheme for Driver Arrhythmia Classification Based on Deep Learning","2023","23","6","3257","","","","10.3390/s23063257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151221156&doi=10.3390%2fs23063257&partnerID=40&md5=da580e1dd1273c43b32aa4a7d50c6ad4","This study proposes an electrocardiogram (ECG) signal stitching scheme to detect arrhythmias in drivers during driving. When the ECG is measured through the steering wheel during driving, the data are always exposed to noise caused by vehicle vibrations, bumpy road conditions, and the driver’s steering wheel gripping force. The proposed scheme extracts stable ECG signals and transforms them into full 10 s ECG signals to classify arrhythmias using convolutional neural networks (CNN). Before the ECG stitching algorithm is applied, data preprocessing is performed. To extract the cycle from the collected ECG data, the R peaks are found and the TP interval segmentation is applied. An abnormal P peak is very difficult to find. Therefore, this study also introduces a P peak estimation method. Finally, 4 × 2.5 s ECG segments are collected. To classify arrhythmias with stitched ECG data, each time series’ ECG signal is transformed via the continuous wavelet transform (CWT) and short-time Fourier transform (STFT), and transfer learning is performed for classification using CNNs. Finally, the parameters of the networks that provide the best performance are investigated. According to the classification accuracy, GoogleNet with the CWT image set shows the best results. The classification accuracy is 82.39% for the stitched ECG data, while it is 88.99% for the original ECG data. © 2023 by the authors.","ECG; ECG classification; ECG concatenation; ECG stitching; EKG; electrocardiogram","Algorithms; Arrhythmias, Cardiac; Deep Learning; Electrocardiography; Humans; Neural Networks, Computer; Automobile steering equipment; Biomedical signal processing; Deep learning; Diseases; Fourier series; Vibrations (mechanical); Wavelet transforms; Wheels; Arrhythmia classification; Classification accuracy; Continuous Wavelet Transform; EKG; Electrocardiogram classification; Electrocardiogram concatenation; Electrocardiogram signal; Electrocardiogram stitching; Exposed to; Steering wheel; algorithm; electrocardiography; heart arrhythmia; human; Electrocardiograms","Division of Human Resource Development, HRD, (2021-0-02067, IITP-2022-RS-2022-00156345); Ministry of Science, ICT and Future Planning, MSIP; National Research Foundation of Korea, NRF, (2020R1C1C1008068); Institute for Information and Communications Technology Promotion, IITP","","MDPI","36991967"
"Sharma A.K.; Tripathi P.K.; Sharma S.","Sharma, Avinash Kumar (57214356058); Tripathi, Pranav Kumar (58171463600); Sharma, Sushant (58172050500)","57214356058; 58171463600; 58172050500","Role of artificial intelligence in biomedical imaging","2023","","","","17","34","17","10.4018/978-1-6684-6957-6.ch002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151702394&doi=10.4018%2f978-1-6684-6957-6.ch002&partnerID=40&md5=a6f4d2695505a40a71b557b0432986ab","A trendy technique based on computer science called artificial intelligence (AI) creates software and algorithms to make machines smart and effective at carrying out activities that often callfor expert human intellect. Machine learning (ML), deep learning (DL), traditional neural networks, fuzzy logic, and speech recognition are only a few of the subsets of AI that have distinctive skills and functions that might enhance the performance of contemporary medical sciences. Biomedical imaging might undergo a revolution thanks to AI, which could increase the efficiency and precision of picture processing and interpretation. Radiologists could miss tiny abnormalities that can be detected by AI systems that have been taught to spot patterns in those pictures that are challenging for humans to interpret. AI may also be used to generate customized medicine by evaluating a patient's medical pictures and other data to customize treatment regimens, as well as to enhance image processing and visualization. © 2023, IGI Global.","","","","","IGI Global",""
"Chen Y.; Yu L.; Wang J.-Y.; Panjwani N.; Obeid J.-P.; Liu W.; Liu L.; Kovalchuk N.; Gensheimer M.F.; Vitzthum L.K.; Beadle B.M.; Chang D.T.; Le Q.-T.; Han B.; Xing L.","Chen, Yizheng (57219519510); Yu, Lequan (56903335400); Wang, Jen-Yeu (57218486799); Panjwani, Neil (57190886774); Obeid, Jean-Pierre (57189644113); Liu, Wu (36020145900); Liu, Lianli (57014076500); Kovalchuk, Nataliya (40461729100); Gensheimer, Michael Francis (55278778700); Vitzthum, Lucas Kas (57190002694); Beadle, Beth M. (57226230999); Chang, Daniel T. (9943395500); Le, Quynh-Thu (57216998256); Han, Bin (55039696900); Xing, Lei (7103349003)","57219519510; 56903335400; 57218486799; 57190886774; 57189644113; 36020145900; 57014076500; 40461729100; 55278778700; 57190002694; 57226230999; 9943395500; 57216998256; 55039696900; 7103349003","Adaptive Region-Specific Loss for Improved Medical Image Segmentation","2023","45","11","","13408","13421","13","10.1109/TPAMI.2023.3289667","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163532381&doi=10.1109%2fTPAMI.2023.3289667&partnerID=40&md5=56fba379193adb401320600d62f7d063","Defining the loss function is an important part of neural network design and critically determines the success of deep learning modeling. A significant shortcoming of the conventional loss functions is that they weight all regions in the input image volume equally, despite the fact that the system is known to be heterogeneous (i.e., some regions can achieve high prediction performance more easily than others). Here, we introduce a region-specific loss to lift the implicit assumption of homogeneous weighting for better learning. We divide the entire volume into multiple sub-regions, each with an individualized loss constructed for optimal local performance. Effectively, this scheme imposes higher weightings on the sub-regions that are more difficult to segment, and vice versa. Furthermore, the regional false positive and false negative errors are computed for each input image during a training step and the regional penalty is adjusted accordingly to enhance the overall accuracy of the prediction. Using different public and in-house medical image datasets, we demonstrate that the proposed regionally adaptive loss paradigm outperforms conventional methods in the multi-organ segmentations, without any modification to the neural network architecture or additional data preparation.  © 1979-2012 IEEE.","Deep learning; loss function; medical image; neural network; segmentation","Algorithms; Image Processing, Computer-Assisted; Neural Networks, Computer; Deep neural networks; Image enhancement; Job analysis; Medical imaging; Network architecture; Biomedical imaging; Deep learning; Images segmentations; Loss functions; Medical image; Neural-networks; Optimisations; Segmentation; Task analysis; algorithm; artificial neural network; image processing; procedures; Image segmentation","","","IEEE Computer Society","37363838"
"Smitha J.C.; Jane A.; Chandran L.","Smitha, J.C. (56111725900); Jane, Ambily (58560714500); Chandran, Lekshmi (57387078400)","56111725900; 58560714500; 57387078400","3D Flattering Amplified Neural Network-Based Segmentation of Amygdala and Hippocampus","2023","66","8","","1949","1964","15","10.1093/comjnl/bxac054","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169588603&doi=10.1093%2fcomjnl%2fbxac054&partnerID=40&md5=9d271fc3ece625a7fc26edeadeb3165d","Recent emergence in deep learning resulted in significant improvement in the segmentation accuracy of sub cortical brain structures like hippocampus and amygdala. The traditional methods of segmentation cannot produce an ideal segmentation result that exhibits issues like redundant computations, inconsistencies, coefficient variations and motion artifacts. Therefore, in this paper, an improved 3D Flatteringly Amplified Neural Network model for biomedical imaging is efficiently proposed, which can make full use of the 3D spatial information of MRI image itself to overcome the inconsistency of segmented images along with equalizing the coefficient variation of tiny region of brain image segmentation. Also while equalizing the coefficient, certain significant minute details are lost due to motion artifacts hence, the robust Amyg-Hippo Seg algorithm has been introducing that extracts the features through deep learning, and achieve high-precision segmentation, it reduced the computational complexity without neglecting minute features. In addition, the Daytona dropout function provides uncertainty information and reduces over-fitting problems. The outcome of the proposed work efficiently segments the most significant regions of hippocampus and amygdala with 97.4% accuracy.  © 2022 The British Computer Society. All rights reserved.","3D Flatteringly Amplified Neural Network (3DFANN); Amyg-Hippo Seg approach; brain image segmentation; Daytona dropout function","Brain; Brain mapping; Deep learning; Image enhancement; Magnetic resonance imaging; Neural network models; 3d flatteringly amplified neural network; Amyg-hippo seg approach; Brain image segmentation; Brain images; Daytona dropout function; Images segmentations; Motion artifact; Network-based; Neural-networks; Segmentation accuracy; Image segmentation","","","Oxford University Press",""
"Zhang C.; Chu H.; Ma M.","Zhang, Chaozhu (57880153900); Chu, Hongxing (57964611600); Ma, Mingyuan (58624155900)","57880153900; 57964611600; 58624155900","Decoding Algorithm of Motor Imagery Electroencephalogram Signal Based on CLRNet Network Model","2023","23","18","7694","","","","10.3390/s23187694","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172736818&doi=10.3390%2fs23187694&partnerID=40&md5=7e0a27b789fe41a498769f20096211ea","EEG decoding based on motor imagery is an important part of brain–computer interface technology and is an important indicator that determines the overall performance of the brain–computer interface. Due to the complexity of motor imagery EEG feature analysis, traditional classification models rely heavily on the signal preprocessing and feature design stages. End-to-end neural networks in deep learning have been applied to the classification task processing of motor imagery EEG and have shown good results. This study uses a combination of a convolutional neural network (CNN) and a long short-term memory (LSTM) network to obtain spatial information and temporal correlation from EEG signals. The use of cross-layer connectivity reduces the network gradient dispersion problem and enhances the overall network model stability. The effectiveness of this network model is demonstrated on the BCI Competition IV dataset 2a by integrating CNN, BiLSTM and ResNet (called CLRNet in this study) to decode motor imagery EEG. The network model combining CNN and BiLSTM achieved 87.0% accuracy in classifying motor imagery patterns in four classes. The network stability is enhanced by adding ResNet for cross-layer connectivity, which further improved the accuracy by 2.0% to achieve 89.0% classification accuracy. The experimental results show that CLRNet has good performance in decoding the motor imagery EEG dataset. This study provides a better solution for motor imagery EEG decoding in brain–computer interface technology research. © 2023 by the authors.","CNN; EEG; LSTM; motor imagery; ResNet","Algorithms; Brain-Computer Interfaces; Electroencephalography; Imagery, Psychotherapy; Neural Networks, Computer; Biomedical signal processing; Bismuth compounds; Brain computer interface; Classification (of information); Convolutional neural networks; Decoding; Image classification; Long short-term memory; Convolutional neural network; Cross layer; Decoding algorithm; Electroencephalogram signals; Interface technology; Motor imagery; Motor imagery EEG; Network models; Performance; Resnet; algorithm; artificial neural network; electroencephalography; guided imagery; Electroencephalography","","","Multidisciplinary Digital Publishing Institute (MDPI)","37765751"
"Muezzinoglu T.; Baygin N.; Tuncer I.; Barua P.D.; Baygin M.; Dogan S.; Tuncer T.; Palmer E.E.; Cheong K.H.; Acharya U.R.","Muezzinoglu, Taha (57222227014); Baygin, Nursena (56340136600); Tuncer, Ilknur (57942800700); Barua, Prabal Datta (36993665100); Baygin, Mehmet (55293658600); Dogan, Sengul (25653093400); Tuncer, Turker (37062172100); Palmer, Elizabeth Emma (55990084100); Cheong, Kang Hao (36674537000); Acharya, U. Rajendra (7004510847)","57222227014; 56340136600; 57942800700; 36993665100; 55293658600; 25653093400; 37062172100; 55990084100; 36674537000; 7004510847","PatchResNet: Multiple Patch Division–Based Deep Feature Fusion Framework for Brain Tumor Classification Using MRI Images","2023","36","3","","973","987","14","10.1007/s10278-023-00789-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148248837&doi=10.1007%2fs10278-023-00789-x&partnerID=40&md5=2648fbbd69d22f49628a3e518213f17b","Modern computer vision algorithms are based on convolutional neural networks (CNNs), and both end-to-end learning and transfer learning modes have been used with CNN for image classification. Thus, automated brain tumor classification models have been proposed by deploying CNNs to help medical professionals. Our primary objective is to increase the classification performance using CNN. Therefore, a patch-based deep feature engineering model has been proposed in this work. Nowadays, patch division techniques have been used to attain high classification performance, and variable-sized patches have achieved good results. In this work, we have used three types of patches of different sizes (32 × 32, 56 × 56, 112 × 112). Six feature vectors have been obtained using these patches and two layers of the pretrained ResNet50 (global average pooling and fully connected layers). In the feature selection phase, three selectors—neighborhood component analysis (NCA), Chi2, and ReliefF—have been used, and 18 final feature vectors have been obtained. By deploying k nearest neighbors (kNN), 18 results have been calculated. Iterative hard majority voting (IHMV) has been applied to compute the general classification accuracy of this framework. This model uses different patches, feature extractors (two layers of the ResNet50 have been utilized as feature extractors), and selectors, making this a framework that we have named PatchResNet. A public brain image dataset containing four classes (glioblastoma multiforme (GBM), meningioma, pituitary tumor, healthy) has been used to develop the proposed PatchResNet model. Our proposed PatchResNet attained 98.10% classification accuracy using the public brain tumor image dataset. The developed PatchResNet model obtained high classification accuracy and has the advantage of being a self-organized framework. Therefore, the proposed method can choose the best result validation prediction vectors and achieve high image classification performance. © 2023, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.","Biomedical engineering; Brain image classification; PatchResNet; Transfer learning; Tumor classification","Algorithms; Brain; Brain Neoplasms; Humans; Magnetic Resonance Imaging; Neural Networks, Computer; Biomedical engineering; Brain; Brain mapping; Classification (of information); Convolutional neural networks; Iterative methods; Magnetic resonance imaging; Nearest neighbor search; Tumors; Brain image classification; Brain images; Classification accuracy; Classification performance; Convolutional neural network; Images classification; Patch divisions; Patchresnet; Transfer learning; Tumor classification; algorithm; artificial neural network; brain; brain tumor; diagnostic imaging; human; nuclear magnetic resonance imaging; Image classification","","","Institute for Ionics","36797543"
"Mohite T.; Sankpal S.","Mohite, Trupti (58734484400); Sankpal, Swati (57192573403)","58734484400; 57192573403","Machine learning approach for detection and classification of biomedical waste objects","2023","2842","1","020003","","","","10.1063/5.0175687","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178262580&doi=10.1063%2f5.0175687&partnerID=40&md5=d21e9f334ab0e72db1ee34e2e8e6b02d","This paper mostly focuses on real-Time detection and classification of biomedical waste objects. Traditional methods for detecting the objects like biomedical waste objects in machine learning are substituted by recent technology of object detection methods in deep learning by building Convolutional Neural Network (CNN) which is nothing but the components of deep learning. This paper proposes a deep learning approach for object detection of biomedical waste material by evaluating the TensorFlow object detection API, which can used for real time application, this biomedical object detection API further we can used for automate the biomedical waste segregation system, this proposed system has been trained using more than 500 images for each type of biomedical waste object. Tensorflow is useful and easy to object detection that can form powerful image recognition software, in this proposed work we are using Faster R-CNN algorithm for developing this object detection process. © 2023 Author(s).","","","","Mishra B.K.; Kasturiwale H.P.; Alegavi S.","American Institute of Physics Inc.",""
"Bhandary S.; Kuhn D.; Babaiee Z.; Fechter T.; Benndorf M.; Zamboglou C.; Grosu A.-L.; Grosu R.","Bhandary, Shrajan (57336379800); Kuhn, Dejan (58251997000); Babaiee, Zahra (57225102627); Fechter, Tobias (55796836400); Benndorf, Matthias (36097606300); Zamboglou, Constantinos (36459419500); Grosu, Anca-Ligia (7005831902); Grosu, Radu (6601973195)","57336379800; 58251997000; 57225102627; 55796836400; 36097606300; 36459419500; 7005831902; 6601973195","Investigation and benchmarking of U-Nets on prostate segmentation tasks","2023","107","","102241","","","","10.1016/j.compmedimag.2023.102241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159431700&doi=10.1016%2fj.compmedimag.2023.102241&partnerID=40&md5=5d8f7f69265085a103be5273c8597539","In healthcare, a growing number of physicians and support staff are striving to facilitate personalized radiotherapy regimens for patients with prostate cancer. This is because individual patient biology is unique, and employing a single approach for all is inefficient. A crucial step for customizing radiotherapy planning and gaining fundamental information about the disease, is the identification and delineation of targeted structures. However, accurate biomedical image segmentation is time-consuming, requires considerable experience and is prone to observer variability. In the past decade, the use of deep learning models has significantly increased in the field of medical image segmentation. At present, a vast number of anatomical structures can be demarcated on a clinician's level with deep learning models. These models would not only unload work, but they can offer unbiased characterization of the disease. The main architectures used in segmentation are the U-Net and its variants, that exhibit outstanding performances. However, reproducing results or directly comparing methods is often limited by closed source of data and the large heterogeneity among medical images. With this in mind, our intention is to provide a reliable source for assessing deep learning models. As an example, we chose the challenging task of delineating the prostate gland in multi-modal images. First, this paper provides a comprehensive review of current state-of-the-art convolutional neural networks for 3D prostate segmentation. Second, utilizing public and in-house CT and MR datasets of varying properties, we created a framework for an objective comparison of automatic prostate segmentation algorithms. The framework was used for rigorous evaluations of the models, highlighting their strengths and weaknesses. © 2023 The Author(s)","Automatic prostate segmentation; Comparison framework; Medical imaging; U-net variations","Algorithms; Benchmarking; Humans; Image Processing, Computer-Assisted; Male; Neural Networks, Computer; Prostate; Prostatic Neoplasms; Computerized tomography; Convolutional neural networks; Deep learning; Image segmentation; Learning systems; Medical imaging; Radiotherapy; Urology; Automatic prostate segmentation; Biomedical image segmentation; Comparison framework; Learning models; Observer variability; Prostate cancers; Prostate segmentation; Radiotherapy planning; Support staff; U-net variation; adult; anatomical concepts; automation; benchmarking; cancer patient; clinician; convolutional neural network; deep learning; human; image segmentation; male; multimodal imaging; nuclear magnetic resonance imaging; prostate cancer; Review; segmentation algorithm; u net; x-ray computed tomography; algorithm; artificial neural network; diagnostic imaging; image processing; procedures; prostate; prostate tumor; Diseases","TU Wien's Faculty of Informatics; TU Wien’s Faculty of Informatics; UAS Technikum Wien; Bundesministerium für Bildung und Forschung, BMBF; Austrian Science Fund, FWF, (I 4718); Austrian Science Fund, FWF","","Elsevier Ltd","37201475"
"","","","ICBSP 2023 - Proceedings of 2023 8th International Conference on Biomedical Imaging, Signal Processing","2023","","","","","","125","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184618215&partnerID=40&md5=9eee67bacadbdcdb2a47208ecc08460c","The proceedings contain 17 papers. The topics discussed include: clustering-based cancer diagnosis model for whole slide image; shared embedding of x-ray & Enose networks for lung cancer classification; performance analysis of lightweight vision transformers and deep convolutional neural networks in detecting brain tumors in MRI scans: an empirical approach; an automated skin lesions classification using hybrid CNN and transformer based deep learning model; a novel approach for repairing unsegmented liver vascular images based on centerline; medical image joint Deringing and denoising using Fourier neural operator; and NerveStitcher2.0: evolution of stitching algorithm for corneal confocal microscope images with optical flow.","","","","","Association for Computing Machinery",""
"Ye S.; Shen L.; Islam M.T.; Xing L.","Ye, Siqi (57200728012); Shen, Liyue (57201327444); Islam, Md Tauhidul (57263730600); Xing, Lei (7103349003)","57200728012; 57201327444; 57263730600; 7103349003","Super-resolution biomedical imaging via reference-free statistical implicit neural representation","2023","68","20","205020","","","","10.1088/1361-6560/acfdf1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175585520&doi=10.1088%2f1361-6560%2facfdf1&partnerID=40&md5=bf8978a5526d0402a0eb039b94eed89f","Objective. Supervised deep learning for image super-resolution (SR) has limitations in biomedical imaging due to the lack of large amounts of low- and high-resolution image pairs for model training. In this work, we propose a reference-free statistical implicit neural representation (INR) framework, which needs only a single or a few observed low-resolution (LR) image(s), to generate high-quality SR images. Approach. The framework models the statistics of the observed LR images via maximum likelihood estimation and trains the INR network to represent the latent high-resolution (HR) image as a continuous function in the spatial domain. The INR network is constructed as a coordinate-based multi-layer perceptron, whose inputs are image spatial coordinates and outputs are corresponding pixel intensities. The trained INR not only constrains functional smoothness but also allows an arbitrary scale in SR imaging. Main results. We demonstrate the efficacy of the proposed framework on various biomedical images, including computed tomography (CT), magnetic resonance imaging (MRI), fluorescence microscopy, and ultrasound images, across different SR magnification scales of 2×, 4×, and 8×. A limited number of LR images were used for each of the SR imaging tasks to show the potential of the proposed statistical INR framework. Significance. The proposed method provides an urgently needed unsupervised deep learning framework for numerous biomedical SR applications that lack HR reference images. © 2023 Institute of Physics and Engineering in Medicine.","biomedical imaging; implicit neural representation; inverse problem; maximum likelihood estimation; multi-scale imaging; super-resolution; unsupervised learning","Algorithms; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Microscopy, Fluorescence; Neural Networks, Computer; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Fluorescence microscopy; Learning systems; Magnetic resonance imaging; Maximum likelihood estimation; Medical imaging; Optical resolving power; Biomedical imaging; High-resolution images; Implicit neural representation; Low resolution images; Maximum-likelihood estimation; Multi-scale imaging; Neural representations; Reference-free; Super resolution imaging; Superresolution; algorithm; artificial neural network; fluorescence microscopy; image processing; nuclear magnetic resonance imaging; procedures; x-ray computed tomography; Inverse problems","National Institutes of Health, NIH, (1R01CA176553, 1R01CA223667, 1R01CA227713); National Institutes of Health, NIH; Shanghai Jiao Tong University, SJTU","","Institute of Physics","37757838"
"Nazir S.; Dickson D.M.; Akram M.U.","Nazir, Sajid (47061625500); Dickson, Diane M. (57075710900); Akram, Muhammad Usman (24474159700)","47061625500; 57075710900; 24474159700","Survey of explainable artificial intelligence techniques for biomedical imaging with deep neural networks","2023","156","","106668","","","","10.1016/j.compbiomed.2023.106668","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149371270&doi=10.1016%2fj.compbiomed.2023.106668&partnerID=40&md5=805a0d649d8ba98c2502e4344fbff105","Artificial Intelligence (AI) techniques of deep learning have revolutionized the disease diagnosis with their outstanding image classification performance. In spite of the outstanding results, the widespread adoption of these techniques in clinical practice is still taking place at a moderate pace. One of the major hindrance is that a trained Deep Neural Networks (DNN) model provides a prediction, but questions about why and how that prediction was made remain unanswered. This linkage is of utmost importance for the regulated healthcare domain to increase the trust in the automated diagnosis system by the practitioners, patients and other stakeholders. The application of deep learning for medical imaging has to be interpreted with caution due to the health and safety concerns similar to blame attribution in the case of an accident involving autonomous cars. The consequences of both a false positive and false negative cases are far reaching for patients' welfare and cannot be ignored. This is exacerbated by the fact that the state-of-the-art deep learning algorithms comprise of complex interconnected structures, millions of parameters, and a ‘black box’ nature, offering little understanding of their inner working unlike the traditional machine learning algorithms. Explainable AI (XAI) techniques help to understand model predictions which help develop trust in the system, accelerate the disease diagnosis, and meet adherence to regulatory requirements. This survey provides a comprehensive review of the promising field of XAI for biomedical imaging diagnostics. We also provide a categorization of the XAI techniques, discuss the open challenges, and provide future directions for XAI which would be of interest to clinicians, regulators and model developers. © 2023 The Authors","Backpropagation; Blackbox; Diagnostic imaging; Features; Interpretable AI; Neural networks; Predictive models; Supervised learning","Algorithms; Artificial Intelligence; Diagnostic Imaging; Humans; Machine Learning; Neural Networks, Computer; Backpropagation; Computer aided diagnosis; Forecasting; Learning systems; Medical imaging; Artificial intelligence techniques; Biomedical imaging; Black boxes; Diagnostic imaging; Disease diagnosis; Feature; Images classification; Interpretable artificial intelligence; Neural-networks; Predictive models; artificial intelligence; back propagation; cancer diagnosis; computer assisted tomography; data compression; data visualization; decision making; decomposition; deep learning; deep neural network; dermatology; diabetic retinopathy; diagnostic accuracy; diagnostic imaging; echography; fluorescence imaging; human; knowledge; malignant neoplasm; nuclear magnetic resonance imaging; physician; prediction; predictive model; radiodiagnosis; Review; X ray; algorithm; diagnostic imaging; machine learning; Deep neural networks","Defense Advanced Research Projects Agency, DARPA; Office of Defense Nuclear Nonproliferation, DNN; Alzheimer's Disease Neuroimaging Initiative, ADNI; Glasgow Caledonian University, GCU, (10386)","","Elsevier Ltd","36863192"
"Ma W.; Wang C.; Sun X.; Lin X.; Niu L.; Wang Y.","Ma, Weifeng (8384527000); Wang, Chuanlai (15844435200); Sun, Xiaoyong (56139100900); Lin, Xuefen (35107581800); Niu, Lei (57221528080); Wang, Yuchen (57655055300)","8384527000; 15844435200; 56139100900; 35107581800; 57221528080; 57655055300","MBGA-Net: A multi-branch graph adaptive network for individualized motor imagery EEG classification","2023","240","","107641","","","","10.1016/j.cmpb.2023.107641","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162904681&doi=10.1016%2fj.cmpb.2023.107641&partnerID=40&md5=702db1cbce989e123669403870623fa1","Background and objective: The development of deep learning has led to significant improvements in the decoding accuracy of Motor Imagery (MI) EEG signal classification. However, current models are inadequate in ensuring high levels of classification accuracy for an individual. Since MI EEG data is primarily used in medical rehabilitation and intelligent control, it is crucial to ensure that each individual's EEG signal is recognized with precision. Methods: We propose a multi-branch graph adaptive network (MBGA-Net), which matches each individual EEG signal with a suitable time-frequency domain processing method based on spatio-temporal domain features. We then feed the signal into the relevant model branch using an adaptive technique. Through an enhanced attention mechanism and deep convolutional method with residual connectivity, each model branch more effectively harvests the features of the related format data. Results: We validate the proposed model using the BCI Competition IV dataset 2a and dataset 2b. On dataset 2a, the average accuracy and kappa values are 87.49% and 0.83, respectively. The standard deviation of individual kappa values is only 0.08. For dataset 2b, the average classification accuracies obtained by feeding the data into the three branches of MBGA-Net are 85.71%, 85.83%, and 86.99%, respectively. Conclusions: The experimental results demonstrate that MBGA-Net could effectively perform the classification task of motor imagery EEG signals, and it exhibits strong generalization performance. The proposed adaptive matching technique enhances the classification accuracy of each individual, which is beneficial for the practical application of EEG classification. © 2023 Elsevier B.V.","Adaptive matching technique; Data processing; Deep learning; Graph convolutional network(GCN); Motor imagery; Multi-branch graph adaptive network","Algorithms; Brain-Computer Interfaces; Electroencephalography; Imagination; Movement; Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Data handling; Deep learning; Image classification; Image enhancement; Adaptive matching; Adaptive matching technique; Adaptive networks; Convolutional networks; Deep learning; Graph convolutional network; Matching techniques; Motor imagery; Motor imagery EEG; Multi-branch graph adaptive network; article; attention; competition; deep learning; electroencephalogram; feeding; human; human experiment; imagery; algorithm; electroencephalography; imagination; movement (physiology); procedures; Frequency domain analysis","","","Elsevier Ireland Ltd","37327754"
"Adnan M.M.; Ramachandra A.C.; Patra R.; Jagadish S.; Hussein A.H.A.","Adnan, Myasar Mundher (57221874677); Ramachandra, A.C. (24081133500); Patra, Rajkumar (36952253500); Jagadish, Sripelli (58735645700); Hussein, Abbas Hameed Abdul (58520692000)","57221874677; 24081133500; 36952253500; 58735645700; 58520692000","Deep Learning based Arrhythmia Classification using Orthogonal Wavelet Filtering with Moth Flame Optimization Algorithm","2023","","","","","","","10.1109/ICIICS59993.2023.10421630","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186089120&doi=10.1109%2fICIICS59993.2023.10421630&partnerID=40&md5=8c9cd9be3ad3e80d1252dc1e14680f1e","An accurate and early detection of arrhythmia have become significant because of its enhanced mortality from the cardiovascular disease (CVD). The Electrocardiogram (ECG) majorly takes place in the CVD diagnosis, but it provides the information about the heartbeat. An automatic detection of arrhythmia performs a significant role in managing as well as curing the CVDs. In this research, pre-processing using an Orthogonal Wavelet-based Filtering approach with Moth Flame optimization (MFO) filter bank is proposed to enhance the denoising performance of the ECG signals. This research utilized the arrhythmia dataset named MIT-BIH to evaluated the performance of the proposed method. After pre-processing, the Convolutional Neural Network (CNN) is utilized for the feature extraction and Supervised Bidirectional Long Short-Term Memory (SBiLSTM) is used for the classification of the arrhythmia images. The proposed method attains better results and achieves the values of accuracy of 99.97%, specificity of 99.98%, sensitivity of 99.96% as well as Positive Predictive Value of 95.75% when compared to the existing methods like ResNet-BiLSTM-Attention, 2D-CNN, CNN-BLSTM, CNN-LSTM and Deep Recurrent CNN (DRCNN) respectively.  © 2023 IEEE.","Arrhythmia classification; Cardiovascular disease; Convolutional Neural Network; Denoising; Moth Flame optimization and Orthogonal wavelet-based Filtering","Biomedical signal processing; Cardiology; Convolution; Convolutional neural networks; Electrocardiography; Long short-term memory; Wavelet analysis; Arrhythmia classification; Cardiovascular disease; Convolutional neural network; De-noising; Moth flame optimization and orthogonal wavelet-based filtering; Optimisations; Orthogonal wavelets; Performance; Pre-processing; Wavelet-based filtering; Diseases","","","Institute of Electrical and Electronics Engineers Inc.",""
"Kumar S.; Mallik A.; Kumar A.; Ser J.D.; Yang G.","Kumar, Sanjay (58732819200); Mallik, Abhishek (57262191100); Kumar, Akshi (56718788600); Ser, Javier Del (9737598300); Yang, Guang (57216243504)","58732819200; 57262191100; 56718788600; 9737598300; 57216243504","Fuzz-ClustNet: Coupled fuzzy clustering and deep neural networks for Arrhythmia detection from ECG signals","2023","153","","106511","","","","10.1016/j.compbiomed.2022.106511","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145648584&doi=10.1016%2fj.compbiomed.2022.106511&partnerID=40&md5=146bd2e7c7ce824358d33a141a5c1a2a","Electrocardiogram (ECG) is a widely used technique to diagnose cardiovascular diseases. It is a non-invasive technique that represents the cyclic contraction and relaxation of heart muscles. ECG can be used to detect abnormal heart motions, heart attacks, heart diseases, or enlarged hearts by measuring the heart's electrical activity. Over the past few years, various works have been done in the field of studying and analyzing the ECG signals to detect heart diseases. In this work, we propose a deep learning and fuzzy clustering (Fuzz-ClustNet) based approach for Arrhythmia detection from ECG signals. We started by denoising the collected ECG signals to remove errors like baseline drift, power line interference, motion noise, etc. The denoised ECG signals are then segmented to have an increased focus on the ECG signals. We then perform data augmentation on the segmented images to counter the effects of the class imbalance. The augmented images are then passed through a CNN feature extractor. The extracted features are then passed to a fuzzy clustering algorithm to classify the ECG signals for their respective cardio diseases. We ran intensive simulations on two benchmarked datasets and evaluated various performance metrics. The performance of our proposed algorithm was compared with several recently proposed algorithms for heart disease detection from ECG signals. The obtained results demonstrate the efficacy of our proposed approach as compared to other contemporary algorithms. © 2023 The Author(s)","Arrhythmia detection; Convolutional Neural Network; Deep learning; Electrocardiogram (ECG); Feature extraction; Fuzzy clustering","Algorithms; Arrhythmias, Cardiac; Electrocardiography; Heart Rate; Humans; Myocardial Infarction; Neural Networks, Computer; Signal Processing, Computer-Assisted; Biomedical signal processing; Cardiology; Clustering algorithms; Deep neural networks; Diseases; Feature extraction; Fuzzy clustering; Fuzzy inference; Fuzzy neural networks; Heart; Signal detection; Arrhythmia detection; Cardiovascular disease; Convolutional neural network; Deep learning; Electrocardiogram; Electrocardiogram signal; Features extraction; Heart disease; Heart muscles; Noninvasive technique; Article; Bayesian learning; comparative study; computer assisted diagnosis; computer language; computer simulation; controlled study; convolutional neural network; decision tree; deep learning; deep neural network; diagnostic accuracy; electrocardiogram; electrocardiography; feature extraction; fuzzy clustering; heart arrhythmia; heart ventricle extrasystole; human; image processing; image segmentation; k means clustering; k nearest neighbor; kernel method; logistic regression analysis; low frequency noise; machine learning; noise reduction; random forest; signal processing; support vector machine; supraventricular premature beat; algorithm; diagnostic imaging; heart arrhythmia; heart infarction; heart rate; Electrocardiograms","Department of Education of the Basque Government, (IT1456-22); ERC IMI, (101005122); Horizon 2020 Framework Programme, H2020, (952172); UK Research and Innovation, UKRI, (MR/V023799/1); Medical Research Council, MRC, (MC/PC/21013); Royal Society, (IEC/NSFC/211235)","","Elsevier Ltd","36608461"
"Prasath Alias S.S.; Manikandan R.; Kumar A.","Prasath Alias, Surendhar S. (57211279085); Manikandan, R. (37061393600); Kumar, Ambeshwar (57202315403)","57211279085; 37061393600; 57202315403","Class activation mapping and deep learning for explainable biomedical applications","2023","","","","123","143","20","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163958840&partnerID=40&md5=6310d19d7477db7a2f3fbf6aa666de45","For a number of medical diagnostic tasks, deep learning (DL) methods have proven to be quite successful, sometimes even outperforming human experts. The algorithms' black-box nature has, however, limited their therapeutic application. Recent studies on explainability seek to identify the factors most responsible for a model's choice. In the biomedical domain, deep neural networks (DNNs) now represent most successful machine learning (ML) technologies. The various topics of interest in this field include BBMI (study of interface between the brain as well as body's mechanical systems), bioimaging (the study of biological cells and tissues), medical imaging (study of human organs through the creation of visual representations), and public and medical health management (PmHM). This study provides an overview of explainable artificial intelligence (XAI) applied in class activation mapping-based DL medical picture analysis. For the purpose of categorizing DL-based medical image analysis (MIA) techniques, a framework of XAI criteria is presented. The papers are then surveyed and categorized in accordance with framework as well as based on anatomical location for use in MIA. © 2023 River Publishers.","","","","","River Publishers",""
"Mühlberg A.; Ritter P.; Langer S.; Goossens C.; Nübler S.; Schneidereit D.; Taubmann O.; Denzinger F.; Nörenberg D.; Haug M.; Schürmann S.; Horstmeyer R.; Maier A.K.; Goldmann W.H.; Friedrich O.; Kreiss L.","Mühlberg, Alexander (57194016374); Ritter, Paul (57218549030); Langer, Simon (57732457500); Goossens, Chloë (57190251798); Nübler, Stefanie (57204427999); Schneidereit, Dominik (57191630256); Taubmann, Oliver (56531961500); Denzinger, Felix (57212002116); Nörenberg, Dominik (36053642300); Haug, Michael (56041711400); Schürmann, Sebastian (13105178800); Horstmeyer, Roarke (24921098400); Maier, Andreas K. (23392966100); Goldmann, Wolfgang H. (7004985300); Friedrich, Oliver (7003457134); Kreiss, Lucas (57207244163)","57194016374; 57218549030; 57732457500; 57190251798; 57204427999; 57191630256; 56531961500; 57212002116; 36053642300; 56041711400; 13105178800; 24921098400; 23392966100; 7004985300; 7003457134; 57207244163","SEMPAI: a Self-Enhancing Multi-Photon Artificial Intelligence for Prior-Informed Assessment of Muscle Function and Pathology","2023","10","28","2206319","","","","10.1002/advs.202206319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167804445&doi=10.1002%2fadvs.202206319&partnerID=40&md5=6f859d613c69ceefd62c9d6dc6e70526","Deep learning (DL) shows notable success in biomedical studies. However, most DL algorithms work as black boxes, exclude biomedical experts, and need extensive data. This is especially problematic for fundamental research in the laboratory, where often only small and sparse data are available and the objective is knowledge discovery rather than automation. Furthermore, basic research is usually hypothesis-driven and extensive prior knowledge (priors) exists. To address this, the Self-Enhancing Multi-Photon Artificial Intelligence (SEMPAI) that is designed for multiphoton microscopy (MPM)-based laboratory research is presented. It utilizes meta-learning to optimize prior (and hypothesis) integration, data representation, and neural network architecture simultaneously. By this, the method allows hypothesis testing with DL and provides interpretable feedback about the origin of biological information in 3D images. SEMPAI performs multi-task learning of several related tasks to enable prediction for small datasets. SEMPAI is applied on an extensive MPM database of single muscle fibers from a decade of experiments, resulting in the largest joint analysis of pathologies and function for single muscle fibers to date. It outperforms state-of-the-art biomarkers in six of seven prediction tasks, including those with scarce data. SEMPAI's DL models with integrated priors are superior to those without priors and to prior-only approaches. © 2023 The Authors. Advanced Science published by Wiley-VCH GmbH.","deep learning; explainable artificial intelligence; meta-learning; multiphoton microscopy; muscle research; prior information integration; scientific machine learning","Bioinformatics; Deep learning; Learning systems; Network architecture; Neural networks; Pathology; Photons; Deep learning; Explainable artificial intelligence; Information integration; Machine-learning; Metalearning; Multiphoton microscopy; Muscle research; Prior information; Prior information integration; Scientific machine learning; Muscle","European Union's Horizon Marie Skłodowska-Curie Action; European Union's Horizon Marie Skłodowska‐Curie Action, (101103200, 812772); Friedrich-Alexander University; Friedrich‐Alexander University; Deutsche Forschungsgemeinschaft, DFG, (326998133, TRR241‐C01)","","John Wiley and Sons Inc",""
"","","","International Conference on Biomedical Engineering and Computing Technologies, ICBECT 2022","2023","2603","","","","","453","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159942008&partnerID=40&md5=636f3ef586ecc092abdcd44a73c3513f","The proceedings contain 60 papers. The topics discussed include: sanitization and restoration of under-utilized healthcare database in single-cloud and multi-cloud environment using optimal key generation for personalized privacy preservation; comparative study on the machine learning approaches for the prognosis of acute inflammations in urinary bladder; deep learning model for the estimation of rheumatoid arthritis in hand radiographs; influence of environmental and demographic factors on the transmission and mortality rate of Covid-19 in India; assessment of primary behavioral aspects towards early detection of cervical cancer assisted by neural networks; automated brain tumor detection from MRI images using transfer learning techniques; performance comparison of feature selection algorithms in the life expectancy risk prediction of post-operative lung cancer patients; evolution and contributions of internet of medical things aided emergency covid-19 health monitoring and quarantine management; influence of artificial intelligence for diagnostic decision making using radiological imaging; cloud computing based renewable energy demand management system; and evaluation of osteoarthritis in plain radiographs using machine learning algorithm.","","","","","American Institute of Physics Inc.",""
"Vellela S.S.; Roja D.; Sowjanya C.; Khader Basha S.K.; Dalavai L.; Kumar K.K.","Vellela, Sai Srinivas (58153508200); Roja, D. (57220874834); Sowjanya, Ch (57217631497); Khader Basha, S.K. (58107258600); Dalavai, Lavanya (58929608300); Kumar, K Kiran (58587281600)","58153508200; 57220874834; 57217631497; 58107258600; 58929608300; 58587281600","Multi-Class Skin Diseases Classification with Color and Texture Features Using Convolution Neural Network","2023","","","","1682","1687","5","10.1109/IC3I59117.2023.10398028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187309823&doi=10.1109%2fIC3I59117.2023.10398028&partnerID=40&md5=8bb84eee13db2d9bb6f7e0b72e4b8a49","Skin diseases are very common in our daily lives. In the present era, the prevalence of skin diseases is significant, resulting in it being a prevalent health concern. Due to the similarities in the appearance of different skin conditions, automatically classifying them using lesion images poses a challenging task.A small circular or randomly shaped spot on the patient's skin may be identified as indicative of a skin disease. Under certain circumstances, this illness can represent a serious threat when it transforms into skin cancer. Multi-Class Skin Diseases Classification with Colour and Texture Features Using Convolution Neural Network is discussed in this paper. The study investigated several deep learning-based methods for extracting characteristics from various skin cancer images, which are then used with machine learning classifiers to identify the type of skin illness. In the biomedical fields, machine learning algorithms are also widely used for segmentation and diagnosis. To alleviate the burden and assist patients in the early evaluation of a skin lesion, Computer-Aided Diagnosis (CAD) systems have been developed. Therefore, choosing appropriate Machine Learning (ML) algorithms and feature extraction techniques is essential to achieving high classification accuracy. The study's results indicate that integrating characteristics obtained from a Convolutional Neural Network can enhance the effectiveness of categorizing various skin lesions. The performance of the provided architecture is evaluated based on its sensitivity, accuracy, and specificity.  © 2023 IEEE.","Computer-aided diagnosis (CAD); Convolution Neural Network; Machine learning; Skin diseases; Skin Lesion","Bioinformatics; Classification (of information); Computer aided instruction; Convolution; Deep learning; Dermatology; Diseases; Image classification; Learning algorithms; Learning systems; Medical computing; Textures; Color and texture features; Computer-aided diagnose; Convolution neural network; Daily lives; Disease classification; Machine learning algorithms; Machine-learning; Skin cancers; Skin disease; Skin lesion; Computer aided diagnosis","","","Institute of Electrical and Electronics Engineers Inc.",""
"Song Y.; Yu L.; Lei B.; Choi K.-S.; Qin J.","Song, Youyi (56420728300); Yu, Lequan (56903335400); Lei, Baiying (26422280400); Choi, Kup-Sze (57191030846); Qin, Jing (35339855100)","56420728300; 56903335400; 26422280400; 57191030846; 35339855100","Data Discernment for Affordable Training in Medical Image Segmentation","2023","42","5","","1431","1445","14","10.1109/TMI.2022.3228316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144749653&doi=10.1109%2fTMI.2022.3228316&partnerID=40&md5=e0cb1e00ad0f695d7c27dde0f8c63810","Collecting sufficient high-quality training data for deep neural networks is often expensive or even unaffordable in medical image segmentation tasks. We thus propose to train the network by using external data that can be collected in a cheaper way, e.g., crowd-sourcing. We show that by data discernment, the network is able to mine valuable knowledge from external data, even though the data distribution is very different from that of the original (internal) data. We discern the external data by learning an importance weight for each of them, with the goal to enhance the contribution of informative external data to network updating, while suppressing the data that are 'useless' or even 'harmful'. An iterative algorithm that alternatively estimates the importance weight and updates the network is developed by formulating the data discernment as a constrained nonlinear programming problem. It estimates the importance weight according to the distribution discrepancy between the external data and the internal dataset, and imposes a constraint to drive the network to learn more effectively, compared with the network without using the external data. We evaluate the proposed algorithm on two tasks: abdominal CT image and cervical smear image segmentation, using totally 6 publicly available datasets. The effectiveness of the algorithm is demonstrated by extensive experiments. Source codes are available at: https://github.com/YouyiSong/Data-Discernment.  © 1982-2012 IEEE.","affordable training; constrained nonlinear programming; Data discernment; medical image segmentation","Algorithms; Crowdsourcing; Image Processing, Computer-Assisted; Neural Networks, Computer; Software; Computerized tomography; Deep neural networks; Digital storage; Iterative methods; Job analysis; Medical imaging; Nonlinear programming; Quality control; Affordable training; Annotation; Biomedical imaging; Constrained nonlinear programming; Data discernment; Images segmentations; Medical image segmentation; Programming; Task analysis; Training data; algorithm; article; controlled study; image segmentation; learning; uterine cervix cytology; artificial neural network; crowdsourcing; image processing; software; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.","37015694"
"Li X.; Yan L.; Qi P.; Zhang L.; Goudail F.; Liu T.; Zhai J.; Hu H.","Li, Xiaobo (56365004800); Yan, Lei (8328907300); Qi, Pengfei (57219935563); Zhang, Liping (57221977938); Goudail, François (57207536959); Liu, Tiegen (7405910538); Zhai, Jingsheng (57194603149); Hu, Haofeng (55612861500)","56365004800; 8328907300; 57219935563; 57221977938; 57207536959; 7405910538; 57194603149; 55612861500","Polarimetric Imaging via Deep Learning: A Review","2023","15","6","1540","","","","10.3390/rs15061540","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151487904&doi=10.3390%2frs15061540&partnerID=40&md5=35b2e760b55f292683417901b078b17a","Polarization can provide information largely uncorrelated with the spectrum and intensity. Therefore, polarimetric imaging (PI) techniques have significant advantages in many fields, e.g., ocean observation, remote sensing (RS), biomedical diagnosis, and autonomous vehicles. Recently, with the increasing amount of data and the rapid development of physical models, deep learning (DL) and its related technique have become an irreplaceable solution for solving various tasks and breaking the limitations of traditional methods. PI and DL have been combined successfully to provide brand-new solutions to many practical applications. This review briefly introduces PI and DL’s most relevant concepts and models. It then shows how DL has been applied for PI tasks, including image restoration, object detection, image fusion, scene classification, and resolution improvement. The review covers the state-of-the-art works combining PI with DL algorithms and recommends some potential future research directions. We hope that the present work will be helpful for researchers in the fields of both optical imaging and RS, and that it will stimulate more ideas in this exciting research field. © 2023 by the authors.","convolutional neural network; deep learning; polarimetric imaging; polarization; remote sensing; synthetic aperture radar","Convolutional neural networks; Deep neural networks; Image enhancement; Image fusion; Image reconstruction; Object detection; Optical remote sensing; Polarimeters; Polarization; Radar imaging; Autonomous Vehicles; Biomedical diagnosis; Breakings; Convolutional neural network; Deep learning; Ocean observations; Physical modelling; Polarimetric imaging; Remote-sensing; Spectra's; Synthetic aperture radar","National Natural Science Foundation of China, NSFC, (62075161, 62205243)","","MDPI",""
"Zhang H.; AbdulJabbar K.; Grunewald T.; Akarca A.U.; Hagos Y.; Sobhani F.; Lecat C.S.Y.; Patel D.; Lee L.; Rodriguez-Justo M.; Yong K.; Ledermann J.A.; Le Quesne J.; Hwang E.S.; Marafioti T.; Yuan Y.","Zhang, Hanyun (57224318516); AbdulJabbar, Khalid (57211428176); Grunewald, Tami (56594670700); Akarca, Ayse U. (55789555400); Hagos, Yeman (57224749199); Sobhani, Faranak (57645411100); Lecat, Catherine S.Y. (57211453909); Patel, Dominic (57190090842); Lee, Lydia (7404388563); Rodriguez-Justo, Manuel (22036034000); Yong, Kwee (7102064249); Ledermann, Jonathan A. (7007134127); Le Quesne, John (57201489814); Hwang, E. Shelley (9735815900); Marafioti, Teresa (57218122723); Yuan, Yinyin (7402706941)","57224318516; 57211428176; 56594670700; 55789555400; 57224749199; 57645411100; 57211453909; 57190090842; 7404388563; 22036034000; 7102064249; 7007134127; 57201489814; 9735815900; 57218122723; 7402706941","Self-supervised deep learning for highly efficient spatial immunophenotyping","2023","95","","104769","","","","10.1016/j.ebiom.2023.104769","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169844999&doi=10.1016%2fj.ebiom.2023.104769&partnerID=40&md5=0de129b47e68a2169abe95cc38a7a63b","Background: Efficient biomarker discovery and clinical translation depend on the fast and accurate analytical output from crucial technologies such as multiplex imaging. However, reliable cell classification often requires extensive annotations. Label-efficient strategies are urgently needed to reveal diverse cell distribution and spatial interactions in large-scale multiplex datasets. Methods: This study proposed Self-supervised Learning for Antigen Detection (SANDI) for accurate cell phenotyping while mitigating the annotation burden. The model first learns intrinsic pairwise similarities in unlabelled cell images, followed by a classification step to map learnt features to cell labels using a small set of annotated references. We acquired four multiplex immunohistochemistry datasets and one imaging mass cytometry dataset, comprising 2825 to 15,258 single-cell images to train and test the model. Findings: With 1% annotations (18–114 cells), SANDI achieved weighted F1-scores ranging from 0.82 to 0.98 across the five datasets, which was comparable to the fully supervised classifier trained on 1828–11,459 annotated cells (−0.002 to −0.053 of averaged weighted F1-score, Wilcoxon rank-sum test, P = 0.31). Leveraging the immune checkpoint markers stained in ovarian cancer slides, SANDI-based cell identification reveals spatial expulsion between PD1-expressing T helper cells and T regulatory cells, suggesting an interplay between PD1 expression and T regulatory cell-mediated immunosuppression. Interpretation: By striking a fine balance between minimal expert guidance and the power of deep learning to learn similarity within abundant data, SANDI presents new opportunities for efficient, large-scale learning for histology multiplex imaging data. Funding: This study was funded by the Royal Marsden/ ICR National Institute of Health Research Biomedical Research Centre. © 2023 The Authors","Cell classification; Deep learning; Imaging mass cytometry; Multiplex imaging; Multiplex immunohistochemistry; Self-supervised learning","Biomedical Research; Deep Learning; Female; Humans; Immunophenotyping; Immunosuppression Therapy; Ovarian Neoplasms; CD8 antigen; transcription factor FOXP3; algorithm; antigen detection; Article; artificial neural network; cell differentiation; computer assisted tomography; controlled study; cytokine production; deep learning; dendritic cell; glycolysis; helper cell; histology; histopathology; human; human cell; human tissue; immunohistochemistry; immunophenotyping; immunosuppressive treatment; learning algorithm; mass cytometry; myeloma; ovary cancer; overall survival; regulatory T lymphocyte; squamous cell lung carcinoma; support vector machine; Th17 cell; tumor microenvironment; female; immunophenotyping; medical research; ovary tumor","ICR National Institute of Health Research Biomedical Research Centre; The Royal Marsden; National Institutes of Health, NIH, (BC132057, R01 CA185138, U54 CA217376); National Institutes of Health, NIH; Children's Cancer and Leukaemia Group, CCLG, (CCLGA201906); Children's Cancer and Leukaemia Group, CCLG; Royal Marsden NHS Foundation Trust; Cancer Research UK, CRUK, (C25858/A28592, C56167/A29363, C9203/A28770, CRUK C45982/A21808); Cancer Research UK, CRUK; University College London, UCL; European Commission, EC, (H2020-MSCA-ITN-2019); European Commission, EC; Rosetrees Trust, (A2714); Rosetrees Trust; Breast Cancer Now, (2015NovPR638); Breast Cancer Now; UCLH Biomedical Research Centre, NIHR BRC","","Elsevier B.V.","37672979"
"Wu D.; Han M.; Song H.; Song L.; Duan Y.","Wu, Dihua (57210377164); Han, Mengxuan (57221916841); Song, Huaibo (17342958900); Song, Lei (57211428262); Duan, Yuanchao (57543631300)","57210377164; 57221916841; 17342958900; 57211428262; 57543631300","Monitoring the respiratory behavior of multiple cows based on computer vision and deep learning","2023","106","4","","2963","2979","16","10.3168/jds.2022-22501","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148610596&doi=10.3168%2fjds.2022-22501&partnerID=40&md5=a02248a7bc92c34f60177a88fca54542","Automatic respiration monitoring of dairy cows in modern farming not only helps to reduce manual labor but also increases the automation of health assessment. It is common for cows to congregate on farms, which poses a challenge for manual observation of cow status because they physically occlude each other. In this study, we propose a method that can monitor the respiratory behavior of multiple cows. Initially, 4,000 manually labeled images were used to fine-tune the YOLACT (You Only Look At CoefficienTs) model for recognition and segmentation of multiple cows. Respiratory behavior in the resting state could better reflect their health status. Then, the specific resting states (lying resting, standing resting) of different cows were identified by fusing the convolutional neural network and bidirectional long and short-term memory algorithms. Finally, the corresponding detection algorithms (lying and standing resting) were used for respiratory behavior monitoring. The test results of 60 videos containing different interference factors indicated that the accuracy of respiratory behavior monitoring of multiple cows in 54 videos was >90.00%, and that of 4 videos was 100.00%. The average accuracy of the proposed method was 93.56%, and the mean absolute error and root mean square error were 3.42 and 3.74, respectively. Furthermore, the effectiveness of the method was analyzed for simultaneous monitoring of respiratory behavior of multiple cows under movement, occlusion disturbance, and behavioral changes. It was feasible to monitor the respiratory behavior of multiple cows based on the proposed algorithm. This study could provide an a priori technical basis for respiratory behavior monitoring and automatic diagnosis of respiratory-related diseases of multiple dairy cows based on biomedical engineering technology. In addition, it may stimulate researchers to develop robots with health-sensing functions that are oriented toward precision livestock farming. © 2023 American Dairy Science Association","computer vision; deep learning; multiple dairy cows; respiratory behavior monitoring","Animals; Behavior, Animal; Cattle; Computers; Dairying; Deep Learning; Feeding Behavior; Female; animal; animal behavior; bovine; computer; dairying; feeding behavior; female; procedures","National Natural Science Foundation of China, NSFC, (32272931); National Key Research and Development Program of China, NKRDPC, (2017YFD0701603); Fundamental Research Funds for the Central Universities, (2452019027)","","Elsevier Inc.","36797189"
"Lou A.; Tawfik K.; Yao X.; Liu Z.; Noble J.","Lou, Ange (57219733410); Tawfik, Kareem (54581853500); Yao, Xing (57799987100); Liu, Ziteng (57216910519); Noble, Jack (22635393500)","57219733410; 54581853500; 57799987100; 57216910519; 22635393500","Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network for Surgical Tools Segmentation","2023","42","10","","2832","2841","9","10.1109/TMI.2023.3266137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153376347&doi=10.1109%2fTMI.2023.3266137&partnerID=40&md5=71b5f50cdf8ff5dfb61db7235caeed5b","A common problem with segmentation of medical images using neural networks is the difficulty to obtain a significant number of pixel-level annotated data for training. To address this issue, we proposed a semi-supervised segmentation network based on contrastive learning. In contrast to the previous state-of-the-art, we introduce Min-Max Similarity (MMS), a contrastive learning form of dual-view training by employing classifiers and projectors to build all-negative, and positive and negative feature pairs, respectively, to formulate the learning as solving a MMS problem. The all-negative pairs are used to supervise the networks learning from different views and to capture general features, and the consistency of unlabeled predictions is measured by pixel-wise contrastive loss between positive and negative pairs. To quantitatively and qualitatively evaluate our proposed method, we test it on four public endoscopy surgical tool segmentation datasets and one cochlear implant surgery dataset, which we manually annotated. Results indicate that our proposed method consistently outperforms state-of-the-art semi-supervised and fully supervised segmentation algorithms. And our semi-supervised segmentation algorithm can successfully recognize unknown surgical tools and provide good predictions. Also, our MMS approach could achieve inference speeds of about 40 frames per second (fps) and is suitable to deal with the real-time video segmentation.  © 1982-2012 IEEE.","Contrastive learning; min-max similarity; real time; semi-supervised; surgical tool segmentation","Algorithms; Deep Learning; Image Processing, Computer-Assisted; Neural Networks, Computer; Supervised Machine Learning; Cochlear implants; Deep learning; Medical imaging; Pixels; Robotic surgery; Statistical tests; Surgical equipment; Transplantation (surgical); Biomedical imaging; Contrastive learning; Features extraction; Images segmentations; Min-max; Min-max similarity; Neural-networks; Real- time; Semi-supervised; Surgical tool segmentation; Surgical tools; Article; deep learning; feature extraction; image segmentation; implantation; laparoscopy; leave one out cross validation; min max similarity algorithm; qualitative analysis; quantitative analysis; robot assisted surgery; segmentation algorithm; semi supervised machine learning; videorecording; algorithm; artificial neural network; image processing; supervised machine learning; Image segmentation","National Institute on Deafness and Other Communication Disorders, NIDCD, (R01DC014037); National Institute on Deafness and Other Communication Disorders, NIDCD","","Institute of Electrical and Electronics Engineers Inc.","37037256"
"Yu K.-L.; Tseng Y.-S.; Yang H.-C.; Liu C.-J.; Kuo P.-C.; Lee M.-R.; Huang C.-D.; Kuo L.-C.; Wang J.-Y.; Ho C.-C.; Shih J.-Y.; Yu C.-J.","Yu, Kai-Lun (57161758200); Tseng, Yi-Shiuan (58516803300); Yang, Han-Ching (57438310000); Liu, Chia-Jung (57192641560); Kuo, Po-Chih (56335546800); Lee, Meng-Rui (43861409600); Huang, Chun-Da (58516490800); Kuo, Lu-Cheng (8161056900); Wang, Jann-Yuan (41462069600); Ho, Chao-Chi (7404653038); Shih, Jin-Yuan (57466329000); Yu, Chong-Jen (7404977466)","57161758200; 58516803300; 57438310000; 57192641560; 56335546800; 43861409600; 58516490800; 8161056900; 41462069600; 7404653038; 57466329000; 7404977466","Deep learning with test-time augmentation for radial endobronchial ultrasound image differentiation: a multicentre verification study","2023","10","1","e001602","","","","10.1136/bmjresp-2022-001602","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166433956&doi=10.1136%2fbmjresp-2022-001602&partnerID=40&md5=1a0d2c57a5cfaaafa4908e62e1d5ae5e","Purpose Despite the importance of radial endobronchial ultrasound (rEBUS) in transbronchial biopsy, researchers have yet to apply artificial intelligence to the analysis of rEBUS images. Materials and methods This study developed a convolutional neural network (CNN) to differentiate between malignant and benign tumours in rEBUS images. This study retrospectively collected rEBUS images from medical centres in Taiwan, including 769 from National Taiwan University Hospital Hsin-Chu Branch, Hsinchu Hospital for model training (615 images) and internal validation (154 images) as well as 300 from National Taiwan University Hospital (NTUH-TPE) and 92 images were obtained from National Taiwan University Hospital Hsin-Chu Branch, Biomedical Park Hospital (NTUH-BIO) for external validation. Further assessments of the model were performed using image augmentation in the training phase and test-time augmentation (TTA). Results Using the internal validation dataset, the results were as follows: area under the curve (AUC) (0.88 (95% CI 0.83 to 0.92)), sensitivity (0.80 (95% CI 0.73 to 0.88)), specificity (0.75 (95% CI 0.66 to 0.83)). Using the NTUH-TPE external validation dataset, the results were as follows: AUC (0.76 (95% CI 0.71 to 0.80)), sensitivity (0.58 (95% CI 0.50 to 0.65)), specificity (0.92 (95% CI 0.88 to 0.97)). Using the NTUH-BIO external validation dataset, the results were as follows: AUC (0.72 (95% CI 0.64 to 0.82)), sensitivity (0.71 (95% CI 0.55 to 0.86)), specificity (0.76 (95% CI 0.64 to 0.87)). After fine-tuning, the AUC values for the external validation cohorts were as follows: NTUH-TPE (0.78) and NTUH-BIO (0.82). Our findings also demonstrated the feasibility of the model in differentiating between lung cancer subtypes, as indicated by the following AUC values: adenocarcinoma (0.70; 95% CI 0.64 to 0.76), squamous cell carcinoma (0.64; 95% CI 0.54 to 0.74) and small cell lung cancer (0.52; 95% CI 0.32 to 0.72). Conclusions Our results demonstrate the feasibility of the proposed CNN-based algorithm in differentiating between malignant and benign lesions in rEBUS images.  © 2023 BMJ Publishing Group. All rights reserved.","bronchoscopy; lung cancer","Artificial Intelligence; Deep Learning; Humans; Lung Neoplasms; Neural Networks, Computer; Retrospective Studies; fentanyl; lidocaine; midazolam; adult; area under the curve; Article; artificial intelligence; augmentation index; benign neoplasm; bronchoscopy; controlled study; convolutional neural network; deep learning; diagnostic test accuracy study; endobronchial ultrasonography; female; human; image analysis; major clinical study; male; middle aged; multicenter study; sensitivity and specificity; small cell lung cancer; squamous cell carcinoma; Taiwan; training; university hospital; validation process; artificial neural network; clinical trial; diagnostic imaging; lung tumor; retrospective study","National Tsing Hua University, NTHU, (111F7MDKE1); National Taiwan University Hospital Hsin-Chu Branch, (111-HCH095)","","BMJ Publishing Group","37532473"
"Khouy M.; Jabrane Y.; Ameur M.; Hajjam El Hassani A.","Khouy, Mohammed (58627999800); Jabrane, Younes (22937642900); Ameur, Mustapha (57201741115); Hajjam El Hassani, Amir (26429325600)","58627999800; 22937642900; 57201741115; 26429325600","Medical Image Segmentation Using Automatic Optimized U-Net Architecture Based on Genetic Algorithm","2023","13","9","1298","","","","10.3390/jpm13091298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172868048&doi=10.3390%2fjpm13091298&partnerID=40&md5=184c8c0c9e72dc997378cc1d81d92615","Image segmentation is a crucial aspect of clinical decision making in medicine, and as such, it has greatly enhanced the sustainability of medical care. Consequently, biomedical image segmentation has become a prominent research area in the field of computer vision. With the advent of deep learning, many manual design-based methods have been proposed and have shown promising results in achieving state-of-the-art performance in biomedical image segmentation. However, these methods often require significant expert knowledge and have an enormous number of parameters, necessitating substantial computational resources. Thus, this paper proposes a new approach called GA-UNet, which employs genetic algorithms to automatically design a U-shape convolution neural network with good performance while minimizing the complexity of its architecture-based parameters, thereby addressing the above challenges. The proposed GA-UNet is evaluated on three datasets: lung image segmentation, cell nuclei segmentation in microscope images (DSB 2018), and liver image segmentation. Interestingly, our experimental results demonstrate that the proposed method achieves competitive performance with a smaller architecture and fewer parameters than the original U-Net model. It achieves an accuracy of 98.78% for lung image segmentation, 95.96% for cell nuclei segmentation in microscope images (DSB 2018), and 98.58% for liver image segmentation by using merely 0.24%, 0.48%, and 0.67% of the number of parameters in the original U-Net architecture for the lung image segmentation dataset, the DSB 2018 dataset, and the liver image segmentation dataset, respectively. This reduction in complexity makes our proposed approach, GA-UNet, a more viable option for deployment in resource-limited environments or real-world implementations that demand more efficient and faster inference times. © 2023 by the authors.","convolutional neural networks (CNNs); genetic algorithms (GAs); medical image segmentation; U-Net","article; cell nucleus; convolutional neural network; genetic algorithm; image segmentation; liver; lung; microscope image; resource limited setting","","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Navaneethakrishnan M.; Anand M.V.; Vasavi G.; Rani V.V.","Navaneethakrishnan, M. (57219354649); Anand, M. Vijay (57751198900); Vasavi, G. (57201994187); Rani, V. Vasudha (57209498941)","57219354649; 57751198900; 57201994187; 57209498941","Deep Fuzzy SegNet-based lung nodule segmentation and optimized deep learning for lung cancer detection","2023","26","3","","1143","1159","16","10.1007/s10044-023-01135-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148643156&doi=10.1007%2fs10044-023-01135-1&partnerID=40&md5=3ae0ca1d2b5223f2110b7e7edbc2668f","Globally, lung cancer has a high fatality rate and is a lethal disease. Since lung cancer affects both men and women, it requires extra consideration when evaluating various diseases. Furthermore, early detection is even more important in order to increase the survival percentage of affected patients. There are many methods for detecting lung cancer, but it can be difficult to locate the affected area due to low visibility of the tumor section and imaging failure rates. Due to poor image quality, which distorts the segmentation process, the standard strategies failed to increase the accuracy rate. In order to diagnose lung cancer disease, this research created an approach known as Bat Deer Hunting Optimization Algorithm-based Deep Convolutional Neural Network (BDHOA-based DCNN). Here, Computed Tomography pictures are used to predict the presence of lung cancer. The Bat Algorithm (BA) and Deer Hunting Optimization Algorithm have been integrated into the newly developed BDHOA algorithm (DHOA). To execute the lung cancer detection and classification, the lung lobe and nodule region is segmented from the lung picture. With accuracy, sensitivity, and specificity scores of 0.9243, 0.9421, and 0.8915, the suggested approach performed better. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Biomedical image processing; DEEP fuzzy clustering; Deep learning; DEER hunting optimization algorithm; Lung cancer; Lung nodule segmentation","","","","Springer Science and Business Media Deutschland GmbH",""
"Franceschini S.; Autorino M.M.; Ambrosanio M.; Pascazio V.; Baselice F.","Franceschini, Stefano (57210950263); Autorino, Maria Maddalena (57483413000); Ambrosanio, Michele (56198620800); Pascazio, Vito (7003486376); Baselice, Fabio (57204648639)","57210950263; 57483413000; 56198620800; 7003486376; 57204648639","A Deep Learning Approach for Diagnosis Support in Breast Cancer Microwave Tomography","2023","13","10","1693","","","","10.3390/diagnostics13101693","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160575766&doi=10.3390%2fdiagnostics13101693&partnerID=40&md5=30f98df3c168f42a7d8eb62b2296cbca","In this paper, a deep learning technique for tumor detection in a microwave tomography framework is proposed. Providing an easy and effective imaging technique for breast cancer detection is one of the main focuses for biomedical researchers. Recently, microwave tomography gained a great attention due to its ability to reconstruct the electric properties maps of the inner breast tissues, exploiting nonionizing radiations. A major drawback of tomographic approaches is related to the inversion algorithms, since the problem at hand is nonlinear and ill-posed. In recent decades, numerous studies focused on image reconstruction techniques, in same cases exploiting deep learning. In this study, deep learning is exploited to provide information about the presence of tumors based on tomographic measures. The proposed approach has been tested with a simulated database showing interesting performances, in particular for scenarios where the tumor mass is particularly small. In these cases, conventional reconstruction techniques fail in identifying the presence of suspicious tissues, while our approach correctly identifies these profiles as potentially pathological. Therefore, the proposed method can be exploited for early diagnosis purposes, where the mass to be detected can be particularly small. © 2023 by the authors.","artificial intelligence; biomedical imaging; breast cancer detection; electromagnetic inverse scattering; microwave tomography; neural networks","Article; artificial intelligence; artificial neural network; breast cancer; cancer diagnosis; clinical outcome; conductance; controlled study; deep learning; diagnostic accuracy; diagnostic test accuracy study; entropy; female; human; image reconstruction; imaging algorithm; microwave radiation; positivity rate; sensitivity and specificity; tomography; tumor volume","","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Satapathy S.K.; Vyas D.; Rajput N.S.; Kumar Shah G.; Gevariya A.K.; Kishan Kondaveeti H.","Satapathy, Santosh Kumar (57216801019); Vyas, Dev (58908711900); Rajput, Nitin Singh (57197365834); Kumar Shah, Gaurav (58908554000); Gevariya, Anupam Kumar (58908252100); Kishan Kondaveeti, Hari (57192006472)","57216801019; 58908711900; 57197365834; 58908554000; 58908252100; 57192006472","Deep Convolutional Neural Network for Multi-class Classification of Motor Imagery from EEG Signals","2023","","","","","","","10.1109/ICRASET59632.2023.10420144","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186077264&doi=10.1109%2fICRASET59632.2023.10420144&partnerID=40&md5=2c1b7ec8be595f7ac9e4cee7197000d3","The Brain-Computer Interface (BCI) technology employs EEG signals to study brain behavior and interact with machines for various purposes that may enhance the human body's cognition behavior. It is essential to analyze the EEG signal for motor imagery patterns. However, traditional motor imagery (MI) based electroencephalogram (EEG) analysis highly depends on EEG feature extraction and classification. Sometimes it may lose some vital feature information, making it challenging to analyze the subject's behavior. In recent research progress, deep learning approaches mainly produced outperformed results in the BCI system for the detection and analysis of motor imagery signals. This research proposes an automated MI-EEG pattern classification system using a convolutional neural network (CNN). The entire experiments based carried out using the Physionet dataset, which the BCI2000 system developers obtained. Experiment results signify that the proposed MI-EEG classification using the CNN model is more feasible and well-performed, incomparable to the traditional machine learning algorithms. © 2023 IEEE.","Classification; Convolutional Neural Network; Deep Learning; Electroencephalogram; Motor Imagery","Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Image analysis; Image classification; Learning algorithms; Learning systems; Convolutional neural network; Deep learning; Electroencephalogram analysis; Electroencephalogram signals; Feature extraction and classification; Feature information; Human bodies; Interface technology; Motor imagery; Multi-class classification; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Le D.; Truong S.; Brijesh P.; Adjeroh D.A.; Le N.","Le, Duc (57938069100); Truong, Sang (57255674900); Brijesh, Patel (36114757600); Adjeroh, Donald A. (6701456737); Le, Ngan (57214452870)","57938069100; 57255674900; 36114757600; 6701456737; 57214452870","SCL-ST: Supervised Contrastive Learning with Semantic Transformations for Multiple Lead ECG Arrhythmia Classification","2023","27","6","","2818","2828","10","10.1109/JBHI.2023.3246241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149460858&doi=10.1109%2fJBHI.2023.3246241&partnerID=40&md5=8096c3e378faecbf9698c89a9576099e","The automatic classification of electrocardiogram (ECG) signals has played an important role in cardiovascular diseases diagnosis and prediction. With recent advancements in deep neural networks (DNNs), particularly Convolutional Neural Networks (CNNs), learning deep features automatically from the original data is becoming an effective and widespread approach in a variety of intelligent tasks including biomedical and health informatics. However, most of the existing approaches are trained on either 1D CNNs or 2D CNNs, and they suffer from the limitations of random phenomena (i.e. random initial weights). Furthermore, the ability to train such DNNs in a supervised manner in healthcare is often limited due to the scarcity of labeled training data. To address the problems of weight initialization and limited annotated data, in this work, we leverage recent self-supervised learning technique, namely, contrastive learning, and present supervised contrastive learning (sCL). Different from existing self-supervised contrastive learning approaches, which often generate false negatives because of random selection of negative anchors, our contrastive learning makes use of labeled data to pull the same class closer together and push different classes far apart to avoid potential false negatives. Furthermore, unlike other kinds of signals (e.g. speech, image, video), ECG signal is sensitive to changes, and inappropriate transformation could directly affect diagnosis results. To deal with this issue, we present two semantic transformations, i.e. semantic split-join and semantic weighted peaks noise smoothing. The proposed deep neural network sCL-ST with supervised contrastive learning and semantic transformations is trained as an end-to-end framework for the multi-label classification of 12-lead ECGs. Our sCL-ST network contains two sub-networks i.e. pre-text task and down-stream task. Our experimental results have been evaluated on 12-lead PhysioNet 2020 dataset and shown that our proposed network outperforms the state-of-the-art existing approaches.  © 2013 IEEE.","arrhythmia classification; contrastive learning; ECG; multiple lead; self-supervised learning","Arrhythmias, Cardiac; Electrocardiography; Humans; Medical Informatics; Neural Networks, Computer; Semantics; Classification (of information); Computer aided diagnosis; Deep neural networks; Diseases; Recurrent neural networks; Semantics; Supervised learning; RNA polymerase II; Arrhythmia classification; Contrastive learning; Convolutional neural network; Deep learning; Electrocardiogram signal; Lead; Multiple lead; Self-supervised learning; Semantic transformation; Task analysis; ablation therapy; accuracy; algorithm; anticoagulation; Article; artificial intelligence; artificial neural network; cardiovascular disease; classification; classification algorithm; controlled study; data base; deep learning; deep neural network; diagnostic test accuracy study; electrocardiogram; electroencephalography; entropy; false negative result; fine needle aspiration biopsy; health care industry; heart arrhythmia; heart infarction; heart rhythm; human; intensive care unit; learning; learning algorithm; machine learning; mathematical analysis; mathematical model; medical informatics; multilabel classification; nerve cell network; noise; nonhuman; P wave; recurrent neural network; semantics; sinus rhythm; speech; support vector machine; training; transcription elongation; videorecording; electrocardiography; heart arrhythmia; medical informatics; Electrocardiograms","National Science Foundation, NSF, (1920920, OIA-1946391); National Science Foundation, NSF","","Institute of Electrical and Electronics Engineers Inc.","37028019"
"Pinasthika K.; Sofyanda E.Y.; Ulumiyah S.; Muflikhah L.","Pinasthika, Krisna (58609382700); Sofyanda, Erika Yussi (58813081500); Ulumiyah, Silfiatul (58813214600); Muflikhah, Lailil (35119270600)","58609382700; 58813081500; 58813214600; 35119270600","Deep Learning Approach for High Recall Pneumonia Classification with Swin Transformer and L2 Regularization","2023","","","","190","195","5","10.1145/3626641.3626670","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182403381&doi=10.1145%2f3626641.3626670&partnerID=40&md5=a385021d2bfc0bdedcbd967bab5c090e","Pneumonia is one of the lung infections that can be lethal to people. Pneumonia can be diagnosed by conducting an X-ray scan of the human chest. Even though X-ray scanning is straightforward, the process of identifying pneumonia in X-ray data is still difficult to do even by radiologists. Therefore, a computational algorithm is needed that can be used to analyze X-ray image data. The use of Deep Learning (DL) methods for analyzing images has been proven to work well in various cases, especially X-ray data. Based on previous research, the transformer architecture has the advantage of analyzing with a larger receptive area if compared to Convolutional Neural Networks (CNN) which have limited kernel size. In this study, we used the Swin transformer in classifying pneumonia diseases through X-ray images. Through the study conducted, the Swin Transformer Architecture is able to provide a fairly good evaluation metric when compared to the use of convolutional neural networks. The Tiny variant of the Swin Transformer architecture is able to provide evaluation metrics with a precision value of 0.870, recall of 0.995, and F1-Score of 0.928. On the other hand, the use of L2 regularization in stage 3 and stage 4 of the Swin Tiny architecture is able to provide a high recall value of 0.997, but the use of L2 regularization does not provide an increase in precision and F1-Score. In biomedical cases that are only concerned with recall values, the use of L2 regularization on Swin Tiny can provide advantages. © 2023 ACM.","Computer vision; L2 Regularization; Pneumonia classification; Swin Transformer","Convolution; Convolutional neural networks; Deep learning; Image analysis; Network architecture; Convolutional neural network; Evaluation metrics; F1 scores; L2 regularization; Learning approach; Pneumonia classification; Regularisation; Swin transformer; X ray data; X-ray image; Computer vision","","","Association for Computing Machinery",""
"Çiğ H.; Güllüoğlu M.T.; Er M.B.; Kuran U.; Kuran E.C.","Çiğ, Harun (57200138132); Güllüoğlu, Mehmet Tahir (6603160891); Er, Mehmet Bilal (57200138180); Kuran, Umut (57200140755); Kuran, Emre Can (57226394399)","57200138132; 6603160891; 57200138180; 57200140755; 57226394399","Enhanced Disease Detection Using Contrast Limited Adaptive Histogram Equalization and Multi-Objective Cuckoo Search in Deep Learning","2023","40","3","","915","925","10","10.18280/ts.400308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166331049&doi=10.18280%2fts.400308&partnerID=40&md5=b8b773a898167f7271dcea6056e57f92","Delayed diagnosis of numerous diseases often results in postponed treatment, adversely affecting patient outcomes. By analyzing biological signals and patient photographs, critical information about an individual's health or the severity of a medical condition can be obtained for various diseases. Signals from Electroencephalography (EEG), Electrocardiography (ECG), and Electrooculography (EOG) can be used to predict and diagnose disorders related to the brain, heart, eyes, muscles, and nervous system. Additionally, biomedical images acquired through X-ray, ultrasound, and magnetic resonance imaging can be utilized for disease diagnosis and detection with the help of image processing techniques, artificial intelligence, and deep learning methods. In this study, we propose a novel approach that combines the Contrast Limited Adaptive Histogram Equalization (CLAHE) algorithm and Multi-Objective Cuckoo Search (MOCS) with Convolutional neural networks (CNNs) to achieve highly accurate disease classification using chest X-ray images. Our method begins by applying a contrast enhancement strategy, specifically, the CLAHE algorithm, with MOCS for optimal parameter selection to attain the highest classification performance. Subsequently, contrast-enhanced images are fed into the CNNs to further improve image quality and classification accuracy. Our approach is employed to categorize three types of chest X-ray images, namely, unhealthy, normal (healthy), and pneumonia. To assess the performance of our proposed method, we utilize the widely-used ""COVID-19 Radiography"" dataset. Experimental results yield an accuracy rate of 99.16%, a precision rate of 99.20%, and a sensitivity rate of 98.99%. These findings demonstrate that our proposed model outperforms existing techniques in the literature and can be effectively employed for disease detection and classification. © 2023 Lavoisier. All rights reserved.","Convolutional neural network (CNN); hybrid CNN; multi-objective cuckoo search algorithm optimization (MOCS)","Biomedical signal processing; Convolution; Convolutional neural networks; Deep learning; Electrocardiography; Electrophysiology; Equalizers; Graphic methods; Image enhancement; Learning algorithms; Learning systems; Medical imaging; Multiobjective optimization; Patient treatment; Adaptive histograms; Algorithms optimizations; Convolutional neural network; Cuckoo search algorithms; Disease detection; Hybrid convolutional neural network; Multi objective; Multi-objective cuckoo search algorithm optimization; Electroencephalography","","","International Information and Engineering Technology Association",""
"Bhattacharjee A.; Murugan R.; Goel T.; Mirjalili S.","Bhattacharjee, Ananya (57207992340); Murugan, R. (37061613800); Goel, Tripti (55787396200); Mirjalili, Seyedali (51461922300)","57207992340; 37061613800; 55787396200; 51461922300","Pulmonary Nodule Segmentation Framework Based on Fine-Tuned and Pretrained Deep Neural Network Using CT Images","2023","7","4","","394","409","15","10.1109/TRPMS.2023.3236719","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147272798&doi=10.1109%2fTRPMS.2023.3236719&partnerID=40&md5=74d6812aeccb3b0b160d86a16ae7fcab","Deep learning is one of the most rapidly growing and emerging technologies in pulmonary nodule segmentation. However, the different shape, size, and location of the nodules make it extremely difficult to segment correctly. The purpose of this study is to obtain a fast and accurate segmentation algorithm with less number of stages. A fine-tuned dual skip connection-based segmentation framework is proposed that integrates pretrained residual neural network (ResNet) 152 with the U-Net architecture, namely, ResiU-Net. Nine different pretrained and fine-tuned encoder backbones, such as ResNet18, ResNet 34, ResNet 50, ResNet 101, ResNet 152, SEResNet18, SE-ResNet34, ResNext 101, and ResNext 50 are compared and the proposed ResiU-Net approach gives the best results. Also, the fine-tuned ResiU-Net performs better than nontuned ResiU-Net. 1224 computed tomography patient images with different nodule shapes and sizes are selected. The proposed method achieves 97.44% F score, 95.02% intersection over union score, 94.87% dice score, 0.34% binary cross-entropy loss, and 0.7585 combined dice coefficient and binary focal loss. The proposed ResiU-Net outperforms the state-of-the-art methods and reports the best evaluation metrics. The time taken by the model to train is 43 min. Hence, the proposed model is a fast and accurate segmentation approach.  © 2017 IEEE.","Lung; nodule; pretrained; residual neural network (ResNet); segmentation; U-Net","Biological organs; Computer architecture; Computerized tomography; Deep neural networks; Diseases; Medical imaging; Network architecture; Positron emission tomography; Biomedical imaging; Cancer; Computed tomography; Images segmentations; Lung; Lung Cancer; Nodule; Pretrained; Resnet; Segmentation; U-net; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Liang T.; Yu X.; Liu X.; Wang H.; Liu X.; Dong B.","Liang, Tie (55230288100); Yu, Xionghui (58543076600); Liu, Xiaoguang (57219874219); Wang, Hongrui (9736821600); Liu, Xiuling (35115326500); Dong, Bin (57207453350)","55230288100; 58543076600; 57219874219; 9736821600; 35115326500; 57207453350","EEG-CDILNet: a lightweight and accurate CNN network using circular dilated convolution for motor imagery classification","2023","20","4","046031","","","","10.1088/1741-2552/acee1f","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168428355&doi=10.1088%2f1741-2552%2facee1f&partnerID=40&md5=09822cff9a146b8f874cc55ad06843df","Objective. The combination of the motor imagery (MI) electroencephalography (EEG) signals and deep learning-based methods is an effective way to improve MI classification accuracy. However, deep learning-based methods often need too many trainable parameters. As a result, the trade-off between the network decoding performance and computational cost has always been an important challenge in the MI classification research. Approach. In the present study, we proposed a new end-to-end convolutional neural network (CNN) model called the EEG-circular dilated convolution (CDIL) network, which takes into account both the lightweight model and the classification accuracy. Specifically, the depth-separable convolution was used to reduce the number of network parameters and extract the temporal and spatial features from the EEG signals. CDIL was used to extract the time-varying deep features that were generated in the previous stage. Finally, we combined the features extracted from the two stages and used the global average pooling to further reduce the number of parameters, in order to achieve an accurate MI classification. The performance of the proposed model was verified using three publicly available datasets. Main results. The proposed model achieved an average classification accuracy of 79.63% and 94.53% for the BCIIV2a and HGD four-classification task, respectively, and 87.82% for the BCIIV2b two-classification task. In particular, by comparing the number of parameters, computation and classification accuracy with other lightweight models, it was confirmed that the proposed model achieved a better balance between the decoding performance and computational cost. Furthermore, the structural feasibility of the proposed model was confirmed by ablation experiments and feature visualization. Significance. The results indicated that the proposed CNN model presented high classification accuracy with less computing resources, and can be applied in the MI classification research. © 2023 IOP Publishing Ltd","convolutional neural networks (CNN); electroencephalography (EEG); lightweight network; motor imagery (MI)","Algorithms; Brain-Computer Interfaces; Electroencephalography; Imagination; Movement; Neural Networks, Computer; Biomedical signal processing; Convolution; Convolutional neural networks; Decoding; Deep learning; Economic and social effects; Electrophysiology; Image classification; Image enhancement; Learning systems; Neural network models; Classification accuracy; Convolutional neural network; Decoding performance; Electroencephalography; Learning-based methods; Lightweight network; Motor imagery; Motor imagery classification; article; convolutional neural network; electroencephalogram; electroencephalography; feasibility study; human; human experiment; imagery; algorithm; artificial neural network; imagination; movement (physiology); procedures; Electroencephalography","Key project of Hebei province Department of Education, (ZD2020146); Natural Science Foundation of Hebei Province, (F2021201002); National Key Research and Development Program of China, NKRDPC, (2017YFB1401200)","","Institute of Physics","37552978"
"Shin J.; Chung W.","Shin, Jinhyo (57698789400); Chung, Wonzoo (22970471800)","57698789400; 22970471800","Multi-Band CNN with Band-Dependent Kernels and Amalgamated Cross Entropy Loss for Motor Imagery Classification","2023","27","9","","4466","4477","11","10.1109/JBHI.2023.3292909","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164397422&doi=10.1109%2fJBHI.2023.3292909&partnerID=40&md5=71042dff4386245d5ed9348415f18e24","In this paper, we present a novel MI classification method based on multi-band convolutional neural network (CNN) with band-dependent kernel sizes, named MBK-CNN, to improve classification performance, by resolving the subject dependency issue of the widely used CNN-based approaches due to the kernel size optimization problem. The proposed structure exploits the frequency diversity of the EEG signals and simultaneously resolves the subject dependent kernel size issue. EEG signal is decomposed into overlapping multi-band and passed through multiple CNNs (termed 'branch-CNNs') with different kernel sizes to generate frequency dependent features, which are combined by a simple weighted sum. In contrast to the existing works where single-band multi-branch CNNs with different kernel sizes are used to resolve the subject dependency issue, a unique kernel size per frequency band is used. To prevent possible overfitting induced by a weighted sum, each branch-CNN is additionally trained by tentative cross entropy loss while overall network is optimized by the end-to-end cross entropy loss, which is named amalgamated cross entropy loss. In addition, we further propose multi-band CNN with enhanced spatial diversity, named MBK-LR-CNN, by replacing each branch-CNN with several sub branch-CNNs applied for channel subsets (termed 'local region') to improve the classification performance. We evaluated the performance of the proposed methods, MBK-CNN and MBK-LR-CNN, on publicly available datasets, BCI Competition IV dataset 2a and High Gamma Dataset. The experimental results confirm the performance improvement of the proposed methods compared to the currently existing MI classification methods.  © 2013 IEEE.","Brain-Computer interface (BCI); convolutional neural network (CNN); electroencephalography (EEG); kernel size; motor imagery (MI); multi-band","Algorithms; Brain-Computer Interfaces; Electroencephalography; Entropy; Humans; Imagination; Neural Networks, Computer; Biomedical signal processing; Brain computer interface; Deep learning; Electroencephalography; Electrophysiology; Entropy; Image classification; Interfaces (computer); Neural networks; Brain-computer interface; Convolutional neural network; Electroencephalography; Features extraction; Kernel; Kernel size; Motor imagery; Multi band; Signal resolution; accuracy; algorithm; Article; artificial neural network; convolutional neural network; electroencephalogram; electroencephalography; entropy; feature extraction; human; imagery; imaging; learning algorithm; signal noise ratio; support vector machine; algorithm; entropy; imagination; procedures; Convolution","","","Institute of Electrical and Electronics Engineers Inc.","37410639"
"Sharma M.; Verma S.; Anand D.; Gadre V.M.; Acharya U.R.","Sharma, Manish (7403269252); Verma, Sarv (58522739900); Anand, Divyansh (58522821500); Gadre, Vikram M. (9633318200); Acharya, U. Rajendra (7004510847)","7403269252; 58522739900; 58522821500; 9633318200; 7004510847","CAPSCNet: A novel scattering network for automated identification of phasic cyclic alternating patterns of human sleep using multivariate EEG signals","2023","164","","107259","","","","10.1016/j.compbiomed.2023.107259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166732451&doi=10.1016%2fj.compbiomed.2023.107259&partnerID=40&md5=8d68d45066c3b9b4207277f6d47925ae","The Cyclic Alternating Pattern (CAP) can be considered a physiological marker of sleep instability. The CAP can examine various sleep-related disorders. Certain short events (A and B phases) manifest related to a specific physiological process or pathology during non-rapid eye movement (NREM) sleep. These phases unexpectedly modify EEG oscillations; hence, manual detection is challenging. Therefore, it is highly desirable to have an automated system for detecting the A-phases (AP). Deep convolution neural networks (CNN) have shown high performance in various healthcare applications. A variant of the deep neural network called the Wavelet Scattering Network (WSN) has been used to overcome the specific limitations of CNN, such as the need for a large amount of data to train the model. WSN is an optimized network that can learn features that help discriminate patterns hidden inside signals. Also, WSNs are invariant to local perturbations, making the network significantly more reliable and effective. It can also help improve performance on tasks where data is minimal. In this study, we proposed a novel WSN-based CAPSCNet to automatically detect AP using EEG signals. Seven dataset variants of cyclic alternating pattern (CAP) sleep cohort is employed for this study. Two electroencephalograms (EEG) derivations, namely: C4-A1 and F4-C4, are used to develop the CAPSCNet. The model is examined using healthy subjects and patients tormented by six different sleep disorders, namely: sleep-disordered breathing (SDB), insomnia, nocturnal frontal lobe epilepsy (NFLE), narcolepsy, periodic leg movement disorder (PLM) and rapid eye movement behavior disorder (RBD) subjects. Several different machine-learning algorithms were used to classify the features obtained from the WSN. The proposed CAPSCNet has achieved the highest average classification accuracy of 83.4% using a trilayered neural network classifier for the healthy data variant. The proposed CAPSCNet is efficient and computationally faster. © 2023 Elsevier Ltd","CAP; Cyclic alternating patterns; EEG; Scattering network; Sleep","Electroencephalography; Humans; Polysomnography; Sleep; Sleep Apnea Syndromes; Sleep Stages; Sleep Wake Disorders; Automation; Bioelectric phenomena; Biomedical signal processing; Classification (of information); Deep neural networks; Learning algorithms; Multilayer neural networks; Sleep research; Automated identification; B phase; Convolution neural network; Cyclic alternating pattern; Electroencephalogram signals; Physiological markers; Physiological process; Scattering networks; Sleep; adult; Article; controlled study; convolutional neural network; cyclic alternating pattern; deep neural network; electroencephalogram; feature extraction; feed forward neural network; finite state machine; human; image processing; insomnia; major clinical study; narcolepsy; nonREM sleep; oscillation; polysomnography; REM sleep; sleep; speech discrimination; support vector machine; wakefulness; electroencephalography; physiology; sleep; sleep apnea syndromes; sleep disorder; sleep stage; Electroencephalography","","","Elsevier Ltd","37544251"
"Hamdi M.; Senan E.M.; Jadhav M.E.; Olayah F.; Awaji B.; Alalayah K.M.","Hamdi, Mohammed (57201749980); Senan, Ebrahim Mohammed (57222957501); Jadhav, Mukti E. (57201156883); Olayah, Fekry (39161803000); Awaji, Bakri (57219144774); Alalayah, Khaled M. (57190568317)","57201749980; 57222957501; 57201156883; 39161803000; 57219144774; 57190568317","Hybrid Models Based on Fusion Features of a CNN and Handcrafted Features for Accurate Histopathological Image Analysis for Diagnosing Malignant Lymphomas","2023","13","13","2258","","","","10.3390/diagnostics13132258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164710227&doi=10.3390%2fdiagnostics13132258&partnerID=40&md5=7dfc2ae8a8d9cce7cb9467623c2261ff","Malignant lymphoma is one of the most severe types of disease that leads to death as a result of exposure of lymphocytes to malignant tumors. The transformation of cells from indolent B-cell lymphoma to B-cell lymphoma (DBCL) is life-threatening. Biopsies taken from the patient are the gold standard for lymphoma analysis. Glass slides under a microscope are converted into whole slide images (WSI) to be analyzed by AI techniques through biomedical image processing. Because of the multiplicity of types of malignant lymphomas, manual diagnosis by pathologists is difficult, tedious, and subject to disagreement among physicians. The importance of artificial intelligence (AI) in the early diagnosis of malignant lymphoma is significant and has revolutionized the field of oncology. The use of AI in the early diagnosis of malignant lymphoma offers numerous benefits, including improved accuracy, faster diagnosis, and risk stratification. This study developed several strategies based on hybrid systems to analyze histopathological images of malignant lymphomas. For all proposed models, the images and extraction of malignant lymphocytes were optimized by the gradient vector flow (GVF) algorithm. The first strategy for diagnosing malignant lymphoma images relied on a hybrid system between three types of deep learning (DL) networks, XGBoost algorithms, and decision tree (DT) algorithms based on the GVF algorithm. The second strategy for diagnosing malignant lymphoma images was based on fusing the features of the MobileNet-VGG16, VGG16-AlexNet, and MobileNet-AlexNet models and classifying them by XGBoost and DT algorithms based on the ant colony optimization (ACO) algorithm. The color, shape, and texture features, which are called handcrafted features, were extracted by four traditional feature extraction algorithms. Because of the similarity in the biological characteristics of early-stage malignant lymphomas, the features of the fused MobileNet-VGG16, VGG16-AlexNet, and MobileNet-AlexNet models were combined with the handcrafted features and classified by the XGBoost and DT algorithms based on the ACO algorithm. We concluded that the performance of the two networks XGBoost and DT, with fused features between DL networks and handcrafted, achieved the best performance. The XGBoost network based on the fused features of MobileNet-VGG16 and handcrafted features resulted in an AUC of 99.43%, accuracy of 99.8%, precision of 99.77%, sensitivity of 99.7%, and specificity of 99.8%. This highlights the significant role of AI in the early diagnosis of malignant lymphoma, offering improved accuracy, expedited diagnosis, and enhanced risk stratification. This study highlights leveraging AI techniques and biomedical image processing; the analysis of whole slide images (WSI) converted from biopsies allows for improved accuracy, faster diagnosis, and risk stratification. The developed strategies based on hybrid systems, combining deep learning networks, XGBoost and decision tree algorithms, demonstrated promising results in diagnosing malignant lymphoma images. Furthermore, the fusion of handcrafted features with features extracted from DL networks enhanced the performance of the classification models. © 2023 by the authors.","ACO; deep learning; DT; fusion features; GVF; malignant lymphoma; XGBoost","alexnet; ant colony optimization; Article; artificial intelligence; biopsy; cancer classification; cancer diagnosis; cancer staging; classifier; controlled study; convolutional neural network; decision tree; deep learning; diagnostic accuracy; diagnostic test accuracy study; discrete wavelet transform; early cancer; early diagnosis; evaluation study; feature extraction; feature extraction algorithm; gradient vector flow algorithm; gray level cooccurrence matrix; handcrafted feature; histopathology; human; human tissue; image analysis; image processing; local binary pattern; lymphocyte; lymphoma; machine learning; mobilenet; radiomics; risk assessment; segmentation algorithm; sensitivity and specificity; XGBoost algorithm","Najran University, NU; Deanship of Scientific Research, University of Jordan, DSR, (NU/DRP/SERC/12/17)","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Arvidsson M.; Rashed S.K.; Aits S.","Arvidsson, Malou (58001558500); Rashed, Salma Kazemi (57188972941); Aits, Sonja (23468829600)","58001558500; 57188972941; 23468829600","An annotated high-content fluorescence microscopy dataset with Hoechst 33342-stained nuclei and manually labelled outlines","2023","46","","108769","","","","10.1016/j.dib.2022.108769","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143768599&doi=10.1016%2fj.dib.2022.108769&partnerID=40&md5=813b6ef950ef5bba6ced06a44fdbc79e","Automated detection of cell nuclei in fluorescence microscopy images is a key task in bioimage analysis. It is essential for most types of microscopy-based high-throughput drug and genomic screening and is often required in smaller scale experiments as well. To develop and evaluate algorithms and neural networks that perform instance or semantic segmentation for detecting nuclei, high quality annotated data is essential. Here we present a benchmarking dataset of fluorescence microscopy images with Hoechst 33342-stained nuclei together with annotations of nuclei, nuclear fragments and micronuclei. Images were randomly selected from an RNA interference screen with a modified U2OS osteosarcoma cell line, acquired on a Thermo Fischer CX7 high-content imaging system at 20x magnification. Labelling was performed by a single annotator and reviewed by a biomedical expert. The dataset, called Aitslab-bioimaging1, contains 50 images showing over 2000 labelled nuclear objects in total, which is sufficiently large to train well-performing neural networks for instance or semantic segmentation. The dataset is split into training, development and test set for user convenience. © 2022","Biomedical image analysis; Computer vision; Deep learning training and evaluation; Fluorescence microscopy; High-content screening; Instance segmentation","Cell culture; Computer vision; Deep learning; Fluorescence; Image analysis; Large dataset; Medical imaging; Quality control; Semantic Segmentation; Semantics; Statistical tests; Automated detection; Biomedical image analysis; Deep learning training and evaluation; Fluorescence microscopy images; High-content; High-content screening; Hoechst; Instance segmentation; Neural-networks; Semantic segmentation; Fluorescence microscopy","Fabrikant Einar Willumsen's Memorial Fund; Längmanska Cultural Fund; National Bioinformatics Infrastructure Sweden; Sigurd & Elsa Golje's Memorial Fund; Swedish Research Council for Sustainable Development; Thora and Viggo Grove's Memorial Fund; Kræftens Bekæmpelse, DCS; Svenska Forskningsrådet Formas, (2019-01554); Crafoordska Stiftelsen; Lunds Universitet; Hjärnfonden; Knut och Alice Wallenbergs Stiftelse, (2018-05973); Vetenskapsrådet, VR, (2016-02003); Kungliga Fysiografiska Sällskapet i Lund; Thorsten och Elsa Segerfalks Stiftelse; Science for Life Laboratory, SciLifeLab","","Elsevier Inc.",""
"Pastore V.P.; Ciranni M.; Bianco S.; Fung J.C.; Murino V.; Odone F.","Pastore, Vito Paolo (57208643040); Ciranni, Massimiliano (58522341000); Bianco, Simone (9737903800); Fung, Jennifer Carol (7203073385); Murino, Vittorio (7006595496); Odone, Francesca (6602231198)","57208643040; 58522341000; 9737903800; 7203073385; 7006595496; 6602231198","Efficient unsupervised learning of biological images with compressed deep features","2023","137","","104764","","","","10.1016/j.imavis.2023.104764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166650733&doi=10.1016%2fj.imavis.2023.104764&partnerID=40&md5=0375c650e48d2f30ec4244b7b88857cd","Machine learning has significantly impacted the analysis of biological images and is now an important part of many biological data analysis pipelines. A variety of biological and biomedical domain-related tasks is gaining benefit from image analysis and pattern recognition tools developed currently. Applications include diagnostic histopathology, environmental monitoring, synthetic biology, genomics, and proteomics. Particularly in the last decade, several deep learning and advanced computer vision methods such as convolutional neural networks (CNNs), typically trained in a supervised fashion, have started to be largely employed in biological image classification. Moreover, the advancement of automatic acquisition systems has been generating a massive amount of biological data, which requires to be analyzed by domain experts. However, the cost of manual annotation of such data has become a bottleneck, impairing the application of supervised machine learning algorithms. Biological images generally have an intrinsic high variability, whose identity is sometimes hard to assign and strongly dependent on the annotator's expertise. In this context, a limited number of annotation-free (i.e., unsupervised) learning solutions have been proposed, typically based on hand-crafted features, specifically tailored for a certain biological domain. Nonetheless, a successful unsupervised learning approach must be accurate, and sufficiently robust to deal with different biological domains. This paper aims at providing a viable solution to these issues, proposing an unsupervised learning algorithm based on compressed deep features for image classification. We exploit features extracted from ImageNet pre-trained transformers and CNNs, further compressed with a customized β-Variational AutoEncoder (β-VAE), that we call reconstruction VAE (R-VAE). We test our algorithm on biological images coming from diverse domains characterized by high variability in shape and texture information and acquired with widely differing imaging platforms. Considered image datasets range from multi-cellular organisms (plankton, coral) to sub-cellular organelles (budding yeast vacuoles, human cells’ nuclei, etc.). Our results show that the compressed deep features extracted from different pre-trained vision models establish new unsupervised learning state-of-the-art performances for the investigated datasets. © 2023 The Authors","Biological images analysis; Model ensembling; Pre-trained features; Transfer learning; Unsupervised learning","Convolutional neural networks; Deep learning; Image classification; Learning algorithms; Learning systems; Molecular biology; Semi-supervised learning; Textures; Biological data; Biological domain; Biological image analysis; Biomedical domain; Convolutional neural network; Images classification; Machine-learning; Model ensembling; Pre-trained feature; Transfer learning; Unsupervised learning","National Science Foundation, NSF, (DBI-1548297); National Science Foundation, NSF; Faculty of Science and Engineering, University of Manchester, FSE, (DM 1062/2021); Faculty of Science and Engineering, University of Manchester, FSE","","Elsevier Ltd",""
"Bimbraw K.; Nycz C.J.; Schueler M.; Zhang Z.; Zhang H.K.","Bimbraw, Keshav (56896094300); Nycz, Christopher J. (57038834700); Schueler, Matthew (57289001500); Zhang, Ziming (56612810100); Zhang, Haichong K. (56352689300)","56896094300; 57038834700; 57289001500; 56612810100; 56352689300","Simultaneous Estimation of Hand Configurations and Finger Joint Angles Using Forearm Ultrasound","2023","5","1","","120","132","12","10.1109/TMRB.2023.3237774","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147289309&doi=10.1109%2fTMRB.2023.3237774&partnerID=40&md5=aa153ff8f14e9fe98ddef63db9dad651","With the advancement in computing and robotics, it is necessary to develop fluent and intuitive methods for interacting with digital systems, augmented/virtual reality (AR/VR) interfaces, and physical robotic systems. Hand motion recognition is widely used to enable these interactions. Hand configuration classification and metacarpophalangeal (MCP) joint angle detection is important for a comprehensive reconstruction of hand motion. Surface electromyography (sEMG) and other technologies have been used for the detection of hand motions. Forearm ultrasound images provide a musculoskeletal visualization that can be used to understand hand motion. Recent work has shown that these ultrasound images can be classified using machine learning to estimate discrete hand configurations. Estimating both hand configuration and MCP joint angles based on forearm ultrasound has not been addressed in the literature. In this paper, we propose a convolutional neural network (CNN) based deep learning pipeline for predicting the MCP joint angles. The results for the hand configuration classification were compared by using different machine learning algorithms. Support vector classifier with different kernels, multi-layer perceptron, and the proposed CNN have been used to classify the ultrasound images into 11 hand configurations based on activities of daily living. Forearm ultrasound images were acquired from 6 subjects instructed to move their hands according to predefined hand configurations. Motion capture data was acquired to get the finger angles corresponding to the hand movements at different speeds (0.5 Hz, 1 Hz, & 2 Hz) for the index, middle, ring, and pinky fingers. Average classification accuracy of 82.7 ± 9.7% for the proposed CNN and over 80% for SVC for different kernels was observed on a subset of the dataset. An average RMSE of 7.35° ± 1.3 ° was obtained between the predicted and the true MCP joint angles. A low latency (6.25 - 9.1 Hz) pipeline has been proposed for estimating both MCP joint angles and hand configuration aimed at real-time control of human-machine interfaces.  © 2018 IEEE.","AI-enabled robotics; and facial expressions; design and development of robots for human-robot interaction; gesture; human-machine interfaces and robotics applications; new technologies and methodologies in medical robotics; posture; user-centered design and applications; wearable robotics; wearable sensor systems","Biomedical signal processing; Convolution; Deep neural networks; Electromyography; Human computer interaction; Human robot interaction; Image classification; Learning algorithms; Man machine systems; Medical imaging; Motion estimation; Object recognition; Real time control; Ultrasonic imaging; AI-enabled robotic; Convolutional neural network; Design and application; Design and Development; Design and development of robot for human-robot interaction; Facial Expressions; Gesture; Human Machine Interface; Human-machine interface and robotic application; Humans-robot interactions; Interface applications; Medical robotics; New technology and methodology in medical robotic; Posture; Robot sensing system; Robotics applications; Static VAr compensator; Wearable robotics; Wearable sensor system -user-centered design and application; Wearable sensor systems; Classification (of information)","","","Institute of Electrical and Electronics Engineers Inc.",""
"Pradhan A.; Srivastava S.","Pradhan, Anushka (58093772600); Srivastava, Subodh (7403306605)","58093772600; 7403306605","Hierarchical extreme puzzle learning machine-based emotion recognition using multimodal physiological signals","2023","83","","104624","","","","10.1016/j.bspc.2023.104624","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147541445&doi=10.1016%2fj.bspc.2023.104624&partnerID=40&md5=925c225ca5aab9d3da72f9fd042bec8f","Detection of exact emotions through multi-modal physiological signals provides relevant information for different processes. Numerous computational approaches have been presented for the precise analysis of emotion types. But due to some problems like ruined signal quality, increased time consumption, and the necessity of high storage space, classification accuracy's efficiency worsens. Hence, this research classified multi-modal physiological signals based on machine and deep learning (DL) models. The proposed work implements the Hierarchical Extreme Puzzle Learning Machine (HEPLM) approach to classify the actual output of embedded emotions. The proposed work comprises four steps: pre-processing, signal-to-image conversion, feature extraction, and classification. Pre-processing is carried out using Savitzky-Golay smoothing filtering (SGF) for the removal of noise and to increase signal quality. Hybrid wavelet scattering with Synchro squeezing Wavelet Transform approach converts the signal into an image. In feature extraction process, the valuable features are extracted using ResNet-152 and the Inception v3 model, whereas the features are combined through an ensemble approach. HEPLM is used in the final classification process, combining Puzzle Optimization Algorithm (POA) and Hierarchical Extreme Learning Machine (HELM) to reduce feature dimensionality and improve classification accuracy. The dataset adopted in the proposed work is Wearable Stress and Affect Detection (WESAD) to collect multi-modal physiological signals. The presentation of the projected work is assessed with metrics like accuracy, recall, precision, F1 score, kappa, and so on. The proposed effort demonstrates better results of emotion classification when compared to the existing methods by holding 96.29% of accuracy. © 2023 Elsevier Ltd","Emotion recognition; Ensemble; Filtering; Optimal features; Physiological signals; Signal conversion","Biomedical signal processing; Deep learning; Extraction; Feature extraction; Image processing; Knowledge acquisition; Learning systems; Physiological models; Physiology; Speech recognition; Wavelet transforms; Classification accuracy; Emotion recognition; Ensemble; Learning machines; Multi-modal; Optimal feature; Physiological signals; Pre-processing; Signal conversion; Signal quality; algorithm; article; deep learning; emotion; feature extraction; filtration; human; human experiment; machine learning; noise; physiological stress; recall; residual neural network; wavelet transform; Emotion Recognition","","","Elsevier Ltd",""
"Guan Y.-X.; An Y.; Guo F.-Y.; Pan W.-B.; Wang J.-X.","Guan, Yu-Xia (56909300300); An, Ying (57204429699); Guo, Feng-Yi (58185233800); Pan, Wei-Bai (57455713100); Wang, Jian-Xin (58848426500)","56909300300; 57204429699; 58185233800; 57455713100; 58848426500","Intelligent Electrocardiogram Analysis in Medicine: Data, Methods, and Applications","2023","38","1","","38","48","10","10.24920/004160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152620852&doi=10.24920%2f004160&partnerID=40&md5=ad756d19aa1c982a8ecfa12e54d532e6","Electrocardiogram (ECG) is a low-cost, simple, fast, and non-invasive test. It can reflect the heart's electrical activity and provide valuable diagnostic clues about the health of the entire body. Therefore, ECG has been widely used in various biomedical applications such as arrhythmia detection, disease-specific detection, mortality prediction, and biometric recognition. In recent years, ECG-related studies have been carried out using a variety of publicly available datasets, with many differences in the datasets used, data preprocessing methods, targeted challenges, and modeling and analysis techniques. Here we systematically summarize and analyze the ECG-based automatic analysis methods and applications. Specifically, we first reviewed 22 commonly used ECG public datasets and provided an overview of data preprocessing processes. Then we described some of the most widely used applications of ECG signals and analyzed the advanced methods involved in these applications. Finally, we elucidated some of the challenges in ECG analysis and provided suggestions for further research. © 2023 Chinese Academy Medical Sciences","database; Electrocardiogram; machine learning; medical big data analysis; preprocessing","Algorithms; Arrhythmias, Cardiac; Electrocardiography; Humans; acoustic stress; autoanalysis; automatic cardioversion; big data; biometry; cardiovascular disease; classification algorithm; clinical outcome; clinical practice; convolutional neural network; coronavirus disease 2019; data preprocessing process; data processing; data protection; data sharing; deep learning; discrete wavelet transform; electrocardiogram; epidemic; feature detection; feature extraction; fetus echography; heart arrhythmia; human; hybrid feature; image processing; image segmentation; intelligent electrocardiogram analysis; learning algorithm; machine learning; medicine; mortality; QRS interval; QT interval; respiratory tract disease; Review; RR interval; sudden cardiac death; supraventricular tachycardia; time series analysis; two dimensional echocardiography; algorithm; electrocardiography; heart arrhythmia; procedures","Changsha Municipal Natural Science Foundation, (kq2202106); National Natural Science Foundation of China-Zhejiang Joint Fund for the Integration of Industrialization and Informatization, (U1909208); National Natural Science Foundation of China-Zhejiang Joint Fund for the Integration of Industrialization and Informatization; Changsha Science and Technology Project, (kh2202004); Changsha Science and Technology Project","","Elsevier Ltd","36851887"
"Rajesh Immanuel R.; Sangeetha S.K.B.","Rajesh Immanuel, Rajeswari (58099142300); Sangeetha, S.K.B. (57225085133)","58099142300; 57225085133","Decoding Emotions Using Deep Learning Approach to EEG-Based Emotion Recognition","2023","","","","","","","10.1109/ICCEBS58601.2023.10449107","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189180332&doi=10.1109%2fICCEBS58601.2023.10449107&partnerID=40&md5=a9c4d1001f986de8d569dcb16bfecf15","In disciplines including medicine, psychology, and human-computer interaction, understanding and interpreting human emotions is crucial. Emotion analysis that is accurate and real-time has the potential to transform these fields. Deep learning methods combined with Electroencephalography (EEG) inputs have become a viable approach for enhancing emotion identification systems in recent years. With EEG data and a cutting-edge Deep CNN algorithm, this study introduces a novel method for emotion analysis that achieves a remarkable accuracy rate of 96.24% and model loss as 0.89. We gathered EEG data from a variety of participants, drepresenting a spectrum of emotional reactions. EEG data are a useful source for emotion research because they provide clear insights into the electrical activity of the brain.In our study, EEG data is processed using a Deep Convolutional Neural Network (CNN) architecture, which is well-known for its efficiency in image-related tasks. This deep learning algorithm improves the precision of emotion identification by learning complex spatial and temporal patterns from EEG data.The creation of a novel feature extraction technique specifically designed for EEG data is a key breakthrough in our strategy. By capturing both spectral and temporal properties, this technique gives the model additional discriminative data for classifying emotions.A great accuracy rate of 96.24% was attained by the suggested technique while classifying emotions. This extraordinary precision indicates the dependability and strength of our method. Real-time emotion detection is made possible by our model's quick analysis of EEG data, which has implications for virtual reality, human-computer interaction, and mental health monitoring, among other fields. In order to further our understanding of how the human brain reacts to emotional inputs, we offer insights into the neural patterns connected to various emotions.This study illustrates the application of deep learning, more especially the Deep CNN algorithm, to emotion analysis using EEG data. With the help of this cutting-edge architecture and our innovative feature extraction technique, accuracy has greatly increased, making it a useful tool for situations where accurate emotion identification is essential. This discovery has ramifications across a range of fields, including psychology, healthcare, and human-computer interaction, eventually improving our capacity to recognize and react to emotional states in others.  © 2023 IEEE.","Accuracy; CNN; Deep Learning; EEG Signal; Emotion Recognition; Feature Extraction; Stress","Biomedical signal processing; Brain; Classification (of information); Convolutional neural networks; Deep neural networks; Electrophysiology; Emotion Recognition; Extraction; Feature extraction; Human computer interaction; Learning algorithms; Learning systems; Network architecture; Speech recognition; Virtual reality; Accuracy; Convolutional neural network; Cutting edges; Deep learning; Electroencephalography signal; Emotion analysis; Emotion identifications; Emotion recognition; Features extraction; Neural networks algorithms; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Demirel B.U.; Chen L.; Al Faruque M.A.","Demirel, Berken Utku (57222186593); Chen, Luke (57232509300); Al Faruque, Mohammad Abdullah (9332640800)","57222186593; 57232509300; 9332640800","Data-driven Energy-efficient Adaptive Sampling Using Deep Reinforcement Learning","2023","4","3","19","","","","10.1145/3598301","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171746581&doi=10.1145%2f3598301&partnerID=40&md5=ac8d3e83c1e296c7592366a9ce1ab78b","This article presents a resource-efficient adaptive sampling methodology for classifying electrocardiogram (ECG) signals into different heart rhythms. We present our methodology in two folds: (i) the design of a novel real-time adaptive neural network architecture capable of classifying ECG signals with different sampling rates and (ii) a runtime implementation of sampling rate control using deep reinforcement learning (DRL). By using essential morphological details contained in the heartbeat waveform, the DRL agent can control the sampling rate and effectively reduce energy consumption at runtime. To evaluate our adaptive classifier, we use the MIT-BIH database and the recommendation of the AAMI to train the classifiers. The classifier is designed to recognize three major types of arrhythmias, which are supraventricular ectopic beats (SVEB), ventricular ectopic beats (VEB), and normal beats (N). The performance of the arrhythmia classification reaches an accuracy of 97.2% for SVEB and 97.6% for VEB beats. Moreover, the designed system is 7.3× more energy-efficient compared to the baseline architecture, where the adaptive sampling rate is not utilized. The proposed methodology can provide reliable and accurate real-time ECG signal analysis with performances comparable to state-of-the-art methods. Given its time-efficient, low-complexity, and low-memory-usage characteristics, the proposed methodology is also suitable for practical ECG applications, in our case for arrhythmia classification, using resource-constrained devices, especially wearable healthcare devices and implanted medical devices.  © 2023 Copyright held by the owner/author(s).","Adaptive sampling; energy-efficient; heart rate; real-time; wearable devices","Biomedical signal processing; Classification (of information); Deep learning; Diseases; Electrocardiograms; Energy efficiency; Energy utilization; Learning algorithms; Network architecture; Signal sampling; Wearable technology; Adaptive sampling; Ectopic beats; Electrocardiogram signal; Energy efficient; Heart-rate; Real- time; Reinforcement learnings; Runtimes; Sampling rates; Wearable devices; Article; classification algorithm; classifier; convolutional neural network; cross validation; deep learning; detection algorithm; dimensionality reduction; electrocardiogram; energy conservation; energy consumption; false negative result; false positive result; Fourier transform; heart arrhythmia; heart beat; heart rhythm; heart ventricle extrasystole; image processing; image segmentation; intermethod comparison; machine learning; Markov decision process; measurement accuracy; predictive value; Q learning; reinforcement learning (machine learning); sensitivity and specificity; signal processing; supraventricular premature beat; waveform; wavelet transform; Reinforcement learning","","","Association for Computing Machinery",""
"Savur C.; Dautov R.; Bukum K.; Xia X.; Couderc J.-P.; Tsouri G.R.","Savur, Celal (57189349006); Dautov, Ruslan (54893701000); Bukum, Kamil (57847658900); Xia, Xiaojuan (23101303900); Couderc, Jean-Philippe (7103249521); Tsouri, Gill R. (9638075500)","57189349006; 54893701000; 57847658900; 23101303900; 7103249521; 9638075500","Monitoring Pulse Rate in the Background Using Front Facing Cameras of Mobile Devices","2023","27","5","","2208","2218","10","10.1109/JBHI.2022.3197076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136096312&doi=10.1109%2fJBHI.2022.3197076&partnerID=40&md5=dc0299d0999d93be2c160d74a637085c","We propose a novel framework to passively monitor pulse rate during the time spent by users on their personal mobile devices. Our framework is based on passively capturing the user's pulse signal using the front-facing camera. Signal capture is performed in the background, while the user is interacting with the device as he/she normally would, e.g., watch movies, read emails, text, and play games. The framework does not require subject participation with the monitoring procedure, thereby addressing the well-known problem of low adherence with such procedures. We investigate various techniques to suppress the impact of spontaneous user motion and fluctuations in ambient light conditions expected in non-participatory environments. Techniques include traditional signal processing, machine learning classifiers, and deep learning methods. Our performance evaluation is based on a clinical study encompassing 113 patients with a history of atrial fibrillation (Afib) who are passively monitored at home using a tablet for a period of two weeks. Our results show that the proposed framework accurately monitors pulse rate, thereby providing a gateway for long-term monitoring without relying on subject participation or the use of a dedicated wearable device.  © 2013 IEEE.","Mobile health; passive monitoring; photoplethysmography; pulse rate; videoplethysmography","Atrial Fibrillation; Female; Heart Rate; Humans; Monitoring, Physiologic; Pulse; Wearable Electronic Devices; Deep learning; Facings; Mobile telecommunication systems; Monitoring; Photoplethysmography; Biomedical monitoring; Face; Heart-rate; Passive monitoring; Performances evaluation; Personal mobile devices; Pulse rate; Pulse signal; Time-spent; Videoplethysmography; accuracy; adult; algorithm; Article; artificial neural network; battery industry; classifier; conceptual framework; deep learning; electrocardiography; facial recognition; feature extraction; female; filtration; health care facility; health insurance; heart arrhythmia; human; human experiment; image artifact; information processing; learning algorithm; machine learning; major clinical study; male; mathematical model; measurement accuracy; middle aged; motion; photoelectric plethysmography; plethysmography; pulse rate; quality control; signal noise ratio; signal processing; support vector machine; training; validation process; waveform; atrial fibrillation; heart rate; physiologic monitoring; Cameras","National Institutes of Health, NIH, (NIH2 5R01HL137617-04)","","Institute of Electrical and Electronics Engineers Inc.","35939479"
"Ayatollahi A.; Afrakhteh S.; Soltani F.; Saleh E.","Ayatollahi, Ahmad (6603353487); Afrakhteh, Sajjad (57204607554); Soltani, Fatemeh (57223221813); Saleh, Ehsan (57208533827)","6603353487; 57204607554; 57223221813; 57208533827","Sleep apnea detection from ECG signal using deep CNN-based structures","2023","14","2","","191","206","15","10.1007/s12530-022-09445-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132416388&doi=10.1007%2fs12530-022-09445-1&partnerID=40&md5=e1628b0e65c7c3bc4980cd256781d851","In this paper, transfer learning is used for the adaptation of pre-trained deep convolutional neural networks (DCNNs) to find the best appropriate method for the classification of obstructive sleep apnea (OSA) using electrocardiogram (ECG) signals. The Physio Apnea-ECG data set has been used for the evaluation of the proposed method. In deep learning algorithms, especially in image data classification, more data leads to better performance. For this reason, in this paper, we propose a novel technique as follows. First, the ECG signal is divided into 2-s segments and filtered, then the recurrence plots (RP) algorithm is used to convert these segments into two-dimensional images. The RP is an advanced tool that can indicate how resemblances between particular orders vary over time. These plots are generally used for the qualitative evaluation of the time series in dynamic systems. Finally, in the classification stage, 5 pre-trained DCNN models on ImageNet datasets including EfficienNet-B0, EfficienNet-B1, EfficienNet-B2, Inception-v3, and Xception are considered for final decision. By using these methods, the classification accuracies of 88.67%, 90.59%, 90.52%, 93.33%, and 93.19%, were obtained respectively. In this research, by analyzing the performance of the models used, we can see that by increasing the input image size, the number of network parameters, its depth, and the classification performance is improved. Also, the performance of the Inception-v3 model which has the largest input image size and number of parameters with 93.33% accuracy, is better than other models for OSA detection. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Apnea; Classification; CNN; DCNN; Deep learning; ECG; OSA","Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Image enhancement; Learning algorithms; Neural network models; Sleep research; Apnea; Convolutional neural network; Deep convolutional neural network; Deep learning; Electrocardiogram signal; Input image; Obstructive sleep apnea; Performance; Recurrence plot; Sleep apnea detection; Electrocardiograms","","","Institute for Ionics",""
"Guan Y.; An Y.; Xu J.; Liu N.; Wang J.","Guan, Yuxia (56909300300); An, Ying (57204429699); Xu, Jingrui (58789732800); Liu, Ning (57221467042); Wang, Jianxin (35197282200)","56909300300; 57204429699; 58789732800; 57221467042; 35197282200","HA-ResNet: Residual Neural Network With Hidden Attention for ECG Arrhythmia Detection Using Two-Dimensional Signal","2023","20","6","","3389","3398","9","10.1109/TCBB.2022.3198998","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136884817&doi=10.1109%2fTCBB.2022.3198998&partnerID=40&md5=67c6a19b6725b56159f1f75eb30c740c","Arrhythmia is an abnormal heart rhythm, a common clinical problem in cardiology. Long-term or severe arrhythmia may lead to stroke and sudden cardiac death. The electrocardiogram (ECG) is the most commonly used tool to diagnose arrhythmia. However, the traditional diagnosis relies on experts for manual interpretation, which is time-consuming and laborious. In recent years, many automatic arrhythmia detection methods have emerged due to advancements in deep learning. These methods can reduce manual intervention and improve diagnostic efficiency. However, extracting useful features from raw ECG signals for arrhythmia detection is still challenging due to the low frequency of ECG signals and noise distribution. In this paper, we propose a novel hidden attention residual network (HA-ResNet) for automated arrhythmia classification. In this model, the one-dimensional ECG signals are first converted into two-dimensional images and fed into an embedding layer to obtain the relevant shallow features in ECG. Then, a hidden attention layer combining Squeeze-and-Excitation (SE) block and Bidirectional Convolutional LSTM (BConvLSTM) is used to further capture the deep Spatio-temporal features. We evaluate our HA-ResNet on two public datasets and achieve F1 scores of 96.0%, 96.7%, and 87.6% on 2s segments, 5s segments, and 10s segments, respectively, which significantly outperform the existing state-of-the-art approaches. The experimental results demonstrate the effectiveness and generalization of our method.  © 2004-2012 IEEE.","arrhythmia; dedep learning; ECG classification","Algorithms; Arrhythmias, Cardiac; Electrocardiography; Humans; Neural Networks, Computer; Signal Processing, Computer-Assisted; Biomedical signal processing; Classification (of information); Convolution; Diseases; Feature extraction; Heart; Long short-term memory; Markov processes; Time series analysis; Arrhythmia; Arrhythmia detection; Deep learning; Electrocardiogram classification; Electrocardiogram signal; Features extraction; Heart beats; Neural-networks; Time-series analysis; algorithm; artificial neural network; electrocardiography; heart arrhythmia; human; procedures; signal processing; Electrocardiograms","National Natural Science Foundation of China-Zhejiang Joint Fund for the Integration of Industrialization and Informatization, (U1909208); National Natural Science Foundation of China-Zhejiang Joint Fund for the Integration of Industrialization and Informatization; National Key Research and Development Program of China, NKRDPC, (2021YFF1201200); National Key Research and Development Program of China, NKRDPC; Changsha Science and Technology Project, (kh2202004); Changsha Science and Technology Project","","Institute of Electrical and Electronics Engineers Inc.","35969555"
"Lahmiri S.","Lahmiri, Salim (39061577500)","39061577500","Integrating convolutional neural networks, kNN, and Bayesian optimization for efficient diagnosis of Alzheimer's disease in magnetic resonance images","2023","80","","104375","","","","10.1016/j.bspc.2022.104375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141326150&doi=10.1016%2fj.bspc.2022.104375&partnerID=40&md5=3fa238c9d6e0a4420fac0cd53a18e040","Deep learning is attracting growing interest from biomedical engineering community. Researchers and clinicians are also increasingly interested in development of machine learning and pattern recognition systems used to diagnose Alzheimer's disease (AD). To enhance diagnostic power for AD, we propose an automatic system integrating convolutional neural networks (CNN) to extract deep traits from magnetic resonance image (MRI) with no prior assumption, a filtering technique to reduce number of features, and k nearest neighbors (kNN) algorithm to discriminate AD subjects from healthy control (HC) ones. The kNN is tuned by Bayesian optimization (BO) algorithm. The experimental outcomes support the hypothesis that our proposed integrative system can be effective at performing MRI classification: 94.96% ± 0.0486 accuracy, 92.05% ± 0.0746 sensitivity, and 96.62% ± 0.0350 specificity. The obtained result underscore the utility of the proposed system for screening AD as it improves accuracy compared to existing models validated on the same data set. © 2022","Alzheimer disease; Bayesian optimization; Classification; Convolutional neural networks; Deep learning; kNN; MRI","Bayesian networks; Biomedical engineering; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Image enhancement; Learning algorithms; Nearest neighbor search; Neurodegenerative diseases; Pattern recognition; Signal to noise ratio; Alzheimers disease; Automatic systems; Bayesian optimization; Convolutional neural network; Deep learning; Engineering community; Filtering technique; Machine-learning; Magnetic resonance image; Power; accuracy; Alzheimer disease; Article; Bayesian network; comparative study; controlled study; convolutional neural network; diagnostic accuracy; extraction; human; k nearest neighbor; nuclear magnetic resonance imaging; sensitivity and specificity; Magnetic resonance imaging","","","Elsevier Ltd",""
"Abubaker M.B.; Babayigit B.","Abubaker, Mohammed B. (58170618100); Babayigit, Bilal (14010616400)","58170618100; 14010616400","Detection of Cardiovascular Diseases in ECG Images Using Machine Learning and Deep Learning Methods","2023","4","2","","373","382","9","10.1109/TAI.2022.3159505","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151594103&doi=10.1109%2fTAI.2022.3159505&partnerID=40&md5=1187ab0f6013081a11f1da985aa5bbd4","Cardiovascular diseases (heart diseases) are the leading cause of death worldwide. The earlier they can be predicted and classified; the more lives can be saved. Electrocardiogram (ECG) is a common, inexpensive, and noninvasive tool for measuring the electrical activity of the heart and is used to detect cardiovascular disease. In this article, the power of deep learning techniques was used to predict the four major cardiac abnormalities: abnormal heartbeat, myocardial infarction, history of myocardial infarction, and normal person classes using the public ECG images dataset of cardiac patients. First, the transfer learning approach was investigated using the low-scale pretrained deep neural networks SqueezeNet and AlexNet. Second, a new convolutional neural network (CNN) architecture was proposed for cardiac abnormality prediction. Third, the aforementioned pretrained models and our proposed CNN model were used as feature extraction tools for traditional machine learning algorithms, namely support vector machine, K-nearest neighbors, decision tree, random forest, and Naïve Bayes. According to the experimental results, the performance metrics of the proposed CNN model outperform the exiting works; it achieves 98.23% accuracy, 98.22% recall, 98.31% precision, and 98.21% F1 score. Moreover, when the proposed CNN model is used for feature extraction, it achieves the best score of 99.79% using the NB algorithm. © 2020 IEEE.","Cardiovascular; deep learning; electrocar diogram (ECG) images; feature extraction; machine learning; transfer learning","Biomedical signal processing; Cardiology; Convolution; Decision trees; Deep neural networks; Diseases; Electrocardiography; Extraction; Heart; Learning algorithms; Learning systems; Nearest neighbor search; Support vector machines; Cardiovascular; Convolutional neural network; Deep learning; Electro-cardiogram image; Features extraction; Machine-learning; Transfer learning; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.",""
"Dai Y.; Li X.; Liang S.; Wang L.; Duan Q.; Yang H.; Zhang C.; Chen X.; Li L.; Li X.; Liao X.","Dai, Yang (58337181900); Li, Xiuli (58337860600); Liang, Shanshan (57194217588); Wang, Lukang (57093546100); Duan, Qingtian (57249336300); Yang, Hui (57467480900); Zhang, Chunqing (55703953800); Chen, Xiaowei (57190497012); Li, Longhui (56195829700); Li, Xingyi (57194534680); Liao, Xiang (57191252675)","58337181900; 58337860600; 57194217588; 57093546100; 57249336300; 57467480900; 55703953800; 57190497012; 56195829700; 57194534680; 57191252675","MultiChannelSleepNet: A Transformer-Based Model for Automatic Sleep Stage Classification with PSG","2023","27","9","","4204","4215","11","10.1109/JBHI.2023.3284160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162732310&doi=10.1109%2fJBHI.2023.3284160&partnerID=40&md5=136cf6e18f37d27b4955a59fbbada185","Automatic sleep stage classification plays an essential role in sleep quality measurement and sleep disorder diagnosis. Although many approaches have been developed, most use only single-channel electroencephalogram signals for classification. Polysomnography (PSG) provides multiple channels of signal recording, enabling the use of the appropriate method to extract and integrate the information from different channels to achieve higher sleep staging performance. We present a transformer encoder-based model, MultiChannelSleepNet, for automatic sleep stage classification with multichannel PSG data, whose architecture is implemented based on the transformer encoder for single-channel feature extraction and multichannel feature fusion. In a single-channel feature extraction block, transformer encoders extract features from time-frequency images of each channel independently. Based on our integration strategy, the feature maps extracted from each channel are fused in the multichannel feature fusion block. Another set of transformer encoders further capture joint features, and a residual connection preserves the original information from each channel in this block. Experimental results on three publicly available datasets demonstrate that our method achieves higher classification performance than state-of-the-art techniques. MultiChannelSleepNet is an efficient method to extract and integrate the information from multichannel PSG data, which facilitates precision sleep staging in clinical applications.  © 2013 IEEE.","Automatic sleep stage classification; deep learning; feature extraction and fusion; PSG data; transformer encoder","Algorithms; Electroencephalography; Humans; Polysomnography; Sleep; Sleep Stages; Biomedical signal processing; Channel coding; Classification (of information); Computer aided diagnosis; Deep learning; Electroencephalography; Electrophysiology; Extraction; Neural networks; Signal encoding; Sleep research; Automatic sleep stage classification; Brain modeling; Convolutional neural network; Deep learning; Features extraction; Features fusions; Polysomnography; Polysomnography data; Sleep; Sleep stages classifications; Time-frequency Analysis; Transformer; Transformer encoder; article; brain; convolutional neural network; deep learning; electroencephalography; feature extraction; frequency analysis; polysomnography; sleep stage; algorithm; electroencephalography; human; polysomnography; procedures; sleep; sleep stage; Feature extraction","Chongqing Technology Innovation and Application DevelopmentSpecial Key Project, (cstc2019jscx-dxwtBX0010); National Natural Science Foundation of China, NSFC, (31925018, 32127801); National Natural Science Foundation of China, NSFC","","Institute of Electrical and Electronics Engineers Inc.","37289607"
"Liu Z.; Hu Y.; Wu X.; Mertes G.; Yang Y.; Clifton D.A.","Liu, Zhangdaihong (57612844400); Hu, Ying (58076860200); Wu, Xuan (57219141209); Mertes, Gert (56769778000); Yang, Yang (56278789400); Clifton, David A. (14036806800)","57612844400; 58076860200; 57219141209; 56769778000; 56278789400; 14036806800","Patient Clustering for Vital Organ Failure Using ICD Code With Graph Attention","2023","70","8","","2329","2337","8","10.1109/TBME.2023.3243311","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148415199&doi=10.1109%2fTBME.2023.3243311&partnerID=40&md5=c4aef64b7a4472f134ba97ee33a26ffb","Objective: Heart failure, respiratory failure and kidney failure are three severe organ failures (OF) that have high mortalities and are most prevalent in intensive care units. The objective of this work is to offer insights into OF clustering from the aspects of graph neural networks and diagnosis history. Methods: This paper proposes a neural network-based pipeline to cluster three types of organ failure patients by incorporating embedding pre-train using an ontology graph of the International Classification of Diseases (ICD) codes. We employ an autoencoder-based deep clustering architecture jointly trained with a K-means loss, and a non-linear dimension reduction is performed to obtain patient clusters on the MIMIC-III dataset. Results: The clustering pipeline shows superior performance on a public-domain image dataset. On the MIMIC-III dataset, it discovers two distinct clusters that exhibit different comorbidity spectra which can be related to the severity of diseases. The proposed pipeline is compared with several other clustering models and shows superiority. Conclusion: Our proposed pipeline gives stable clusters, however, they do not correspond to the type of OF which indicates these OF share significant hidden characteristics in diagnosis. These clusters can be used to signal possible complications and severity of illness and aid personalised treatment. Significance: We are the first to apply an unsupervised approach to offer insights from a biomedical engineering perspective on these three types of organ failure, and publish the pre-trained embeddings for future transfer learning.  © 2023 IEEE.","Artificial neural networks; clustering methods; graph attention; ICD ontology; organ failure","Cluster Analysis; Electronic Health Records; Humans; Intensive Care Units; International Classification of Diseases; Neural Networks, Computer; Cluster analysis; Codes (symbols); Diagnosis; Job analysis; Medical imaging; Network coding; Neural networks; Pipelines; Clustering methods; Code; Graph attention; International classification of disease; International classification of disease ontology; Medical diagnostic imaging; Ontology's; Organ failure; Radiofrequencies; Task analysis; Article; artificial neural network; autoencoder; classification algorithm; clustering algorithm; comorbidity; deep neural network; disease severity; glove embedding; heart failure; human; ICD-9; intermethod comparison; International Classification of Diseases; k means clustering; kidney failure; manifold learning; nonlinear dimensionality reduction; ontology; respiratory failure; unsupervised machine learning; validation process; cluster analysis; electronic health record; intensive care unit; Ontology","InnoHK Centre for Cerebro-cardiovascular Engineering; Jiangsu Provincial Double Innovation Talent Programme; RAEng Research Chair; Shanghai Municipal Health Commission, (202040083, BJ1-3000-22-0066); National Institute for Health and Care Research, NIHR; Department of Health and Social Care, DH; University of Oxford","","IEEE Computer Society","37022848"
"Xie Y.; Oniga S.","Xie, Yu (57224368996); Oniga, Stefan (24341788400)","57224368996; 24341788400","Classification of Motor Imagery EEG Signals Based on Data Augmentation and Convolutional Neural Networks","2023","23","4","1932","","","","10.3390/s23041932","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148970625&doi=10.3390%2fs23041932&partnerID=40&md5=6de9878bebb67508759c570cc67de64c","In brain–computer interface (BCI) systems, motor imagery electroencephalography (MI-EEG) signals are commonly used to detect participant intent. Many factors, including low signal-to-noise ratios and few high-quality samples, make MI classification difficult. In order for BCI systems to function, MI-EEG signals must be studied. In pattern recognition and other fields, deep learning approaches have recently been successfully applied. In contrast, few effective deep learning algorithms have been applied to BCI systems, especially MI-based systems. In this paper, we address these problems from two aspects based on the characteristics of EEG signals: first, we proposed a combined time–frequency domain data enhancement method. This method guarantees that the size of the training data is effectively increased while maintaining the intrinsic composition of the data. Second, our design consists of a parallel CNN that takes both raw EEG images and images transformed through continuous wavelet transform (CWT) as inputs. We conducted classification experiments on a public data set to verify the effectiveness of the algorithm. According to experimental results based on the BCI Competition IV Dataset2a, the average classification accuracy is 97.61%. A comparison of the proposed algorithm with other algorithms shows that it performs better in classification. The algorithm can be used to improve the classification performance of MI-based BCIs and BCI systems created for people with disabilities. © 2023 by the authors.","convolutional neural network (CNN); data augmentation (DA); electroencephalogram (EEG); motor imagery (MI)","Algorithms; Electroencephalography; Humans; Imagery, Psychotherapy; Intention; Neural Networks, Computer; Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Electrophysiology; Frequency domain analysis; Image classification; Learning algorithms; Signal to noise ratio; Wavelet transforms; Convolutional neural network; Data augmentation; Electroencephalogram; Electroencephalogram signals; Interface system; Low signal-to-noise ratio; Motor imagery; algorithm; behavior; electroencephalography; human; Electroencephalography","","","MDPI","36850530"
"Jasmine Pemeena Priyadarsini M.; Kotecha K.; Rajini G.K.; Hariharan K.; Utkarsh Raj K.; Bhargav Ram K.; Indragandhi V.; Subramaniyaswamy V.; Pandya S.","Jasmine Pemeena Priyadarsini, M. (55752319500); Kotecha, Ketan (6506676097); Rajini, G.K. (56085350800); Hariharan, K. (58099102100); Utkarsh Raj, K. (58099038400); Bhargav Ram, K. (58099070100); Indragandhi, V. (55759761300); Subramaniyaswamy, V. (54888993500); Pandya, Sharnil (57200178916)","55752319500; 6506676097; 56085350800; 58099102100; 58099038400; 58099070100; 55759761300; 54888993500; 57200178916","Lung Diseases Detection Using Various Deep Learning Algorithms","2023","2023","","3563696","","","","10.1155/2023/3563696","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147835312&doi=10.1155%2f2023%2f3563696&partnerID=40&md5=03555d6144a41b79493e74fd63cd7cf0","The primary objective of this proposed framework work is to detect and classify various lung diseases such as pneumonia, tuberculosis, and lung cancer from standard X-ray images and Computerized Tomography (CT) scan images with the help of volume datasets. We implemented three deep learning models namely Sequential, Functional & Transfer models and trained them on open-source training datasets. To augment the patient's treatment, deep learning techniques are promising and successful domains that extend the machine learning domain where CNNs are trained to extract features and offers great potential from datasets of images in biomedical application. Our primary aim is to validate our models as a new direction to address the problem on the datasets and then to compare their performance with other existing models. Our models were able to reach higher levels of accuracy for possible solutions and provide effectiveness to humankind for faster detection of diseases and serve as best performing models. The conventional networks have poor performance for tilted, rotated, and other abnormal orientation and have poor learning framework. The results demonstrated that the proposed framework with a sequential model outperforms other existing methods in terms of an F1 score of 98.55%, accuracy of 98.43%, recall of 96.33% for pneumonia and for tuberculosis F1 score of 97.99%, accuracy of 99.4%, and recall of 98.88%. In addition, the functional model for cancer outperformed with an accuracy of 99.9% and specificity of 99.89% and paves way to less number of trained parameters, leading to less computational overhead and less expensive than existing pretrained models. In our work, we implemented a state-of-the art CNN with various models to classify lung diseases accurately.  © 2023 M. Jasmine Pemeena Priyadarsini et al.","","Algorithms; Deep Learning; Humans; Machine Learning; Pneumonia; Tomography, X-Ray Computed; Biological organs; Classification (of information); Computerized tomography; Deep learning; Diseases; Learning algorithms; Learning systems; Medical applications; Computerized tomography scan; Disease detection; F1 scores; Functional modelling; Lung Cancer; Primary objective; Scan images; Sequential modeling; Volume data sets; X-ray image; accuracy; Article; computer assisted tomography; convolutional neural network; deep learning; feature extraction; human; lung cancer; lung disease; machine learning; pneumonia; positivity rate; thorax radiography; tuberculosis; algorithm; diagnostic imaging; pneumonia; procedures; x-ray computed tomography; Patient treatment","","","Hindawi Limited","36776955"
"Rao K.T.; Sridevi K.","Rao, K. Tarakeswara (57931344800); Sridevi, K. (57210201544)","57931344800; 57210201544","Development of tuned hybrid fuzzy and BiLSTM-based epileptic seizure classification model with stacked 1D-CNN-fisher discriminant feature selection","2023","11","6","","2239","2261","22","10.1080/21681163.2023.2227729","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166622537&doi=10.1080%2f21681163.2023.2227729&partnerID=40&md5=63dcc7141aa389d3b452e198cacf2eea","Electroencephalogram (EEG) is a signal which consists of different sinusoidal components with a dense frequency spectrum. The existing methods are time-consumingand includes inconsistencies in judgment among seizure classification. Therefore, it is very difficult to accurately detect epileptic seizures from the recorded EEG. Therefore, a new epileptic seizure detection model is developed with hybrid deep-structured technology. The EEG signal data obtained from the standard online resources which are given into the pre-processing phase with the help of band pass filtering and smoothing techniques. Then, the 5-level Discrete Wavelet Transform (5-level DWT) is used for signal decomposition to get the decomposed signals. 1-D stacked Convolutional Neural Network (1-D stacked CNN) is utilized for the extraction of features. After, the feature selection process is executed by utilizing the Fisher Discriminant Analysis (FDA). The selected features are subjected to the classification phase by Tuned Hybrid Fuzzy Bi-directional Long Short-Term Memory (THFBi-LSTM). Here, the parameter optimization takes place with hybridized optimization algorithm of Probability-based Dingo Coyote Optimization (P-DCO). In the overall simulation estimation, the offered approach achieves a 97% accuracy rate and also a 92% F1-score rate. Thus, the experimental results are reveled that it is better than the other baseline approaches. © 2023 Informa UK Limited, trading as Taylor & Francis Group.","1-D stacked convolutional neural network; 5-level discrete wavelet transform; Epileptic Seizure Classification; Probability-based dingo coyote optimisation; Tuned hybrid fuzzy and bi-directional long short term memory","Biomedical signal processing; Brain; Convolution; Convolutional neural networks; Discriminant analysis; Electroencephalography; Feature extraction; Learning algorithms; Long short-term memory; Neurodegenerative diseases; Neurophysiology; Signal reconstruction; 1-D stacked convolutional neural network; 5-level; 5-level discrete wavelet transform; Bi-directional; Convolutional neural network; Discrete-wavelet-transform; Epileptic seizure classification; Epileptic seizures; Optimisations; Probability-based dingo coyote optimization; Tuned hybrid fuzzy and bi-directional long short term memory; accuracy; Article; bi directional long short term memory; brain depth stimulation; convolutional neural network; decision making; decision tree; deep learning; discrete wavelet transform; discriminant analysis; electroencephalogram; electroencephalography; entropy; epilepsy; false discovery rate; fuzzy system; human; image segmentation; learning algorithm; long short term memory network; machine learning; mathematical model; neurologist; Q wave; seizure; sensitivity and specificity; signal noise ratio; signal processing; simulation; subthalamic nucleus; Discrete wavelet transforms","","","Taylor and Francis Ltd.",""
"He Y.; Zhang R.; Jiang Z.; Zhu H.","He, Yue (58817885600); Zhang, Rui (58509318900); Jiang, Zhichao (58817891800); Zhu, Hu (55551505700)","58817885600; 58509318900; 58817891800; 55551505700","BGFormer: Deep Bayersian Gabor Filtering Guided Transformer for Medical Image Denoising","2023","","","","799","805","6","10.1109/DASC/PiCom/CBDCom/Cy59711.2023.10361344","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182607858&doi=10.1109%2fDASC%2fPiCom%2fCBDCom%2fCy59711.2023.10361344&partnerID=40&md5=e0c477a97a910f218c024a41b8772c54","In recent years, modern diagnostic medical technology has developed rapidly, and computer tomography (CT) has become an important tool due to its fast detection speed and low cost. It is frequently used to assist in diagnosing complex conditions such as fractures and tumors. However, low-dose CT can lead to a decrease in image quality. For de-noising low-dose CT images, the enhanced performance not only relies on local features but also depends on the overall global characteristics due to the specific nature of medical images, where the shape and location of lesions vary for each patient. Nowadays, deep learning methods have gradually replaced traditional methods as the main-stream direction in low-dose CT image denoising, owing to their powerful feature representation capabilities. However, most algorithms still suffer from issues such as unclear local details, blurred line contours, and high computational complexity. In this paper, we propose a medical image denoising method based on gabor filtering neural network, combining the advantages of traditional filters with the unique strengths of deep learning. First, since gabor filtering is particularly effective for medical image processing, we use gabor filter obtained through variational inference instead of traditional convolutions, which enhances performance while reducing computational complexity. Second, we incorporate the use of Transformers in feature extraction to address the limitations of upsampling and downsampling operations, which cannot effectively model long-term context interactions and maintain the overall texture features of the images. Finally, we validate our method on the 2016 AAPM-Mayo Clinic Low-Dose CT Grand Challenge dataset and a fluorescence microscopy denoising dataset. The results show that our approach outperforms existing denoising methods in terms of PSNR, SSIM, and RMSE metrics, demonstrating its superiority.  © 2023 IEEE.","deep learning; gabor filtering; medical image denoising; U-Net","Biomedical engineering; Complex networks; Computational complexity; Computerized tomography; Diagnosis; Fluorescence microscopy; Gabor filters; Image denoising; Image enhancement; Image quality; Medical imaging; Textures; Computer tomography images; De-noising; Deep learning; Fast detections; Gabor filtering; Low dose; Medical image de-noising; Medical technologies; Performance; U-net; Deep learning","National Natural Science Foundation of China, NSFC, (62072256)","","Institute of Electrical and Electronics Engineers Inc.",""
"Zidane M.; Makky A.; Bruhns M.; Rochwarger A.; Babaei S.; Claassen M.; Schürch C.M.","Zidane, Mohammed (58251599200); Makky, Ahmad (58076474600); Bruhns, Matthias (58534904300); Rochwarger, Alexander (58096322800); Babaei, Sepideh (57221709578); Claassen, Manfred (26640261400); Schürch, Christian M. (26642210200)","58251599200; 58076474600; 58534904300; 58096322800; 57221709578; 26640261400; 26642210200","Corrigendum: A review on deep learning applications in highly multiplexed tissue imaging data analysis (Front. Bioinform., (2023), 3, 1159381, 10.3389/fbinf.2023.1159381)","2023","3","","1287407","","","","10.3389/fbinf.2023.1287407","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174854913&doi=10.3389%2ffbinf.2023.1287407&partnerID=40&md5=0fd80dad07ad512a9fc94f4ad14f9ff2","In the published article, there was an error. “The abstract is duplicated.” A correction has been made to Abstract. This sentence previously stated: “Since its introduction into the field of oncology, deep learning (DL) has impacted clinical discoveries and biomarker predictions. DL-driven discoveries and predictions in oncology are based on a variety of biological data such as genomics, proteomics, and imaging data. DL-based computational frameworks can predict genetic variant effects on gene expression, as well as protein structures based on amino acid sequences. Furthermore, DL algorithms can capture valuable mechanistic biological information from several spatial “omics” technologies, such as spatial transcriptomics and spatial proteomics. Here, we review the impact that the combination of artificial intelligence (AI) with spatial omics technologies has had on oncology, focusing on DL and its applications in biomedical image analysis, encompassing cell segmentation, cell phenotype identification, cancer prognostication, and therapy prediction. We highlight the advantages of using highly multiplexed images (spatial proteomics data) compared to single-stained, conventional histopathological (“simple”) images, as the former can provide deep mechanistic insights that cannot be obtained by the latter, even with the aid of explainable AI. Furthermore, we provide the reader with the advantages/disadvantages of DL-based pipelines used in preprocessing highly multiplexed images (cell segmentation, cell type annotation). Therefore, this review also guides the reader to choose the DLbased pipeline that best fits their data. In conclusion, DL continues to be established as an essential tool in discovering novel biological mechanisms when combined with technologies such as highly multiplexed tissue imaging data. In balance with conventional medical data, its role in clinical routine will become more important, supporting diagnosis and prognosis in oncology, enhancing clinical decision-making, and improving the quality of care for patients. Since its introduction into the field of oncology, deep learning (DL) has impacted clinical discoveries and biomarker predictions. DL-driven discoveries and predictions in oncology are based on a variety of biological data such as genomics, proteomics, and imaging data. DL-based computational frameworks can predict genetic variant effects on gene expression, as well as protein structures based on amino acid sequences. Furthermore, DL algorithms can capture valuable mechanistic biological information from several spatial “omics” technologies, such as spatial transcriptomics and spatial proteomics. Here, we review the impact that the combination of artificial intelligence (AI) with spatial omics technologies has had on oncology, focusing on DL and its applications in biomedical image analysis, encompassing cell segmentation, cell phenotype identification, cancer prognostication, and therapy prediction. We highlight the advantages of using highly multiplexed images (spatial proteomics data) compared to single-stained, conventional histopathological (“simple”) images, as the former can provide deep mechanistic insights that cannot be obtained by the latter, even with the aid of explainable AI. Furthermore, we provide the reader with the advantages/ disadvantages of the DL-based pipelines used in preprocessing the highly multiplexed images (cell segmentation, cell type annotation). Therefore, this review also guides the reader to choose the DL-based pipeline that best fits their data. In conclusion, DL continues to be established as an essential tool in discovering novel biological mechanisms when combined with technologies such as highly multiplexed tissue imaging data. In balance with conventional medical data, its role in clinical routine will become more important, supporting diagnosis and prognosis in oncology, enhancing clinical decision-making, and improving the quality of care for patients.” The corrected sentence appears below: “Since its introduction into the field of oncology, deep learning (DL) has impacted clinical discoveries and biomarker predictions. DL-driven discoveries and predictions in oncology are based on a variety of biological data such as genomics, proteomics, and imaging data. DL-based computational frameworks can predict genetic variant effects on gene expression, as well as protein structures based on amino acid sequences. Furthermore, DL algorithms can capture valuable mechanistic biological information from several spatial “omics” technologies, such as spatial transcriptomics and spatial proteomics. Here, we review the impact that the combination of artificial intelligence (AI) with spatial omics technologies has had on oncology, focusing on DL and its applications in biomedical image analysis, encompassing cell segmentation, cell phenotype identification, cancer prognostication, and therapy prediction. We highlight the advantages of using highly multiplexed images (spatial proteomics data) compared to single-stained, conventional histopathological (“simple”) images, as the former can provide deep mechanistic insights that cannot be obtained by the latter, even with the aid of explainable AI. Furthermore, we provide the reader with the advantages/disadvantages of DL-based pipelines used in preprocessing highly multiplexed images (cell segmentation, cell type annotation). Therefore, this review also guides the reader to choose the DL-based pipeline that best fits their data. In conclusion, DL continues to be established as an essential tool in discovering novel biological mechanisms when combined with technologies such as highly multiplexed tissue imaging data. In balance with conventional medical data, its role in clinical routine will become more important, supporting diagnosis and prognosis in oncology, enhancing clinical decision-making, and improving the quality of care for patients.” In the published article, there was an error. “the word ‘recently’ is repeated.” A correction has been made to Applications in highly multiplexed images, [paragraph 3]. This sentence previously stated: “Recently, Graph Neural Networks (GNNs) (Scarselli et al., 2009) were recently used to model the TME.” The corrected sentence appears below: “Recently, Graph Neural Networks (GNNs) (Scarselli et al., 2009) were used to model the TME.” In the published article, there was an error. “the term ‘convolutional neural network’ is repeated”. A correction has been made to Applications in conventional medical (“simple”) images, [paragraph 5]. This sentence previously stated: “The DL-based framework consists of two neural networks: a convolutional neural network: a convolutional neural network CNN (pre-trained GoogleNet on ImageNet), which was trained on the CT scans to extract the important features from lesions of different organs, and a recurrent neural network RNN which learned the changes happening in these lesions across multiple time points.” The corrected sentence appears below: “The DL-based framework consists of two neural networks: a convolutional neural network CNN (pre-trained GoogleNet on ImageNet), which was trained on the CT scans to extract the important features from lesions of different organs, and a recurrent neural network RNN which learned the changes happening in these lesions across multiple time points.” In the published article, there was an error. “two references are not written as a hyperlink; it is just a number that you cannot click on”. A correction has been made to reference (148) in Table 1 is not a hyperlink and reference (171) in Table 3. Both references are written as numbers not as hyperlinks. This sentence previously stated: “Could be combined with TrackMate (148) for cell tracking in Table 1.” “Map snRNA-seq data to spatial data of different resolutions, ISH associated with histological and anatomical coordinates, midresolution Spatial Transcriptomics, and high-resolution STARmap (171) and MERFISH in Table 3.” The corrected sentence appears below: “They should be hyperlinks.” The authors apologize for these errors and state that this does not change the scientific conclusions of the article in any way. The original article has been updated. Copyright © 2023 Zidane, Makky, Bruhns, Rochwarger, Babaei, Claassen and Schürch.","artificial intelligence; biomarker; cancer; deep learning; highly multiplexed tissue imaging; prediction; review; spatial transcriptomics","","","","Frontiers Media SA",""
"Kumar A.; Sharma A.; Singh A.K.; Singh S.K.; Saxena S.","Kumar, Abhinav (57307821000); Sharma, Anshul (57216653969); Singh, Amit Kumar (55726466900); Singh, Sanjay Kumar (57413852300); Saxena, Sonal (57225828070)","57307821000; 57216653969; 55726466900; 57413852300; 57225828070","Data Augmentation for Medical Image Classification based on Gaussian Laplacian Pyramid Blending with a Similarity Measure","2023","","","","1","8","7","10.1109/JBHI.2023.3307216","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168751962&doi=10.1109%2fJBHI.2023.3307216&partnerID=40&md5=b99ad6cd5754ba6bf9bd1fa04b4309cb","Breast cancer is a devastating disease that affects women worldwide, and computer-aided algorithms have shown potential in automating cancer diagnosis. Recently Generative Artificial Intelligence (GenAI) opens new possibilities for addressing the challenges of labeled data scarcity and accurate prediction in critical applications. However, a lack of diversity, as well as unrealistic and unreliable data, have a detrimental impact on performance. Therefore, this study proposes an augmentation scheme to address the scarcity of labeled data and data imbalance in medical datasets. This approach integrates the concepts of the Gaussian-Laplacian pyramid and pyramid blending with similarity measures. In order to maintain the structural properties of images and capture inter-variability of patient images of the same category similarity-metric-based intermixing has been introduced. It helps to maintain the overall quality and integrity of the dataset. Subsequently, deep learning approach with significant modification, that leverages transfer learning through the usage of concatenated pre-trained models is applied to classify breast cancer histopathological images. The effectiveness of the proposal, including the impact of data augmentation, is demonstrated through a detailed analysis of three different medical datasets, showing significant performance improvement over baseline models. The proposal has the potential to contribute to the development of more accurate and reliable approach for breast cancer diagnosis. IEEE","Biomedical imaging; Breast cancer; Breast Cancer Classification; Cancer; Computer-aided Diagnosis; Convolution Neural Networks(CNN); Data augmentation; Data Augmentation; Gaussian-Laplacian Pyramid; Histopathology; Medical diagnostic imaging; Similarity measure; Solid modeling; Transfer learning","","","","Institute of Electrical and Electronics Engineers Inc.","37603476"
"Geetha S.; Sharmila V.; Sasikala S.; Balamurugan S.A.A.; Balamurugan N.M.","Geetha, S. (24472945600); Sharmila, V. (57289564900); Sasikala, S. (57218147540); Balamurugan, S. Appavu Alias (55757784880); Balamurugan, N.M. (57212762173)","24472945600; 57289564900; 57218147540; 55757784880; 57212762173","Detecting Gastro-Intestinal Cancer from Wireless Capsule Endoscopy Images using Efficient Net Model","2023","","","","222","227","5","10.1109/ICTS58770.2023.10330886","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180374648&doi=10.1109%2fICTS58770.2023.10330886&partnerID=40&md5=4fcb8051520d073f702bb458b6e3c5ad","Recently polyps and ulcers have become a fatal form of gastrointestinal problem, and several researchers have looked into algorithms to diagnose gastrointestinal cancer lesions. This research work investigates the application of CNN to detect Gastro-Intestinal (GI) cancer from wireless capsule endoscopy (WCE) GI images. Five distinct CNN architectures EfficientNet, LeNet, GoogleNet, MobileNet-V2, and ResNet-50 have been studied, with two different setups i) original data with transfer learning ii) original data with data augmentation, and transfer learning. Simulations ran on 37,790 images with five different CNN architectures proved that the EfficientNet model exhibited superior performance of about 99.15% accuracy over all other CNN models, on the augmented dataset. Furthermore, the results from the experiments show that the EfficientNet model significantly outperforms previous methods in terms of classification accuracy.  © 2023 IEEE.","Biomedical Application; Convolution Neural Network (CNN); Data Augmentation; Deep learning; Efficient Net; Gastro-Intestinal (GI); GoogleNet; LeNet; MobileNet-V2; ResNet-50; Transfer learning; Wireless Capsule Endoscopy (WCE)","Convolutional neural networks; Deep learning; Endoscopy; Learning systems; Medical applications; Network architecture; Transfer learning; Biomedical applications; Convolution neural network; Data augmentation; Deep learning; Efficient net; Gastro-intestinal; Googlenet; Lenet; Mobilenet-v2; Resnet-50; Transfer learning; Wireless capsule endoscopy; Diseases","","","Institute of Electrical and Electronics Engineers Inc.",""
"Shchetinin E.Y.; Glushkova A.G.; Blinkov Y.A.","Shchetinin, Eugene Yu. (16408533100); Glushkova, Anastasia G. (57485591900); Blinkov, Yury A. (6701893186)","16408533100; 57485591900; 6701893186","On Effectiveness of the Adversarial Attacks on the Computer Systems of Biomedical Images Classification","2023","1748 CCIS","","","91","103","12","10.1007/978-3-031-30648-8_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161391475&doi=10.1007%2f978-3-031-30648-8_8&partnerID=40&md5=1be7cdf52aeacb41c838831351b7b3da","The problems of vulnerability of the computer systems of biomedical images classification to adversarial attacks on are investigated. The aim of the work is to study the effectiveness of the impact of various models of adversarial attacks on biomedical images and the values of control parameters of algorithms for generating their attacking versions. The effectiveness of attacks prepared using the projected gradient descent algorithm (PGD), Deep Fool (DF) algorithm and Carlini-Wagner algorithm (CW) is investigated. Experimental studies were carried out on the example of solving typical problems of medical images classification using deep neural networks VGG16, EfficientNetB2, DenseNet121, Xception, ResNet50 as well as data containing chest X-rays images and brain MRI-scan images. Our findings in this work are as follows. Deep models were very susceptible to adversarial attacks, which led to decrease of the accuracy classification of the models for all datasets. Prior to the use of adversarial methods, we achieved a classification accuracy of 93.6% for brain MRI and 99.1% for chest X-rays. During the DF attack the accuracy of the VGG16 model showed a maximum absolute decrease of 49.8% for MRI-scans, and 57.3% for chest X-rays images. The gradient descent (PGD) algorithm with the same values of malicious image disturbances is less effective than the DF and the CW adversarial attacks. VGG16 deep model is more effective in accuracy classification on considered datasets and most vulnerable to adversarial attacks among other deep models. We hope that these results would be useful to design more robust and secure medical deep learning systems. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","adversarial attacks; black-box attack; brain tumor MRI-scans; chest X-ray images; deep learning; white-box attacks","Bioinformatics; Deep neural networks; Gradient methods; Image classification; Learning systems; Magnetic resonance imaging; Medical imaging; Medical problems; Adversarial attack; Black boxes; Black-box attack; Brain tumor MRI-scan; Brain tumors; Chest X-ray image; Deep learning; MRI scan; White box; White-box attack; Classification (of information)","RUDN University","Vishnevskiy V.M.; Samouylov K.E.; Kozyrev D.V.; Kozyrev D.V.","Springer Science and Business Media Deutschland GmbH",""
"Mondal S.; Paul S.; Singh N.; Saha R.K.","Mondal, Sudeep (58681331100); Paul, Subhadip (57404479800); Singh, Navjot (57214659061); Saha, Ratan K. (8567237300)","58681331100; 57404479800; 57214659061; 8567237300","Deep learning on photoacoustic tomography to remove image distortion due to inaccurate measurement of the scanning radius","2023","14","11","","5817","5832","15","10.1364/BOE.501277","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175720396&doi=10.1364%2fBOE.501277&partnerID=40&md5=8fdb85d88d2b57dbe567ed32343b973e","Photoacoustic tomography (PAT) is a non-invasive, non-ionizing hybrid imaging modality that holds great potential for various biomedical applications and the incorporation with deep learning (DL) methods has experienced notable advancements in recent times. In a typical 2D PAT setup, a single-element ultrasound detector (USD) is used to collect the PA signals by making a 360° full scan of the imaging region. The traditional backprojection (BP) algorithm has been widely used to reconstruct the PAT images from the acquired signals. Accurate determination of the scanning radius (SR) is required for proper image reconstruction. Even a slight deviation from its nominal value can lead to image distortion compromising the quality of the reconstruction. To address this challenge, two approaches have been developed and examined herein. The first framework includes a modified version of dense U-Net (DUNet) architecture. The second procedure involves a DL-based convolutional neural network (CNN) for image classification followed by a DUNet. The first protocol was trained with heterogeneous simulated images generated from three different phantoms to learn the relationship between the reconstructed and the corresponding ground truth (GT) images. In the case of the second scheme, the first stage was trained with the same heterogeneous dataset to classify the image type and the second stage was trained individually with the appropriate images. The performance of these architectures has been tested on both simulated and experimental images. The first method can sustain SR deviation up to approximately 6% for simulated images and 5% for experimental images and can accurately reproduce the GTs. The proposed DL-approach extends the limits further (approximately 7% and 8% for simulated and experimental images, respectively). Our results suggest that classification-based DL method does not need a precise assessment of SR for accurate PAT image formation. © 2023 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement.","","Classification (of information); Convolutional neural networks; Deep learning; Image classification; Learning systems; Medical applications; Network architecture; Photoacoustic effect; Tomography; Biomedical applications; Hybrid imaging; Image distortions; Imaging modality; Learning methods; Measurements of; Photoacoustic tomography; Simulated images; Single element; Ultrasound detectors; Article; artificial neural network; convolutional neural network; deep learning; image display; image distortion; image quality; image reconstruction; image segmentation; information processing; learning algorithm; mean absolute error; Network optimization; photoacoustic tomography; process optimization; radius; scanning radius; signal noise ratio; simulation; three-dimensional imaging; training; Image reconstruction","Department of Biotechnology, Ministry of Science and Technology, India, DBT, (BT/PR44547/MED/32/791/2021); Indian Council of Medical Research, ICMR, (56/2/2020-Hae/BMS)","","Optica Publishing Group (formerly OSA)",""
"Neeraja R.; Jani Anbarasi L.","Neeraja, R. (57194408631); Jani Anbarasi, L. (57222292455)","57194408631; 57222292455","CephXNet: A Deep Convolutional Squeeze-and-Excitation Model for Landmark Prediction on Lateral Cephalograms","2023","11","","","90780","90800","20","10.1109/ACCESS.2023.3307636","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168734424&doi=10.1109%2fACCESS.2023.3307636&partnerID=40&md5=8dc6af736ab4a92a9f2421b8617228ed","Cephalometric landmark identification is a crucial and significant procedure that is generally used for orthodontic treatment planning and diagnosis. Computer-aided fully automated solutions can assist orthodontists and orthognathic surgeons' to precisely identify the landmarks from cephalograms more efficiently. Most of the existing research studies deployed Convolutional Neural Network models, transfer learning methods, and pre-trained architectures to predict the XY coordinates of landmarks from cephalometric radiographs. Deep learning architectures have achieved good results in accurately predicting landmarks compared to machine learning methodologies. In this paper, a custom CNN model integrated with Squeeze-and-Excitation (SEB) attention block named CephXNet architecture is proposed to automatically classify and predicts the XY coordinates of 19 landmarks from lateral cephalograms. The SEB block, which can adaptively refine information from various feature channels of X-ray images models the interdependence between the channels to enhance the discriminative features and suppress noise. The Squeeze-and-Excitation block incorporated with multiple Convolution and Max pooling layers enhances independent channel feature learning and thereby improves the representational power of the proposed CephXNet architecture. The proposed framework obtained an accuracy of 97.72% for 19 landmark classifications and has achieved 88.06% and 78.72% of Successful Detection Rate (SDR) in clinically accepted 2mm precision range for test1 and test2 datasets provided in the 2015 International Symposium on Biomedical Imaging (ISBI) grand challenge for dental X-ray analysis conducted by IEEE. Furthermore, the proposed CephXNet is also tested with private clinical dataset comprised of 100 cephalograms collected from Solanki Dental Care Clinic in Sharjah, United Arab Emirates. The proposed CephXNet model obtained a classification accuracy of 90.08% and an average SDR of 73.94% in the 2mm precision range. The experimental outcomes show proposed CephXNet model is efficient and has great potential to deploy in clinical practice.  © 2013 IEEE.","Artificial deep neural networks; cephalometric landmark classification; landmark prediction; squeeze-and-excitation block; X-ray images","Classification (of information); Computer aided diagnosis; Computer architecture; Convolution; Feature extraction; Forecasting; Image classification; Image enhancement; Medical imaging; Network architecture; X ray analysis; Artificial deep neural network; Cephalometric landmark classification; Classification algorithm; Convolutional neural network; Deep learning; Features extraction; Landmark prediction; Predictive models; Squeeze-and-excitation block; X-ray image; X-ray imaging; Deep neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Ambika G.N.; Suresh Y.","Ambika, G.N. (57507803900); Suresh, Yeresime (56120910500)","57507803900; 56120910500","An Efficient Deep Learning with Optimization Algorithm for Emotion Recognition in Social Networks","2023","14","8","","206","215","9","10.14569/IJACSA.2023.0140823","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170651793&doi=10.14569%2fIJACSA.2023.0140823&partnerID=40&md5=a0ee55f13d5ad446819912002114c4cf","Emotion recognition, or computers' ability to interpret people's emotional states, is a rapidly expanding topic with many life-improving applications. However, most image-based emotion recognition algorithms have flaws since people can disguise their emotions by changing their facial expressions. As a result, brain signals are being used to detect human emotions with increased precision. However, most proposed systems could do better because electroencephalogram (EEG) signals are challenging to classify using typical machine learning and deep learning methods. Human-computer interaction, recommendation systems, online learning, and data mining all benefit from emotion recognition in photos. However, there are challenges with removing irrelevant text aspects during emotion extraction. As a consequence, emotion prediction is inaccurate. This paper proposes Radial Basis Function Networks (RBFN) with Blue Monkey Optimization to address such challenges in human emotion recognition (BMO). The proposed RBFN-BMO detects faces on large-scale images before analyzing face landmarks to predict facial expressions for emotional acknowledgment. Patch cropping and neural networks comprise the two stages of the RBFN-BMO. Pre-processing, feature extraction, rating, and organizing are the four categories of the proposed model. In the ranking stage, appropriate features are extracted from the pre-processed information, the data are then classed, and accurate output is obtained from the classification phase. This study compares the results of the proposed RBFN-BMO algorithm to the previous state-of-the-art algorithms using publicly available datasets derived from the RBFN-BMO model. Furthermore, we demonstrated the efficacy of our framework in comparison to previous works. The results show that the projected method can progress the rate of emotion recognition on datasets of various sizes. © (2023), (Science and Information Organization). All Rights Reserved.","Blue monkey optimization (BMO); deep learning; electroencephalograph (EEG); emotion recognition; human-computer interaction (HCI); radial basis function networks (RBFN)","Biomedical signal processing; Classification (of information); Data mining; Deep learning; Electroencephalography; Emotion Recognition; Extraction; Human computer interaction; Learning algorithms; Learning systems; Online systems; Social networking (online); Speech recognition; Blue monkey optimization; Deep learning; Electroencephalograph; Emotion recognition; Emotional state; Facial Expressions; Human-computer interaction; Optimisations; Optimization algorithms; Radial base function network; Radial basis function networks","","","Science and Information Organization",""
"Obayya M.; Al-Wesabi F.N.; Maashi M.; Mohamed A.; Hamza M.A.; Drar S.; Yaseen I.; Alsaid M.I.","Obayya, Marwa (6505869929); Al-Wesabi, Fahd N. (57211901842); Maashi, Mashael (57216199758); Mohamed, Abdullah (57213606201); Hamza, Manar Ahmed (57223407265); Drar, Suhanda (58131064100); Yaseen, Ishfaq (57410292800); Alsaid, Mohamed Ibrahim (57964125000)","6505869929; 57211901842; 57216199758; 57213606201; 57223407265; 58131064100; 57410292800; 57964125000","Modified Salp Swarm Algorithm with Deep Learning Based Gastrointestinal Tract Disease Classification on Endoscopic Images","2023","11","","","25959","25967","8","10.1109/ACCESS.2023.3256084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149866871&doi=10.1109%2fACCESS.2023.3256084&partnerID=40&md5=ee1578ee18ab5ad1a7259bd50ebd69e5","Nowadays, the analysis of gastrointestinal (GI) tract disease utilzing endoscopic image classification becomes an active research activity from the biomedical sector. The latest technology in medical imaging is Wireless Capsule Endoscopy (WCE) for diagnosing gastrointestinal diseases namely bleeding, ulcer, polyp, and so on. Manual diagnoses will be time taking and tough for the medical practitioner; thus, the authors have designed computerized approaches for classifying and detecting such diseases. Many research groups presented various machine learning (ML) and image processing methods for classifying GI tract diseases in recent times. Conventional data augmentation and image processing methods are integrated with adjusted pre-trained deep convolutional neural networks (CNNs) for classifying diseases in the GI tract from WCI images. This study presents a Modified Salp Swarm Algorithm with Deep Learning based Gastrointestinal Tract Disease Classification (MSSADL-GITDC) on Endoscopic Images. The presented MSSADL-GITDC technique mainly focuses on the examination of WCE images for GIT classification. To accomplish this, the presented MSSADL-GITDC technique applies median filtering (MF) technique for image smoothening. The presented MSSADL-GITDC technique designs improved capsule network (CapsNet) model for feature extraction where the CapsNet model is modified by the class attention layer (CAL). Moreover, MSSA based hyperparameter tuning process is performed to improve the efficiency of the improved CapsNet model. For GIT classification, deep belief network with extreme learning machine (DBN-ELM) was used. Finally, backpropagation is applied for supervised fine tuning of the DBN-ELM model. The experimental validation of the MSSADL-GITDC technique takes place on Kvasir-V2 database reported the betterment of the MSSADL-GITDC technique on GIT classification with maximum accuracy of 98.03%. © 2013 IEEE.","deep learning; fine-tuning; gastrointestinal tract diseases; Medical imaging; metaheursitics; salp swarm algorithm","Data handling; Deep neural networks; Endoscopy; Image classification; Iterative methods; Learning algorithms; Median filters; Medical imaging; Swarm intelligence; Classification technique; Deep learning; Disease classification; Fine tuning; Gastrointestinal tract; Gastrointestinal tract disease; Metaheursitic; Salp swarm algorithm; Salp swarms; Swarm algorithms; Classification (of information)","","","Institute of Electrical and Electronics Engineers Inc.",""
"Mylonas N.; Mollas I.; Bassiliades N.; Tsoumakas G.","Mylonas, Nikolaos (57226736804); Mollas, Ioannis (57204474208); Bassiliades, Nick (6603620714); Tsoumakas, Grigorios (8088070600)","57226736804; 57204474208; 6603620714; 8088070600","Local Multi-label Explanations for Random Forest","2023","1752 CCIS","","","369","384","15","10.1007/978-3-031-23618-1_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149886121&doi=10.1007%2f978-3-031-23618-1_25&partnerID=40&md5=0e2d7e66974fb914f221232f33dfa2d4","Multi-label classification is a challenging task, particularly in domains where the number of labels to be predicted is large. Deep neural networks are often effective at multi-label classification of images and textual data. When dealing with tabular data, however, conventional machine learning algorithms, such as tree ensembles, appear to outperform competition. Random forest, being a popular ensemble algorithm, has found use in a wide range of real-world problems. Such problems include fraud detection in the financial domain, crime hotspot detection in the legal sector, and in the biomedical field, disease probability prediction when patient records are accessible. Since they have an impact on people’s lives, these domains usually require decision-making systems to be explainable. Random Forest falls short on this property, especially when a large number of tree predictors are used. This issue was addressed in a recent research named LionForests, regarding single-label classification and regression. In this work, we adapt this technique to multi-label classification problems, by employing three different strategies regarding the labels that the explanation covers. Finally, we provide a set of qualitative and quantitative experiments to assess the efficacy of this approach. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Explainable artificial intelligence; Interpretable machine learning; Multi-label learning; Random forest","Behavioral research; Classification (of information); Crime; Decision making; Deep neural networks; Learning systems; Explainable artificial intelligence; Image data; Interpretable machine learning; Machine-learning; Multi-label classifications; Multi-label learning; Multi-labels; Random forests; Tabular data; Textual data; Learning algorithms","Hellenic Foundation for Research and Innovation, ΕΛ.ΙΔ.Ε.Κ, (514); Hellenic Foundation for Research and Innovation, ΕΛ.ΙΔ.Ε.Κ","Koprinska I.; Mignone P.; Guidotti R.; Jaroszewicz S.; Fröning H.; Gullo F.; Ferreira P.M.; Roqueiro D.; Ceddia G.; Nowaczyk S.; Gama J.; Ribeiro R.; Gavaldà R.; Masciari E.; Ras Z.; Ritacco E.; Naretto F.; Theissler A.; Biecek P.; Verbeke W.; Schiele G.; Pernkopf F.; Blott M.; Bordino I.; Danesi I.L.; Ponti G.; Severini L.; Appice A.; Andresini G.; Medeiros I.; Graça G.; Cooper L.; Ghazaleh N.; Richiardi J.; Saldana D.; Sechidis K.; Canakoglu A.; Pido S.; Pinoli P.; Bifet A.; Pashami S.","Springer Science and Business Media Deutschland GmbH",""
"Ali M.S.; Hassan A.; Rahim A.; Ashraf M.H.; Rahim A.; Saghir S.","Ali, Muhammad Shahroze (57223753208); Hassan, Ali (57184855600); Rahim, Aqsa (57214824606); Ashraf, Muhammad Hashir (58590729700); Rahim, Amna (57214824607); Saghir, Shayaan (57221926785)","57223753208; 57184855600; 57214824606; 58590729700; 57214824607; 57221926785","Motor Imagery EEG Classification Using Fine-Tuned Deep Convolutional EfficientNetB0 Model","2023","","","","1","6","5","10.1109/ICAI58407.2023.10136681","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162729019&doi=10.1109%2fICAI58407.2023.10136681&partnerID=40&md5=218c9e3a1b2d99b18dcff391757ef9bf","This work proposes a new way to apply the deep convolutional EfficientN etB0 model for the classification to learn various electroencephalogram (EEG) signal properties on BCI competition IV dataset 2b. Several deep convolutional neural networks (DCNN)-based techniques have been applied to enhance the accuracy of motor imagery-based brain-computer interfaces (BCIs). The time-varying nature of various frequency bands makes extracting informative features from EEG signals difficult, causing the loss of DCNN classification accuracy. The EfficientNetB0 baseline model's feature extraction capability is used to overcome these limitations by first transforming EEG 1D signals into 2D images using the feature extraction technique of the Short-Time Fourier Transform (STFT) algorithm to train and evaluate the EfficientNetB0 model. The transfer learning approach is used to expand the initial feature sets for efficient model training in a short period. After learning from the dataset, the entire model is retrained and fine-tuned to work with the proposed layers. Our evaluated results demonstrated that the highest average Accuracy, Precision, Recall, F1-Score and MCC with the STFT method is 86.46%,88.2%, 91.2%,89.78% and 0.815 respectively over 10 epochs. According to the results, the proposed methodology outperforms other state-of-the-art DCNN models for feature extraction and classification of two-class motor imagery, namely right-hand and left-hand movements for the given dataset.  © 2023 IEEE.","Deep Convolutional Neural Networks (DCNNs); EfficientNetB0; Fine-Tuning; Motor Imagery (MI); Short Time Fourier Transform (STFT); Transfer Learning","Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Electroencephalography; Extraction; Feature extraction; Image classification; Image enhancement; Learning systems; Convolutional neural network; Deep convolutional neural network; Efficientnetb0; Electroencephalogram signals; Fine tuning; Motor imagery; Short time fourier transform; Short time Fourier transforms; Transfer learning; Brain computer interface","","","Institute of Electrical and Electronics Engineers Inc.",""
"Toubal I.E.; Al-Shakarji N.; Cornelison D.; Palaniappan K.","Toubal, Imad Eddine (57223828098); Al-Shakarji, Noor (57192087400); Cornelison, DDW (6602471760); Palaniappan, K. (6701784534)","57223828098; 57192087400; 6602471760; 6701784534","Ensemble Deep Learning Object Detection Fusion for Cell Tracking, Mitosis, and Lineage","2023","","","","1","17","16","10.1109/OJEMB.2023.3288470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163448883&doi=10.1109%2fOJEMB.2023.3288470&partnerID=40&md5=527924532fc5e120d33945d4ff2e444c","Cell tracking and motility analysis are essential for understanding multicellular processes, automated quantification in biomedical experiments, and medical diagnosis and treatment. However, manual tracking is labor-intensive, tedious, and prone to selection bias and errors. Building upon our previous work, we propose a new deep learning-based method, EDNet, for cell detection, tracking, and motility analysis that is more robust to shape across different cell lines, and models cell lineage and proliferation. EDNet uses an ensemble approach for 2D cell detection that is deep-architecture-agnostic and achieves state-of-the-art performance surpassing single-model YOLO and FasterRCNN convolutional neural networks. EDNet detections are used in our M2Track multiobject tracking algorithm for tracking cells, detecting cell mitosis (cell division) events, and cell lineage graphs. Our methods produce state-of-the-art performance on the Cell Tracking and Mitosis (CTMCv1) dataset with a Multiple Object Tracking Accuracy (MOTA) score of 50.6&#x0025; and tracking lineage graph edit (TRA) score of 52.5&#x0025;. Additionally, we compare our detection and tracking methods to human performance on external data in studying the motility of muscle stem cells with different physiological and molecular stimuli. We believe that our method has the potential to improve the accuracy and efficiency of cell tracking and motility analysis. This could lead to significant advances in biomedical research and medical diagnosis. Our code is made publicly available on GitHub1. Author","cell tracking; Computer architecture; Deep learning; deep learning; deformable object tracking; detection; ensemble; Image segmentation; Microprocessors; Microscopy; multiobject tracking; Task analysis; Training","Cell culture; Cell proliferation; Computer architecture; Deep learning; Diagnosis; Image segmentation; Medical imaging; Network architecture; Neural networks; Object recognition; Stem cells; Cell tracking; Deep learning; Deformable object; Deformable object tracking; Detection; Ensemble; Images segmentations; Multi-object tracking; Object Tracking; Task analysis; Object detection","","","Institute of Electrical and Electronics Engineers Inc.",""
"Agarwal R.; Sarma P.; Dev N.; Mazumder P.P.","Agarwal, Rashi (59031244600); Sarma, Parismita (57195313986); Dev, Nabamita (58852199200); Mazumder, Partha Pratim (57405259600)","59031244600; 57195313986; 58852199200; 57405259600","Detection of Brain Tumor from MRI Samples Using Deep Learning Algorithms","2023","","","","","","","10.1109/ICAEECI58247.2023.10370777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183550578&doi=10.1109%2fICAEECI58247.2023.10370777&partnerID=40&md5=f8a40d1c63e296105317ac6f6a7b69f1","Biomedical image processing is a rapidly expanding and challenging discipline. Brain tumor segmentation technique is critical in the detection and treatment of MRI brain cancers. It aids clinicians in the detection and measurement of cancers, as well as the development of treatment and rehabilitation methods. MRI brain tumor segmentation approaches based on U-Net architecture have gained popularity because they significantly enhance segmentation accuracy by combining high-level and low-level feature information using skip connections. This project, shows comparison of the performance of deep learning models such as ResNet50, VGG16 (via transfer learning), and CNN models in detecting brain tumor, demonstrating that ResNet50 outperforms VGG16 and CNN models by achieving the highest classification accuracy of 98 percent. © 2023 IEEE.","Brain tumor; CNN; MRI scan; ResNet-50; VGG-16","Brain; Convolutional neural networks; Deep learning; Diseases; Learning algorithms; Learning systems; Medical imaging; Tumors; Brain cancer; Brain tumor segmentation; Brain tumors; CNN models; Learning models; Measurements of; MRI scan; Resnet-50; Segmentation techniques; VGG-16; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"Pattichis M.S.; Acton S.T.; Pattichis C.S.; Panayides A.S.","Pattichis, Marios S. (7004755649); Acton, Scott T. (7006577888); Pattichis, Constantinos S. (35495139000); Panayides, Andreas S. (16646871500)","7004755649; 7006577888; 35495139000; 16646871500","Guest Editorial Large-Scale Medical Image and Video Analytics for Clinical Decision Support","2023","27","1","","4","6","2","10.1109/JBHI.2022.3227126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147148092&doi=10.1109%2fJBHI.2022.3227126&partnerID=40&md5=f37653dd0c112f20cea70bc2f5f37358","[No abstract available]","","accuracy; adenocarcinoma; artificial intelligence; artificial neural network; biomedical image classification method; brain tissue segmentation; Bruch membrane; conceptual framework; data base; decision support system; deep learning; degenerative disease; dual attention deep manifold harmonic discrimination; Editorial; endobronchial ultrasonography; endoscopy; ensemble learning; gastritis atrophy; geometry; glioma; human; image classification; intestinal metaplasia; large scale production; learning algorithm; light imaging; meta learning; microscopy; multiinstance learning; multilabel classification; nerve cell network; neurilemoma; optical coherence tomography; partial image phase correlation; performance; personalized medicine; polyculture; radiography; radiologist; rheumatoid arthritis; small cell carcinoma; squamous cell carcinoma; training; ultrasound; validation study; video analytics; videorecording; visual feature","","","Institute of Electrical and Electronics Engineers Inc.",""
"Lu H.; Zhao B.","Lu, Hengfa (57194704542); Zhao, Bo (55823580100)","57194704542; 55823580100","Accelerated Magnetic Resonance Parameter Mapping With Low-Rank Modeling and Deep Generative Priors","2023","2023-July","","","403","407","4","10.1109/SSP53291.2023.10207997","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163073816&doi=10.1109%2fSSP53291.2023.10207997&partnerID=40&md5=48872be8d0cee2d2a60c268628a68eda","Magnetic resonance (MR) parameter mapping aims to quantify MR tissue parameter maps that are valuable biomarkers for a range of biomedical applications. However, it involves solving a high-dimensional imaging problem and its practical utility has been limited by long acquisition times. This paper presents a new image reconstruction method for accelerated MR parameter mapping, integrating low-rank modeling with deep generative priors. Specifically, the proposed method employs a low-rank model to capture the strong spatiotemporal correlation of contrast-weighted images in an MR parameter mapping experiment, while representing the spatial subspace of the model using an untrained generative neural network. Here the untrained neural network serves as an effective regularizer for the low-rank and subspace reconstruction. We develop an algorithm based on variable splitting and the alternating direction method of multipliers to solve the resulting optimization problem. We demonstrate the effectiveness of the proposed method in an MR parameter mapping application example. © 2023 IEEE.","deep learning; generative model; Low-rank model; quantitative MRI; subspace model","Deep learning; Generative adversarial networks; Image reconstruction; Mapping; Medical applications; Medical imaging; Biomedical applications; Deep learning; Generative model; High-dimensional; Low-rank model; Neural-networks; Quantitative MRI; Rank modeling; Resonance parameters; Subspace modeling; Magnetic resonance","National Institutes of Health, NIH, (NIH-R00-EB027181)","","IEEE Computer Society",""
"Sakthi U.; Thangaraj K.; Tamizhselvi A.; Kirubakaran M.K.","Sakthi, U. (57722437700); Thangaraj, K. (56735937800); Tamizhselvi, A. (55761740700); Kirubakaran, M.K. (56023962000)","57722437700; 56735937800; 55761740700; 56023962000","Deep Convolutional Neural Network Framework for Brain Tumor Classification using MRI Images","2023","","","","548","553","5","10.1109/ICACRS58579.2023.10404771","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185387748&doi=10.1109%2fICACRS58579.2023.10404771&partnerID=40&md5=a7d8b55d5166622e96d78b7f775d436c","Brain cancer is one of the high-risk diseases and increases the death rate in all countries, affecting both men and women. The early diagnosis and severity of brain cancer leads to better medical treatment and save people's lives. The machine learning procedure has been applied for early detection and treatment of brain cancer in the biomedical field by classifying them into low-risk and high-risk groups. In cancer research, the predictive and classification model has been developed using Deep Convolutional Neural Network (DCNN) algorithms for accurate decision making. The Magnetic Resonance Image (MRI) classification technique DCNN is advanced to detect and match feature points of training and test images. The DCNN classifier based on the outcome of feature points then classifies images. The key notion of this proposed research effort is to implement and execute the proposed DCNN algorithm on cancer patient datasets for risk level classification. The brain cancer affected patient details are collected from UCI machine learning data repository for experimental analysis. In this research study, the DCNN algorithm is proposed and it gives better accuracy and faster than the KNN, CNN and SVM. © 2023 IEEE.","Brain Cancer; Convolutional Neural Convolutional Network; Deep Learning; Medical Resonance Image Classification","Behavioral research; Classification (of information); Convolution; Convolutional neural networks; Decision making; Deep neural networks; Diagnosis; Diseases; Learning systems; Magnetic resonance imaging; Medical imaging; Support vector machines; Brain cancer; Brain tumor classifications; Convolutional neural convolutional network; Convolutional neural network; Deep learning; Images classification; Machine-learning; Medical resonance image classification; Network frameworks; Neural networks algorithms; Image classification","","","Institute of Electrical and Electronics Engineers Inc.",""
"Li B.; Song Z.; Shi L.; Li Y.; Yu D.; Guo X.","Li, Bo (58264954300); Song, Zhi (58264581700); Shi, Liujia (57221819331); Li, Yutao (57209029125); Yu, Duli (57200576355); Guo, Xiaoliang (58593256200)","58264954300; 58264581700; 57221819331; 57209029125; 57200576355; 58593256200","Label-free viability detection of T-cells based on 2D bright-field microscopic images and deep learning","2023","12603","","126030D","","","","10.1117/12.2673564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159759405&doi=10.1117%2f12.2673564&partnerID=40&md5=8c6239955cc93055f37ee79e637ad557","The measurement of cell viability is critical in the biomedical field. It is currently accomplished by staining cells with various stains and then manually or with instruments such as counters counting dead or live cells. However, the cell staining step is relatively time-consuming, and the stain is toxic. The internal structure of the cells is destroyed after staining, resulting in valuable cells that cannot be reused later. We proposed a label-free cell detection algorithm based on 2D bright-field images of T-cells and deep learning in this work. When used, this method eliminates the need for staining operations on cells, and cell viability is determined directly from the detection of bright-field cell images. The method based on YOLOX deep learning analysis has an excellent detection performance on bright-field images of T-cells, and the framework achieves the mAP (mean average precision) of more than 96.31% after cell detection. Experimental results show that combining 2D cell bright-field images with deep neural networks can yield a new label-free method for cell analysis. © 2023 SPIE.","bright-field; deep learning; image processing; label-free; microscopic images; T-cells; viability measurement; YOLOX","Cytology; Deep neural networks; Image analysis; Bright-field images; Bright-fields; Cell detection; Cell viability; Deep learning; Images processing; Label free; Microscopic image; Viability measurement; YOLOX; T-cells","State Key Lab of Space Medicine Fundamentals and Application, (SMFA17B02, SMFA20C01); National Natural Science Foundation of China, NSFC, (61904010); Beijing Institute of Technology, BIT","Yang S.","SPIE",""
"Bera S.; Biswas P.K.","Bera, Sutanu (57204668566); Biswas, Prabir Kumar (7202443668)","57204668566; 7202443668","Self Supervised Low Dose Computed Tomography Image Denoising Using Invertible Network Exploiting Inter Slice Congruence","2023","","","","5603","5612","9","10.1109/WACV56688.2023.00557","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149000028&doi=10.1109%2fWACV56688.2023.00557&partnerID=40&md5=d5f5acaaa1123244d16c51edcf939941","The resurgence of deep neural networks has created an alternative pathway for low-dose computed tomography denoising by learning a nonlinear transformation function between low-dose CT (LDCT) and normal-dose CT (NDCT) image pairs. However, those paired LDCT and NDCT images are rarely available in the clinical environment, making deep neural network deployment infeasible. This study proposes a novel method for self-supervised low-dose CT denoising to alleviate the requirement of paired LDCT and NDCT images. Specifically, we have trained an invertible neural network to minimize the pixel-based mean square distance between a noisy slice and the average of its two immediate adjacent noisy slices. We have shown the aforementioned is similar to training a neural network to minimize the distance between clean NDCT and noisy LDCT image pairs. Again, during the reverse mapping of the invertible network, the output image is mapped to the original input image, similar to cycle consistency loss. Finally, the trained invertible network's forward mapping is used for denoising LDCT images. Extensive experiments on two publicly available datasets showed that our method performs favourably against other existing unsupervised methods. © 2023 IEEE.","and algorithms (including transfer, low-shot, semi-, self-, and un-supervised learning); Applications: Biomedical/healthcare/medicine; Computational photography; formulations; image and video synthesis; Machine learning architectures","Bioinformatics; Color photography; Deep neural networks; Image denoising; Learning systems; Mapping; And algorithm (including transfer, low-shot, semi-, self-, and un-supervised learning); Application: biomedical/healthcare/medicine; Computational photography; Formulation; Images synthesis; Learning architectures; Machine learning architecture; Machine-learning; Un-supervised learning; Video synthesis; Computerized tomography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Fu W.; Xue B.; Zhang M.; Schindler J.","Fu, Wenlong (36801652400); Xue, Bing (55329093700); Zhang, Mengjie (8729040400); Schindler, Jan (57219929281)","36801652400; 55329093700; 8729040400; 57219929281","Evolving U-Nets Using Genetic Programming for Tree Crown Segmentation","2023","13836 LNCS","","","188","201","13","10.1007/978-3-031-25825-1_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147987723&doi=10.1007%2f978-3-031-25825-1_14&partnerID=40&md5=221f096403c5b621c4c069c1e08632d0","The U-Net deep learning algorithm and its variants have been developed for biomedical image segmentation, and due to their success gained popularity in other science domains including remote sensing. So far no U-Net structure has been specifically designed to segment complex tree canopies from aerial imagery. In this paper, a handcrafted convolutional block is introduced to replace the raw convolutional block used in the standard U-Net structure. Furthermore, we proposed a Genetic Programming (GP) approach to evolving convolutional blocks used in the U-Net structure. The experimental results on a tree crown dataset show that both the handcrafted block and the GP evolved blocks have better segmentation results than the standard U-Net. Additionally, the U-Net using the proposed handcrafted blocks has fewer numbers of the learning parameters than the standard U-Net. Also, the proposed GP approach can evolve convolutional blocks used in U-Nets that perform better than the handcrafted U-Net and the standard U-Net, and can also achieve automation. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Convolutional neural network; Genetic programming; Image segmentation; U-Net","Aerial photography; Antennas; Bioinformatics; Convolution; Deep learning; Genetic algorithms; Genetic programming; Learning algorithms; Remote sensing; Aerial imagery; Biomedical image segmentation; Convolutional neural network; Images segmentations; Net structures; Remote-sensing; Segmentation results; Tree canopy; Tree crowns; U-net; Image segmentation","Ministry of Business, Innovation and Employment, MBIE, (C09X1923); Ministry of Business, Innovation and Employment, MBIE","Yan W.Q.; Nguyen M.; Stommel M.","Springer Science and Business Media Deutschland GmbH",""
"Deepa R.; Vidyabharathi D.; Hemlata; Kalaivaani P.C.D.; Marimuthu M.; Ismail K M.","Deepa, R. (56497735100); Vidyabharathi, D. (57226744279); Hemlata (57223010331); Kalaivaani, P.C.D. (55208414600); Marimuthu, M. (57290887500); Ismail K, Mohamed (57216857638)","56497735100; 57226744279; 57223010331; 55208414600; 57290887500; 57216857638","Revolutionizing Hand Gesture Recognition: A Transfer Learning Approach using Surface Electromyography and Convolutional Neural Networks","2023","","","","70","75","5","10.1109/ICAISS58487.2023.10250724","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173612850&doi=10.1109%2fICAISS58487.2023.10250724&partnerID=40&md5=3ae9b4eb215ea4a24a164af9a3a74722","The popularity of deep learning algorithms has increased significantly over the past few years, which are unrivaled in their capacity to automatically discover discriminant features from massive datasets. Deep learning techniques are rarely used for electromyography-based gesture detection due to the large amount of work involved in creating thousands of instances. In order to achieve high generalization and minimal training burden in Surface Electromyography (SEMG)-based gesture recognition, this research provides an effective Transfer Learning (TL) technique. This study aims to determine whether or not a certain EMG signal, captured by a sensor-based band, corresponds to a particular hand gesture. In order to identify and categorize objects, surface EMG and Machine Learning (ML) methods are employed. Suitable pre-processing processes are applied to the raw EMG signal recorded by the sensor in order to remove noise artifacts. We use transfer learning and convolutional neural networks to discover a good controller for a myoelectric prosthetic hand. First, pictures are generated from the sEMG signal using the continuous wavelet transform (CWT), which is a robust feature for the separation of various hand gestures. Then, we used what we learned from many image classification neural nets, including AlexNet and ResNet-18, to sEMG classification. When these deep neural networks were applied, they beat standard machine learning methods regarding precision and quickness. State-of-the-art accuracy levels of 100% on the publically available datasets, for example, have been reached using a hybrid of CNN and VGG16 for these data sets. To obtain excellent accuracy in two sEMG datasets, this research establishes an algorithmic based on Continuous Wavelet Transform (CWT) and CNN-VGG16 deep neural networks. © 2023 IEEE.","Continuous Wavelet Transform; Deep Learning; Hand Gesture; Surface Electromyography; Transfer Learning","Biomedical signal processing; Convolution; Deep neural networks; Gesture recognition; Learning algorithms; Learning systems; Palmprint recognition; Transfer learning; Wavelet transforms; Continuous Wavelet Transform; Convolutional neural network; Deep learning; EMG signal; Hand gesture; Hand-gesture recognition; Learning techniques; Machine learning methods; Surface electromyography; Transfer learning; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Kastryulin S.; Zakirov J.; Pezzotti N.; Dylov D.V.","Kastryulin, Sergey (57215562987); Zakirov, Jamil (57556383900); Pezzotti, Nicola (58150639100); Dylov, Dmitry V. (23977461000)","57215562987; 57556383900; 58150639100; 23977461000","Image Quality Assessment for Magnetic Resonance Imaging","2023","11","","","14154","14168","14","10.1109/ACCESS.2023.3243466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148444471&doi=10.1109%2fACCESS.2023.3243466&partnerID=40&md5=8c0ded87591366a218428e8f1c10f079","Image quality assessment (IQA) algorithms aim to reproduce the human's perception of the image quality. The growing popularity of image enhancement, generation, and recovery models instigated the development of many methods to assess their performance. However, most IQA solutions are designed to predict image quality in the general domain, with the applicability to specific areas, such as medical imaging, remaining questionable. Moreover, the selection of these IQA metrics for a specific task typically involves intentionally induced distortions, such as manually added noise or artificial blurring; yet, the chosen metrics are then used to judge the output of real-life computer vision models. In this work, we aspire to fill these gaps by carrying out the most extensive IQA evaluation study for Magnetic Resonance Imaging (MRI) to date (14,700 subjective scores). We use outputs of neural network models trained to solve problems relevant to MRI, including image reconstruction in the scan acceleration, motion correction, and denoising. Our emphasis is on reflecting the radiologist's perception of the reconstructed images, gauging the most diagnostically influential criteria for the quality of MRI scans: signal-to-noise ratio, contrast-to-noise ratio, and the presence of art efacts. Seven trained radiologists assess these distorted images, with their verdicts then correlated with 35 different image quality metrics (full-reference, no-reference, and distribution-based metrics considered). The top performers- DISTS, HaarPSI, VSI, and FIDVGG16- are found to be efficient across three proposed quality criteria, for all considered anatomies and the target tasks.  © 2013 IEEE.","deep learning; Image quality; metrics; MRI; reconstruction quality","Acceleration; Deep learning; Image enhancement; Image quality; Image reconstruction; Medical imaging; Quality control; Signal to noise ratio; Biomedical imaging; Deep learning; Image generations; Image quality assessment; Image recovery; Metric; Performance; Reconstruction quality; Recovery model; Task analysis; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"Youneszade N.; Marjani M.; Pei C.P.","Youneszade, Nina (58088837200); Marjani, Mohsen (57190296193); Pei, Chong Pei (55507457900)","58088837200; 57190296193; 55507457900","Deep Learning in Cervical Cancer Diagnosis: Architecture, Opportunities, and Open Research Challenges","2023","11","","","6133","6149","16","10.1109/ACCESS.2023.3235833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147287971&doi=10.1109%2fACCESS.2023.3235833&partnerID=40&md5=62db8bf12e803a9debc3326cdccfeff1","Nowadays, deep learning (DL) is a popular tool used in various applications in different fields, including the medical domain. DL techniques can cope with several challenges, which are difficult to resolve via traditional artificial intelligence (AI) techniques. Cervical cancer (CC) is one of the leading reasons for death in females and ranks second after breast cancer, with more than 700 mortalities daily. This number is estimated to be 400,000 annually by 2030. However, if the cancer is detected in the early and precancerous stages, it is completely curable. Pap smear and colposcopy are the most widely used screening methods for the detection of cervical cancer. But manual screening approach suffers from a high false rate due to human errors. To overcome this challenge, machine learning (ML) and DL-based computer-aided diagnostic (CAD) techniques are being extensively expanded to automatically segment and categorize cervical cytology and colposcopy images. These methods increase the accuracy of detecting different stages of cervical cancer. Hence, there is an increased interest in creating computer-aided solutions for CC screening, especially in less-developed countries where the majority of cervical cancer-related fatalities occur. This review overviews state-of-the-art approaches that use DL techniques to analyze cervical cytology and screening images. It reviews and discusses relevant DL techniques, their architectures, classification methods, and the segmentation of cervical cytology and colposcopy images. Finally, it reviews the DL algorithms that are currently used in CC screening and offers useful insights, research opportunities and future directions in this field. © 2013 IEEE.","cervical cancer; classification; colposcopy images; cytology images; Deep learning","Bioinformatics; Computer aided diagnosis; Deep learning; Diseases; Endoscopy; Image classification; Image segmentation; Medical imaging; Network architecture; Neural networks; Biomedical imaging; Cancer; Cervical cancers; Classification algorithm; Colposcopy image; Convolutional neural network; Cytology image; Deep learning; Images segmentations; Medical diagnostic imaging; Cytology","","","Institute of Electrical and Electronics Engineers Inc.",""
"Obaid M.K.; Abed H.A.; Abdullah S.B.; Al-Jawahry H.M.; Majed S.; Hassan A.R.","Obaid, Mohammed Kadhim (58816345800); Abed, Hanaa Ali (58816427900); Abdullah, Salima Baji (58816345400); Al-Jawahry, Hassan M. (57223710456); Majed, Safa (58816347600); Hassan, Ahmed R. (57982175600)","58816345800; 58816427900; 58816345400; 57223710456; 58816347600; 57982175600","Automated Osteosarcoma Detection and Classification Using Advanced Deep Learning with Remora Optimization Algorithm","2023","","","","122","128","6","10.1109/IICETA57613.2023.10351357","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182524768&doi=10.1109%2fIICETA57613.2023.10351357&partnerID=40&md5=88cdbad22449c784c996433e4dbd944d","Osteosarcoma is considered a primary malignant bone tumor which affects young people and adults. Manual osteosarcoma identification is time consuming and necessitates expert knowledge. Since earlier detection of osteosarcoma reduces death rate, computer aided diagnosis (CAD) models can be developed to examine the medical images for decision making. The latest breakthroughs in machine learning (ML) and deep learning (DL) methods find to be useful for enhancing detection performance and diagnostic time. In this view, this article introduces an Automated Osteosarcoma Detection and Classification using metaheuristics with Advanced Deep Learning (AODC-MADL) algorithm. The proposed AODC-MADL model makes use of recent DL models with hyperparameter optimization algorithms to detect and classify osteosarcoma. For achieving that, the presented AODC-MADL algorithm pre-processes the input images to optimize the image quality. Moreover, the Dense-EfficientNet architecture is utilized to form a set of feature vectors. Besides, attention based bidirectional recurrent neural network (ABiRNN) model receives the feature vectors and performs classification process. At last, the remora optimization algorithm (ROA) is used to optimally choose the hyperparameters related to the ABiRNN model. A series of experiments have been conducted to depict the outstanding performance of the AODC-MADL algorithm. The experimental outcome emphasized that the AODC-MADL algorithm has obtained higher performance over other approaches.  © 2023 IEEE.","Advanced deep learning; Biomedical data; Medical imaging; Metaheuristics; Osteosarcoma classification","Behavioral research; Bioinformatics; Classification (of information); Computer aided diagnosis; Computer aided instruction; Decision making; Heuristic algorithms; Medical imaging; Optimization; Recurrent neural networks; Advanced deep learning; Biomedical data; Bone tumor; Features vector; Learning models; Metaheuristic; Optimization algorithms; Osteosarcoma classification; Osteosarcomas; Performance; Learning algorithms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Alrowais F.; Mahmood K.; Alotaibi S.S.; Hamza M.A.; Marzouk R.; Mohamed A.","Alrowais, Fadwa (56266498100); Mahmood, Khalid (58584573000); Alotaibi, Saud S. (57202829227); Hamza, Manar Ahmed (57223407265); Marzouk, Radwa (35749022100); Mohamed, Abdullah (57213606201)","56266498100; 58584573000; 57202829227; 57223407265; 35749022100; 57213606201","Laryngeal Cancer Detection and Classification Using Aquila Optimization Algorithm With Deep Learning on Throat Region Images","2023","11","","","115306","115315","9","10.1109/ACCESS.2023.3324880","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174819496&doi=10.1109%2fACCESS.2023.3324880&partnerID=40&md5=282360a6050f5ac09e87d28b8e45734f","Laryngeal cancer detection on throat area images is a vital application of medical image diagnosis and computer vision (CV) in the healthcare domain. It contains the analysis and detection of cancerous or abnormal tissues from the larynx, an essential part of the respiratory and vocal systems. Several machine learning (ML) and deep learning (DL) systems are executed for classifying the extraction features as both cancerous and healthy tissue. Convolutional Neural Networks (CNNs) and recurrent neural networks (RNNs) have shown promise in this context. With this motivation, this study designs a new Laryngeal Cancer Detection and Classification using the Aquila Optimization Algorithm with Deep Learning (LCDC-AOADL) technique on neck region images. The purpose of the LCDC-AOADL technique is to examine the histopathological images for the recognition and classification of Laryngeal Cancer. In the presented LCDC-AOADL technique, the Inceptionv3 model is used for the feature extraction process. Besides, the LCDC-AOADL technique employed a deep belief network (DBN) model for the identification and classification of LC. Moreover, the AOA is utilized for the hyperparameter tuning of the DBN model which results in improved detection rate. The simulation analysis of the LCDC-AOADL method is validated on the benchmark Laryngeal dataset. The experimental results pointed out the enhanced detection results of the LCDC-AOADL technique over other recent approaches with a maximum accuracy of 96.02%, precision of 92.10%, recall of 91.87%, and F-score of 91.86%. © 2013 IEEE.","Aquila optimizer; Computer-aided diagnosis; deep learning; ENT; Laryngeal cancer","Biomedical signal processing; Classification (of information); Complex networks; Computer aided diagnosis; Convolution; Deep neural networks; Diseases; Extraction; Learning algorithms; Medical computing; Medical imaging; Optimization; Recurrent neural networks; Tissue; Aquila optimizer; Cancer; Cancer detection; Convolutional neural network; Deep learning; ENT; Features extraction; Laryngeal cancer; Larynx; Optimizers; Solid modelling; Thorax; Tuning; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.",""
"Yuan S.; Chen Y.; Ye C.; Bhatt M.W.; Saradeshmukh M.; Hossain M.S.","Yuan, Shuping (57224940153); Chen, Yang (57846517500); Ye, Chengqiong (57223099696); Bhatt, Mohammed Wasim (57222961220); Saradeshmukh, Mhalasakant (55898294500); Hossain, Md Shamim (57210989648)","57224940153; 57846517500; 57223099696; 57222961220; 55898294500; 57210989648","Cross-modal multi-label image classification modeling and recognition based on nonlinear","2023","12","1","20220194","","","","10.1515/nleng-2022-0194","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146732047&doi=10.1515%2fnleng-2022-0194&partnerID=40&md5=c7a5b25aa71d42f0773d681a8b420685","Recently, it has become a popular strategy in multi-label image recognition to predict those labels that co-occur in a picture. Previous work has concentrated on capturing label correlation but has neglected to correctly fuse picture features and label embeddings, which has a substantial influence on the model's convergence efficiency and restricts future multi-label image recognition accuracy improvement. In order to better classify labeled training samples of corresponding categories in the field of image classification, a cross-modal multi-label image classification modeling and recognition method based on nonlinear is proposed. Multi-label classification models based on deep convolutional neural networks are constructed respectively. The visual classification model uses natural images and simple biomedical images with single labels to achieve heterogeneous transfer learning and homogeneous transfer learning, capturing the general features of the general field and the proprietary features of the biomedical field, while the text classification model uses the description text of simple biomedical images to achieve homogeneous transfer learning. The experimental results show that the multi-label classification model combining the two modes can obtain a hamming loss similar to the best performance of the evaluation task, and the macro average F1 value increases from 0.20 to 0.488, which is about 52.5% higher. The cross-modal multi-label image classification algorithm can better alleviate the problem of overfitting in most classes and has better cross-modal retrieval performance. In addition, the effectiveness and rationality of the two cross-modal mapping techniques are verified.  © 2023 the author(s), published by De Gruyter.","cross-mode retrieval; deep learning; multiple label points","Classification (of information); Convolutional neural networks; Deep neural networks; Image enhancement; Image recognition; Text processing; Transfer learning; Classification models; Cross-modal; Cross-mode retrieval; Deep learning; Images classification; Label images; Label points; Multi-labels; Multiple label point; Multiple labels; Image classification","","","De Gruyter Open Ltd",""
"Jose A.; Roy R.; Stegmaier J.","Jose, Abin (57221473187); Roy, Rĳo (58080719100); Stegmaier, Johannes (55584699900)","57221473187; 58080719100; 55584699900","Weakly-supervised Temporal Segmentation of Cell-cycle Stages with Center-cell Focus using Recurrent Neural Networks","2023","","","","212","219","7","10.1007/978-3-658-41657-7_47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164964949&doi=10.1007%2f978-3-658-41657-7_47&partnerID=40&md5=9f3ab6bb9ca126f7607ba63067803d77","Training deep-learning models for biomedical images has always been a problem due to the lack of annotated data. Here we propose using a model and a training approach for the weakly-supervised temporal classification of cell-cycle stages during mitosis. Instead of using annotated data, by using an ordered set of classes called transcript, our proposed approach classifies the cell-cycle stages of cell video sequences. The network design helps to propagate information in time using Recurrent Neural Network and helps to focus the features on the center-cell. The algorithm is evaluated on four datasets from Moreno-Andrés et al. [1] and has a performance close to the supervised approaches, which is impressive, considering that annotated data is not used in training. © 2023 Der/die Autor(en), exklusiv lizenziert an Springer Fachmedien Wiesbaden GmbH, ein Teil von Springer Nature.","","Cells; Cytology; Biomedical images; Cell cycle; Learning models; Network design; Ordered set; Performance; Temporal classification; Temporal segmentations; Video sequences; Recurrent neural networks","","Deserno T.M.; Handels H.; Maier A.; Maier-Hein K.; Palm C.; Tolxdorff T.","Springer Science and Business Media Deutschland GmbH",""
"Qu C.; Tangge Y.; Yang G.","Qu, Chenyao (58663607700); Tangge, Yanhao (58663798600); Yang, Guang (58732512700)","58663607700; 58663798600; 58732512700","Digital signal processing techniques for image enhancement and restoration","2023","12799","","127992R","","","","10.1117/12.3005862","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174812223&doi=10.1117%2f12.3005862&partnerID=40&md5=1b804423927b98cc79cbe6eabc88a823","The image processing technology is widely used in digital signal processing, biomedical engineering, and industrial automation control. In image processing, image enhancement and restoration techniques are used in many imaging applications, such as astrophotography, medical imaging camera, film production, and infrared imaging. At the same time, image enhancement and restoration technology based on both deep learning and neural network is a major research hotspot in the area of image processing. This paper reviews the related research of image enhancement and restoration technology. In terms of image enhancement, the working principle of its technology based on spatial domain and frequency domain and contrast enhancement technology, including color image contrast enhancement, are introduced. In image restoration, median filtering technology and the Lucy-Richardson (LR) algorithm are introduced, including the adaptive median filtering algorithm and the improved LR algorithm based on the Gaussian low-pass filter. Finally, the merits and demerits of these technologies are discussed, and the development prospect of image enhancement and restoration technology has prospected.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Digital signal processing; Image enhancement; Image restoration.","Adaptive filtering; Adaptive filters; Biomedical engineering; Deep learning; Digital signal processing; Engineering education; Frequency domain analysis; Image enhancement; Median filters; Medical imaging; Restoration; Thermography (imaging); Automation controls; Engineering automation; Image processing technology; Image restoration.; Images processing; Imaging applications; Industrial automation; Lucy-Richardson; Restoration techniques; Technology-based; Image reconstruction","","Subramaniam K.; Loskot P.","SPIE",""
"Myriam H.; Abdelhamid A.A.; El-Kenawy E.-S.M.; Ibrahim A.; Eid M.M.; Jamjoom M.M.; Khafaga D.S.","Myriam, Hadjouni (23396729500); Abdelhamid, Abdelaziz A. (55328560100); El-Kenawy, El-Sayed M. (57191347112); Ibrahim, Abdelhameed (34876676400); Eid, Marwa Metwally (35795379100); Jamjoom, Mona M. (57142648900); Khafaga, Doaa Sami (58088844800)","23396729500; 55328560100; 57191347112; 34876676400; 35795379100; 57142648900; 58088844800","Advanced Meta-Heuristic Algorithm Based on Particle Swarm and Al-Biruni Earth Radius Optimization Methods for Oral Cancer Detection","2023","11","","","23681","23700","19","10.1109/ACCESS.2023.3253430","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149834542&doi=10.1109%2fACCESS.2023.3253430&partnerID=40&md5=4ff93881a313e0eba3ffe3a4d5ca444c","Oral cancer is a deadly form of cancerous tumor that is widely spread in low and middle-income countries. An early and affordable oral cancer diagnosis might be achieved by automating the detection of precancerous and malignant lesions in the mouth. There are many research attempts to develop a robust machine-learning model that can detect oral cancer from images. However, these are still lacking high precision in oral cancer detection. Therefore, this work aims to propose a new approach capable of detecting oral cancer in medical images with higher accuracy. In this work, a novel and robust oral cancer detection based on a convolutional neural network (CNN) and optimized deep belief network (DBN). The design parameters of CNN and DBN are optimized using a new optimization algorithm, which is developed as a hybrid of Particle Swarm Optimization (PSO) and Al-Biruni Earth Radius (BER) Optimization algorithms and is denoted by (PSOBER). Using a standard biomedical images dataset available on the Kaggle repository, the proposed approach shows promising results outperforming various competing approaches with an accuracy of 97.35%. In addition, a set of statistical tests, such as One-way analysis-of-variance (ANOVA) and Wilcoxon signed-rank tests, are conducted to prove the significance and stability of the proposed approach. The proposed methodology is solid and efficient, and specialists can adopt it. However, additional research on a larger scale dataset is required to confirm the findings and highlight other oral features that can be utilized for cancer detection.  © 2013 IEEE.","Al-Biruni earth radius algorithm; convolutional neural network; deep belief network; metaheuristic optimization; Oral cancer; particle swarm optimization","Analysis of variance (ANOVA); Convolution; Deep neural networks; Diagnosis; Diseases; Heuristic algorithms; Heuristic methods; Medical imaging; Particle swarm optimization (PSO); Al-biruni earth radius algorithm; Cancer; Cancer detection; Convolutional neural network; Deep belief networks; Deep learning; Earth radii; Features extraction; Lesion; Metaheuristic; Metaheuristic optimization; Oral cancer; Particle swarm; Particle swarm optimization; Swarm optimization; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.",""
"Immanuel R.R.; Sangeetha S.K.B.","Immanuel, Rajeswari Rajesh (58099142300); Sangeetha, S.K.B. (57225085133)","58099142300; 57225085133","Implementation of an Automatic EEG Feature Extraction with Gated Recurrent Neural Network for Emotion Recognition","2023","967","","","133","150","17","10.1007/978-981-19-7169-3_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147849303&doi=10.1007%2f978-981-19-7169-3_13&partnerID=40&md5=2488b611f2d591853afd50a9b95daca4","Emotion is a complicated state that influences one's thoughts and behaviour. Recognizing the emotions of a human being is a major research interest in the affective computing after this pandemic situation and which can be applied in medical related fields to cure physical and mental illness. Early detection of stress helps humans to avoid or prevent many diseases related to it. The development of an emotion recognition system using machine learning algorithms has taken a lot of time and effort for researchers and is less focused with Electroencephalography (EEG) signals because EEG signals are noisy, non-linear, and non-stationary. Deep learning algorithms are the most popular solution due to its ability to see images as data. In this paper, we propose a deep learning framework, Gated Recurrent Unit Emotion Recognizer (GRUER) that can detect human emotion with help of EEG signals. This is achieved by implementing four feature extraction algorithms such as Short-Time Fourier Transform (STFT), Wavelet Entropy, Hjorth and Statistical features on dataset and the feature selection method Principal Component Analysis (PCA) is applied to the extracted features to select most significant features to obtain high-accuracy emotion recognizing model. Keras libraries are used to train the model in an appropriate way so that it is neither overfit nor underfit with the data using the Early-stopping function. The performance of the GRUER model is measured using performance metrics such as accuracy, precision, recall and F1-Score are illustrated in the results. The accuracy of the GRUER is 98% and it is a 3-dimensional model which has valence, arousal and dominance for emotion detection. The model loss obtained by GRUER is 1.12 which is low when compared to other models. Finally, the suggested method and its results show that this proposed method outperforms numerous existing emotion recognition systems. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Classification; CNN; Dataset; Deep learning; EEG signals; Emotion recognition; Feature extraction; Stress","Biomedical signal processing; Diseases; Electroencephalography; Electrophysiology; Emotion Recognition; Extraction; Feature Selection; Learning algorithms; Principal component analysis; Recurrent neural networks; Speech recognition; Affective Computing; Dataset; Deep learning; Electroencephalography signal; Emotion recognition; Features extraction; Human being; Mental illness; Recognition systems; Research interests; Classification (of information)","","Kannan R.J.; Thampi S.M.; Wang S.","Springer Science and Business Media Deutschland GmbH",""
"Kim T.; Kim S.; Kim J.; Lee Y.; Choi J.","Kim, Taewan (58154001000); Kim, Sangyeop (58145918800); Kim, Jaeyoung (57191685592); Lee, Yeonjoon (56416784300); Choi, June (36019909600)","58154001000; 58145918800; 57191685592; 56416784300; 36019909600","Toward Better Ear Disease Diagnosis: A Multi-Modal Multi-Fusion Model Using Endoscopic Images of the Tympanic Membrane and Pure-Tone Audiometry","2023","11","","","116721","116731","10","10.1109/ACCESS.2023.3325346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174827245&doi=10.1109%2fACCESS.2023.3325346&partnerID=40&md5=c5a75e090a93ded0f728ae2dafeaa431","Chronic otitis media is characterized by recurrent infections, leading to serious complications, such as meningitis, facial palsy, and skull base osteomyelitis. Therefore, active treatment based on early diagnosis is essential. This study developed a multi-modal multi-fusion (MMMF) model that automatically diagnoses ear diseases by applying endoscopic images of the tympanic membrane (TM) and pure-tone audiometry (PTA) data to a deep learning model. The primary aim of the proposed MMMF model is adding 'normal with hearing loss' as a category, and improving the diagnostic accuracy of the conventional four ear diseases: normal, TM perforation, retraction, and cholesteatoma. To this end, the MMMF model was trained on 1,480 endoscopic images of the TM and PTA data to distinguish five ear disease states: normal, TM perforation, retraction, cholesteatoma, and normal (hearing loss). It employs a feature fusion strategy of cross-attention, concatenation, and gated multi-modal units in a multi-modal architecture encompassing a convolutional neural network (CNN) and multi-layer perceptron. We expanded the classification capability to include an additional category, normal (hearing loss), thereby enhancing the diagnostic performance of extant ear disease classification. The MMMF model demonstrated superior performance when implemented with EfficientNet-B7, achieving 92.9% accuracy and 90.9% recall, thereby outpacing the existing feature fusion methods. In addition, five-fold cross-validation experiments were conducted, in which the model consistently demonstrated robust performance when endoscopic images of the TM and PTA data were applied to the deep learning model across all datasets. The proposed MMMF model is the first to include a category of normal ear disease state with hearing loss. The developed model demonstrated superior performance compared to existing CNN models and feature fusion methods. Consequently, this study substantiates the utility of simultaneously applying PTA data and endoscopic images of the TM for the automated diagnosis of ear diseases in clinical settings and validates the usefulness of the multi-fusion method. © 2013 IEEE.","Artificial intelligence; biomedical imaging; classification algorithms; computer aided diagnosis; convolutional neural networks; deep learning; electronic medical records","Audition; Bioinformatics; Computer aided instruction; Convolution; Convolutional neural networks; Deep neural networks; Endoscopy; Image fusion; Medical computing; Medical imaging; Auditory systems; Biomedical imaging; Classification algorithm; Convolutional neural network; Deep learning; Ear; Electronic medical record; Medical record; Medium; Computer aided diagnosis","","","Institute of Electrical and Electronics Engineers Inc.",""
"Patel S.A.; Yildirim A.","Patel, Sahaj Anilbhai (57903823800); Yildirim, Abidin (7004847142)","57903823800; 7004847142","Non-stationary neural signal to image conversion framework for image-based deep learning algorithms","2023","17","","1081160","","","","10.3389/fninf.2023.1081160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152572636&doi=10.3389%2ffninf.2023.1081160&partnerID=40&md5=d0fb5489adf0331bca9d9f1839a868fb","This paper presents a time-efficient preprocessing framework that converts any given 1D physiological signal recordings into a 2D image representation for training image-based deep learning models. The non-stationary signal is rasterized into the 2D image using Bresenham’s line algorithm with time complexity O(n). The robustness of the proposed approach is evaluated based on two publicly available datasets. This study classified three different neural spikes (multi-class) and EEG epileptic seizure and non-seizure (binary class) based on shapes using a modified 2D Convolution Neural Network (2D CNN). The multi-class dataset consists of artificially simulated neural recordings with different Signal-to-Noise Ratios (SNR). The 2D CNN architecture showed significant performance for all individual SNRs scores with (SNR/ACC): 0.5/99.69, 0.75/99.69, 1.0/99.49, 1.25/98.85, 1.5/97.43, 1.75/95.20 and 2.0/91.98. Additionally, the binary class dataset also achieved 97.52% accuracy by outperforming several others proposed algorithms. Likewise, this approach could be employed on other biomedical signals such as Electrocardiograph (EKG) and Electromyography (EMG). Copyright © 2023 Patel and Yildirim.","2D convolution neural network (2D CNN); biomedical signals; Bresenham’s line algorithm; electroencephalogram (EEG); non-stationary signal to 2D image representation","accuracy; algorithm; Article; Bayesian learning; conceptual framework; convolutional neural network; deep learning; electroencephalography; electromyography; epilepsy; feature extraction; human; k nearest neighbor; learning; learning algorithm; multi layer perceptron; nerve cell network; non stationary neural signal; physiology; random forest; recall; recording; scoring system; signal noise ratio; support vector machine; training","","","Frontiers Media S.A.",""
"Wang L.; Wang J.; Wen B.; Mu W.; Liu L.; Han J.; Zhang L.; Jia J.; Kang X.","Wang, Lu (57196331304); Wang, Junkongshuai (57795418700); Wen, Bo (58179025500); Mu, Wei (57448676700); Liu, Lusheng (57904830400); Han, Jiaguan (58178959000); Zhang, Lihua (57223101319); Jia, Jie (59157655800); Kang, Xiaoyang (55505307000)","57196331304; 57795418700; 58179025500; 57448676700; 57904830400; 58178959000; 57223101319; 59157655800; 55505307000","Enhancing Motor Imagery EEG Signal Classification with Simplified GoogLeNet","2023","2023-February","","","","","","10.1109/BCI57258.2023.10078448","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152207911&doi=10.1109%2fBCI57258.2023.10078448&partnerID=40&md5=764f5ceadf42cca817011fbcf7f5a580","The brain-computer interface is a novel tool for interaction between the brain and external devices, and is an important tool at the forefront of international brain science research. Motor imagery does not require external stimulation and is one of the most widely used BCI paradigms, and is now widely used to address the treatment of neurological impairments such as paralysis, stroke, and acromegaly. Electrophysiological source imaging is a technique based on the observation of electromagnetic signals from the cerebral cortex, reflecting the electrophysiological activity of brain nerve cells on the scalp surface of the brain. The wavelet transform, on the other hand, is commonly used for the processing of non-smooth signals and aims to extract excellent signal features. This paper combines these two algorithms as feature extraction methods. In recent years, deep learning has been increasingly combined with MI-EEG-based BCI. GoogLeNet is one of the most classical convolutional neural networks and has made a splash in ImageNet image recognition. However, using GoogLeNet to train the BCI public dataset BCI IV IIa and dataset HGD has shown problems such as long training time, overfitting, and gradient disappearance. In response, this paper proposes an improved and streamlined version of GoogLeNet for training based on this dataset to achieve an overall improvement in accuracy, training time, number of parameters, and other indicators. It is useful for the realistic application of MI-based BCI systems.  © 2023 IEEE.","brain computer interface; EEG; GoogLeNet.; motor imagery","Biomedical signal processing; Brain computer interface; Deep learning; Electrophysiology; Image classification; Image enhancement; Image recognition; Neurons; Wavelet transforms; Brain science; EEG signals classification; Electromagnetic signals; External stimulation; Googlenet.; Motor imagery; Motor imagery EEG; Science research; Source imaging; Training time; Brain","Fudan University-CIOMP; Opening Project of Shanghai Robot R&D, (KEH2310024); Shanghai Sailing Program, (19YF1403600); Zhejiang Lab, (2021MC0AB01); Ji Hua Laboratory, JHL, (X190021TB190, X190021TB191, X190021TB193); Ji Hua Laboratory, JHL; National Natural Science Foundation of China, NSFC, (61904038, U1913216); National Natural Science Foundation of China, NSFC; Science and Technology Commission of Shanghai Municipality, STCSM, (19441907600, 19441908200, 19511132000, 2018SHZDZX01, 2021SHZDZX0103); Science and Technology Commission of Shanghai Municipality, STCSM; National Key Research and Development Program of China, NKRDPC, (2018YFC1705800, 2021YFC0122702); National Key Research and Development Program of China, NKRDPC","","Institute of Electrical and Electronics Engineers Inc.",""
"De Marco F.; Citarella A.A.; Di Biasi L.; D'Errico L.; Francese R.; Mettivier G.; Staffa M.; Tortora G.","De Marco, Fabiola (57211021892); Citarella, Alessia Auriemma (57226113587); Di Biasi, Luigi (57188978927); D'Errico, Lorenzo (57838369700); Francese, Rita (6602289285); Mettivier, Giovanni (8350315900); Staffa, Mariacarla (8892560900); Tortora, Genoveffa (35587906400)","57211021892; 57226113587; 57188978927; 57838369700; 6602289285; 8350315900; 8892560900; 35587906400","AI-based solutions for the analysis of biomedical images and signals","2023","3486","","","171","176","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173838682&partnerID=40&md5=47864e179481a3125435b917cdd2c370","Artificial intelligence (AI) has emerged as a disruptive technology that is transforming the medical field. The use of AI algorithms, machine learning, and neural networks has revealed a great potential in enhancing healthcare delivery, including early detection and diagnosis of diseases, improving patient outcomes, and reducing healthcare costs. The application of AI in medical imaging analysis is going to obtaining remarkable success in identifying tumors and other anomalies, leading to earlier diagnoses and better treatment outcomes. In addition, AI has also been applied to medical data analysis, drug discovery, and personalized medicine. In this review article we present an overview of the research work conducted by our team in the field of medical AI. Our primary focus has been on the development and validation of AI-based approaches for the early detection and accurate diagnosis of breast cancer, skin melanoma, and heart disease. Our research has demonstrated the potential of AI in improving the accuracy and efficiency of medical diagnosis and treatment. With the growing availability of medical data and advances in AI technology, we anticipate that the future of medical AI will bring about a paradigm shift in the way healthcare is delivered. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","Artificial Intelligence; classification; data augmentation; Deep Convolutional Neural Network; digital breast tomosynthesis; ECG; Generative Adversarial Network; neural network; pattern detection; skin melanoma","Computer aided diagnosis; Controlled drug delivery; Convolutional neural networks; Deep neural networks; Dermatology; Diseases; Generative adversarial networks; Medical imaging; Medical informatics; Oncology; Pattern recognition; Targeted drug delivery; Tomography; Tumors; Biomedical images; Biomedical signal; Convolutional neural network; Data augmentation; Deep convolutional neural network; Digital breast tomosynthesis; Disruptive technology; Neural-networks; Pattern detection; Skin melanoma; Electrocardiograms","","Falchi F.; Institute of Information Science and Technologies ""A. Faedo"" of the National Research Council of Italy, Via G. Moruzzi 1, Pisa; Giannotti F.; Scuola Normale Superiore, P.za dei Cavalieri, 7, Pisa; Monreale A.; Pisa University, Computer Science Department, Largo Bruno Pontecorvo, 3, Pisa; Boldrini C.; Institute of Informatics and Telematics of the National Research Council of Italy, Via G. Moruzzi 1, Pisa; Rinzivillo S.; Institute of Information Science and Technologies ""A. Faedo"" of the National Research Council of Italy, Via G. Moruzzi 1, Pisa; Colantonio S.; Institute of Information Science and Technologies ""A. Faedo"" of the National Research Council of Italy, Via G. Moruzzi 1, Pisa","CEUR-WS",""
"Kang H.; Seo K.; Lee S.; Oh B.H.; Yang S.","Kang, Hyunyoung (57640583000); Seo, Kyungdeok (57640441700); Lee, Sena (57218215512); Oh, Byung Ho (55576410700); Yang, Sejung (7406950248)","57640583000; 57640441700; 57218215512; 55576410700; 7406950248","Wound image segmentation using deep convolutional neural network","2023","12352","","123520F","","","","10.1117/12.2649913","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159657189&doi=10.1117%2f12.2649913&partnerID=40&md5=84918450b099bfdb6cabe920e1d94a42","Traditional methods of wound diagnosis have been diagnosed and prescribed by the naked eye of an expert. If the wound segmentation algorithm is applied to the wound diagnosis, the area of wound can be quantitated and used as an auxiliary means of treatment. Even with dramatic development of Deep learning technology in recent years, However, a lack of datasets generally occurs overfitting problem of deep learning model, which leads to poor performance for external datasets. Therefore, we trained the wound segmentation model by adding a new wound dataset in addition to the existing Open dataset, the Diabetic Foot Ulcer Challenge Dataset. Machine learning based methods are used when producing new dataset, ground truth images. Thus, in addition to the manual methods, Gradient Vector Flow machine learning techniques is used for ground-truth image production to reduce the time consumed in vain. The wound segmentation model used in this study is a U-net with residual block combined with cross entropy loss and Dice loss. As a result of the experiment, the wound segmentation accuracy was about 90% for Dice coefficient. © 2023 SPIE.","Biomedical Imaging Machine learning; Deep Convolutional Neural Network; Deep Learning; Gradient Vector Flow; Residual U-net; Wound Segmentation","Convolution; Deep neural networks; Image segmentation; Learning systems; Medical imaging; Biomedical imaging; Biomedical imaging machine learning; Convolutional neural network; Deep convolutional neural network; Deep learning; Gradient-vector flow; Imaging machines; Machine-learning; Residual U-net; Wound segmentation; Convolutional neural networks","National Research Foundation of Korea, NRF, (NRF-2022R1A2C2091160)","Choi B.; Zeng H.","SPIE",""
"","","","Emergent Converging Technologies and Biomedical Systems Select Proceedings of the 2nd International Conference, ETBS 2022","2023","1040 LNEE","","","","","712","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172281703&partnerID=40&md5=338f3dbe78ea48a95dad972d153b1ab2","The proceedings contain 55 papers. The special focus in this conference is on Emergent Converging Technologies and Biomedical Systems. The topics include: Development of a Coconut De-Husking Machine; health Sector: An Overview of Various Smartphone Apps; survey on IoT Based Secure Health Care Framework Using Block Chain Technology; a Methodology for Increasing Precision for the Efficient Implementation of Sigmoid Function; fog-Based Smart Healthcare Architecture in IoT Environment; COVID-19 and SDG 3 in Bangladesh: A Statistical and Machine Learning Approach; Analysis of Power Consumption and IoT Devices Using SPSS Tool; analyzing Optimal Environment for the Text Classification in Deep Learning; estimating Factors of Agile Software Development Using Fuzzy Logic: A Survey; hyperspectral Image and Deep Learning Methodology for Water Evaporation Prediction and Control System; computational System Based on Machine Learning with Hybrid Security Technique to Classify Crime Offenses; Analysis of Robotically Controlled Percutaneous Needle Insertion into Ex Vivo Kidney Tissue for Minimally Invasive Percutaneous Nephrolithotomy (PCNL) Surgery; location-Based Attendance Monitoring System with Facial Authentication; load Balancing in Cloud Computing Using Multi-agent-Based Algorithms; Viable Methods Adopted for Reducing SAR Value in Mobile Phone Antenna: A Review; numerical Modelling of Cu2O-Based Gas Sensor for Detection of Volatile Organic Compounds in Human Breath; significance of Convolutional Neural Network in Fake Content Detection: A Systematic Survey; wavelet and Savitzky–Golay Filter-Based Denoising of Electrocardiogram Signal: An Improved Approach; Heart Disease Detection Using Phonocardiogram (PCG) Signals; enigmas of Various Techniques to Implementing Authentication and Integrity in Blockchain-Based Wireless Sensor Networks; data Integration in IoT Using Edge Gateway.","","","","Jain S.; Marriwala N.; Tripathi C.C.; Kumar D.","Springer Science and Business Media Deutschland GmbH",""
"Neelam B.; Kumar Palakayala P.; Mbangweta K.; Raparla K.; Devi S.A.","Neelam, Bindu (58573991800); Kumar Palakayala, Pavan (58573912800); Mbangweta, Kusiyo (58573875000); Raparla, Karthik (58573912900); Devi, S Anjali (57201477120)","58573991800; 58573912800; 58573875000; 58573912900; 57201477120","FCN Based Deep Learning Architecture for Medical Image Segmentation","2023","","","","556","562","6","10.1109/ICECAA58104.2023.10212108","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170825280&doi=10.1109%2fICECAA58104.2023.10212108&partnerID=40&md5=2dba6292a510d9dd1b757fe4a7f413a1","By eliminating the laborious and time-consuming task of manually drawing contours around organs and tumors, deep learning algorithms have revolutionized the area of medical image segmentation. Deep learning can significantly improve treatment outcomes for patients with gastrointestinal cancer and many other medical illnesses where precise and effective segmentation is essential for successful treatment by automating the segmentation process. Fully convolutional neural networks (FCNs), a type of convolutional neural network, have been researched for medical image segmentation. In this study, a U-Net model, a form of Fully Convolutional Network (FCN), is evaluated for its use in segmenting brain tumors. The precision and accuracy of medical image processing have been proven to be greatly improved by deep learning-based techniques. Deep learning model interpretability, generalizability across different imaging modalities, and the requirement for larger and more varied datasets are still problems that need to be overcome. This research work intends to provide a performance and generalizability analysis of the U-Net model for medical image segmentation in brain tumor detection.  © 2023 IEEE.","Biomedical Imaging (BMI); Brain Tumor Detection (BTD); Convolutional Neural Network (CNN); Deep Learning (DL); Fully Convolutional Network (FCN); Machine Learning (ML); Medical Image Segmentation (MIS); Neural Networks (NN); U-Net model (UNet)","Brain; Convolution; Deep learning; Diseases; Image enhancement; Image segmentation; Learning algorithms; Learning systems; Medical imaging; Patient treatment; Tumors; Biomedical imaging; Brain tumor detection; Brain tumors; Convolutional networks; Convolutional neural network; Deep learning; Fully convolutional network; Machine learning; Machine-learning; Medical image segmentation; Net model; Neural network; Neural-networks; Tumour detection; U-net model; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","International Health Informatics Conference, IHIC 2022","2023","990 LNEE","","","","","406","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161143496&partnerID=40&md5=644355e1a0cb0efee04ea243a6ada616","The proceedings contain 34 papers. The special focus in this conference is on International Health Informatics. The topics include: Telemedicine: Enhancing and Reimagining the Public Health in India; effect of Point of Service on Health Department Student’s Creativity in Comprehensive Universities of Ethiopia: Moderating Role of Public-Private Partnership and Mediating Role of Work Place Learning; prediction and Comparative Analysis of Few Most Impacted Countries by Coronavirus; an Efficient Method for Skin Cancer Detection Using Convolutional Neural Network; collective Behavior in Community-Structured Network and Epidemic Dynamics; incorporating Semantics for Text Classification in Biomedical Domain; COVID-19 Prediction from CT and X-Ray Scan Images: A Review; design of a Prototypic Mental Health Ontology for Sentiment Analysis of Tweets; a Novel Yoga-Based Practice Protocol to Quantify Stress After Performing Attention Task Using Non-invasive Technique; an Ensemble for Attendance Management with Face Visualization and Recognition Using Local Binary Pattern Histogram; healthcare Question–Answering System: Trends and Perspectives; An Analysis of Word Sense Disambiguation (WSD); classification of Breast Invasive Ductal Carcinomas Using Histopathological Images Based on Deep Learning Techniques; heart Disease Detection Using Machine Learning Techniques; evaluation of Spatiotemporal Fetal Cardiac Imaging Using Deep Learning Techniques; application of Deep Learning on Skin Cancer Prediction; feature Analysis for Detection of Breast Cancer Thermograms Using Dimensionality Reduction Techniques; covid-19 Question-Answering System Based on Semantic Similarity; Impact of EEG Signals on Human Brain Before and After Meditation; a Study of Deep Learning Algorithms in Sentiment Analysis of Diverse Domains; COVID-19 Detection and Classification Method Based on Machine Learning and Image Processing.","","","","Jain S.; Groppe S.; Mihindukulasooriya N.","Springer Science and Business Media Deutschland GmbH",""
"Mezzini M.","Mezzini, Mauro (6505802476)","6505802476","Emotion detection using deep learning on spectrogram images of the electroencephalogram","2023","3576","","","1","14","13","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179584939&partnerID=40&md5=3add52e0dd8ab461c3fa2345311e0410","In this paper it is proposed a deep learning technique for emotion classification using spectrogram images produced from the related electroencephalogram (EEG) signals. The idea is to use the classical, state-of-the-art deep learning techniques for image recognition applied to the spectrogram of the EEG signal. The goal is to detect and recognize the level of valence, arousal, dominance, and likability. Extensive experiments are carried on with different convolutional neural network architectures on the publicly available DEAP dataset in order to find the best possible model with respect to the accuracy of the prediction. A new data augmentation technique on EEG signals has been experimented with and validated. The model has been developed and evaluated by taking a random permutation of the dataset and partitioning it in 80% training, 10% validation, and 10% test. Doing so allowed us to assess the model’s ability to recognize an individual’s emotion based on the EEG signals of other individuals. Results show that the models can learn and detect emotions with high accuracy at the same level as the state of the art of analogous models already presented in the literature. © 2023 CEUR-WS. All rights reserved.","CNN; Deep learning; EEG; Emotion recognition","Biomedical signal processing; Convolutional neural networks; Deep learning; Electroencephalography; Image recognition; Learning algorithms; Learning systems; Network architecture; Spectrographs; Speech recognition; Statistical tests; Convolutional neural network; Deep learning; Electroencephalogram signals; Emotion classification; Emotion detection; Emotion recognition; Learning techniques; Neural network architecture; Spectrograms; State of the art; Emotion Recognition","","Saibene A.; University of Milano-Bicocca, Viale Sarca 336, Milano; Saibene A.; NeuroMI, Milan Center for Neuroscience, Piazza dell�Ateneo Nuovo 1, Milano; Corchs S.; NeuroMI, Milan Center for Neuroscience, Piazza dell�Ateneo Nuovo 1, Milano; Corchs S.; University of Insubria, Via J. H. Dunant 3, Varese; Fontana S.; University of Milano-Bicocca, Viale Sarca 336, Milano; Sole-Casals J.; University of Vic-Central University of Catalonia, C de la Laura 13, Barcelona; Sole-Casals J.","CEUR-WS",""
"Pon Bharathi A.; Srinivasan P.; Sarika A.S.; Vedha Vinodha D.; Parthiban K.G.","Pon Bharathi, A. (58021617700); Srinivasan, P. (58581359000); Sarika, A.S. (58017755800); Vedha Vinodha, D. (58009320300); Parthiban, K.G. (57516303500)","58021617700; 58581359000; 58017755800; 58009320300; 57516303500","Chronological golden search optimization-based deep learning for classification of heartbeat using ECG signal","2023","11","6","","2333","2349","16","10.1080/21681163.2023.2228930","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164496572&doi=10.1080%2f21681163.2023.2228930&partnerID=40&md5=121afefd0cc1c6726ee1e380c2a5e089","Electrocardiogram (ECG) is the simplest test, used for checking the heart’s rhythm and measuring the heart’s electrical activity. This method is the most probably used technique for identifying heart diseases because of its non-invasive nature. The patient’s status is identified by handling the irregularities in the ECG signals. For computation in the existing system, they use signal processing methods which result in time consumption in real time. In existing system, it is hard to predict the detection of heartbeat early and accurately. In this work, the heartbeat is classified using ECG signal by proposed Chronological Golden Search Optimisation (CGSO)-based Deep Learning (DL). Here, the CGSO algorithm is developed by hybridising the Chronological concept with the Golden search optimisation (GSO) algorithm, which is utilised to train SqueezeNet. After the acquisition of ECG signals, pre-processing is done by a median filter. Then, the features are extracted, and this tends to the data augmentation process. Finally, the heartbeat is classified using SqueezeNet-enabled CGSO. The performance is analysed using ECG heartbeat categorisation data set. The proposed model obtained a specificity of 93.5%, sensitivity of 93.1% and precision of 89.8%. From the results, it is known that the proposed system offers more accurate results. © 2023 Informa UK Limited, trading as Taylor & Francis Group.","Chronological golden search; golden search optimisation; herat beat; median filter; SqueezeNet","Biomedical signal processing; Deep learning; Electrocardiograms; Chronological golden search; Classifieds; Electrocardiogram signal; Existing systems; Golden search optimization; Herat beat; Median-Filter; Optimization algorithms; Search optimization; Squeezenet; algorithm; Article; artificial neural network; Chronological golden search optimization; deep learning; electric activity; electrocardiography; feature extraction; Fourier transform; heart beat; human; image segmentation; independent component analysis; information processing; mathematical analysis; mathematical model; mathematical phenomena; measurement precision; P wave; principal component analysis; QRS complex; QT interval; residual neural network; RR interval; sensitivity and specificity; signal processing; support vector machine; Median filters","","","Taylor and Francis Ltd.",""
"Obayya M.; Saeed M.K.; Alruwais N.; Alotaibi S.S.; Assiri M.; Salama A.S.","Obayya, Marwa (6505869929); Saeed, Muhammad Kashif (57202381130); Alruwais, Nuha (58000746700); Alotaibi, Saud S. (57202829227); Assiri, Mohammed (57219344932); Salama, Ahmed S. (56480035100)","6505869929; 57202381130; 58000746700; 57202829227; 57219344932; 56480035100","Hybrid Metaheuristics with Deep Learning-Based Fusion Model for Biomedical Image Analysis","2023","11","","","117149","117158","9","10.1109/ACCESS.2023.3326369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174859346&doi=10.1109%2fACCESS.2023.3326369&partnerID=40&md5=63fe7da16e2472f5531f57306a513e45","Biomedical image analysis has played a pivotal role in modern healthcare by facilitating automated analysis and interpretation of medical images. Biomedical image classification is the process of automatically labelling or categorizing medical images based on their content. In recent years, this field has received considerable attention because of the abundance of bio-medical image data and the potential for deep learning (DL) algorithms to assist medical staff in identifying diseases and making treatment decisions. DL methods are mostly convolutional neural networks (CNN) has illustrated outstanding performance in analyzing and classifying biomedical images. Therefore, this study presents a new Hybrid Metaheuristics with Deep Learning based Fusion Model Biomedical Image Analysis (HMDL-MFMBIA) technique. The HMDL-MFMBIA technique initially performs image pre-processing and Swin-UNet-based segmentation. Besides, a fusion of multiple DL-based feature extractors takes place using Xception and Residual Network (ResNet) model. Moreover, a hybrid salp swarm algorithm (HSSA) was employed for the optimal hyperparameter selection of the DL models. Finally, the gated recurrent unit (GRU) algorithm can be exploited for the detection and classification of bio-medical images. A widespread of simulated is conducted to establish the enhanced biomedical image classification results of the HMDL-MFMBIA method. The simulation outcomes inferred the greater outcome of the HMDL-MFMBIA algorithm over other DL models.  © 2013 IEEE.","Biomedical image analysis; computer vision; deep learning; fusion model; image classification","Bioinformatics; Computer vision; Convolution; Deep learning; Diagnosis; Feature extraction; Heuristic algorithms; Image analysis; Image classification; Image enhancement; Image fusion; Medical image processing; Neural networks; Biological system modeling; Biomedical image analysis; Classification algorithm; Convolutional neural network; Deep learning; Features extraction; Fusion model; Images classification; Images segmentations; Medical diagnostic imaging; Tuning; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Meca A.","Meca, Alba (57450429300)","57450429300","Applications of Deep Learning to Magnetic Resonance Imaging (MRI)","2023","","","","113","120","7","10.1109/iCCECE59400.2023.10238598","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172931505&doi=10.1109%2fiCCECE59400.2023.10238598&partnerID=40&md5=1eb58e2920f462eb25374cfd0c13cb3c","In recent years, there has been significant attention towards deep neural networks and they are increasingly being applied to clinical practices. Medical imaging technology, biomedical data analysis, computer-Aided diagnosis, and healthcare in general are all to gain immensely from these breakthroughs which are just now becoming apparent. Our study focuses on Magnetic Resonance Imaging (MRI) scans, an area of growing interest in medical research. The availability of sophisticated, low-cost computer hardware over the past decade has been the primary driving force in the advancement of computer vision in medical research, which has led to immense developments in digital MRI image analysis that ranges from simple qualitative analysis of disease detection to acquiring more insight into its nature. As deep learning techniques evolve and more data becomes available, new opportunities arise to further explore and optimize their utilization in MRI analysis. This study aims to contribute to this dynamic area of research by providing a broad overview of the latest applications and identifying potential areas for continued growth and improvement. The paper is an attempt to address the research gap by exploring how deep learning techniques and architectures can be effectively employed in various stages of the classical medical image processing workflow for MRI scans, from image acquisition and retrieval to preprocessing, segmentation, feature extraction and disease detection or prediction. The intended outcome of this study is an up-To-date, comprehensive summary of the state-of-The-Art deep learning techniques employed in MRI-based research. With an understanding of the present landscape, researchers and medical practitioners can garner valuable insights into the recent advancements and identify prospective avenues for future investigations. By emphasizing the potential of deep learning in medical imaging and providing a clear perspective on its applications and limitations, this study aims to contribute to the advancement of both deep learning and MRI technology.  © 2023 IEEE.","Deep Learning; Image Reconstruction; Image Registration; Magnetic Resonance Fingerprinting; Magnetic Resonance Imaging; Medical Imaging; Quantitative Susceptibility Mapping; Segmentation","Computer aided diagnosis; Computer aided instruction; Computer hardware; Deep neural networks; Feature extraction; Health care; Image reconstruction; Image segmentation; Learning algorithms; Learning systems; Medical computing; Medical imaging; Deep learning; Disease detection; Images reconstruction; Images registration; Learning techniques; Magnetic resonance fingerprinting; Medical research; Quantitative susceptibility mapping; Segmentation; Susceptibility mapping; Magnetic resonance imaging","","Miraz M.H.; Southall G.; Ali M.; Ware A.; Campbell C.; Walcott T.","Institute of Electrical and Electronics Engineers Inc.",""
"Sumathy V.; Pretty Diana Cyril C.","Sumathy, V. (57212708697); Pretty Diana Cyril, C. (57222521426)","57212708697; 57222521426","Systematic Literature Review on Early Diagnosis of Oral Squamous Cell Carcinoma by Deep Learning Techniques","2023","","","","","","","10.1109/RMKMATE59243.2023.10369110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183537880&doi=10.1109%2fRMKMATE59243.2023.10369110&partnerID=40&md5=579ea4a0fdf99e1ecbd4722613076a1f","Oral Squamous Cell Carcinoma (OSCC) is the seventh most prevalent type of cancer in the neck and head. The prognosis and survival rate of the patient is significantly improved by early identification of OSCC. Due to tumor heterogeneity, such a diagnosis requires much time and a high-efficiency human experience. As a result, artificial intelligence systems assist professionals and physicians in making precise diagnoses. Recent advances in computer vision-based techniques and Computational Intelligence (CI) improve accuracy in medical images. This study aims to develop hybrid methodologies based on fused features to produce excellent outcomes for the early detection of OSCC. This systematic review aims to estimate deep learning (DL) based algorithms for early diagnosis OSCC to assist clinicians in oral cancer diagnosis and screening. The terms ""squamous cell carcinoma, "" ""early diagnosis, "" ""oral cavity, "" ""histopathological image, "" ""biomarker, "" ""Optical Coherence Tomography (OCT) image, "" and ""deep learning"" were used in a Google Scholar Cochrane and MEDLINE (PubMed), Embase and WoS databases (January 2018 to July 2023) to find relevant articles. The inclusion criteria were the use of deep learning approaches for early diagnosis of OSCC, articles older than 5 years, and publications written in English. Case reports and studies written in foreign languages met the exclusion criteria. 70 publications were chosen to be included in the systematic review out of the 194 studies that were initially found through the search. Deep learning techniques based on hybrid features are examined in evaluating performance metrics and superior results of the present systems employing biomedical images for OSCC diagnosis. It has been established that the deep learning-based early identification method for biomedical images has the ability to offer decision support for efficient oral cancer diagnosis and screening. © 2023 IEEE.","convolutional neural network; deep learning; hybrid method; OCT; Oral Squamous Cell Carcinoma","Cells; Convolutional neural networks; Cytology; Decision support systems; Deep learning; Diseases; Image enhancement; Learning algorithms; Learning systems; Medical imaging; Optical tomography; Cancer diagnosis; Cancer screening; Convolutional neural network; Deep learning; Early diagnosis; Hybrid method; Learning techniques; Oral cancer; Oral squamous cell carcinomata; Systematic Review; Diagnosis","","","Institute of Electrical and Electronics Engineers Inc.",""
"Sarma M.; Bond C.; Nara S.; Raza H.","Sarma, Minerva (58884280000); Bond, Charles (58884280100); Nara, Sanjeev (57213172086); Raza, Haider (57195623793)","58884280000; 58884280100; 57213172086; 57195623793","MEGNet: A MEG-Based Deep Learning Model for Cognitive and Motor Imagery Classification","2023","","","","2571","2578","7","10.1109/BIBM58861.2023.10385695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184865756&doi=10.1109%2fBIBM58861.2023.10385695&partnerID=40&md5=af871cfcaf6f7be8f78fb1e42b46e960","Decoding complex patterns associated with task-specific activities embedded within magnetoencephalography (MEG) signals is pivotal for understanding brain functions and developing applications such as brain-computer interfacing. It is widely recognized that machine learning algorithms rely on feature extraction before undertaking decoding tasks. In this work, we introduce MEGNet, aiming to enhance the single-trial decoding framework of a compact deep neural network inspired by EEGNet, a model widely utilized in electroencephalography (EEG) studies. MEGNet accepts raw MEG signals, evoked responses and frequency spectrum as input. For validation, the MEG dataset containing motor and cognitive imagery tasks was used for classification. We performed pair-wise decoding of cognitive and motor tasks. Classification accuracy was evaluated using metric scores and benchmarked against ShallowConvNet and DeepConvNet. Our findings demonstrate that MEGNet can successfully decode between cognitive and mental imagery tasks. This MEGNet model surpasses existing feature extraction techniques, exhibiting consistent and stable mean accuracy of 64.76%±3% across tasks and subjects. All codes are available at our GitHub repository: https://github.com/Charliebond125/MEGNet.git.  © 2023 IEEE.","Cognitive and Motor Imagery; Convolutional Neural Network; Deep Learning; Magnetoencephalography","Biomedical signal processing; Brain; Brain computer interface; Brain mapping; Classification (of information); Convolutional neural networks; Decoding; Deep neural networks; Electroencephalography; Electrophysiology; Extraction; Feature extraction; Image classification; Learning algorithms; Learning systems; Brain functions; Cognitive and motor imagery; Complex pattern; Convolutional neural network; Deep learning; Imagery task; Learning models; Motor imagery; Motor imagery classification; Specific activity; Magnetoencephalography","Business and Local Government Data Research Centre, (ES/S007156/1); Hessian Ministry of Higher Education, Science, Research and Art; Economic and Social Research Council, ESRC","Jiang X.; Wang H.; Alhajj R.; Hu X.; Engel F.; Mahmud M.; Pisanti N.; Cui X.; Song H.","Institute of Electrical and Electronics Engineers Inc.",""
"Chiu C.-C.; Li C.-L.; Chien W.; Wu H.-Y.; Chen P.H.; Lim E.H.; Chen G.-Z.","Chiu, Chien-Ching (7402303547); Li, Ching-Lieh (14050388900); Chien, Wei (7005813118); Wu, Hong-Yu (58532916200); Chen, Po Hsiang (57226299072); Lim, Eng Hock (24825036300); Chen, Guo-Zheng (58298506600)","7402303547; 14050388900; 7005813118; 58532916200; 57226299072; 24825036300; 58298506600","Microwave Imaging of Conductors by Direct Sampling Method and U-Net","2023","35","7","","2399","2411","12","10.18494/SAM4446","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167724513&doi=10.18494%2fSAM4446&partnerID=40&md5=8f314beeb1ccd31ecc14d0c237698dd8","Electromagnetic imaging is an emerging technology widely applied in many fields, such as medical imaging, biomedical imaging, and nondestructive testing. In this study, we place transmitter and receiver antennas around an unknown object. We can use the direct sampling method (DSM) to reconstruct the material size and shape of the unknown object on the basis of the scattered field. We apply U-Net to reconstruct electromagnetic images of perfect conductors. Perfect conductors in free space are studied by irradiating a transverse magnetic (TM) polarization wave. Using the scattered electric field measured outside the object together with the boundary conditions on the conductor surface, a set of nonlinear integral equations can be derived and further converted into matrix form by the method of moments. Since an iterative algorithm is computationally expensive and time-consuming, a real-time electromagnetic imaging technique combining deep learning neural networks is proposed for reconstructing the perfect conductors. The initial shapes of the conductors are first computed by DSM by using the scattered electric field measured outside the object. The initial shapes of the conductors are then input to U-Net for training. Numerical results show that U-Net is capable of reconstructing accurate conductor shapes. Therefore, artificial intelligence techniques can reconstruct shapes more accurately than iterative algorithms, when combined with DSM. © MYU K.K.","conductor; direct sampling method; frequency domain; inverse scattering; U-Net","Deep learning; Electromagnetic wave scattering; Forward scattering; Frequency domain analysis; Integral equations; Inverse problems; Iterative methods; Medical imaging; Method of moments; Nondestructive examination; Nonlinear equations; Receiving antennas; Conductor; Direct sampling method; Electromagnetic imaging; Frequency domains; Initial shape; Inverse-scattering; Iterative algorithm; Microwave imaging; U-net; Unknown objects; Electric fields","","","M Y U Scientific Publishing Division",""
"Napte K.; Mahajan A.; Urooj S.","Napte, Kiran (57222042420); Mahajan, Anurag (40461791800); Urooj, Shabana (36163484800)","57222042420; 40461791800; 36163484800","ESP-UNet: Encoder-Decoder Convolutional Neural Network with Edge-Enhanced Features for Liver Segmentation","2023","40","5","","2275","2281","6","10.18280/ts.400545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177832369&doi=10.18280%2fts.400545&partnerID=40&md5=3011ec70f0972f7ccba7992f7bd1ccfb","Precise liver segmentation in Computed Tomography (CT) scans plays a pivotal role in numerous biomedical applications, spanning surgical planning, postoperative assessment, and pathological detection of hepatic diseases. The task, however, is fraught with challenges due to the inherent complexities of liver morphology, including indistinct boundaries, irregular shapes, and complex architecture. Consequences of under-segmentation and over-segmentation of the liver in CT images can lead to inaccurate localizations and diagnoses of liver diseases, underscoring the necessity for accurate segmentation. This study introduces an Encoder-Decoder Convolutional Neural Network, termed ESP-UNet, which is designed to reduce under-segmentation and over-segmentation, thereby enhancing the accuracy of liver segmentation. The proposed ESP-UNet employs Kirsch's filter to bolster the texture and edge information of liver images, thus aiding in improved segmentation performance. The efficacy of the ESP-UNet segmentation technique was evaluated using the LiTS dataset, with performance metrics including accuracy, Dice Score Coefficient (DSC), Volume Overlapping Error (VOE), and Relative Volume Difference (RVD). The algorithm yielded impressive results, with a Dice Score of 0.959, a VOE of 0.089, a Jaccard Index (JI) of 0.921, and an RVD of 0.09. Despite requiring a larger number of trainable parameters and an increased network complexity due to the parallel UNet, the proposed ESP-UNet not only enhances liver segmentation but also has the potential to improve the detection of liver cancer at the image borders. A comparison with existing state-of-the-art liver segmentation techniques revealed that ESP-UNet offers superior performance, validating its potential as a useful tool in the diagnosis and treatment of liver diseases. © 2023 Lavoisier. All rights reserved.","automatic liver segmentation; deep learning; image segmentation; liver cancer detection; medical image segmentation","Complex networks; Computerized tomography; Convolution; Convolutional neural networks; Decoding; Deep learning; Diagnosis; Diseases; Image enhancement; Medical applications; Medical imaging; Textures; Automatic liver segmentation; Convolutional neural network; Deep learning; Encoder-decoder; Images segmentations; Liver cancer detection; Liver disease; Liver segmentation; Medical image segmentation; Over segmentation; Image segmentation","Abdulrahman University, (PNURSP2023R79); Princess Nourah Bint Abdulrahman University, PNU","","International Information and Engineering Technology Association",""
"Hu Z.; Wu R.; Rao Z.; Li Y.","Hu, Zhangfang (7404211399); Wu, Ruosai (58660651700); Rao, Zherui (58659776900); Li, Yao (58855241200)","7404211399; 58660651700; 58659776900; 58855241200","A Motor Imagery EEG Classification Algorithm Based on ResCNN-BiGRU","2023","12765","","1276515","","","","10.1117/12.2685762","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181849093&doi=10.1117%2f12.2685762&partnerID=40&md5=e0f9d9603210d2c4b513bb697c3f5d6f","In recent years, deep learning-based methods for motor imagery EEG classification have become increasingly popular in the field of brain-computer interfaces. However, most of the studies tend to use sequence-structured classification networks to extract spatial features when dealing with motor imagery EEG signal classification tasks, ignoring the fact that EEG signals as time-series signals contain rich temporal information and features between neural network layers, resulting in poor classification performance. Therefore, this paper proposes a feature fusion network called ResCNN-BiGRU, which consists of ResNet-based residual convolutional neural network (ResCNN) and bidirectional gated recurrent unit (BiGRU) connected in parallel. The two branches use different forms of EEG signal feature representation as input, the input to the ResCNN branch is a wavelet transformed time-frequency image, and the input to the BiGRU branch is EEG data in a two-dimensional matrix format. ResCNN extracts spatial features and utilizes interlayer features through residual connections. It also introduces convolutional block attention module (CBAM) to avoid introducing too much useless low-level feature information during interlayer feature fusion. BiGRU extracts temporal features. Finally, experiments are conducted on the authoritative four-category motor imagery dataset BCI Competition IV 2a to verify the performance of the proposed algorithm. © 2023 SPIE.","BiGRU; CBAM; EEG; Feature fusion; Motor imagery","Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Image classification; Multilayer neural networks; Recurrent neural networks; Bidirectional gated recurrent unit; Convolutional block attention module; Convolutional neural network; EEG classification; EEG signals; Features fusions; Motor imagery; Motor imagery EEG; Spatial features; Temporal features; Network layers","","Wang Y.; Kidger T.E.; Wu R.","SPIE",""
"Liu W.; Bao F.","Liu, Weiheng (58248997300); Bao, Fengge (58250164700)","58248997300; 58250164700","Signal Recognition Methods in Motor Imagery BCI","2023","12587","","125871H","","","","10.1117/12.2667874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159309693&doi=10.1117%2f12.2667874&partnerID=40&md5=33474129a1dadc6c7674be5c4ed68788","Brain computer interface constructs the direct connection between human brain and external devices, which is becoming a promising method in reconstructing human's motor abilities who suffered from body disability. Among several kinds of BCI technologies, Motor Imagery based Brain-computer Interface (MI-BCI) has attracted more and more attentions since it's a more intuitive method. In the procedure of MI-BCI, the signal recognition methods play a significant role. Therefore, this paper would search into the classification techniques utilized in the processing procedure in MI-BCI systems, including machine learning techniques, naïve bayes classifier (NB), support vector machines (SVM) and linear discriminant analysis (LDA). For deep learning techniques, sparse autoencoder (SAE), convolutional neural network (CNN), recurrent neural network (RNN) was introduced. Then the paper would compare them in terms of accuracy, classification speed and data requirement. This paper would give an overview on the commonly seen classification method used in MI-BCI, and also present researchers who are selecting classification methods the most suitable choice. © 2023 SPIE.","Brain-computer interface; Deep learning; EEG classification; Machine learning; motor imagery","Biomedical signal processing; Convolutional neural networks; Discriminant analysis; Image classification; Learning algorithms; Learning systems; Recurrent neural networks; Support vector machines; Classification methods; Deep learning; EEG classification; Human brain; Human motor; Machine-learning; Motor abilities; Motor imagery; Recognition methods; Signal recognition; Brain computer interface","","Hu N.; Zhang G.","SPIE",""
"Buradkar V.S.; Ambhaikar A.","Buradkar, Vanita S. (56021497400); Ambhaikar, Asha (37013228600)","56021497400; 37013228600","Applications in Medical Technology for Optimized Convolutional Neural Network Using Differential Evolutionary Algorithm","2023","1046 LNEE","","","323","332","9","10.1007/978-981-99-2710-4_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172220557&doi=10.1007%2f978-981-99-2710-4_26&partnerID=40&md5=a445b8729711ff981167e8cc771a7f18","Overall, in the world, most deaths are caused by heart attacks and cancer. Development in medical imaging technology using deep learning algorithms and optimizers is becoming more and more possible. It is a growing area for analytics in the medical field. Medical imaging classification uses convolutional neural networks. It is a difficult effort to choose their hyperparameters and architecture. The CNN is optimized using a variety of evolutionary algorithm versions. Among the evolutionary algorithms are the genetic algorithm, particle swarm optimization, and differential evolutionary algorithms. A straightforward and effective population-based method is a differential evolutionary one to optimize the CNN model, we are using a different evolutionary algorithm. Due to the natural intricacy of medicine, optimization has become an important technique. This article's objective is to provide a thorough summary of applications, methods of CNNs, DE optimizer, and their different versions. The planned algorithm is discussed, and an effort will be made to increase the algorithm's performance to over 90%. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Convolutional neural network (CNN); CT images; Deep learning model; Differential evolutionary algorithm; Genetic algorithm; Lungs cancer","Biomedical engineering; Computerized tomography; Convolution; Convolutional neural networks; Deep learning; Diseases; Learning algorithms; Medical imaging; Particle swarm optimization (PSO); Convolutional neural network; CT Image; Deep learning model; Differential evolutionary algorithm; Heart attack; Learning models; Lung Cancer; Medical technologies; Optimizers; Genetic algorithms","","Sarkar D.K.; Sadhu P.K.; Bhunia S.; Samanta J.; Paul S.","Springer Science and Business Media Deutschland GmbH",""
"Sankaranarayaanan R.; Kumar M.S.; Chidhambararajan B.; Sirenjeevi P.","Sankaranarayaanan, R. (58190846800); Kumar, M. Senthil (57212627912); Chidhambararajan, B. (57572707700); Sirenjeevi, P. (58190489200)","58190846800; 57212627912; 57572707700; 58190489200","Brain tumor detection and Classification using VGG 16","2023","","","","","","","10.1109/ICECONF57129.2023.10083866","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153096320&doi=10.1109%2fICECONF57129.2023.10083866&partnerID=40&md5=97e2deaa589d4250f417fbf68965f481","The rapid advancement of medical technology has brought about the impending arrival of the era of big data in the medical field. As a direct and immediate consequence of the analysis and mining of these data, there will be significant effects on the prediction, monitoring, diagnosis, and treatment of tumor-related issues. Due to the fact that it possesses a diverse collection of traits, a low survival rate, and an aggressive nature, brain tumours are widely regarded as the disease that is both the most lethal and the one that causes the greatest disability. It has been proposed that deep learning has the ability to solve the difficulties associated with diagnosing and treating brain cancers. Through the use of FL on brain tumor identification from MRI images, the purpose of this research is to find a solution to the problem of centralized data collecting. Using the Visual Geometry Group (VGG 16) as a tool for detecting brain cancers, implementing a convolutional neural network (CNN) model framework, and determining the parameters to train the model for this problem were the objectives of this research. The MR images might be analyzed with our method to spot brain cancers. The testing results showed that the algorithm worked better than the standard methods that are currently used for detecting brain tumors, with an excellent accuracy of 92%. © 2023 IEEE.","brain tumor; CNN; convolutional neural network; deep learning; VGG","Biomedical engineering; Brain; Convolution; Deep learning; Diagnosis; Diseases; Magnetic resonance imaging; Neural network models; Tumors; Brain cancer; Brain tumors; Convolutional neural network; Deep learning; Medical fields; Medical technologies; Tumor classification; Tumour detection; VGG; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Bui P.-N.; Le D.-T.; Bum J.; Kim S.; Song S.J.; Choo H.","Bui, Phuoc-Nguyen (58034781500); Le, Duc-Tai (55314939400); Bum, Junghyun (57190274322); Kim, Seongho (57204243702); Song, Su Jeong (22433864200); Choo, Hyunseung (59066066500)","58034781500; 55314939400; 57190274322; 57204243702; 22433864200; 59066066500","Semi-Supervised Learning With Fact-Forcing for Medical Image Segmentation","2023","11","","","99413","99425","12","10.1109/ACCESS.2023.3313646","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171563021&doi=10.1109%2fACCESS.2023.3313646&partnerID=40&md5=8478adf6ccdb4e64579f3a918af0fe92","Precise and robust image segmentation is one of the most important steps in supervised deep learning-applied studies. Especially in the medical field, image segmentation requires an enormous time and professionals with clinical knowledge. Although there are constant attempts for automatic and semi-automatic image segmentation algorithm development, acquiring not only clinically accurate but also precise pixel-level annotations for medical images remains insufficient. This article presents a semi-supervised learning method with a novel fact-forcing process, referred to as FFSS, to reduce the labeling cost while improving the prediction accuracy for medical image segmentation. FFSS includes two components: a pre-trained teacher and a student that would be trained, iteratively. In each iteration, the teacher first generates a pseudo-label for each image in an unlabeled set, the student is then trained on the pseudo-labeled set and sends feedback to update the teacher. A fact-forcing process is designed to improve the quality of the student model using a labeled set. We have comprehensively evaluated our method on both three-dimensional binary segmentation and two-dimensional multi-class segmentation. The evaluation results demonstrate significant accuracy improvements of FFSS compared with the state-of-the-art semi-supervised methods. Due to the fact-forcing process, the proposed method consistently outperforms the other ones under various labeled data ratios for all benchmark datasets, including left atrium MRI, pancreas CT, ACDC MRI, and OCT. By refining the quality of student feedback with complementary supervised training, the proposed FFSS shows robustness under labeled data scarcity for diverse types of medical images.  © 2013 IEEE.","Convolutional neural network; fact-forcing process; medical image segmentation; semi-supervised learning","Computer aided instruction; Computerized tomography; Convolution; Deep learning; Feedback; Image enhancement; Image segmentation; Iterative methods; Medical imaging; Neural networks; Students; Supervised learning; Teaching; Biomedical imaging; Convolutional neural network; Fact-forcing process; Forcings; Images segmentations; Medical image segmentation; Predictive models; Semi-supervised learning; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"Tesfaye Z.R.; Zhu E.; Chai R.; Zhang B.; Chai S.","Tesfaye, Zeru Rediet (58677654400); Zhu, Enjun (55490554500); Chai, Runqi (57169952500); Zhang, Baihai (36096131000); Chai, Senchun (8319672500)","58677654400; 55490554500; 57169952500; 36096131000; 8319672500","Automatic Cardiac MRI Segmentation Using Deep Learning","2023","2023-July","","","8715","8720","5","10.23919/CCC58697.2023.10239829","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175548631&doi=10.23919%2fCCC58697.2023.10239829&partnerID=40&md5=0fad07469b0c2c2356a861c23ad07311","In the biomedical realm, automatic medical image segmentation is regarded as a challenging research topic. Among the different automatic methods, U-shaped models have significantly advanced a wide range of medical image segmentation. When training deep neural networks like U-net, gradient degradation is one of the problems we need to prevent from occurring. In addition, giving more focus to the important objects in the image while disregarding unneeded areas is one of the desired properties in medical image segmentation. In order to prevent gradient degradation and focus on the important objects in the image, a novel U-net-based architecture is proposed for cardiac MRI segmentation. The model uses the merit of U-Net, residual U-Net (ResU-Net), and Attention U-Net (AttU-Net) for better performance and prediction results. U-Net, ResU-Net, and AttU-Net are used as benchmark models. For the model to efficiently train the data and to improve its accuracy, a data preprocessing mechanism is applied. The data preprocessing step includes contrast enhancement, data augmentation, and data normalization. For the contrast enhancement method, we tested three different contrast enhancement methods. These methods are non-linear contrast enhancement (gamma correction), multi-scale Retinex, and adaptive histogram equalization. After testing the three contrast enhancement methods on the data, the best one was selected for use in the deep learning algorithms. The proposed and benchmark models are tested on data from Anzhen Hospital and ACDC public data set. The result shows that the proposed model achieved a better prediction result on both data sets than the benchmarks. This is due to the benefits of using ResU-Net and AttU - Net, which enable it to concentrate on the small class, reintroduce features, and prevent gradient degradation, resulting in its advantage. © 2023 Technical Committee on Control Theory, Chinese Association of Automation.","AttU-Net; Cardiac image segmentation; Magnetic resonance imaging (MRI); ResU-Net; U-Net","Deep neural networks; Image segmentation; Learning algorithms; Medical imaging; Attention U-net; Benchmark models; Cardiac image segmentation; Cardiac magnetic resonance imaging; Contrast Enhancement; Important object; Magnetic resonance imaging; Medical image segmentation; Residual U-net; U-net; Magnetic resonance imaging","","","IEEE Computer Society",""
"Chobola T.; Müller G.; Dausmann V.; Theileis A.; Taucher J.; Huisken J.; Peng T.","Chobola, Tomáš (57219694776); Müller, Gesine (58540719500); Dausmann, Veit (56574215000); Theileis, Anton (57933771900); Taucher, Jan (36873253700); Huisken, Jan (18037338700); Peng, Tingying (56245821000)","57219694776; 58540719500; 56574215000; 57933771900; 36873253700; 18037338700; 56245821000","Leveraging Classic Deconvolution and Feature Extraction in Zero-Shot Image Restoration","2023","","","","3876","3885","9","10.1109/ICCVW60793.2023.00419","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182927046&doi=10.1109%2fICCVW60793.2023.00419&partnerID=40&md5=5b2ed116516fbfdcbf5ee2d7eeb2ea3c","Non-blind deconvolution aims to restore a sharp image from its blurred counterpart given an obtained kernel. Existing deep neural architectures are often built based on large datasets of sharp ground truth images and trained with supervision. Sharp, high quality ground truth images, however, are not always available, especially for biomedical applications. This severely hampers the applicability of current approaches in practice. In this paper, we propose a novel non-blind deconvolution method that leverages the power of deep learning and classic iterative deconvolution algorithms. Our approach combines a pre-trained network to extract deep features from the input image with iterative Richardson-Lucy deconvolution steps. Subsequently, a zero-shot optimisation process is employed to integrate the deconvolved features, resulting in a high-quality reconstructed image. By performing the preliminary reconstruction with the classic iterative deconvolution method, we can effectively utilise a smaller network to produce the final image, thus accelerating the reconstruction whilst reducing the demand for valuable computational resources. Our method demonstrates significant improvements in various real-world applications non-blind deconvolution tasks. © 2023 IEEE.","deconvolution; microscopy; self supervised; zero shot","Computer vision; Convolution; Deconvolution; Deep learning; Iterative methods; Large datasets; Medical applications; Restoration; Biomedical applications; Blind deconvolution; Deconvolutions; Features extraction; Ground truth; High quality; Large datasets; Neural architectures; Self supervised; Zero shot; Image reconstruction","Helmholtz Associ-ationunderthejointresearchschool","","Institute of Electrical and Electronics Engineers Inc.",""
"Bechelli S.; Apostal D.; Bergstrom A.","Bechelli, Solene (57195488496); Apostal, David (55795687500); Bergstrom, Aaron (56869103800)","57195488496; 55795687500; 56869103800","The Importance of High Speed Storage in Deep Learning Training","2023","2023-May","","","513","517","4","10.1109/eIT57321.2023.10187241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166739584&doi=10.1109%2feIT57321.2023.10187241&partnerID=40&md5=d2a3a280e3845689c9b68ee79dc3f3bf","With the increase of computational power and techniques over the past decades, the use of Deep Learning (DL) algorithms in the biomedical field has grown significantly. One of the remaining challenges to using deep neural networks is the proper tuning of the model's performance beyond its simple accuracy. Therefore, in this work, we implement the combination of the NVIDIA DALI API for high-speed storage access alongside the TensorFlow framework, applied to the image classification task of skin cancer. To that end, we use the VGG16 model, known to perform accurately on skin cancer classification. We compare the performance between the use of CPU, GPU and multi-GPU devices training both in terms of accuracy and runtime performance. These performances are also evaluated on additional models, as a mean for comparison. Our work shows the high importance of model choice and fine tuning tailored to a particular application. Moreover, we show that the use of high-speed storage considerably increases the performance of DL models, in particular when handling images and large databases which may be a significant improvement for larger databases.  © 2023 IEEE.","application specific storage; cancer application; deep learning; High-speed storage; image clas-sification","Bioinformatics; Convolutional neural networks; Deep neural networks; Graphics processing unit; Image enhancement; Application specific; Application specific storage; Cancer application; Deep learning; High Speed; High-speed storage; Image cla-sification; Performance; Skin cancers; Speed storage; Diseases","National Science Foundation, NSF, (1946202)","","IEEE Computer Society",""
"Hua J.; Zou J.; Rao J.; Yin H.; Chen J.","Hua, Jing (56581206000); Zou, Jiawen (58172546100); Rao, Jue (57556990300); Yin, Hua (56540485200); Chen, Jie (58181422900)","56581206000; 58172546100; 57556990300; 56540485200; 58181422900","ECG Signals Deep Compressive Sensing Framework Based on Multiscale Feature Fusion and SE Block","2023","11","","","104359","104372","13","10.1109/ACCESS.2023.3316487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173037769&doi=10.1109%2fACCESS.2023.3316487&partnerID=40&md5=390420ffd911ce27b0799eca698b59d4","Electrocardiogram (ECG) is nowadays an important technology to be applied in the clinical diagnosis for the detection of the heart disease. But the large storage and high-burden transmission of the ECG data is a challenge. Therefore, the compressive sensing (CS) is appropriate to deal with those signals for it can compress and sample the signal at the same time. In order to get rid of the constraints in the traditional CS methods, we propose a compressive sensing framework based on multiscale feature fusion and SE block. In the compression process we use sequential convolutional layers instead of the traditional compressive sensing using measurement matrix projection for ECG signals. In the reconstruction process, the multi-scale feature fusion method is first used to fuse multiple feature maps output from the convolution layer to better extract signal features. Subsequently, Squeeze-and-Excitation (SE) block is used to further enhance the feature representation. Finally, sequence modeling of the ECG signal is performed using LSTM to obtain the reconstructed signal. The results show that the proposed method performs well on various datasets and evaluation metrics, in the case of SR = 0.4, the PRD and SNR of the experiments on the MIT-BIH Arrhythmia database are 1.55% and 37.66dB, respectively. The PRD and SNR of the experiments on the Non-Invasive Fetal ECG Arrhythmia Database were 2.48% and 34.57dB, respectively, which were the lowest among all the comparison methods, indicating that the proposed method has good ECG signal processing capability.  © 2013 IEEE.","compressive sensing; Deep learning; LSTM; multi-scale feature; SE block","Biomedical signal processing; Compressed sensing; Convolution; Digital storage; Diseases; Feature extraction; Image coding; Image reconstruction; Iterative methods; Long short-term memory; Compressed-Sensing; Compressive sensing; Convolutional neural network; Deep learning; Features detections; Images reconstruction; Iterative algorithm; LSTM; Multi-scale features; Optimisations; Squeeze-and-excitation block; Electrocardiography","National Natural Science Foundation of China, NSFC, (61861021); Natural Science Foundation of Jiangxi Province, (20224BAB202038)","","Institute of Electrical and Electronics Engineers Inc.",""
"Ledwosinski K.; Czapla P.; Kocejko T.; Jo K.-H.","Ledwosinski, Kacper (58693801200); Czapla, Pawel (58694668200); Kocejko, Tomasz (24824292600); Jo, Kang-Hyun (56978116100)","58693801200; 58694668200; 24824292600; 56978116100","Analysis of the Capability of Deep Learning Algorithms for EEG-based Brain-Computer Interface Implementation","2023","","","","","","","10.1109/IWIS58789.2023.10284600","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176560674&doi=10.1109%2fIWIS58789.2023.10284600&partnerID=40&md5=8c26b40c164076b4f9e9083d0e189946","Machine learning models have received significant attention for their exceptional performance in classifying electroencephalography (EEG) data. They have proven to be highly effective in extracting intricate patterns and features from the raw signal data, thereby contributing to their success in EEG classification tasks. In this study, we explore the possibilities of utilizing contemporary machine learning algorithms in decoding brain activity signals for a quick and efficient feature extraction in a potential BCI application. Specifically, the EEG data is associated with movement imagination as well as the state of relaxation. A total of 4 models based on neural networks, with distinct structures, were implemented and evaluated on a proprietary subject-specific dataset: EEGNet, EEG Inception, Spatial-Temporal Tiny Transformer (S3T), DeepConvNet. The experiments resulted in promising prediction accuracy. However, the performance of classifiers was not evaluated for new subjects or different hardware. © 2023 IEEE.","BCI control; EEG classification; EEG-based BCI; Motor imagery; Subject specific BCI","Biomedical signal processing; Brain; Brain computer interface; Classification (of information); Data mining; Deep learning; Electrophysiology; Image classification; Learning algorithms; Learning systems; BCI control; Electroencephalography classification; Electroencephalography-based BCI; Machine learning models; Motor imagery; Performance; Raw signals; Signal data; Subject specific BCI; Subject-specific; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","2nd International Conference on Advances in Information and Communication Technology, ICTA 2023","2023","847 LNNS","","","","","340","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180285725&partnerID=40&md5=836ab3a511902622c753a393c08c69bf","The proceedings contain 35 papers. The special focus in this conference is on Advances in Information and Communication Technology. The topics include: A Real-time Crowd Density Level Detection System; an Architecture for More Fine-Grained Hidden Representation in Named Entity Recognition for Biomedical Texts; application of Deep Learning Methods for Forest Fire Intelligent Image Processing; choosing Data Points to Label for Semi-supervised Learning Based on Neighborhood; classification of Fermentation Levels of Cacao Beans (Theobroma cacao L.) Using Sensing Technology and Neural Networks; DCDynUnet: Deep Supervision Attention Context for Brain Segmentation; enhancing Wildfire Detection Using Semi-supervised Fuzzy Clustering on Satellite Imagery; Evaluating the Performance of Some Deep Learning Model for the Problem of Emotion Recognition Based on EEG Signal; a Novel Arm Bone Fracture Detection Using Deep Learning; feature Reduction for Interpretability of Neuro-Fuzzy Classifier; improved Accuracy of Path System on Creating Intelligence Base; the Vehicle Routing Problem with Drones for Fresh Agricultural Products; ViT-SigNet: Combining Deep CNN and Vision Transformer for Enhanced Signature Verification; combining Local Search and Multi-objective Optimization Algorithm in Signalized Intersection Optimization; Comparative Evaluation of PRR and PODA Methods for Model Order Reduction in Electrical Circuits; data-Driven Narratives: Unleashing the Potential of R for Journalistic Storytelling; dynamic Analysis of Capsubot Model in Liquid Environment by Numerical Method; genetic Programming–A Preliminary Study of Knowledge Transfer in Mutation; improvement of Spectral Clustering Method in Social Network Community Detection; a Systematic Review of Artificial Intelligence in Geographic Information Systems; probable Characteristics of Multi-channel Queuing Systems with “Impatient” and “Patient” Claims.","","","","Nghia P.T.; Thai V.D.; Thuy N.T.; Son L.H.; Huynh V.-N.","Springer Science and Business Media Deutschland GmbH",""
"Kumar R.; Anand V.; Gupta S.; Ganzha M.; Paprzycki M.","Kumar, Rakesh (57203184529); Anand, Vatsala (57197116465); Gupta, Sheifali (57072019200); Ganzha, Maria (8948360500); Paprzycki, Marcin (56216975300)","57203184529; 57197116465; 57072019200; 8948360500; 56216975300","Automatic Identification of Cataract by Analyzing Fundus Images Using VGG19 Model","2023","13830 LNCS","","","135","148","13","10.1007/978-3-031-28350-5_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151045407&doi=10.1007%2f978-3-031-28350-5_11&partnerID=40&md5=d128e66ba4cb5f16ec904b6c85aced3d","Nowadays, cataracts are one of the prevalent eye conditions that may lead to vision loss. Precise and prompt recognition of the cataract is the best method to prevent/treat it in early stages. Artificial intelligence-based cataract detection systems have been considered in multiple studies. There, different deep learning algorithms have been used to recognize the disease. In this context, it has been established that the training time of the VGG19 model is very low, when compared to other Convolutional Neural Networks. Hence, in this research, the VGG19 model, for automatic cataract identification in fundus images, has been proposed for healthy lives. The performance of the VGG19 is explored with four different optimizers, i.e. Adam, AdaDelta, SGD and AdaGrad and tested on a collection of 5000 fundus images. Overall, the best experimental results reached 98% precision of classification. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Biomedical; Cataract; Classification; Convolutional Neural Network; Disease; Transfer learning; VGG19","Automation; Convolution; Deep learning; Image classification; Learning algorithms; Automatic identification; Biomedical; Cataract; Convolutional neural network; Detection system; Eye conditions; Fundus image; Transfer learning; VGG19; Vision loss; Convolutional neural networks","Centre for Priority Research Area Artificial Intelligence and Robotics of Warsaw University of Technology","Sachdeva S.; Watanobe Y.; Bhalla S.","Springer Science and Business Media Deutschland GmbH",""
"Anand V.; Shourie P.","Anand, Vatsala (57197116465); Shourie, Poonam (58246074400)","57197116465; 58246074400","Hemorrhage Classification in Head Computed Tomography Images using Convolution Neural Network Model","2023","","","","","","","10.1109/CISCT57197.2023.10351262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182935075&doi=10.1109%2fCISCT57197.2023.10351262&partnerID=40&md5=079fe59600143260d9e5cf30e78023c2","Head CT - hemorrhage classification refers to the use of deep learning algorithms to automatically classify different types of hemorrhages on CT scans of the head. Hemorrhages in the brain can have serious consequences, and prompt and accurate diagnosis is crucial for proper management and treatment. Traditional methods of diagnosis rely on manual analysis of CT images by radiologists, which can be time-consuming and subject to variability. Therefore, in this research, a deep convolution neural network is presented for the detection of head CT haemorrhage. This algorithm has the potential to improve patient outcomes by enabling faster and more accurate diagnoses, reducing the workload of radiologists, and improving access to healthcare in areas with a shortage of radiologists. The model has obtained the value of accuracy as 0.968. Further research and development are needed to fully realize the potential benefits of this approach and to address challenges such as dataset bias and generalization to new populations.  © 2023 IEEE.","Biomedical; Brain; Computed Tomography (CT); Diseases","Computerized tomography; Convolution; Diagnosis; Image classification; Biomedical; Computed tomography; Computed tomography images; Computed tomography scan; Convolution neural network; Haemorrage; Manual analysis; Neural network model; Potential benefits; Research and development; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Li H.; Liu H.; Wang Y.; Ding M.; Ma X.","Li, Hongli (36679148300); Liu, Haoyu (57952062800); Wang, Youliang (58656254800); Ding, Man (57329395700); Ma, Xin (48561589500)","36679148300; 57952062800; 58656254800; 57329395700; 48561589500","Research on Feature Fusion Based on CNN-LSTM Network for Motion Imagery EEG Classification","2023","","","","3067","3071","4","10.1109/CCDC58219.2023.10327404","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181801915&doi=10.1109%2fCCDC58219.2023.10327404&partnerID=40&md5=2d6a7ae1d37f88f476c2f351eb77b18e","By analyzing the time-domain and spatial domain features of EEG signals, a feature fusion based on CNN-LSTM parallel network for EEG classification is proposed, which realizes feature fusion for different networks and different layers. The parallel network consists of two layers of CNN and one layer of LSTM to decode EEG signals. The CNN network is used to extract the spatial features of signals from different channels, and the LSTM network is used to extract the temporal features of signals, so as to extract the features of original EEG signals from the spatial and temporal domains. At the same time, the features of the intermediate layer of the flatten layer storage network are also used. The classification results can be obtained by fusing at the full connection layer. Public Dataset BCI competition IV-2a are used to verify the proposed algorithm. The Kappa value and average correct rate obtained in Datasets 2a data set reach 0.824 and 87.6% respectively, which are 9.5% and 3.7% higher than those of EEGNet algorithm and higher than the existing base-line classification algorithms. © 2023 IEEE.","convolutional neural network; deep learning; motion imagination; short-term and short-term memory network","Biomedical signal processing; Convolutional neural networks; Digital storage; Image classification; Long short-term memory; Network layers; Convolutional neural network; Deep learning; EEG classification; EEG signals; Features fusions; Memory network; Motion imagination; Short term memory; Short-term and short-term memory network; Spatial domains; Classification (of information)","","","Institute of Electrical and Electronics Engineers Inc.",""
"Wang Y.; Liu L.; Wang C.","Wang, Yanbu (57793267900); Liu, Linqing (57792998700); Wang, Chao (59091368100)","57793267900; 57792998700; 59091368100","Trends in using deep learning algorithms in biomedical prediction systems","2023","17","","1256351","","","","10.3389/fnins.2023.1256351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177679324&doi=10.3389%2ffnins.2023.1256351&partnerID=40&md5=e2adfcc9b12e90f1b5625bc50c6331c6","In the domain of using DL-based methods in medical and healthcare prediction systems, the utilization of state-of-the-art deep learning (DL) methodologies assumes paramount significance. DL has attained remarkable achievements across diverse domains, rendering its efficacy particularly noteworthy in this context. The integration of DL with health and medical prediction systems enables real-time analysis of vast and intricate datasets, yielding insights that significantly enhance healthcare outcomes and operational efficiency in the industry. This comprehensive literature review systematically investigates the latest DL solutions for the challenges encountered in medical healthcare, with a specific emphasis on DL applications in the medical domain. By categorizing cutting-edge DL approaches into distinct categories, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), generative adversarial networks (GANs), long short-term memory (LSTM) models, support vector machine (SVM), and hybrid models, this study delves into their underlying principles, merits, limitations, methodologies, simulation environments, and datasets. Notably, the majority of the scrutinized articles were published in 2022, underscoring the contemporaneous nature of the research. Moreover, this review accentuates the forefront advancements in DL techniques and their practical applications within the realm of medical prediction systems, while simultaneously addressing the challenges that hinder the widespread implementation of DL in image segmentation within the medical healthcare domains. These discerned insights serve as compelling impetuses for future studies aimed at the progressive advancement of using DL-based methods in medical and health prediction systems. The evaluation metrics employed across the reviewed articles encompass a broad spectrum of features, encompassing accuracy, precision, specificity, F-score, adoptability, adaptability, and scalability. Copyright © 2023 Wang, Liu and Wang.","bioinformatics; deep learning; IoT; machine learning; medical informatics","article; benchmarking; bioinformatics; convolutional neural network; deep learning; diagnosis; human; image segmentation; learning algorithm; long short term memory network; machine learning; medical informatics; medical information system; prediction; recurrent neural network; short term memory; simulation; support vector machine","","","Frontiers Media SA",""
"Chevvuri S.T.; Kumar Reddy S V.R.; Nelluru S.T.; Yadlapalli P.","Chevvuri, Swarna Tejaswi (58245599400); Kumar Reddy S, Venkata Rohit (58246070200); Nelluru, Sai Teja (58246070300); Yadlapalli, Priyanka (57193317195)","58245599400; 58246070200; 58246070300; 57193317195","Brain Hemorrhage Detection using Heatmaps and Deep Learning Algorithms","2023","","","","89","94","5","10.1109/ICIDCA56705.2023.10100076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159075221&doi=10.1109%2fICIDCA56705.2023.10100076&partnerID=40&md5=acb464e68abd6c78f9f769da9ee92ea1","Bleeding or an escape of blood from a ruptured blood vessel within the brain tissue or between the adjacent bones is referred to as brain hemorrhage. Therefore, head bleeding can result in a variety of harmful outcomes, particularly brain bleeding. For the patient's life, early and effective assistance by professionals in such situations is crucial. By using VGG19, a type of convolutional neural network models recently used in the biomedical industry, brain hemorrhage computed tomography pictures are classified in this study. To increase the accuracy of the categorization, every image in the given dataset has its heat map extracted in this context. Support vector machines are used in the categorization process. The classification's highest success rate was 96.07% as a consequence. In conclusion, the suggested method helped to categories photos of cerebral hemorrhage.  © 2023 IEEE.","deeplearing; Hemorrhage; Support Vector Machine; Visual Geometry Group","Blood; Blood vessels; Computerized tomography; Convolutional neural networks; Deep learning; Bleedings; Brain tissue; Convolutional neural network; Deeplearing; Haemorrage; Heatmaps; Hemorrhage detection; Neural network model; Support vectors machine; Visual geometry group; Support vector machines","","","Institute of Electrical and Electronics Engineers Inc.",""
"Mydhili S.K.; Venkatesh C.; Amrin Z.; Jaya Dharani M.","Mydhili, S.K. (56441633400); Venkatesh, C. (57224654771); Amrin, Z. (57220892463); Jaya Dharani, M. (58648047900)","56441633400; 57224654771; 57220892463; 58648047900","CNN based Deep Learning for Pneumonia Detection","2023","","","","","","","10.1109/ICoAC59537.2023.10249251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174217558&doi=10.1109%2fICoAC59537.2023.10249251&partnerID=40&md5=b5f5f70e62b5c63246416aaf36b40db8","The role of artificial intelligence in our society is growing, according to recent developments. CNNs, also known as convolutional neural networks, are an artificial intelligence algorithm class used in computer vision and image processing. a future-oriented medical technology with great potential. The capacity to manipulate and examine images could aid in a more accurate diagnosis of medical conditions. This article introduces a lung X-ray image classification model that was developed and evaluated on an 8071 sample of chest x-ray images using the proposed CNN model. Patients fall into one of three categories: those who are healthy, those who have viral or bacterial pneumonia, or both. An investigation into the phenomenon of lung diseases like asthma and covid 19 along with pneumonia detection was conducted as a result of the effects of incorporating data augmentation techniques on the prevention and performance of the model. The precision obtained from the analysis's findings demonstrates an accuracy of 97% detection, and these discoveries hold great promise for the future.  © 2023 IEEE.","CNN; Data Augmentation; Image Classification; Pneumonia","Biological organs; Biomedical engineering; Computer aided diagnosis; Convolutional neural networks; Deep learning; Medical imaging; Artificial intelligence algorithms; Convolutional neural network; Data augmentation; Images classification; Images processing; Medical conditions; Medical technologies; Pneumonia; Vision processing; X-ray image classifications; Image classification","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","Control Instrumentation System Conference, CISCON 2021","2023","957","","","","","523","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151080180&partnerID=40&md5=1d2bba68f80d6f60a40de2d5fa47af3e","The proceedings contain 36 papers. The special focus in this conference is on Control Instrumentation System. The topics include: Maximum Sensitivity-Based PID Controller for a Lab-Scale Batch Reactor; performance Prediction of Solar Cell Using Virtual Production Simulation; Optimisation of FPGA-Based Designs for Convolutional Neural Networks; design and Implementation of an Automated Fuel Station; heart Disease Prediction Using Machine Learning Algorithms; design and Performance Evaluation of a Simple Resistance-to-Digital Converter for Tunneling Magneto-Resistance-Based Angular Position Sensor with 180° Range; The Use of LBP Features in Transform Domain for Object Recognition; design and Simulation of Capacitive Pressure Sensor for Monitoring Lead-Acid Battery Charge; design and Simulation of a Wireless Charging System for Electric Vehicle; development of Screw Press-Dewatering Unit for Biogas Slurry; the Use of Photoplethysmography for Blood Glucose Estimation by Noninvasive Method; single-Stage Stand-Alone Induction Motor Driven Solar Water Pumping System with Minimal Sensors; automation of Weight-Based Sorting System Using Programmable Logic Controllers; design, Development and Verification of a Fault Injection Capable Synchronous Generator; UKF/H-Infinity Filter for Low-Cost Localization in Self-driving Cars; design and Implementation of Efficient IoT-Based Smart Oil Skimmer; comparison of Discrete Time Sliding Manifold and Its Impact on System Dynamics; Volkswagen Emission: An Analysis on the VW Vento Using Automotive Network Data; hand Gesture-Controlled Wheeled Mobile Robot for Prospective Application as Smart Wheelchairs; recent Advances in Sensor Technology for Biomedical Applications: A Review; manual Dexterity Assessment Using a Nine-Hole Pegboard Test; implementation of Indoor Navigation Control for Two-Wheeled Self-balancing Robot; secure Image Classification Using Deep Learning.","","","","Chokkadi S.; Bandyopadhyay R.","Springer Science and Business Media Deutschland GmbH",""
"Mandal A.C.; Phatak A.","Mandal, Aditya Chandra (57224996864); Phatak, Abhijeet (57189728869)","57224996864; 57189728869","Optimizing Deep Learning Based Retinal Diseases Classification On Optical Coherence Tomography Scans","2023","12632","","1263220","","","","10.1117/12.2672249","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172889893&doi=10.1117%2f12.2672249&partnerID=40&md5=00c711b706b20cf20e6973c8389b14a8","Optical Coherence Tomography (OCT) is a widely used medical imaging technique for diagnosing various eye conditions and for assessing the health of the retina and other structures in the eye. As the amount of data generated from OCT scans increases day by day, the need for automated support systems for medical staff becomes more pressing. In this study, we used a computer based diagnostic system for detecting and classifying three retinal diseases (Choroidal Neovascularization (CNV), Drusen, Diabetic Macular Edema (DME)) in OCT B-scans. Our system applies Convolutional Neural Networks (EfficeintNet) and Transfer learning to make accurate predictions of the diseases or healthy eye. Transfer learning, a technique commonly used in deep learning, is implemented to train EfficientNet architectures using a publicly available dataset (OCT2017) of approx 84000 OCT B-scans. EfficientNet models were chosen for their known efficiency in terms of performance and their ability to classify effectively with fewer parameters and lower computational requirements in comparison to other Convolutional Neural Networks (CNN) models. We used EfficeintNet models that were pretrained on ImageNet dataset and fine-tuned the models on our dataset. In order to assess the effectiveness of transfer learning and fine-tuning, we evaluated their performance on an imbalanced multiclass classification task using metrics like F1 Score, Precision, Recall, Accuracy, and Confusion Matrices (CM). The results of our evaluations are presented in the form of CM for each class and model. We tried out various EfficientNet models (B0, B3, B5) as base models utilizing similar data resolution, volume and other hyperparameters, and discovered that larger EfficientNet models did not necessarily lead to better classification performance. We accounted for class imbalance in the data to make our method robust for real-world scenarios. The best result was found to be from lowest complexity model, EfficientNet B0. Our research found that the EfficientNet B0 model demonstrated exceptional performance with a macro average F1 Score of 99.8% and an Accuracy of 99.8%. Additionally, our results also revealed that the EfficientNets B0, B3, B5 models are particularly well-suited for multiclass classification based on highly imbalanced OCT2017 dataset. High classification scores are achieved due to several factors, such as data enhancement, resolution scaling, fine-tuning, and successful transfer learning using ImageNet weights. Based on our preliminary results our approach performs as well or outperforms other known approaches. Our goal is to provide assistance to medical staff in diagnositic process with the help of artificial intelligence (AI) algorithms. Improving the efficiency and accuracy of diagnosis is important in the field of medicine, and the use of AI algorithms such as the one proposed in this research has the potential to make a significant impact in this regard. © 2023 SPIE. All rights reserved.","Biomedical imaging; EfficientNet; Optical Coherence Tomography; Transfer learning","Classification (of information); Computer aided diagnosis; Convolution; Convolutional neural networks; Deep learning; Image enhancement; Learning systems; Medical imaging; Ophthalmology; Transfer learning; B-scans; Biomedical imaging; Convolutional neural network; Efficientnet; F1 scores; Fine tuning; Multi-class classification; Performance; Retinal disease; Transfer learning; Optical tomography","","Vakoc B.J.; Wojtkowski M.; Yasuno Y.","SPIE",""
"Marwala T.; Mongwe W.T.; Mbuvha R.","Marwala, Tshilidzi (6701686531); Mongwe, Wilson Tsakane (57218326724); Mbuvha, Rendani (57200961334)","6701686531; 57218326724; 57200961334","Hamiltonian Monte Carlo Methods in Machine Learning","2023","","","","1","190","189","10.1016/C2021-0-02845-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152815448&doi=10.1016%2fC2021-0-02845-5&partnerID=40&md5=87e7c7e6f57e931ea546f2ba6e1394d9","Hamiltonian Monte Carlo Methods in Machine Learning introduces methods for optimal tuning of HMC parameters, along with an introduction of Shadow and Non-canonical HMC methods with improvements and speedup. Lastly, the authors address the critical issues of variance reduction for parameter estimates of numerous HMC based samplers. The book offers a comprehensive introduction to Hamiltonian Monte Carlo methods and provides a cutting-edge exposition of the current pathologies of HMC-based methods in both tuning, scaling and sampling complex real-world posteriors. These are mainly in the scaling of inference (e.g., Deep Neural Networks), tuning of performance-sensitive sampling parameters and high sample autocorrelation. Other sections provide numerous solutions to potential pitfalls, presenting advanced HMC methods with applications in renewable energy, finance and image classification for biomedical applications. Readers will get acquainted with both HMC sampling theory and algorithm implementation. © 2023 Elsevier Inc. All rights reserved.","","","","","Elsevier",""
"Aggarwal S.; Juneja S.; Rashid J.; Gupta D.; Gupta S.; Kim J.","Aggarwal, Sonam (57224361738); Juneja, Sapna (57210408722); Rashid, Junaid (57203222981); Gupta, Deepali (57208714508); Gupta, Sheifali (57072019200); Kim, Jungeun (56600264800)","57224361738; 57210408722; 57203222981; 57208714508; 57072019200; 56600264800","Protein Subcellular Localization Prediction by Concatenation of Convolutional Blocks for Deep Features Extraction From Microscopic Images","2023","11","","","1057","1073","16","10.1109/ACCESS.2022.3232564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146250862&doi=10.1109%2fACCESS.2022.3232564&partnerID=40&md5=c07546cb43a08edb371f50dd60478f85","Understanding where proteins are located within the cells is essential for proteomics research. Knowledge of protein subcellular location aids in early disease detection and drug targeting treatments. Incorrect localization of proteins can interfere with the functioning of cells and leads to illnesses like cancer. Technological advances have enabled computational methods to detect protein's subcellular location in living organisms. The advent of high-quality microscopy has led to the development of image-based prediction algorithms for protein subcellular localization. Confocal microscopy, which is used by the Human Protein Atlas (HPA), is a great tool for locating proteins. HPA database comprises millions of images which have been procured using confocal microscopy and are annotated with single as well as multi-labels. However, the multi-instance nature of the classification task and the low quality of the images make image-based prediction an extremely difficult problem. There are probably just a few algorithms for automatically predicting protein localization, and most of them are limited to single-label classification. Therefore, it is important to develop a satisfactory automatic multi-label HPA recognition system. The aim of this research is to design a model based on deep learning for automatic recognition system for classifying multi-label HPA. Specifically, a novel Convolutional Neural Network design for classifying protein distribution across 28 subcellular compartments has been presented in this paper. Extensive experiments have been done on the proposed model to achieve the best results for multilabel classification. With the proposed CNN framework as F1-score of 0.77 was achieved which outperformed the latest approaches.  © 2013 IEEE.","biomedical image analysis; convolutional neural network; Deep learning; protein subcellular localization prediction; proteomics","Bioinformatics; Cell engineering; Convolution; Deep neural networks; Diseases; Extraction; Feature extraction; Forecasting; Image processing; Location; Molecular biology; Biomedical image analysis; Convolutional neural network; Deep learning; Features extraction; Location awareness; Protein engineering; Protein subcellular localization prediction; Proteomics; Proteins","Ministry of Education, MOE; Ministry of SMEs and Startups, MSS, (S3033853)","","Institute of Electrical and Electronics Engineers Inc.",""
"Chaitanya M.K.; Sharma L.D.","Chaitanya, M Krishna (57195259859); Sharma, Lakhan Dev (57188567436)","57195259859; 57188567436","Capsule Network for 1-D Biomedical signals: A Review","2023","","","","","","","10.1109/PCEMS58491.2023.10136076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163222255&doi=10.1109%2fPCEMS58491.2023.10136076&partnerID=40&md5=a7332e71559da02607ce8ca05595f1a8","The heartbeat, muscle contractions, and other phys- iological functions are examples of biomedical signal sources. Electrocardiograms (ECG), electroencephalograms (EEG), and electromyograms (EMG) are examples of the signals that can be non-invasively recorded and used for diagnosis and as health in- dicators. Hence, timely and accurate diagnosis of the biomedical signals plays a prominent role. Professional healthcare workers assess the signal in search of a clear pattern that would indicate a normal or abnormal heartbeat is a tedious job. Manual inter- pretation of the signals may lead to misdiagnosis. The automated computer-aided diagnosis (CAD) method is one way to support decision-making for the eradication of these deficiencies. The CAD tool should operate as a real-time system for early diagnosis, requiring little time investment, data dependence, and device- specific measurement variances. Deep learning-based methods are becoming more and more common in CAD techniques. Convolutional neural network (CNN), one of the well-known deep learning network, fail of recognise position, texture, and genetic anomalies in the image. A capsule network is one of the newest and most promising deep learning algorithms that tackles CNN's shortcomings. In this study, we present a thorough analysis of the cutting-edge methodology, tools, and topologies used in current capsule network implementations. The key contribution with this review study is its explanation and summary of major existing Capsule Network implementations and architectures. © 2023 IEEE.","Capsule network; Computer-aided diagnosis; Deep learning; Electrocardiogram; Electroencephalogram; Electromyogram","Bioelectric phenomena; Biomedical signal processing; Computer aided diagnosis; Computer aided instruction; Cutting tools; Decision making; Deep learning; Electroencephalography; Interactive computer systems; Learning algorithms; Learning systems; Real time systems; Textures; Biomedical signal; Capsule network; Decisions makings; Deep learning; Diagnosis methods; Diagnosis tools; Electromyo grams; Healthcare workers; Muscle contractions; Signal source; Electrocardiograms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Hadi M.R.; Hassan A.R.; Mohammed I.H.; Alazzai W.K.; Alzubaidi L.H.; Ai Sadi H.I.","Hadi, Maysam Reyad (58816400800); Hassan, Ahmed R. (57982175600); Mohammed, Ibraheem Hatem (57203679756); Alazzai, Waleed Khalid (58816388700); Alzubaidi, Laith H. (58497808300); Ai Sadi, Hafidh I. (58313572900)","58816400800; 57982175600; 57203679756; 58816388700; 58497808300; 58313572900","Integrated Design of Artificial Neural Network with Bald Eagle Search Optimization for Osteosarcoma Classification","2023","","","","552","558","6","10.1109/IICETA57613.2023.10351254","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182524442&doi=10.1109%2fIICETA57613.2023.10351254&partnerID=40&md5=7940eceef8547adca797ded7c234730f","Osteosarcoma becomes a most leading factor of bone cancer worldwide and results in high death rates. Initial diagnosis might raise survival rate but the process seems to be time-taking (complexity and reliability indulged for extracting the hand-crafted features) and majorly relies on the experience of pathologists. This work mainly concentrates in the enhancement of diagnosis and recognition of osteosarcoma by making use of computer aided diagnosis (CAD) and computer aided detection (CADx). These tools as convolutional neural network (CNN) could reduce the workload of physicians and offer superior prognosis for patient conditions. CNNs must be well-trained on an enormous volume of data for attaining a more promising performance. The study emphasis on the design of bald eagle search optimization with deep transfer learning (DTL) model for osteosarcoma classification (BESODL-OC) algorithm. The projected BESODL-OC methodology scrutinizes the histopathological images (HSI) for the identification of osteosarcoma. To achieve this, the BESODLOC algorithm exploits Gabor filtering (GF) model for noise removal process. Besides, a deep convolutional neural network (DCNN) based Inceptionv3 methodology is exploited for feature extraction process. Since trial and error based hyperparameter tuning process will be a tedious process, the BESO algorithm is utilized in this study. At last, artificial neural network (ANN) method can be exploited for classifying purposes. A wide range of experiments were made to exhibit the improvised outcome of the BESODL-OC system. Wide-ranging comparison analysis demonstrated the enhancements of the BESODL-OC system over other recent approaches.  © 2023 IEEE.","Artificial intelligence; Bald eagle search; Biomedical imaging; Osteosarcoma classification; Transfer learning","Computer aided diagnosis; Convolution; Deep neural networks; Gabor filters; Medical imaging; Transfer learning; Bald eagle search; Bald eagles; Biomedical imaging; Bone cancer; Convolutional neural network; Integrated designs; Osteosarcoma classification; Osteosarcomas; Search optimization; Transfer learning; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Jahir Pasha M.; Sreevani R.; Siri Chandana N.; Sreenidhi M.; Satwika Chowdary T.","Jahir Pasha, M. (57189247597); Sreevani, R. (58564551800); Siri Chandana, N. (58564047600); Sreenidhi, M. (58245728700); Satwika Chowdary, T. (58563793400)","57189247597; 58564551800; 58564047600; 58245728700; 58563793400","Brain Tumour Image Segmentation Using Deep Networks","2023","","","","","","","10.1109/CONIT59222.2023.10205722","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169904981&doi=10.1109%2fCONIT59222.2023.10205722&partnerID=40&md5=bb9794dcbafc55799a8c4bd99102989e","The analyses done on diseases are heavily on the automated segmentation so this is done on brain tumour through image segmentation through MRI images. Due to malignant nature and heterogeneity in the cell tissues, proper intra-tumour classification of tumour requires the application of precise and effective segmentation techniques. Comparing deep learning algorithms to more traditional, context-based computer vision techniques, semantic segmentation challenges show that deep learning algorithms perform better. Space invariant Artificial Neural Networks which are to be a great extent in biomedical sector to bring the perfect output, accuracy in detection of diseases. so in this research we previously owned two types of segmentation networks as 3Dimensional Space invariant Artificial Neural Networks and U-Net in substantial in simple involving combination methods in which they are good and more precise predictions. In addition to assemble partitioning maps that are accordingly mixed from each other regarding to portioned tumour, and both models are skilled separately on the one of the popular dataset known as BraTs. These results are appear like differently to get the final prophesy. In contrast to the most cutting-edge design now on the market, and proposed appear in achieving roll ratings as 0.768, 0.915, and 0.820 for ameliorate the cancerous cells, whole tumour, tumour layer respectively authenticate set.  © 2023 IEEE.","Artificial Neural networks; BraTs; Context-based computer vision; Neural networks; Semantic segmentation","Brain; Computer vision; Deep learning; Learning algorithms; Magnetic resonance imaging; Neural networks; Semantic Web; Semantics; Tumors; Automated segmentation; Brain tumors; Brat; Context-based; Context-based computer vision; Images segmentations; MRI Image; Neural-networks; Semantic segmentation; Tumor images; Semantic Segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Zhang Z.; Sun M.","Zhang, Zhaoguan (58666974900); Sun, Muxin (58668351200)","58666974900; 58668351200","Research on Biomedical Image Segmentation Method Based on Full Convolutional Neural Network","2023","","","","1541","1545","4","10.1109/ICSECE58870.2023.10263584","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175075238&doi=10.1109%2fICSECE58870.2023.10263584&partnerID=40&md5=ddd1c3daef2cf152b0990fb520088087","With the continuous progress of deep learning technology, the application of artificial intelligence in the field of smart medical care has been deepened, and many new artificial intelligence algorithms have been applied to the process of medical diagnosis. At present, computed tomography (CT) is the most commonly used method to examine liver tumors, and tumor resection, intervention and radiation are the main treatment methods. Accurately knowing the size, number and location of tumors before surgery can make a scientific and reasonable surgical plan, which is a necessary condition for successful surgery. Product neural network can learn the features that describe the essence of images, and these features can be better used for classification or reconstruction after nonlinear mapping, so as to deal with different medical tasks. Therefore, this paper conducts segmentation research on cell data set and blood vessel data set. Experiments show that, compared with U-Net and RU Net models, this method only uses nearly 2/3 of the training parameters and achieves better segmentation evaluation performance. Among them, Dice coefficient increases by 0.56% and 1.46%, and Jacob coefficient increases by 0.91% and 1.92%. Therefore, compared with U-Net and RU Net models, This method has higher segmentation performance and better generalization performance.  © 2023 IEEE.","Biomedical science; Full Convolutional Neural Network; Image segmentation","Blood vessels; Computerized tomography; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Medical imaging; Surgery; Tumors; Artificial intelligence algorithms; Biomedical image segmentation; Biomedical science; Convolutional neural network; Data set; Full convolutional neural network; Images segmentations; Learning technology; Net model; Segmentation methods; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Saranya K.; Sumathi S.","Saranya, K. (57212317644); Sumathi, S. (57208201529)","57212317644; 57208201529","OPTIMIZATION ENABLED DEEP LEARNING for STROKE DISEASE PREDICTION from MULTIMODALITIES","2023","","","2350078","","","","10.1142/S0219519423500781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170693445&doi=10.1142%2fS0219519423500781&partnerID=40&md5=8dc2efdbe07c8e85c215b65ff45e123e","Stroke is a disease that is caused due to the blockage and burst in the blood vessels of the brain, thus resulting in abrupt brain dysfunction, like sensory or motor disorders, unconsciousness, limb paralysis, and pronunciation disorders. The existing stroke prediction algorithms have some limitations because of the lengthy testing procedures and hefty testing expenses. The main goal of this study is to develop and implement the proposed fusion-based, optimized deep learning model for stroke disease prediction using multimodalities. For that, this research considers the Computed Tomography (CT) and electroencephalogram (EEG) signals as input, and all of these inputs are processed separately to predict the stroke disease. While predicting the stroke disease with a CT image, the bilateral filter performs the pre-processing and the disease prediction is done with the DenseNet model, which is tuned by the proposed Jaya Fractional Reptile Search Algorithm (Jaya FRSA). Similar to how the proposed FRSA does CNN-LSTM training, the Convolutional Neural Network-Long Short Term Memory (CNN-LSTM) predicts the stroke disease using the EEG data as an input after the Gaussian filter removes signal noise. Additionally, the CT image and the EEG signal are processed independently from the image and signal properties. Additionally, the CNN-LSTM model and DenseNet model results are combined using the overlap coefficient to get the final disease prediction. According to the experimental study, the suggested method achieved the maximum image accuracy, sensitivity, and specificity of 0.924, 0.930, and 0.935.  © 2023 World Scientific Publishing Company.","convolutional neural network; fractional calculus; Jaya algorithm; long short term memory; Reptile search algorithm","Biomedical signal processing; Blood vessels; Brain; Computerized tomography; Convolution; Convolutional neural networks; Electroencephalography; Forecasting; Learning algorithms; Brain dysfunctions; Computed tomography images; Convolutional neural network; Electroencephalogram signals; Fractional calculus; Jaya algorithm; Optimisations; Prediction algorithms; Reptile search algorithm; Search Algorithms; Long short-term memory","","","World Scientific",""
"Guo X.; Li Y.; Chang D.; He P.; Feng P.; Yu H.; Wu W.","Guo, Xiaodong (57209254578); Li, Yonghui (57457343000); Chang, Dingyue (57222570045); He, Peng (55226397500); Feng, Peng (8903298300); Yu, Hengyong (20435223800); Wu, Weiwen (57191421267)","57209254578; 57457343000; 57222570045; 55226397500; 8903298300; 20435223800; 57191421267","Spectral2Spectral: Image-Spectral Similarity Assisted Deep Spectral CT Reconstruction Without Reference","2023","9","","","1031","1042","11","10.1109/TCI.2023.3328278","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177043943&doi=10.1109%2fTCI.2023.3328278&partnerID=40&md5=361ea00f8225de761a254682ccc2df5f","Spectral computed tomography based on a photon-counting detector (PCD) attracts more and more attentions since it has the capability to provide more accurate identification and quantitative analysis for biomedical materials. The limited number of photons within narrow energy bins leads to imaging results of low signal-noise ratio. The existing supervised deep reconstruction networks for CT reconstruction are difficult to address these challenges because it is usually impossible to acquire noise-free clinical images with clear structures as references. In this paper, we propose an iterative deep reconstruction network to synergize unsupervised method and data priors into a unified framework, named as Spectral2Spectral. Our Spectral2Spectral employs an unsupervised deep training strategy to obtain high-quality images from noisy data in an end-to-end fashion. The structural similarity prior within image-spectral domain is refined as a regularization term to further constrain the network training. The weights of neural network are automatically updated to capture image features and structures within the iterative process. Three large-scale preclinical datasets experiments demonstrate that the Spectral2spectral reconstructs better image quality than other the state-of-the-art methods.  © 2015 IEEE.","image reconstruction; iterative reconstruction; neural network; Spectral CT; unsupervised learning","Biomedical engineering; Computerized tomography; Image denoising; Image reconstruction; Iterative methods; Medical imaging; Photons; Computed tomography; CT-reconstruction; Images reconstruction; Iterative reconstruction; Neural-networks; Noise measurements; Reconstruction algorithms; Spectral CT; Noise abatement","National Natural Science Foundation of China, NSFC, (62201628); Natural Science Foundation of Chongqing Municipality, (CSTB2022NSCQ-MSX0360); National Key Research and Development Program of China, NKRDPC, (2022YFA1204201); Basic and Applied Basic Research Foundation of Guangdong Province, (2023A1515011780)","","Institute of Electrical and Electronics Engineers Inc.",""
"Sharma D.; Mishra I.; Parepalli R.; Jayanth S.","Sharma, Divya (57651690800); Mishra, Ishani (36617800000); Parepalli, Ramanamma (57638406500); Jayanth, S. (58026977400)","57651690800; 36617800000; 57638406500; 58026977400","Biomedical Image Classification Using Convolutional Neural Networks","2023","","","","840","845","5","10.1109/IITCEE57236.2023.10091043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156149562&doi=10.1109%2fIITCEE57236.2023.10091043&partnerID=40&md5=76390918fdf10c493f64a39a5fb8f272","Recent research trends in the field image processing have focussed on challenges and few techniques for processing and classification tasks related to it. Image classification aims at classifying images based on several predefined categories. Several research works have been carried out to overcome shortcomings in image classification, nevertheless the output was restricted to the elementary low-level picture. Several deep neural network techniques are employed for image classification such as Convolutional Neural Network, Machine Learning Algorithms like Random Forest, SVM, etc. In this paper, we aim at designing a COVID-19 detection using the CNN model with support of Open-Source software such as Keras, Python, Google Colab, Google Drive, Kaggle, and Visual Studio for aggregate, design, create, train, visualize, and analyze bulk load of data on the cloud after programing a Deep neural network without a need for high-end processing hardware. We have made use of weights to test and analyse the accuracy, visualize and predict the condition of a lung using chest X-Rays at certain accuracy. This will help in identifying the problems of the patients at a faster rate, thus giving an appropriate treatment at an early stage itself to saving one life.  © 2023 IEEE.","Convolutional Neural Network (CNN); Covid-19 detector; Google Colab; Kaggle; Keras API; Modelling","Convolution; Deep neural networks; Digital storage; Image classification; Learning algorithms; Medical imaging; Open source software; Open systems; Patient treatment; Support vector machines; Biomedical images; Convolutional neural network; Covid-19 detector; Google colab; Google+; Images classification; Kaggle; Keras API; Modeling; Convolutional neural networks","","Niranjan S.K.; Vijaya P.A.; Munavalli J.R.; S B.; Shirur Y.M.","Institute of Electrical and Electronics Engineers Inc.",""
"Xia Y.; Dong J.; Li D.; Li K.; Nan J.; Xu R.","Xia, Yongquan (24831338200); Dong, Jianhua (57889976500); Li, Duan (57194348234); Li, Keyun (58114405300); Nan, Jiaofen (54411076800); Xu, Ruyun (58304287800)","24831338200; 57889976500; 57194348234; 58114405300; 54411076800; 58304287800","An Adaptive Channel Selection and Graph ResNet Based Algorithm for Motor Imagery Classification","2023","14","5","","240","248","8","10.14569/IJACSA.2023.0140525","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161243889&doi=10.14569%2fIJACSA.2023.0140525&partnerID=40&md5=1dacf415f692471a7a6e82103f83c402","In Brain-Computer interface (BCI) applications, achieving accurate control relies heavily on the classification accuracy and efficiency of motor imagery electroencephalogram (EEG) signals. However, factors such as mutual interference between multi-channel signals, inter-individual variability, and noise interference in the channels pose challenges to motor imagery EEG signal classification. To address these problems, this paper proposes an Adaptive Channel Selection algorithm aimed at optimizing classification accuracy and Information Translate Rate (ITR). First, C3, C4, and Cz are selected as key channels based on neurophysiological evidence and extensive experimental studies. Next, the channel selection is fine-tuned using spatial location and absolute Pearson correlation coefficients. By analyzing the relationship between EEG channels and key channels, the most relevant channel combination is determined for each subject, reducing confounding information and improving classification accuracy. To validate the method, the SHU Dataset and the PhysioNet Dataset are used in experiments. The Graph ResNet classification model is employed to extract features from the selected channel combinations using deep learning techniques. Experimental results show that the average classification accuracy is improved by 5.36% and 9.19%, and the Information Translate Rate is improved by 29.24% and 26.75%, respectively, compared to a single channel combination. © 2023, International Journal of Advanced Computer Science and Applications.All Rights Reserved.","Brain-Computer Interface; channel selection; deep learning; graph convolutional neural network; motor imagery","Biomedical signal processing; Brain computer interface; Classification (of information); Convolutional neural networks; Correlation methods; Deep learning; Image classification; Image enhancement; Learning systems; Adaptive channel selection; Brain-computer interface applications; Channel selection; Classification accuracy; Convolutional neural network; Deep learning; Electroencephalogram signals; Graph convolutional neural network; Motor imagery; Motor imagery classification; Electroencephalography","","","Science and Information Organization",""
"Mahmood T.; Rehman A.; Saba T.; Nadeem L.; Bahaj S.A.O.","Mahmood, Tariq (57208210697); Rehman, Amjad (35093155800); Saba, Tanzila (36110026100); Nadeem, Lubna (57207679320); Bahaj, Saeed Ali Omer (58835236700)","57208210697; 35093155800; 36110026100; 57207679320; 58835236700","Recent Advancements and Future Prospects in Active Deep Learning for Medical Image Segmentation and Classification","2023","11","","","113623","113652","29","10.1109/ACCESS.2023.3313977","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171527945&doi=10.1109%2fACCESS.2023.3313977&partnerID=40&md5=12f0c62eeb2deefbe7e976ca9c756205","Medical images are helpful for the diagnosis, treatment, and evaluation of diseases. Precise medical image segmentation improves diagnosis and decision-making, aiding intelligent medical services for better disease management and recovery. Due to the unique nature of medical images, image segmentation algorithms based on deep learning face problems such as sample imbalance, edge blur, false positives, and false negatives. In view of these problems, researchers primarily improve the network structure but rarely improve from the unstructured aspect. The paper tackles these challenges, accentuating the limitations of deep convolutional neural network-based methods and proposing solutions to reduce annotation costs, particularly in complex images, and introduces the improvement strategies to solve the problems of sample imbalance, edge blur, false positives, and false negatives. Additionally, the article introduces the latest deep learning-based applications in medical image analysis, covering segmentation, image acquisition, enhancement, registration, and classification. Moreover, the article provides an overview of four cutting-edge deep learning models, namely convolutional neural network (CNN), deep belief network (DBN), stacked autoencoder (SAE), and recurrent neural network (RNN). The study selection involved searching benchmark academic databases, collecting relevant literature and appropriate indicator for analysis, emphasizing DL-based segmentation and classification approaches, and evaluating performance metrics. The research highlights clinicians' and scholars' obstacles in developing an efficient and accurate malignancy prognostic framework based on state-of-the-art deep-learning algorithms. Furthermore, future perspectives are explored to overcome challenges and advance the field of medical image analysis.  © 2013 IEEE.","artificial intelligence; beast cancer; deep learning; image segmentation; Medical imaging","Benchmarking; Classification (of information); Convolution; Decision making; Deep neural networks; Diseases; Image analysis; Image enhancement; Learning algorithms; Medical imaging; Problem solving; Recurrent neural networks; Beast cancer; Biomedical imaging; Deep learning; Image-analysis; Images segmentations; Medical diagnostic imaging; Medical image segmentation; Solid modelling; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Rauf F.; Khan M.A.; Bashir A.K.; Jabeen K.; Hamza A.; Alzahrani A.I.; Alalwan N.; Masood A.","Rauf, Fatima (58798832600); Khan, Muhammad Attique (57222652080); Bashir, Ali Kashif (57193954653); Jabeen, Kiran (57416151900); Hamza, Ameer (57617681000); Alzahrani, Ahmed Ibrahim (54912750300); Alalwan, Nasser (35309472000); Masood, Anum (57213374479)","58798832600; 57222652080; 57193954653; 57416151900; 57617681000; 54912750300; 35309472000; 57213374479","Automated deep bottleneck residual 82-layered architecture with Bayesian optimization for the classification of brain and common maternal fetal ultrasound planes","2023","10","","1330218","","","","10.3389/fmed.2023.1330218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181714329&doi=10.3389%2ffmed.2023.1330218&partnerID=40&md5=e3bd2e89476e444197894059b3225677","Despite a worldwide decline in maternal mortality over the past two decades, a significant gap persists between low- and high-income countries, with 94% of maternal mortality concentrated in low and middle-income nations. Ultrasound serves as a prevalent diagnostic tool in prenatal care for monitoring fetal growth and development. Nevertheless, acquiring standard fetal ultrasound planes with accurate anatomical structures proves challenging and time-intensive, even for skilled sonographers. Therefore, for determining common maternal fetuses from ultrasound images, an automated computer-aided diagnostic (CAD) system is required. A new residual bottleneck mechanism-based deep learning architecture has been proposed that includes 82 layers deep. The proposed architecture has added three residual blocks, each including two highway paths and one skip connection. In addition, a convolutional layer has been added of size 3 × 3 before each residual block. In the training process, several hyper parameters have been initialized using Bayesian optimization (BO) rather than manual initialization. Deep features are extracted from the average pooling layer and performed the classification. In the classification process, an increase occurred in the computational time; therefore, we proposed an improved search-based moth flame optimization algorithm for optimal feature selection. The data is then classified using neural network classifiers based on the selected features. The experimental phase involved the analysis of ultrasound images, specifically focusing on fetal brain and common maternal fetal images. The proposed method achieved 78.5% and 79.4% accuracy for brain fetal planes and common maternal fetal planes. Comparison with several pre-trained neural nets and state-of-the-art (SOTA) optimization algorithms shows improved accuracy. Copyright © 2023 Rauf, Khan, Bashir, Jabeen, Hamza, Alzahrani, Alalwan and Masood.","biomedical imaging; bottleneck layers; deep learning; maternal fetal; optimization; residual architecture","Article; Bayes theorem; classification algorithm; classifier; computer assisted diagnosis; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; disease classification; false negative result; false positive result; feature extraction; feature selection; female; fetus; fetus brain; fetus echography; human; intermethod comparison; k fold cross validation; residual neural network; sensitivity and specificity","King Saud University, KSU","","Frontiers Media SA",""
"Shankar A.; Chakraborty D.; Saikia M.J.; Dandapat S.; Barma S.","Shankar, Anand (57218874213); Chakraborty, Debaleena (59029835700); Saikia, Manob Jyoti (56046733400); Dandapat, Samarendra (15922221700); Barma, Shovan (55787081200)","57218874213; 59029835700; 56046733400; 15922221700; 55787081200","Seizure Type Detection Using EEG Signals Based on Phase Synchronization and Deep Learning","2023","","","","","","","10.1109/BSN58485.2023.10331565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181588865&doi=10.1109%2fBSN58485.2023.10331565&partnerID=40&md5=a5aecf3ea736e22d8b97ee356bcb2236","Epileptic seizure occurs due to the intricate reorganization of neural networks in the brain that can be identified by using Electroencephalogram (EEG) signals. Several attempts have been made at its automatic detection by involving several machine learning algorithms, but fewer efforts have been made at the discrimination of its types. Eventually, accurate identification of different types of seizures can play an important role in clinical care, diagnosis, and preference for propitious drugs. However, its discrimination is very challenging due to indiscernible variation and distinct preeminent synchronization among them. Meanwhile, deep learning (DL), that automatically identifies feature vectors from input, has shown notable performance in image classification and could be suitable. However, its effective performance relies on how the 2D images are generated from 1D EEG followed by its feeding in the DL pipeline. Certainly, during a seizure, significant changes in phase synchronization among EEG channels can be observed, which can be exploited in the discrimination of seizure types. Therefore, in this work, 2D images were generated based on a phase synchronization matrix by measuring mean phase coherence among each pair of common EEG channels and fed into a convolution neural network (CNN) to classify three seizure types (absence, complex partial, and myoclonic seizures). For validation, an EEG dataset from the Temple University Hospital was used. The classification performance was evaluated in terms of accuracy, sensitivity, specificity, and weighted F1-score which reached up to 83.30%, 91.43%, 82.90%, and 83.03% respectively, which is significantly high. Further, through a 5-fold cross-validation, the proposed method shows its robustness. © 2023 IEEE.","Convolution neural network; deep learning; electroencephalogram; phase synchronization; seizure types","Biomedical signal processing; Convolution; Deep learning; Learning algorithms; Synchronization; 2D images; Automatic Detection; Convolution neural network; Deep learning; Electroencephalogram signals; Epileptic seizures; Neural-networks; Phase synchronization; Reorganisation; Seizure type; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Ponraj A.; Canessane R.A.","Ponraj, Anitha (57204631663); Canessane, R. Aroul (57074163800)","57204631663; 57074163800","Generative adversarial networks with modified wasp swarm algorithm-based early-stage breast cancer detection techniques","2023","","","","","","","10.1007/s00500-023-08332-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159341240&doi=10.1007%2fs00500-023-08332-4&partnerID=40&md5=2d0a0366e89a3e90270151acc78b324b","Breast cancer is a common health concern among women, with one in every eight deaths. Many women dismiss the need for a breast cancer diagnosis due to the risk of being exposed to radioactive rays. Non-invasiveness, hazardous radiation, and a lack of tumor selectivity are problems with breast cancer screening approaches. Breast cancer must be detected as soon as possible. Breast cancer, as we all know, accounts for around 24.8% of all female tumors worldwide, with over 1.68 million new cases identified in 2012. Mammography, radiography scans and biopsies are treatments used to investigate this cancer adequately. Mammography is a breast X-ray examination. Deep learning (DL), a subfield of machine learning (ML), has delivered exceptional results in a variety of industries, particularly the biomedical one, due to its capacity to manage vast volumes of data. To extract features, deep learning algorithms efficiently analyze high-dimensional and connected data. Additionally, DL models have been implemented and successfully tested for the diagnosis and prognosis of BC utilizing histo-pathological and radiographic data. A range of medical issues are resolved using ML, transfer knowledge, and DL, methodologies. To identify breast cancer at an early stage, a special generative adversarial network using breast mammography data and a modified wasp swarm algorithm (MWSA) is being created. Following breast mammography image training, a linear spatial filter (LSP) is created to pre-process noisy mammography image data. Breast cancer images were subjected to background removal and picture restoration using the LSP filter. Furthermore, compared to earlier models, the suggested model GSN-MWSA provides the highest precision and performance. The proposed method for finding and classifying breast cancer gives more accurate and efficient results. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Breast cancer; Breast cancer detection; Deep learning (DL); Linear spatial filter (LSP); Machine learning (ML); Neural network; Transfer learning (TL)","Beamforming; Deep learning; Diseases; Learning algorithms; Learning systems; Medical imaging; Neural networks; Tumors; X ray radiography; Breast Cancer; Breast cancer detection; Deep learning; Linear spatial filter; Machine learning; Machine-learning; Neural-networks; Spatial filters; Transfer learning; Generative adversarial networks","","","Springer Science and Business Media Deutschland GmbH",""
"Jaganathan S.; Kukla M.; Wang J.; Shetty K.; Maier A.","Jaganathan, Srikrishna (57222252904); Kukla, Maximilian (57952389400); Wang, Jian (55861629900); Shetty, Karthik (57222258475); Maier, Andreas (23392966100)","57222252904; 57952389400; 55861629900; 57222258475; 23392966100","Self-Supervised 2D/3D Registration for X-Ray to CT Image Fusion","2023","","","","2787","2797","10","10.1109/WACV56688.2023.00281","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149010887&doi=10.1109%2fWACV56688.2023.00281&partnerID=40&md5=4961eb29671da59e91ef81d4402b55e1","Deep Learning-based 2D/3D registration enables fast, robust, and accurate X-ray to CT image fusion when large annotated paired datasets are available for training. However, the need for paired CT volume and X-ray images with ground truth registration limits the applicability in interventional scenarios. An alternative is to use simulated X-ray projections from CT volumes, thus removing the need for paired annotated datasets. Deep Neural Networks trained exclusively on simulated X-ray projections can perform significantly worse on real X-ray images due to the domain gap. We propose a self-supervised 2D/3D registration framework combining simulated training with unsupervised feature and pixel space domain adaptation to overcome the domain gap and eliminate the need for paired annotated datasets. Our framework achieves a registration accuracy of 1.83 ± 1.16 mm with a high success ratio of 90.1% on real X-ray images showing a 23.9% increase in success ratio compared to reference annotation-free algorithms. © 2023 IEEE.","and algorithms (including transfer, low-shot, semi-, self-, and un-supervised learning); Applications: Biomedical/healthcare/medicine; formulations; Machine learning architectures","Bioinformatics; Computerized tomography; Deep neural networks; Large dataset; Medical imaging; 2-D-3-D registration; And algorithm (including transfer, low-shot, semi-, self-, and un-supervised learning); Application: biomedical/healthcare/medicine; CT Image; Formulation; Learning architectures; Machine learning architecture; Machine-learning; Un-supervised learning; X-ray image; Image fusion","","","Institute of Electrical and Electronics Engineers Inc.",""
"Roni N.A.; Hossain M.S.; Hossain M.B.; Efat M.I.A.; Yousuf M.A.","Roni, Nasim Ahmed (58144168100); Hossain, Md. Shazzad (57215326863); Hossain, Musarrat Bintay (58475136200); Efat, Md. Iftekharul Alam (55842773500); Yousuf, Mohammad Abu (57188663159)","58144168100; 57215326863; 58475136200; 55842773500; 57188663159","Deep Convolutional Comparison Architecture for Breast Cancer Binary Classification","2023","490 LNICST","","","187","200","13","10.1007/978-3-031-34619-4_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164157511&doi=10.1007%2f978-3-031-34619-4_16&partnerID=40&md5=d949ad53503dec1ea7e71b7230effc17","Early discernment of breast cancer can significantly improve the prospect of successful recovery and survival, but it takes a lot of time that frequently leads to pathologists disagreeing. Recently, much research has tried to develop the best breast cancer classification models to help pathologists make more precise diagnoses. Consequently, convolutional networks are prominent in biomedical imaging because they discover significant features and automate image processing. Knowing which CNN models are optimal for breast cancer binary classification is crucial. This work proposed architecture for finding the best CNN model. Inception-V3, ResNet-50, VGG-16, VGG- 19, DenseNet-121, DenseNet-169, DenseNet-201, and Xception are analyzed as classifiers in this paper. We have examined these deep learning techniques on the breast ultra-sound image dataset. Due to limited data, a generative adversarial network is used to improve the algorithm’s precision. Several statistical analyses are used to determine the finest convolutional technique for premature breast cancer detection using improved images in binary class scenarios. This binary classification experiment evaluates each strategy across various dimensions to determine what aspects improve success. In both normalized and denormalized conditions, the Xception maintained 95% accuracy. Xception uses the complete knowledge-digging technique and is highly advanced. Therefore, the accuracy is considered to be better than that of others. © 2023, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Binary Classification; Breast Cancer; Convolutional Network; Data Augmentation; Generative Adversarial Network; Xception","Classification (of information); Convolution; Convolutional neural networks; Deep learning; Diseases; Image enhancement; Learning systems; Medical imaging; Network architecture; Binary classification; Biomedical imaging; Breast Cancer; Breast cancer classifications; Classification models; CNN models; Convolutional networks; Data augmentation; Images processing; Xception; Generative adversarial networks","","Satu M.S.; Moni M.A.; Kaiser M.S.; Arefin M.S.; Arefin M.S.","Springer Science and Business Media Deutschland GmbH",""
"Schilling M.P.; Klinger L.; Schumacher U.; Schmelzer S.; López M.B.; Nestler B.; Reischl M.","Schilling, Marcel P. (57221699120); Klinger, Lukas (58037215400); Schumacher, Ulrike (58761510100); Schmelzer, Svenja (57387344000); López, Miguel Bordallo (20336637500); Nestler, Britta (6701382692); Reischl, Markus (6602490688)","57221699120; 58037215400; 58761510100; 57387344000; 20336637500; 6701382692; 6602490688","AI2Seg: A Method and Tool for AI-based Annotation Inspection of Biomedical Instance Segmentation Datasets","2023","","","","","","","10.1109/EMBC40787.2023.10341074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179642678&doi=10.1109%2fEMBC40787.2023.10341074&partnerID=40&md5=8061905a31545f00b8b8a67c520916ae","In biomedical engineering, deep neural networks are commonly used for the diagnosis and assessment of diseases through the interpretation of medical images. The effectiveness of these networks relies heavily on the availability of annotated datasets for training. However, obtaining noise-free and consistent annotations from experts, such as pathologists, radiologists, and biologists, remains a significant challenge. One common task in clinical practice and biological imaging applications is instance segmentation. Though, there is currently a lack of methods and open-source tools for the automated inspection of biomedical instance segmentation datasets concerning noisy annotations. To address this issue, we propose a novel deep learning-based approach for inspecting noisy annotations and provide an accompanying software implementation, AI2Seg, to facilitate its use by domain experts. The performance of the proposed algorithm is demonstrated on the medical MoNuSeg dataset and the biological LIVECell dataset. © 2023 IEEE.","","Algorithms; Bioengineering; Biomedical Engineering; Health Personnel; Humans; Neural Networks, Computer; Bioinformatics; Computer vision; Deep neural networks; Diagnosis; Medical imaging; Open source software; Annotated datasets; Automated inspection; Biological imaging; Clinical practices; Domain experts; Imaging applications; Learning-based approach; Open source tools; Performance; Software implementation; algorithm; artificial neural network; bioengineering; biomedical engineering; health care personnel; human; Inspection","Ministry of Science, Research","","Institute of Electrical and Electronics Engineers Inc.","38083322"
"Fan Z.; Xi X.; Gao Y.; Wang T.; Fang F.; Houston M.; Zhang Y.; Li L.; Lu Z.","Fan, Zhuyao (57477422700); Xi, Xugang (57209638494); Gao, Yunyuan (18041796400); Wang, Ting (57221634884); Fang, Feng (57209173303); Houston, Michael (57209181929); Zhang, Yingchun (36452572400); Li, Lihua (55616748400); Lu, Zhong (57214079114)","57477422700; 57209638494; 18041796400; 57221634884; 57209173303; 57209181929; 36452572400; 55616748400; 57214079114","Joint Filter-Band-Combination and Multi-View CNN for Electroencephalogram Decoding","2023","31","","","2101","2110","9","10.1109/TNSRE.2023.3269055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153794108&doi=10.1109%2fTNSRE.2023.3269055&partnerID=40&md5=dfab014ce33a20058faa1fb3941dea1d","Motor imagery (MI) electroencephalogram (EEG) signals have an important role in brain-computer interface (BCI) research. However, effectively decoding these signals remains a problem to be solved. Traditional EEG signal decoding algorithms rely on parameter design to extract features, whereas deep learning algorithms represented by convolution neural network (CNN) can automatically extract features, which is more suitable for BCI applications. However, when EEG data is taken as input in raw time series, traditional 1D-CNNs are unable to acquire both frequency domain and channel association information. To solve this problem, this study proposes a novel algorithm by inserting two modules into CNN. One is the Filter Band Combination (FBC) Module, which preserves as many frequency domain features as possible while maintaining the time domain characteristics of EEG. Another module is Multi-View structure that can extract features from the output of FBC module. To prevent over fitting, we used a cosine annealing algorithm with restart strategy to update the learning rate. The proposed algorithm was validated on the BCI competition dataset and the experiment dataset, using accuracy, standard deviation, and kappa coefficient. Compared with traditional decoding algorithms, our proposed algorithm achieved an improvement of the maximum average correct rate of 6.6% on the motion imagery 4-classes recognition mission and 11.3% on the 2-classes classification task.  © 2001-2011 IEEE.","brain-computer interface; convolutional neural networks; Electroencephalogram; motor imagery","Algorithms; Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Neural Networks, Computer; Biomedical signal processing; Classification (of information); Convolution; Decoding; Deep learning; Electroencephalography; Electrophysiology; Frequency domain analysis; Image classification; Image enhancement; Interfaces (computer); Learning algorithms; Neural networks; Time domain analysis; Band combinations; Classification algorithm; Convolution neural network; Convolutional neural network; Decoding; Features extraction; Kernel; Motor imagery; Multi-views; algorithm; Article; artificial neural network; clinical article; controlled study; convolutional neural network; data analysis; electroencephalogram; feature extraction; human; human experiment; imagery; joint approximate diagonalization of eigenmatrix; measurement accuracy; runica algorithm; second order blind identification algorithm; electroencephalography; imagination; Brain computer interface","","","Institute of Electrical and Electronics Engineers Inc.","37083516"
"Pasha M.D.A.; Narayana M.","Pasha, Md Azam (58582483200); Narayana, M. (57197608792)","58582483200; 57197608792","Development of Trio Optimal Feature Extraction Model for Attention-Based Adaptive Weighted RNN-Based Lung and Colon Cancer Detection Framework Using Histopathological Images","2023","","","2550027","","","","10.1142/S0219467825500275","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172312772&doi=10.1142%2fS0219467825500275&partnerID=40&md5=c7d4aec90519e360d8c0010252f759e9","Due to the combination of genetic diseases as well as a variety of biomedical abnormalities, the fatal disease named cancer is caused. Colon and lung cancer are regarded as the two leading diseases for disability and death. The most significant component for demonstrating the best course of action is the histopathological identification of such malignancies. So, in order to minimize the mortality rate caused by cancer, there is a need for early detection of the aliment on both fronts accordingly. In this case, both the deep and machine learning techniques have been utilized to speed up the detection process of cancer which may also help the researchers to study a huge amount of patients over a short period and less loss. Hence, it is highly essential to design a new lung and colon detection model based on deep learning approaches. Initially, a different set of histopathological images is collected from benchmark resources to perform effective analysis. Then, to attain the first set of features, the collected image is offered to the dilated net for attaining deep image features with the help of the Visual Geometry Group (VGG16) and Residual Neural Network (ResNet). Further, the second set of features is attained by the below process. Here, the collected image is given to pre-processing phase and the image is pre-pre-processed with the help of Contrast-limited Adaptive Histogram Equalization (CLAHE) and filter technique. Then, the pre-processed image is offered to the segmentation phase with the help of adaptive binary thresholding and offered to a dilated network that holds VGG16 and ResNet and attained the second set of features. The parameters of adaptive binary thresholding are tuned with the help of a developed hybrid approach called Sand Cat swarm JAya Optimization (SC-JAO) via Sand Cat swarm Optimization (SCO) and JAYA (SC-JAO). Finally, the third set of features is attained by offering the image to pre-processing phase. Then, the pre-processed image is offered to the segmentation phase and the image is a segmented phase and features are tuned by developed SC-JAO. Further, the segmented features are offered to attain the textural features like Gray-Level Co-Occurrence Matrix (GLCM) and Local Weber Pattern (LWP) and attained the third set of features. Then, the attained three different sets of features are given to the optimal weighted feature phase, where the parameters are optimized by the SC-JAO algorithm and then given to the disease prediction phase. Here, disease prediction is made with the help of Attention-based Adaptive Weighted Recurrent Neural Networks (AAW-RNN), and their parameters are tuned by developed SC-JAO. Thus, the developed model achieved an effective lung and colon detection rate over conventional approaches over multiple experimental analyses. © 2025 World Scientific Publishing Company.","adaptive binary thresholding; attention-based adaptive weighted recurrent neural network; histopathological images; Lung and colon cancer detection; optimal fused feature selection; Sand Cat swarm JAya Optimization","","","","World Scientific",""
"Vasundhara N.; Nandan A.S.; Hemanth S.V.; MacHerla S.; Madhura G.K.","Vasundhara, N. (58237745200); Nandan, Archana S (57211289388); Hemanth, S.V. (56586002200); MacHerla, Sivudu (58236539200); Madhura, G.K. (57224616202)","58237745200; 57211289388; 56586002200; 58236539200; 57224616202","An Efficient Biomedical Solicitation in Liver Cancer Classification by Deep Learning Approach","2023","","","","","","","10.1109/ICICACS57338.2023.10099828","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158141475&doi=10.1109%2fICICACS57338.2023.10099828&partnerID=40&md5=6bc8f7b9cb660f3043daa4c0297369c8","The liver, a significant physical organ, is located in the upper right and left abdominal cavities just below the diaphragm. It produces several different chemicals that the body needs to function properly. Researchers can benefit from converting images into data to more easily exchange and generate precise results. Since the process of conversion relies on technology and an algorithm, it eliminates the possibility of human error. Liver cancer has the highest fatality rate of any cancer since its symptoms don't present until late in the disease's progression, making early detection difficult. Skimming, sifting, segmenting, feature abstraction, and presentation via ANN (Artificial Neural Network) are the primary topics of the first stage of the debate. Real-time data sets use Feed-Forward Neural Network (FFNN) for identifying liver cancer and classifying its severity. Filtering has two primary applications: noise suppression and edge rounding. Then, segmentation is employed to isolate the relevant area, allowing for more compact data storage. The Gray Level and Co-occurrence Matrix (GLCM) is used to extract features, and the resulting matrix can have many different forms. This criterion helps classify tumors as benign or malignant. Metrics such as accuracy, sensitivity, positive and negative predictive values, and precision are used to assess the rate. The experimental method for identifying liver tumors uses CT liver pictures to achieve an average accuracy of 99.45% for malignant images. © 2023 IEEE.","ANN; CT scan; GLCM; Liver cancer","Classification (of information); Deep learning; Digital storage; Diseases; Feedforward neural networks; Matrix algebra; Tumors; Abdominal cavity; Cancer classification; Cooccurrence matrixes (COM); CT-scan; Fatality rates; Gray level and co-occurrence matrix; Gray-level; Human errors; Learning approach; Liver cancers; Computerized tomography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Habib G.; Qureshi S.","Habib, Gousia (57221589277); Qureshi, Shaima (26325864200)","57221589277; 26325864200","Compressed lightweight deep learning models for resource-constrained Internet of things devices in the healthcare sector","2023","","","","","","","10.1111/exsy.13269","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150632978&doi=10.1111%2fexsy.13269&partnerID=40&md5=98df5bbde753379f963657f0054f5de0","The performance of convolutional neural networks (CNNs) in image classification and object detection has been remarkable, even though they contain millions and billions of parameters. This over-parameterization of CNN makes them both memory-intensive and computationally complex and exhaustive. This greatly hinders the application of CNNs in resource-constrained environments such as Internet of things (IoT) and edge devices. This poses a critical challenge for CNNs in deploying these powerful computer vision tools to mobile devices, which needs immediate attention. In this study, we have proposed a novel technique based on non-convex optimization, max-norm regularization. The max-norm will structurally prune the number of parameters without compromising the model's performance. The proximal gradient descent algorithm is used for network optimization while using this non-convex regularizer. The max-norm is combined with the channel pruning to achieve more sparse CNN networks. Later, the pruned network can be easily deployed in the resource-constrained application environment. The proposed technique is tested on several benchmark datasets for validation. In addition, in this study, the sparsified CNNs are used for biomedical image analysis using the BRAIN MRI dataset. This sparsely trained CNN model can later serve as the best lightweight model applicable in the IoT healthcare sector for detecting and classifying three types of brain tumours, one of the most life-threatening diseases whose early detection can save the costly lives of human beings. This is the first paper to propose the novel max-norm regularizer to enforce sparse learning through CNNs. The paper provides a detailed analysis of convex and non-convex regularizers before presenting the proposed novel max-norm regularizer. Finally, the paper compares the proposed max-norm regularizer with existing regularization methods using state-of-the-art CNN models. © 2023 John Wiley & Sons Ltd.","CNN; FLOPS; infinity norm; max-norm; NLP; regularization; VGG-19; weight pruning","Convex optimization; Convolutional neural networks; Deep learning; Gradient methods; Health care; Magnetic resonance imaging; Object detection; Convolutional neural network; FLOPS; Healthcare sectors; Infinity norm; Max-norms; Neural network model; Regularisation; Regularizer; VGG-19; Weight pruning; Internet of things","","","John Wiley and Sons Inc",""
"Rahman M.M.; Marculescu R.","Rahman, Md Mostafijur (57204151210); Marculescu, Radu (35555100900)","57204151210; 35555100900","Medical Image Segmentation via Cascaded Attention Decoding","2023","","","","6211","6220","9","10.1109/WACV56688.2023.00616","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149039273&doi=10.1109%2fWACV56688.2023.00616&partnerID=40&md5=66d9e17648f5be781ab339e8563ef1e3","Transformers have shown great promise in medical image segmentation due to their ability to capture long-range dependencies through self-attention. However, they lack the ability to learn the local (contextual) relations among pixels. Previous works try to overcome this problem by embedding convolutional layers either in the encoder or decoder modules of transformers thus ending up sometimes with inconsistent features. To address this issue, we propose a novel attention-based decoder, namely CASCaded Attention DEcoder (CASCADE), which leverages the multi-scale features of hierarchical vision transformers. CASCADE consists of i) an attention gate which fuses features with skip connections and ii) a convolutional attention module that enhances the long-range and local context by suppressing background information. We use a multi-stage feature and loss aggregation framework due to their faster convergence and better performance. Our experiments demonstrate that transformers with CASCADE significantly outperform state-of-the-art CNN- and transformer-based approaches, obtaining up to 5.07% and 6.16% improvements in DICE and mIoU scores, respectively. CASCADE opens new ways of designing better attention-based decoders. © 2023 IEEE.","and algorithms (including transfer, low-shot, semi-, self-, and un-supervised learning); Applications: Biomedical/healthcare/medicine; formulations; Image recognition and understanding (object detection, categorization, segmentation, scene modeling, visual reasoning); Machine learning architectures","Bioinformatics; Convolution; Convolutional neural networks; Decoding; Deep learning; Image recognition; Image segmentation; Learning systems; Medical imaging; And algorithm (including transfer, low-shot, semi-, self-, and un-supervised learning); Application: biomedical/healthcare/medicine; Formulation; Image recognition and understanding (object detection, categorization, segmentation, scene modeling, visual reasoning); Learning architectures; Machine learning architecture; Machine-learning; Objects detection; Scene model; Un-supervised learning; Visual reasoning; Object detection","National Science Foundation, NSF, (CNS 2007284); National Science Foundation, NSF","","Institute of Electrical and Electronics Engineers Inc.",""
"Rabie K.; Karthik C.; Chowdhury S.; Dutta P.K.","Rabie, Khaled (55884933100); Karthik, Chandran (57226546597); Chowdhury, Subrata (57200565797); Dutta, Pushan Kumar (7202355384)","55884933100; 57226546597; 57200565797; 7202355384","Deep learning in medical image processing and analysis","2023","","","","1","358","357","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178972591&partnerID=40&md5=f0ab8a9c4f6734e6ac2cd3e208a91804","Medical images, in various formats, are used by clinicians to identify abnormalities or markers associated with certain conditions, such as cancers, diseases, abnormalities or other adverse health conditions. Deep learning algorithms use vast volumes of data to train the computer to recognise certain features in the images that are associated with the disease or condition that you wish to identify. Whilst analysing the images by eye can take a lot of time, deep learning algorithms have the benefit of reviewing medical images at a faster rate than a human can, which aids the clinician, speeding up diagnoses and freeing up clinicians' time for other duties. Deep Learning in Medical Image Processing and Analysis introduces the fundamentals of deep learning for biomedical image analysis for applications including ophthalmology, cancer detection and heart disease. The book considers the principles of multi-instance feature selection, swarm optimisation, parallel processing models, artificial neural networks, support vector machines, as well as their design and optimisation, in biomedical applications. Topics such as data security, patient confidentiality, effectiveness and reliability will also be discussed. Written by an international team of experts, this edited book covers principles and applications for industry and academic researchers, scientists, engineers, developers, and designers in the fields of machine learning, deep learning, AI, image processing, signal processing, computer science or related fields. It will also be of interest to standards bodies and regulators, and clinicians using deep learning models. © The Institution of Engineering and Technology 2023. All rights reserved.","","","","","Institution of Engineering and Technology",""
"Mirza O.M.; Alsobhi A.; Hasanin T.; Ishak M.K.; Karim F.K.; Mostafa S.M.","Mirza, Olfat M. (57195937469); Alsobhi, Aisha (56112818500); Hasanin, Tawfiq (57140698600); Ishak, Mohamad Khairi (57203233310); Karim, Faten Khalid (57222495869); Mostafa, Samih M. (56278605900)","57195937469; 56112818500; 57140698600; 57203233310; 57222495869; 56278605900","Computer Aided Diagnosis for Gastrointestinal Cancer Classification Using Hybrid Rice Optimization With Deep Learning","2023","11","","","76321","76329","8","10.1109/ACCESS.2023.3297441","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165410977&doi=10.1109%2fACCESS.2023.3297441&partnerID=40&md5=6f4f824d4f422fbcdba1cada59c2952b","A gastrointestinal disease is a group of cancers which mainly affects the digestive system, along with the stomach, small intestine, oesophagus, rectum, and colon. Accurate classification and earlier diagnosis of this cancer are crucial for better patient outcomes. Deep learning (DL) algorithm, especially convolutional neural network (CNN), is trained to categorize endoscopic images of gastrointestinal tissue as either benign or malignant. Gastrointestinal cancer (GC) classification with DL is the process of using artificial intelligence (AI), especially the DL algorithm, to categorize endoscopic images of gastric tissue as benign or malignant. It could help clinicians to identify the earliest symptoms of cancer and make treatment decisions, resulting in improved patient outcomes. The study designs a new gastrointestinal disease Detection and Classification using Hybrid Rice Optimization with Deep Learning (GDDC-HRODL) model. The presented GDDC-HRODL model intends to classify the medical images for GC. To achieve this, the GDDC-HRODL technique initially preprocesses the input data to improve image quality. In addition, the presented GDDC-HRODL algorithm employs the HybridNet model to produce feature vectors and the hyperparameter tuning process takes place using the HRO algorithm. For GC classification purposes, the GDDC-HRODL technique uses an attention-based long short-term memory (ALSTM) model and its hyperparameters can be selected by the ant lion optimization (ALO) algorithm. The design of hyperparameter tuning processes helps to accomplish enhanced GC classification performance. The experimental analysis of the GDDC-HRODL algorithm on the medical dataset demonstrates its betterment in the GC classification process.  © 2013 IEEE.","Artificial intelligence; deep learning; gastric cancer classification; hybrid rice optimization; hyperparameter tuning; medical imaging","Bioinformatics; Classification (of information); Computer aided diagnosis; Computer aided instruction; Deep learning; Diseases; Endoscopy; Image classification; Image enhancement; Learning algorithms; Medical imaging; Neural networks; Patient treatment; Tissue; Biomedical imaging; Cancer; Cancer classification; Classification algorithm; Deep learning; Features extraction; Gastric cancer classification; Gastric cancers; Gastrointestinal tract; Hybrid rice; Hybrid rice optimization; Hyper-parameter; Hyper-parameter optimizations; Hyperparameter tuning; Images reconstruction; Medical diagnostic imaging; Optimisations; Tuning; Image reconstruction","Princess Nourah Bint Abdulrahman University, PNU, (PNURSP2023R300)","","Institute of Electrical and Electronics Engineers Inc.",""
"Song Y.","Song, Yuehua (57561380300)","57561380300","Artificial Intelligence Algorithms in Biomedical Application","2023","","","","42","47","5","10.1109/ISBP57705.2023.10061317","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150684025&doi=10.1109%2fISBP57705.2023.10061317&partnerID=40&md5=7dde2b63227144356e0ca8dbf6187114","In recent years, the rapid development of artificial intelligence (AI) has accelerated the development of many social industries. In view of the demand for large data collection and effective medical data processing, AI has undoubtedly become an important part of biomedical research. Medical professionals can accurately diagnose and treat a variety of symptoms in patients with the help of AI algorithms. Modern AI technologies, such as traditional neural networks for structured data and natural language processing for unstructured data, can accurately analyze various medical data. The medical industry uses these AI learning techniques for disease diagnosis, drug discovery, and medical image analysis. Against this backdrop, this paper focuses on the application of AI algorithms in biomedicine and examined cases from biomedical research in addition to the introduction of machine learning, deep learning, and transformer models. Last but not least, we briefly introduce the progress of AI in biomedicine and the difficulties it will encounter.  © 2023 IEEE.","Artificial Intelligence; Biomedical Applications; Deep Learning; Machine Learning; Transformer","Bioinformatics; Data handling; Deep learning; Diagnosis; Learning systems; Medical applications; Medical imaging; Natural language processing systems; Artificial intelligence algorithms; Biomedical applications; Biomedical research; Data collection; Deep learning; Large data; Machine-learning; Medical data; Medical professionals; Transformer; Learning algorithms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Jaiswal A.; Chen T.; Rousseau J.F.; Peng Y.; Ding Y.; Wang Z.","Jaiswal, Ajay (57221254179); Chen, Tianlong (57221072108); Rousseau, Justin F. (57150150300); Peng, Yifan (55561453200); Ding, Ying (35229200000); Wang, Zhangyang (56288839400)","57221254179; 57221072108; 57150150300; 55561453200; 35229200000; 56288839400","Attend Who is Weak: Pruning-assisted Medical Image Localization under Sophisticated and Implicit Imbalances","2023","","","","4976","4985","9","10.1109/WACV56688.2023.00496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148996283&doi=10.1109%2fWACV56688.2023.00496&partnerID=40&md5=e919bb5679e9d44e94249b33448b45a9","Deep neural networks (DNNs) have rapidly become a de facto choice for medical image understanding tasks. However, DNNs are notoriously fragile to the class imbalance in image classification. We further point out that such imbalance fragility can be amplified when it comes to more sophisticated tasks such as pathology localization, as imbalances in such problems can have highly complex and often implicit forms of presence. For example, different pathology can have different sizes or colors (w.r.t.the background), different underlying demographic distributions, and in general different difficulty levels to recognize, even in a meticulously curated balanced distribution of training data. In this paper, we propose to use pruning to automatically and adaptively identify hard-to-learn (HTL) training samples, and improve pathology localization by attending them explicitly, during training in supervised, semi-supervised, and weakly-supervised settings. Our main inspiration is drawn from the recent finding that deep classification models have difficult-to-memorize samples and those may be effectively exposed through network pruning [15] - and we extend such observation beyond classification for the first time. We also present an interesting demographic analysis which illustrates HTLs ability to capture complex demographic imbalances. Our extensive experiments on the Skin Lesion Localization task in multiple training settings by paying additional attention to HTLs show significant improvement of localization performance by ∼2-3%. © 2023 IEEE.","Algorithms: Machine learning architectures; and algorithms (including transfer); Biomedical/healthcare/medicine; formulations; Image recognition and understanding (object detection, categorization, segmentation, scene modeling, visual reasoning)","Bioinformatics; Complex networks; Deep neural networks; Image recognition; Image segmentation; Learning algorithms; Medical imaging; Pathology; Algorithm: machine learning architecture; And algorithm (including transfer); Biomedical/healthcare/medicine; Formulation; Image recognition and understanding (object detection, categorization, segmentation, scene modeling, visual reasoning); Learning architectures; Machine-learning; Objects detection; Scene model; Visual reasoning; Object detection","National NSF; U.S. National Library of Medicine, NLM, (4R00LM013001)","","Institute of Electrical and Electronics Engineers Inc.",""
"Choi S.J.; Kim D.K.; Kim B.S.; Cho M.; Jeong J.; Jo Y.H.; Song K.J.; Kim Y.J.; Kim S.","Choi, Seung Jae (58032704200); Kim, Dae Kon (57216822391); Kim, Byeong Soo (57365979400); Cho, Minwoo (56783471200); Jeong, Joo (39061606100); Jo, You Hwan (25822597600); Song, Kyoung Jun (57037616400); Kim, Yu Jin (56658847500); Kim, Sungwan (27169083000)","58032704200; 57216822391; 57365979400; 56783471200; 39061606100; 25822597600; 57037616400; 56658847500; 27169083000","Mask R-CNN based multiclass segmentation model for endotracheal intubation using video laryngoscope","2023","9","","","","","","10.1177/20552076231211547","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176430215&doi=10.1177%2f20552076231211547&partnerID=40&md5=98a109508f241780296a9ddba0a8b5f8","Objective: Endotracheal intubation (ETI) is critical to secure the airway in emergent situations. Although artificial intelligence algorithms are frequently used to analyze medical images, their application to evaluating intraoral structures based on images captured during emergent ETI remains limited. The aim of this study is to develop an artificial intelligence model for segmenting structures in the oral cavity using video laryngoscope (VL) images. Methods: From 54 VL videos, clinicians manually labeled images that include motion blur, foggy vision, blood, mucus, and vomitus. Anatomical structures of interest included the tongue, epiglottis, vocal cord, and corniculate cartilage. EfficientNet-B5 with DeepLabv3+, EffecientNet-B5 with U-Net, and Configured Mask R-Convolution Neural Network (CNN) were used; EffecientNet-B5 was pretrained on ImageNet. Dice similarity coefficient (DSC) was used to measure the segmentation performance of the model. Accuracy, recall, specificity, and F1 score were used to evaluate the model's performance in targeting the structure from the value of the intersection over union between the ground truth and prediction mask. Results: The DSC of tongue, epiglottis, vocal cord, and corniculate cartilage obtained from the EfficientNet-B5 with DeepLabv3+, EfficientNet-B5 with U-Net, and Configured Mask R-CNN model were 0.3351/0.7675/0.766/0.6539, 0.0/0.7581/0.7395/0.6906, and 0.1167/0.7677/0.7207/0.57, respectively. Furthermore, the processing speeds (frames per second) of the three models stood at 3, 24, and 32, respectively. Conclusions: The algorithm developed in this study can assist medical providers performing ETI in emergent situations. © The Author(s) 2023.","Biomedical image processing; convolutional neural networks; deep learning; image segmentation; intubation","","National Research Foundation of Korea, NRF, (2021R1C1C101035213)","","SAGE Publications Inc.",""
"Negm N.; Aldehim G.; Nafie F.M.; Marzouk R.; Assiri M.; Alsaid M.I.; Drar S.; Abdelbagi S.","Negm, Noha (57224513486); Aldehim, Ghadah (57977814800); Nafie, Faisal Mohammed (57202832074); Marzouk, Radwa (35749022100); Assiri, Mohammed (57219344932); Alsaid, Mohamed Ibrahim (57964125000); Drar, Suhanda (58131064100); Abdelbagi, Sitelbanat (58136535600)","57224513486; 57977814800; 57202832074; 35749022100; 57219344932; 57964125000; 58131064100; 58136535600","Intracranial Haemorrhage Diagnosis Using Willow Catkin Optimization With Voting Ensemble Deep Learning on CT Brain Imaging","2023","11","","","75474","75483","9","10.1109/ACCESS.2023.3297281","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165387170&doi=10.1109%2fACCESS.2023.3297281&partnerID=40&md5=4ada2bed6839b96a3ca5237aac533129","Intracranial haemorrhage (ICH) has become a critical healthcare emergency that needs accurate assessment and earlier diagnosis. Due to the high rates of mortality (about 40%), the early classification and detection of diseases through computed tomography (CT) images were needed to guarantee a better prognosis and control the occurrence of neurologic deficiencies. Generally, in the earlier diagnoses test for severe ICH, CT imaging of the brain was implemented in the emergency department. Meanwhile, manual diagnoses are labour-intensive, and automatic ICH recognition and classification techniques utilizing artificial intelligence (AI) models are needed. Therefore, the study presents an Intracranial Haemorrhage Diagnosis using Willow Catkin Optimization with Voting Ensemble (ICHD-WCOVE) Model on CT images. The presented ICHD-WCOVE technique exploits computer vision and ensemble learning techniques for automated ICH classification. The presented ICHD-WCOVE technique involves the design of a multi-head attention-based CNN (MAFNet) model for feature vector generation with optimal hyperparameter tuning using the WCO algorithm. For automated ICH detection and classification, the majority voting ensemble deep learning (MVEDL) technique is used, which comprises recurrent neural network (RNN), Bi-directional long short-term memory (BiLSTM), and extreme learning machine-stacked autoencoder (ELM-SAE). The experimental analysis of the ICHD-WCOVE approach can be tested by a medical dataset and the outcomes signified the betterment of the ICHD-WCOVE technique over other existing approaches. © 2013 IEEE.","Brain imaging; computer vision; deep learning; ensemble learning; intracranial haemorrhage; willow catkin optimization","Brain mapping; Computer vision; Computerized tomography; Diagnosis; Disease control; Biomedical imaging; Brain imaging; Brain modeling; Computed tomography; Convolutional neural network; Cranial pressure; Deep learning; Ensemble learning; Features extraction; Hemorrhaging; Intracranial hemorrhages; Medical diagnostic imaging; Optimisations; Solid modelling; Willow catkin optimization; Recurrent neural networks","Deanship of Scientific Research, King Khalid University, (RGP2/96/44); Deanship of Scientific Research, King Khalid University","","Institute of Electrical and Electronics Engineers Inc.",""
"Ren J.; Fu X.; Wang M.; Zhao T.; Wang Z.; Feng K.; Liang Y.; Wang S.; Lei M.","Ren, Jingrong (57484478000); Fu, Xiangda (58136058700); Wang, Mengrui (57948855800); Zhao, Tianyu (57195633941); Wang, Zhaojun (57188729613); Feng, Kun (57222494574); Liang, Yansheng (55818884400); Wang, Shaowei (56178083400); Lei, Ming (57203456278)","57484478000; 58136058700; 57948855800; 57195633941; 57188729613; 57222494574; 55818884400; 56178083400; 57203456278","Advances in Rapid Three-Dimensional Wide Field Microscopy; [快 速 宽 场 三 维 显 微 技 术 研 究 进 展]","2023","50","3","0307104","","","","10.3788/CJL221303","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149760900&doi=10.3788%2fCJL221303&partnerID=40&md5=66ed4451ea704c43bcad1779fe8e9aab","Significance Three-dimensional (3D) imaging is an important research direction in microscopy and has been applied to many fields such as biomedicine and engineering science. Typical 3D microscopy techniques, such as laser confocal microscopy and multi-photon microscopy, are based on laser point scanning geometry, and the imaging speed is limited by the scanning speed; therefore, biological samples are likely to be damaged under long scanning durations and high-intensity illumination. Recently, wide-field microscopy with 3D imaging capability has received significant attention. Wide-field microscopy can yield complete two-dimensional imaging simultaneously and affords temporal resolutions higher than spot scanning by two to three orders of magnitude. Additionally, wide-field imaging offers high-quality grayscale images and fewer samples to be damaged, thus rendering it suitable for the real-time observation of living samples. However, conventional wide-field microscopy suffers from defocused backgrounds and low axial resolutions. Owing to the rapid development of computer science and optical technology, various algorithms and techniques for processing wide-field images have been proposed to improve their axial resolutions, thus providing more possibilities for 3D imaging. We focus on three types of rapid 3D wide-field microscopy techniques, i. e., shape of focus (SFF), structural illumination microscopy (SIM), and deep learning-assisted 3D imaging. The SFF technique enables the extraction of focal plane information by processing a series of image stacks and reconstructing the 3D morphology of samples without requiring specific hardware. In SIM, samples are illuminated by phase-shifted light fields with high spatial frequencies, images are captured using a CCD camera, and the in- and out-focus information can be effectively separated using decoding algorithms. Deep learning models can learn the mapping relationship between different types of images from a large amount of data, such as the conversion between wide-field images and confocal images; this is a simple method to obtain high-quality images. The trained model can remove the background information of wide-field microscopic images to improve the axial resolution of imaging, thus facilitating the realization of 3D imaging via wide-field microscopy. It is believed that rapid 3D microscopes based on wide-field imaging will be applied to many fields such as biomedicine, materials science, and precision manufacturing in the near future. Progress This paper focuses on three rapid wide-field 3D imaging techniques, namely, SFF, SIM, and deep learning-assisted 3D imaging. In the SFF technique, a focusing evaluation operator is used to calculate and extract the highest focus position of each pixel from a wide-field image stack; subsequently, the 3D depth image of the sample is reconstructed via a recovery algorithm, which is mainly used for surface topography measurement. We investigate the effect of the focused evaluation operator on the calculation results yielded by the SFF technique in different cases. Additionally, we discuss the development and application of the focused topography recovery operator and the optimization of related hardware. Optical sectioning SIM utilizes encoded structured light fields to illuminate the sample and then recovers the 3D information of the sample using decoding algorithms, which can be used for both fluorescent and non-fluorescent imaging. We introduce the theoretical basis of optical sectioning SIM and then propose various rapid decoding algorithms for improving the reconstruction speed. Then, we discuss the development of related techniques and their most recent applications in the field of 3D color imaging. Deep learning-assisted 3D imaging applies the learning ability of neural network models to complete target image tasks, such as the conversion between wide-field and confocal images as well as that between wide-field microscopy and SIM so as to achieve widefield 3D imaging. We present the theoretical basis of deep learning-related models. Subsequently, we discuss the development and application of deep learning models for conversion between wide-field and confocal images as well as that between wide-field microscopy and SIM, followed by the applications of deep learning for achieving more rapid SIM imaging. Finally, we discuss the current problems and future research directions for rapid 3D wide-field microscopy techniques. Conclusions and Prospects Rapid 3D wide-field microscopy techniques have demonstrated performance improvement either through hardware modification or software assistance. However, these techniques are not perfect. SFF combined with other techniques is expected to benefit deep tissue imaging. The amount of SIM imaging data is two to three times that of the conventional wide-field microscopy, and the imaging speed of SIM can be further improved. Deep learning can be flexibly combined with other technologies. In summary, the potential of wide-field microscopy with 3D imaging capability is yet to be realized. Progress in technology and cross integration will enable the routine use of rapid 3D wide-field microscopy techniques in biomedical laboratories. © 2023 Science Press. All rights reserved.","3D imaging; bio<sup>-</sup>optics; deep learning; shape from focus; structured illumination microscope; wide field microscope","CCD cameras; Deep learning; Image enhancement; Imaging systems; Photons; Three dimensional computer graphics; 3D imaging; Biooptics; Deep learning; Microscopy technique; Shape from focus; Structured illumination; Structured illumination microscope; Wide field microscope; Wide-field; Wide-field microscopies; Microscopes","","","Science Press",""
"Shi H.; Zhang J.; Pei Z.","Shi, Hongbing (58575298400); Zhang, Jinhui (57211478397); Pei, Zhongcai (15835746200)","58575298400; 57211478397; 15835746200","Spatial information considered convolutional neural network for electroencephalogram-based motor imagery classification","2023","12756","","127564W","","","","10.1117/12.2686181","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171162887&doi=10.1117%2f12.2686181&partnerID=40&md5=c115c80a9af6f9fdeeae6c21cb3f6dd1","As brain-computer interface (BCI) technology continues to advance in various fields, it has become one of the possible solutions for patients with motor dysfunction who have healthy thinking ability to regain motor ability. The vigorous development of deep learning (DL) provides it with a possible tool to analyze electroencephalogram (EEG) signals. Through analyzing and categorizing EEG signals associated with motor imagery (MI), the system can effectively perceive the patient's motor intentions. Currently, Convolutional Neural Networks (CNN) have exhibited exceptional performance in a variety of fields, including computer vision (CV) and natural language processing (NLP). However, the brain structure has rich spatial information, which was not fully utilized by CNN for MI-EEG signal analysis in the past. This paper introduces SP-CNN, a convolutional neural network that incorporates spatial information from the brain, to address the classification challenge of MI-EEG signals. The experimental findings indicate that this method exhibits stable and robust performance across diverse subjects. © 2023 SPIE.","autoencoder; convolutional neural network; deep learning; EEG; motor imagery","Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Image analysis; Image classification; Learning algorithms; Learning systems; Medical computing; Medical imaging; Natural language processing systems; Auto encoders; Convolutional neural network; Deep learning; Electroencephalogram signals; Interface technology; Motor abilities; Motor imagery; Motor imagery classification; Performance; Spatial informations; Electroencephalography","","Chen X.; Srivastava H.M.","SPIE",""
"Yi S.; Zhou L.; Ma L.; Shao D.","Yi, Sanli (35340183100); Zhou, Lingxiang (57986564000); Ma, Lei (56349331800); Shao, Dangguo (58333478100)","35340183100; 57986564000; 56349331800; 58333478100","MTRA-CNN: A Multi-Scale Transfer Learning Framework for Glaucoma Classification in Retinal Fundus Images","2023","11","","","142689","142701","12","10.1109/ACCESS.2023.3342910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180347483&doi=10.1109%2fACCESS.2023.3342910&partnerID=40&md5=9f0f6538910947870f4568ee4bd4fcc6","In the diagnosis of glaucoma based on deep learning, it is more meaningful for ophthalmologist to make a graded diagnosis using fundus images to reflect the degree of disease. Such multi-classification diagnosis tasks require a larger amount of data to enable the neural network to extract more feature information, while it is very difficult in medical field. To address these issues, we propose a novel Multi-Scale Transfer Learning framework (MTRA-CNN) which can make a graded diagnosis effectively based on graded glaucoma dataset with small volume: (1) Aiming at the problem of small data volume, we innovatively apply multi-stage transfer learning technique in glaucoma, in which the advantage of different types of datasets such as ImageNet and Ocular disease intelligent recognition (ODIR) are taken. (2) We innovatively combine the Residual attention(RA) block, a functional module designed specifically for fundus images, with transfer learning techniques and pre-trained it on the ODIR dataset to further improve the network's upper-level feature extraction ability of glaucoma fundus images. (3) To achieve better diagnostic performance, we propose a novel multi-scale transfer learning method by combining the two-stage transfer learning with one-stage transfer learning. To validate our framework, we conducted experiments on the private glaucoma 4 classification dataset, and the results show that the accuracy of our method is 86.8%, compared to the method without any transfer learning, the accuracy of our experiments improved by 19.79%.  © 2013 IEEE.","bottom-level feature; deep CNNs; graded glaucoma diagnosis; Multi-scale transfer learning; upper-level feature","Classification (of information); Computer aided diagnosis; Data mining; Deep learning; Extraction; Image enhancement; Learning algorithms; Medical computing; Medical imaging; Ophthalmology; Biomedical imaging; Bottom-level feature; Deep CNN; Features extraction; Glaucoma; Graded glaucoma diagnose; Medical diagnostic imaging; Multi-scale transfer learning; Multi-scales; Scale transfer; Transfer learning; Upper-level feature; X-ray imaging; Feature extraction","National Natural Science Foundation of China, NSFC, (62266025); National Natural Science Foundation of China, NSFC","","Institute of Electrical and Electronics Engineers Inc.",""
"Dhoundiyal P.; Sharma V.; Vats S.; Singh K.","Dhoundiyal, Parveen (58838871400); Sharma, Vikrant (56785043200); Vats, Satvik (57193131437); Singh, Karan (57199490853)","58838871400; 56785043200; 57193131437; 57199490853","Harnessing CNNs for Accurate Skin Disease Identification","2023","","","","933","937","4","10.1109/ICTACS59847.2023.10389836","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185377057&doi=10.1109%2fICTACS59847.2023.10389836&partnerID=40&md5=afecfdd04c91847f1c982153977add7b","Skin disorders are common and can be brought on by several things, including viruses, bacteria, allergies, or fungi. The speed and precision of detecting skin diseases have increased because of developments in laser and photonics-based medical technologies. The expense of such a diagnostic is still considerable, though, which restricts accessibility. An automated early-stage dermatological screening system has been developed using image processing techniques to solve this issue. Effective skin disease classification requires the extraction of key information from pictures, and many detection algorithms rely on computer vision. DenseNet169 and NASNetMobile are some of the methods that were employed in the study. Graphs were used to display the results as the researchers compared the algorithms' performance based on training accuracy and confusion matrix. Keywords: Skin Disease, Medical Diagnosis, Deep Learning, Transfer Learning, CNNs  © 2023 IEEE.","","Biomedical engineering; Classification (of information); Convolutional neural networks; Deep learning; Diagnosis; Image processing; Viruses; Algorithm performance; Detection algorithm; Disease classification; Image processing technique; Medical technologies; Performance based; Screening system; Skin disease; Skin disease identifications; Skin disorders; Dermatology","","Chaudhary N.","Institute of Electrical and Electronics Engineers Inc.",""
"Mandala S.; Amini S.S.; Adiwijaya; Syaifullah A.R.; Pramudyo M.; Nurmaini S.; Abdullah A.H.","Mandala, Satria (57193871656); Amini, Sabilla Suci (58654108100); Adiwijaya (36338419400); Syaifullah, Aulia Rayhan (58773373100); Pramudyo, Miftah (57471721100); Nurmaini, Siti (26639610000); Abdullah, Abdul Hanan (11338934800)","57193871656; 58654108100; 36338419400; 58773373100; 57471721100; 26639610000; 11338934800","Enhanced Myocardial Infarction Identification in Phonocardiogram Signals Using Segmented Feature Extraction and Transfer Learning-Based Classification","2023","11","","","136654","136665","11","10.1109/ACCESS.2023.3338853","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180270148&doi=10.1109%2fACCESS.2023.3338853&partnerID=40&md5=35c2ef6a6f648fbd410fe6fb3d55a1e2","Myocardial Infarction (MI), commonly known as a heart attack, is a type of cardiovascular disease characterized by the death of heart muscle cells. This condition occurs due to the blockage of blood vessels around the heart, inhibiting blood flow and causing an insufficient oxygen supply to the body. Typically, cardiovascular disease tests involve electrocardiogram (ECG) and photoplethysmogram (PPG) signals. In recent years, researchers have explored the application of Phonocardiogram (PCG) signals for cardiovascular detection due to their non-invasive, efficient, accessible, and cost-effective nature. While deep learning has been successful in object detection in digital images, its application to PCG signals for heart attack detection is rare. This study bridges this gap by introducing an enhanced technique called the Myocardial Infarction Detection System (MIDs). In contrast to previous deep learning research, this study employs a transfer learning algorithm as a classifier for MI feature datasets. Feature extraction is performed in segments to obtain more accurate MI features. Six feature extraction methods and transfer learning models based on Convolutional Neural Networks (CNN) using the VGG-16 architecture were selected as the primary components for MI identification. Additionally, this study compares these models with other CNN transfer learning models, such as VGG-19 and Xception, to assess their performance. Two experimental scenarios were conducted to evaluate MIDs performance in MI detection: experiments without hyperparameter tuning and with hyperparameter tuning. The results indicate that MIDs with CNN (VGG-16) after tuning exhibited the highest detection performance compared to other transfer learning CNN models, both with and without tuning. The accuracy, specificity, and sensitivity of MIDS detection with this configuration were 96.7%, 96.0%, and 97.4%, respectively. This research contributes to the development of an enhanced MI detection technique based on PCG signals using a transfer learning CNN.  © 2013 IEEE.","classification; deep learning; Myocardial infarction; PCG","Biomedical signal processing; Blood vessels; Cardiology; Cost effectiveness; Deep learning; Diseases; Electrocardiography; Extraction; Feature extraction; Heart; Learning systems; Neural networks; Object detection; Signal detection; Tuning; Cardiovascular disease; Convolutional neural network; Deep learning; Features extraction; Heart attack; Learning models; Myocardial Infarction; Performance; Phonocardiograms; Transfer learning; Classification (of information)","","","Institute of Electrical and Electronics Engineers Inc.",""
"Shen T.; Huang F.; Xu H.","Shen, Tongping (57205528078); Huang, Fangliang (57211835468); Xu, Huanqing (57223046678)","57205528078; 57211835468; 57223046678","HarDNet and Dual-Code Attention Mechanism Based Model for Medical Images Segmentation","2023","11","","","47827","47835","8","10.1109/ACCESS.2023.3275966","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160229022&doi=10.1109%2fACCESS.2023.3275966&partnerID=40&md5=a86281f836cd5439da97af470c1e4883","During the formation of medical images, they are easily disturbed by factors such as acquisition devices and tissue backgrounds, causing problems such as blurred image backgrounds and difficulty in differentiation. In this paper, we combine the HarDNet module and the multi-coding attention mechanism module to optimize the two stages of encoding and decoding to improve the model segmentation performance. In the encoding stage, the HarDNet module extracts medical image feature information to improve the segmentation network operation speed. In the decoding stage, the multi-coding attention module is used to extract both the position feature information and channel feature information of the image to improve the model segmentation effect. Finally, to improve the segmentation accuracy of small targets, the use of Cross Entropy and Dice combination function is proposed as the loss function of this algorithm. The algorithm has experimented on three different types of medical datasets, Kvasir-SEG, ISIC2018, and COVID-19CT. The values of JS were 0.7189, 0.7702, 0.9895, ACC were 0.8964, 0.9491, 0.9965, SENS were 0.7634, 0.8204, 0.9976, PRE were 0.9214, 0.9504, 0.9931. The experimental results showed that the model proposed in this paper achieved excellent segmentation results in all the above evaluation indexes, which can effectively assist doctors to diagnose related diseases quickly and improve the speed of diagnosis and patients' quality of life.  © 2013 IEEE.","Attention module; deep learning; medical images; segmentation","Data mining; Decoding; Deep learning; Diagnosis; Encoding (symbols); Image coding; Image enhancement; Medical computing; Medical image processing; Neural networks; Signal encoding; Attention module; Biomedical imaging; Convolutional neural network; Decoding; Deep learning; Features extraction; Images segmentations; Medical diagnostic imaging; Medical image; Segmentation; Image segmentation","Anhui Province Quality Engineering, (2021jyxm0801); Excellent Young Talents in Anhui Universities, (gxyq2022026); Science Foundation of Universities in Anhui Province, (2022AH050428)","","Institute of Electrical and Electronics Engineers Inc.",""
"Apostolopoulos I.D.; Papathanasiou N.D.; Papandrianos N.I.; Papageorgiou E.I.; Panayiotakis G.S.","Apostolopoulos, Ioannis D. (57195641603); Papathanasiou, Nikolaos D. (23995562200); Papandrianos, Nikolaos I. (24779749100); Papageorgiou, Elpiniki I. (56429800100); Panayiotakis, George S. (7006755481)","57195641603; 23995562200; 24779749100; 56429800100; 7006755481","Deep Learning Assessment for Mining Important Medical Image Features of Various Modalities","2022","12","10","2333","","","","10.3390/diagnostics12102333","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140777302&doi=10.3390%2fdiagnostics12102333&partnerID=40&md5=a89512a0ce1f2fb4400dbafd50a79d7c","Deep learning (DL) is a well-established pipeline for feature extraction in medical and nonmedical imaging tasks, such as object detection, segmentation, and classification. However, DL faces the issue of explainability, which prohibits reliable utilisation in everyday clinical practice. This study evaluates DL methods for their efficiency in revealing and suggesting potential image biomarkers. Eleven biomedical image datasets of various modalities are utilised, including SPECT, CT, photographs, microscopy, and X-ray. Seven state-of-the-art CNNs are employed and tuned to perform image classification in tasks. The main conclusion of the research is that DL reveals potential biomarkers in several cases, especially when the models are trained from scratch in domains where low-level features such as shapes and edges are not enough to make decisions. Furthermore, in some cases, device acquisition variations slightly affect the performance of DL models. © 2022 by the authors.","biomarkers; deep learning; feature extraction; medical imaging","area under the curve; Article; classification algorithm; clinical article; computer assisted tomography; congenital skin disease; convolutional neural network; coronary artery disease; coronavirus disease 2019; data mining; deep learning; diagnostic accuracy; diagnostic imaging; diagnostic value; disease marker; feature extraction; gradient weighted class activation mapping; human; image processing; lung nodule; myocardial perfusion imaging; photography; positron emission tomography-computed tomography; prostate cancer; radiography; residual neural network; sensitivity and specificity; single photon emission computed tomography; skin cancer","Second Call for H.F.R.I., (3656); Hellenic Foundation for Research and Innovation, ΕΛ.ΙΔ.Ε.Κ","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Shi L.; Wank M.; Chen Y.; Wang Y.; Liu Y.; Hector E.C.; Song P.X.K.","Shi, Lan (57919436000); Wank, Marianthie (57919436100); Chen, Yan (57920647800); Wang, Yibo (57919792300); Liu, Yachuan (57919958200); Hector, Emily C. (57195237241); Song, Peter X.K. (7201917675)","57919436000; 57919436100; 57920647800; 57919792300; 57919958200; 57195237241; 7201917675","Sleep Classification With Artificial Synthetic Imaging Data Using Convolutional Neural Networks","2023","27","1","","421","432","11","10.1109/JBHI.2022.3210485","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139470272&doi=10.1109%2fJBHI.2022.3210485&partnerID=40&md5=c4a7718c7f9582769479098f0d583aa4","Objective: We propose a new analytic framework, 'Artificial Synthetic Imaging Data (ASID) Workflow,' for sleep classification from a wearable device comprising: 1) the creation of ASID from data collected by a non-invasive wearable device that permits real-time multi-modal physiological monitoring on heart rate (HR), 3-axis accelerometer, electrodermal activity, and skin temperature, denoted as 'Temporal E4 Data' (TED) and 2) the use of an image classification supervised learning algorithm, convolutional neural network (CNN), to classify periods of sleep. Methods: We investigate ASID Workflow under 6 settings (3 data resolutions × 2 HR scenarios). Competing machine/deep learning classification algorithms, including logistic regression, support vector machine, random forest, k-nearest neighbors, and Long Short-Term Memory, are applied to TED as comparisons, termed 'Competing Workflow.' Results: The ASID Workflow achieves excellent performance with mean weighted accuracy across settings of 94.7%, and is superior to the Competing Workflow with high and low resolution data regardless of the inclusion of HR modality. This superiority is maximized for low resolution data without HR. Additionally, CNN has a relatively low subject-wise test computational cost compared with competing algorithms. Conclusion: We demonstrate the utility of creating ASID from multi-modal physiological data and applying a preexisting image classification algorithm to achieve better classification accuracy. We shed light on the influence of data resolution and HR modality on the Workflow's performance. Significance: Applying CNN to ASID allows us to capture both temporal and spatial dependency among physiological variables and modalities by using 2D images' topological structure that competing algorithms fail to utilize.  © 2013 IEEE.","Artificial synthetic imaging data; convolutional neural network; physiological signals; sleep classification; wearable","Algorithms; Diagnostic Imaging; Humans; Machine Learning; Neural Networks, Computer; Random Forest; Bioinformatics; Biomedical signal processing; Convolution; Decision trees; Heart; Image classification; Learning algorithms; Nearest neighbor search; Neural networks; Support vector machines; Wearable technology; Artificial synthetic imaging data; Biomedical monitoring; Classification algorithm; Convolutional neural network; Heart-rate; Imaging data; Physiological signals; Signal resolution; Sleep classification; Support vectors machine; Wearable; adult; Article; classification algorithm; clinical classification; controlled study; convolutional neural network; data processing; deep learning; diagnostic test accuracy study; electrodermal response; female; heart rate; human; human experiment; image analysis; image classification; image quality; k nearest neighbor; learning algorithm; machine learning; male; measurement accuracy; random forest; skin temperature; sleep; sleep classification; support vector machine; workflow; algorithm; diagnostic imaging; Classification (of information)","University of Michigan, U-M, (N026059)","","Institute of Electrical and Electronics Engineers Inc.","36173777"
"Hu K.; Wu W.; Li W.; Simic M.; Zomaya A.; Wang Z.","Hu, Kun (57209197449); Wu, Wenhua (57735563700); Li, Wei (57214815586); Simic, Milena (35185761200); Zomaya, Albert (7005128430); Wang, Zhiyong (36976302000)","57209197449; 57735563700; 57214815586; 35185761200; 7005128430; 36976302000","Adversarial Evolving Neural Network for Longitudinal Knee Osteoarthritis Prediction","2022","41","11","","3207","3217","10","10.1109/TMI.2022.3181060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131726602&doi=10.1109%2fTMI.2022.3181060&partnerID=40&md5=8f105ebd102dc36d16fd4f4e0970d8f6","Knee osteoarthritis (KOA) as a disabling joint disease has doubled in prevalence since the mid-20th century. Early diagnosis for the longitudinal KOA grades has been increasingly important for effective monitoring and intervention. Although recent studies have achieved promising performance for baseline KOA grading, longitudinal KOA grading has been seldom studied and the KOA domain knowledge has not been well explored yet. In this paper, a novel deep learning architecture, namely adversarial evolving neural network (A-ENN), is proposed for longitudinal grading of KOA severity. As the disease progresses from mild to severe level, ENN involves the progression patterns for accurately characterizing the disease by comparing an input image it to the template images of different KL grades using convolution and deconvolution computations. In addition, an adversarial training scheme with a discriminator is developed to obtain the evolution traces. Thus, the evolution traces as fine-grained domain knowledge are further fused with the general convolutional image representations for longitudinal grading. Note that ENN can be applied to other learning tasks together with existing deep architectures, in which the responses characterize progressive representations. Comprehensive experiments on the Osteoarthritis Initiative (OAI) dataset were conducted to evaluate the proposed method. An overall accuracy was achieved as 62.7%, with the baseline, 12-month, 24-month, 36-month, and 48-month accuracy as 64.6%, 63.9%, 63.2%, 61.8% and 60.2%, respectively. © 1982-2012 IEEE.","adversarial learning; deep learning; Knee osteoarthritis","Humans; Knee Joint; Neural Networks, Computer; Osteoarthritis, Knee; Convolution; Deep learning; Diagnosis; Domain Knowledge; Grading; Job analysis; Network architecture; Neural networks; Adversarial learning; Biomedical imaging; Deep learning; Evolving neural network; Features extraction; Knee osteoarthritis; Osteoarthritis; Task analysis; X-ray imaging; adult; age distribution; aged; Article; binary classification; classifier; clinical assessment; cohort analysis; computer vision; controlled study; convolution algorithm; deconvolution algorithm; deep learning; demographics; diagnostic accuracy; diagnostic imaging; disease severity; female; follow up; human; knee osteoarthritis; longitudinal study; major clinical study; male; performance indicator; prediction; residual neural network; sex ratio; knee; knee osteoarthritis; Medical imaging","National Institute of Arthritis and Musculoskeletal and Skin Diseases, NIAMS, (N01AR022262); National Institute of Arthritis and Musculoskeletal and Skin Diseases, NIAMS","","Institute of Electrical and Electronics Engineers Inc.","35675256"
"Valanarasu J.M.J.; Sindagi V.A.; Hacihaliloglu I.; Patel V.M.","Valanarasu, Jeya Maria Jose (57219450328); Sindagi, Vishwanath A. (56829595000); Hacihaliloglu, Ilker (24467768400); Patel, Vishal M. (56660008900)","57219450328; 56829595000; 24467768400; 56660008900","KiU-Net: Overcomplete Convolutional Architectures for Biomedical Image and Volumetric Segmentation","2022","41","4","","965","976","11","10.1109/TMI.2021.3130469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120042907&doi=10.1109%2fTMI.2021.3130469&partnerID=40&md5=eefa38c45acc8d157806cf40dddf3b17","Most methods for medical image segmentation use U-Net or its variants as they have been successful in most of the applications. After a detailed analysis of these 'traditional' encoder-decoder based approaches, we observed that they perform poorly in detecting smaller structures and are unable to segment boundary regions precisely. This issue can be attributed to the increase in receptive field size as we go deeper into the encoder. The extra focus on learning high level features causes U-Net based approaches to learn less information about low-level features which are crucial for detecting small structures. To overcome this issue, we propose using an overcomplete convolutional architecture where we project the input image into a higher dimension such that we constrain the receptive field from increasing in the deep layers of the network. We design a new architecture for im- age segmentation- KiU-Net which has two branches: (1) an overcomplete convolutional network Kite-Net which learns to capture fine details and accurate edges of the input, and (2) U-Net which learns high level features. Furthermore, we also propose KiU-Net 3D which is a 3D convolutional architecture for volumetric segmentation. We perform a detailed study of KiU-Net by performing experiments on five different datasets covering various image modalities. We achieve a good performance with an additional benefit of fewer parameters and faster convergence. We also demonstrate that the extensions of KiU-Net based on residual blocks and dense blocks result in further performance improvements. Code: https://github.com/jeya-maria-jose/KiU-Net-pytorch © 1982-2012 IEEE.","deep learning; Medical image segmentation; overcomplete representations","Image Processing, Computer-Assisted; Neural Networks, Computer; Computer architecture; Convolution; Deep learning; Diagnosis; Image segmentation; Medical imaging; Network architecture; Network layers; Signal encoding; Three dimensional displays; Deep learning; Features extraction; Images segmentations; Learn+; Medical diagnostic imaging; Medical image segmentation; Over-complete; Over-complete representations; Three-dimensional display; Volumetric segmentations; Article; clinical article; convolutional neural network; deep learning; echoencephalography; feature extraction; glioblastoma; glioma; human; image processing; image segmentation; liver tumor; neuroanatomy; newborn; nuclear magnetic resonance imaging; qualitative analysis; quantitative analysis; receptive field; segmentation algorithm; image processing; procedures; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.","34813472"
"Naeem A.; Anees T.; Fiza M.; Naqvi R.A.; Lee S.-W.","Naeem, Ahmad (57215772535); Anees, Tayyaba (50461069100); Fiza, Makhmoor (57853673900); Naqvi, Rizwan Ali (55975847900); Lee, Seung-Won (57223118056)","57215772535; 50461069100; 57853673900; 55975847900; 57223118056","SCDNet: A Deep Learning-Based Framework for the Multiclassification of Skin Cancer Using Dermoscopy Images","2022","22","15","5652","","","","10.3390/s22155652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136341545&doi=10.3390%2fs22155652&partnerID=40&md5=e88839a56ed44629475b2fc55ce2fb19","Skin cancer is a deadly disease, and its early diagnosis enhances the chances of survival. Deep learning algorithms for skin cancer detection have become popular in recent years. A novel framework based on deep learning is proposed in this study for the multiclassification of skin cancer types such as Melanoma, Melanocytic Nevi, Basal Cell Carcinoma and Benign Keratosis. The proposed model is named as SCDNet which combines Vgg16 with convolutional neural networks (CNN) for the classification of different types of skin cancer. Moreover, the accuracy of the proposed method is also compared with the four state-of-the-art pre-trained classifiers in the medical domain named Resnet 50, Inception v3, AlexNet and Vgg19. The performance of the proposed SCDNet classifier, as well as the four state-of-the-art classifiers, is evaluated using the ISIC 2019 dataset. The accuracy rate of the proposed SDCNet is 96.91% for the multiclassification of skin cancer whereas, the accuracy rates for Resnet 50, Alexnet, Vgg19 and Inception-v3 are 95.21%, 93.14%, 94.25% and 92.54%, respectively. The results showed that the proposed SCDNet performed better than the competing classifiers. © 2022 by the authors.","automated/computer aided diagnosis; biomedical image; melanoma; skin cancer; transfer learning","Deep Learning; Dermoscopy; Humans; Melanoma; Neural Networks, Computer; Skin Neoplasms; Classification (of information); Convolutional neural networks; Deep learning; Dermatology; Diseases; Learning algorithms; Oncology; Transfer learning; Accuracy rate; Automated/computer aided diagnose; Biomedical images; Dermoscopy images; Early diagnosis; Melanoma; Multi-classification; Skin cancers; State of the art; Transfer learning; diagnostic imaging; epiluminescence microscopy; human; melanoma; pathology; procedures; skin tumor; Computer aided diagnosis","Ministry of Science, ICT and Future Planning, MSIP, (NRF2021R1I1A2059735, NRF2022R1G1A101022611); National Research Foundation of Korea, NRF","","MDPI","35957209"
"","","","12th National Conference on Recent Advancements in Biomedical Engineering","2022","2405","","","","","817","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128038899&partnerID=40&md5=ae712374596c3c5931be53eb68ba0262","The proceedings contain 100 papers. The topics discussed include: automatic segmentation of kidney stones using active contour method by machine learning; segmentation of breast cancer using fuzzy C means and classification by SVM based on LBP features; detection of face skin cancer using deep convoluted neural network; a lung tumor detection technique using gradient vector flow algorithm; diagnosis of diabetic retinopathy and thyroid using retinal image; MAREMADS: microgravity and radiation effects on musculoskeletal atrophy detection system; eye tracking to study eye gaze in juveniles with autism; finite element analysis on clavicle bone during normal and extended range of motions under loading conditions; and the experimental study on change in lifting capacity and isometric muscle strength due to aging among Korean population.","","","","Kalidoss R.; George K.; Vinayagam M.","American Institute of Physics Inc.",""
"Malik N.; Bzdok D.","Malik, Nahiyan (57766405900); Bzdok, Danilo (37021155400)","57766405900; 37021155400","From YouTube to the brain: Transfer learning can improve brain-imaging predictions with deep learning","2022","153","","","325","338","13","10.1016/j.neunet.2022.06.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132895156&doi=10.1016%2fj.neunet.2022.06.014&partnerID=40&md5=2084e9f7a38baf3c97a54ad64fad2223","Deep learning has recently achieved best-in-class performance in several fields, including biomedical domains such as X-ray images. Yet, data scarcity poses a strict limit on training successful deep learning systems in many, if not most, biomedical applications, including those involving brain images. In this study, we translate state-of-the-art transfer learning techniques for single-subject prediction of simpler (sex and age) and more complex phenotypes (number of people in household, household income, fluid intelligence and smoking behavior). We fine-tuned 2D and 3D ResNet-18 convolutional neural networks for target phenotype predictions from brain images of ∼40,000 UK Biobank participants, after pretraining on YouTube videos from the Kinetics dataset and natural images from the ImageNet dataset. Transfer learning was effective on several phenotypes, especially sex and age classification. Additionally, transfer learning in particular outperformed deep learning models trained from scratch especially on smaller sample sizes. The out-of-sample performance using transfer learning from previously learned knowledge based on real-world images and videos could unlock the potential in many areas of imaging neuroscience where deep learning solutions are currently infeasible. © 2022 Elsevier Ltd","Brain imaging; Convolutional neural network algorithms; Deep learning; Imaging neuroscience; Machine learning; Transfer learning","Brain; Deep Learning; Humans; Intelligence; Neural Networks, Computer; Social Media; Brain mapping; Deep learning; Forecasting; Knowledge based systems; Learning systems; Medical applications; Neurology; Brain imaging; Convolutional neural network; Convolutional neural network algorithm; Deep learning; Imaging neuroscience; Machine-learning; Neural networks algorithms; Performance; Transfer learning; YouTube; adult; article; biobank; brain; convolutional neural network; deep learning; female; household income; human; intelligence; kinetics; machine learning; major clinical study; male; neuroimaging; neuroscience; phenotype; prediction; residual neural network; sample size; smoking; social media; transfer of learning; videorecording; brain; diagnostic imaging; Convolutional neural networks","CIFAR Artificial Intelligence Chairs; Canada Brain Research Fund; National Institutes of Health, NIH, (R01 AG068563A, R01 R01DA053301-01A1); National Institutes of Health, NIH; Google; Canadian Institute for Advanced Research, CIFAR; Fondation Brain Canada; Health Canada; Canadian Institutes of Health Research, IRSC, (438531, CIHR 470425); Canadian Institutes of Health Research, IRSC","","Elsevier Ltd","35777174"
"de Freitas Barbosa V.A.; Félix da Silva A.; de Santana M.A.; Rabelo de Azevedo R.; Fernandes de Lima R.D.C.; dos Santos W.P.","de Freitas Barbosa, Valter Augusto (57201760368); Félix da Silva, Anderson (57894860500); de Santana, Maíra Araújo (57211919598); Rabelo de Azevedo, Rian (57894860600); Fernandes de Lima, Rita de Cássia (8986453100); dos Santos, Wellington Pinheiro (57193746428)","57201760368; 57894860500; 57211919598; 57894860600; 8986453100; 57193746428","Deep-Wavelets and convolutional neural networks to support breast cancer diagnosis on thermography images","2023","11","3","","895","913","18","10.1080/21681163.2022.2118174","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138268240&doi=10.1080%2f21681163.2022.2118174&partnerID=40&md5=84c3cf6717c0528b6b0a3920a75acd50","Breast cancer is the most dangerous type of cancer and one of the most lethal for women, both in underdeveloped and central countries. Breast thermography is an emerging imaging technique that can be applied as a complementary procedure for screening breast lesions. However, the low knowledge about the interpretation of these images by mastologists makes it difficult to adopt them in clinical practice. Computer-aided detection (CAD) systems can assist medical professionals in this task. Deep learning techniques have contributed to obtaining good results in the classification of biomedical images in general. In this work, we propose Deep-Wavelet Neural Networks (DWNN), convolutional architectures based on the general theory of Wavelets to extract features from images. For classification of thermographic images, we propose hybrid architectures based on deep network for feature extraction, Random Forests for selection of the most statistically relevant features and linear kernel support vector machines for final layer classification. We compare DWNN with next-gen deep networks. Our dataset consists of 336 thermographic images, classified into healthy (no lesion), cyst, benign lesion and malignant lesion. Experimental results show that the 6-layer DWNN achieved accuracy, sensitivity, specificity, kappa and precision above 98%. These results show that DWNN are competitive deep architectures that can be used to optimise thermographic image analysis and clinical adoption. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","breast cancer diagnosis; convolutional neural networks; Deep-Wavelet Neural Networks; Hybrid deep architectures; image diagnosis","Computer aided diagnosis; Computer aided instruction; Convolution; Decision trees; Deep neural networks; Diseases; Feature extraction; Image classification; Learning systems; Medical imaging; Network architecture; Support vector machines; Thermography (imaging); Architecture-based; Breast Cancer; Breast cancer diagnosis; Breast lesion; Convolutional neural network; Deep architectures; Deep-wavelet neural network; Hybrid deep architecture; Image diagnosis; Neural-networks; Article; breast cancer; cancer diagnosis; classifier; clinical decision making; clinical practice; computer assisted tomography; controlled study; convolutional neural network; cross validation; deep learning; deep neural network; diagnostic test accuracy study; feature extraction; female; high throughput sequencing; human; image segmentation; inception v3; learning algorithm; machine learning; mathematical analysis; measurement accuracy; mobilenet neural network; neighborhood; random forest; residual neural network; sensitivity and specificity; support vector machine; thermography; very deep convolutional network; wavelet analysis; xception nerual network; Convolutional neural networks","CAPES-PPGEC-UPE-2020; CNPq-DT2-2021; Ci?ncia e Tecnologia do Estado de Pernambuco, (IBPG-PPGEC-UPE-2020); Coordenação de Aperfeiçoamento de Pessoal de Nível Superior, CAPES; Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq; Fundação de Amparo à Ciência e Tecnologia do Estado de Pernambuco, FACEPE; Universidade de Pernambuco, UPE, (PPGEC-UPE-2020); Universidade de Pernambuco, UPE","","Taylor and Francis Ltd.",""
"Obayya M.; Haj Hassine S.B.; Alazwari S.; K. Nour M.; Mohamed A.; Motwakel A.; Yaseen I.; Sarwar Zamani A.; Abdelmageed A.A.; Mohammed G.P.","Obayya, Marwa (6505869929); Haj Hassine, Siwar Ben (57556207300); Alazwari, Sana (57867288800); K. Nour, Mohamed (57885708800); Mohamed, Abdullah (57213606201); Motwakel, Abdelwahed (57103616300); Yaseen, Ishfaq (57410292800); Sarwar Zamani, Abu (57295189700); Abdelmageed, Amgad Atta (57876641300); Mohammed, Gouse Pasha (57886165200)","6505869929; 57556207300; 57867288800; 57885708800; 57213606201; 57103616300; 57410292800; 57295189700; 57876641300; 57886165200","Aquila Optimizer with Bayesian Neural Network for Breast Cancer Detection on Ultrasound Images","2022","12","17","8679","","","","10.3390/app12178679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137843061&doi=10.3390%2fapp12178679&partnerID=40&md5=b463627ced7ee2bfa675a2a3c4b892a5","Breast cancer is the second most dominant kind of cancer among women. Breast Ultrasound images (BUI) are commonly employed for the detection and classification of abnormalities that exist in the breast. The ultrasound images are necessary to develop artificial intelligence (AI) enabled diagnostic support technologies. For improving the detection performance, Computer Aided Diagnosis (CAD) models are useful for breast cancer detection and classification. The current advancement of the deep learning (DL) model enables the detection and classification of breast cancer with the use of biomedical images. With this motivation, this article presents an Aquila Optimizer with Bayesian Neural Network for Breast Cancer Detection (AOBNN-BDNN) model on BUI. The presented AOBNN-BDNN model follows a series of processes to detect and classify breast cancer on BUI. To accomplish this, the AOBNN-BDNN model initially employs Wiener filtering (WF) related noise removal and U-Net segmentation as a pre-processing step. Besides, the SqueezeNet model derives a collection of feature vectors from the pre-processed image. Next, the BNN algorithm will be utilized to allocate appropriate class labels to the input images. Finally, the AO technique was exploited to fine-tune the parameters related to the BNN method so that the classification performance is improved. To validate the enhanced performance of the AOBNN-BDNN method, a wide experimental study is executed on benchmark datasets. A wide-ranging experimental analysis specified the enhancements of the AOBNN-BDNN method in recent techniques. © 2022 by the authors.","Aquila Optimizer; Bayesian Neural Network; breast cancer; medical images; ultrasound images","","Abdulrahman University, (PNURSP2022R203); Deanship of Scientific Research at Umm Al-Qura University, (22UQU4310373DSR31); Princess Nourah Bint Abdulrahman University, PNU; Deanship of Scientific Research, King Faisal University, DSR, KFU, (25/43)","","MDPI",""
"Pu X.; Yi P.; Chen K.; Ma Z.; Zhao D.; Ren Y.","Pu, Xiaorong (8897925500); Yi, Peng (59114073600); Chen, Kecheng (57203150190); Ma, Zhaoqi (57271734300); Zhao, Di (56701350400); Ren, Yazhou (49964327400)","8897925500; 59114073600; 57203150190; 57271734300; 56701350400; 49964327400","EEGDnet: Fusing non-local and local self-similarity for EEG signal denoising with transformer","2022","151","","106248","","","","10.1016/j.compbiomed.2022.106248","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141326028&doi=10.1016%2fj.compbiomed.2022.106248&partnerID=40&md5=316a7a9849d69e3e1e072bfadbad34ec","Electroencephalogram (EEG) has shown a useful approach to produce a brain–computer interface (BCI). One-dimensional (1-D) EEG signal is yet easily disturbed by certain artifacts (a.k.a. noise) due to the high temporal resolution. Thus, it is crucial to remove the noise in received EEG signal. Recently, deep learning-based EEG signal denoising approaches have achieved impressive performance compared with traditional ones. It is well known that the characteristics of self-similarity (including non-local and local ones) of data (e.g., natural images and time-domain signals) are widely leveraged for denoising. However, existing deep learning-based EEG signal denoising methods ignore either the non-local self-similarity (e.g., 1-D convolutional neural network) or local one (e.g., fully connected network and recurrent neural network). To address this issue, we propose a novel 1-D EEG signal denoising network with 2-D transformer, namely EEGDnet. Specifically, we comprehensively take into account the non-local and local self-similarity of EEG signal through the transformer module. By fusing non-local self-similarity in self-attention blocks and local self-similarity in feed forward blocks, the negative impact caused by noises and outliers can be reduced significantly. Extensive experiments show that, compared with other state-of-the-art models, EEGDnet achieves much better performance in terms of both quantitative and qualitative metrics. Specifically, EEGDnet can achieve 18% and 11% improvements in correlation coefficients when removing ocular artifacts and muscle artifacts, respectively. © 2022 Elsevier Ltd","Artifact removal; Electroencephalography; Transformer","Algorithms; Artifacts; Brain-Computer Interfaces; Electroencephalography; Muscles; Neural Networks, Computer; Biomedical signal processing; Brain computer interface; Convolution; Convolutional neural networks; Electrophysiology; One dimensional; Recurrent neural networks; Time domain analysis; Artifact removal; Denoising approach; Electroencephalogram signals; High temporal resolution; Local selfsimilarity; Nonlocal; One-dimensional; Performance; Self-similarities; Transformer; article; artifact; attention; controlled study; convolutional neural network; correlation coefficient; deep learning; electroencephalogram; electroencephalography; muscle; noise; recurrent neural network; algorithm; artifact; brain computer interface; procedures; Electroencephalography","Open Foundation of Nuclear Medicine Laboratory of Mianyang Central Hospital, (2021HYX017); Sichuan Province Science and Technology Support Program, (2021YFS0172, 2022YFS0047, 2022YFS0055); Sichuan Province Science and Technology Support Program; Sichuan University, SCU, (2021HXFH004); Sichuan University, SCU; University of Electronic Science and Technology of China, UESTC, (ZYGX2021YGLH022); University of Electronic Science and Technology of China, UESTC; West China Hospital, Sichuan University, WCH","","Elsevier Ltd","36343405"
"Dong Y.; Zhou S.; Xing L.; Chen Y.; Ren Z.; Dong Y.; Zhang X.","Dong, Yao (35111107100); Zhou, Shaoze (57932412400); Xing, Li (57207050158); Chen, Yumeng (57932551600); Ren, Ziyu (57931710600); Dong, Yongfeng (24922854500); Zhang, Xuekui (16053655400)","35111107100; 57932412400; 57207050158; 57932551600; 57931710600; 24922854500; 16053655400","Deep learning methods may not outperform other machine learning methods on analyzing genomic studies","2022","13","","992070","","","","10.3389/fgene.2022.992070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140082763&doi=10.3389%2ffgene.2022.992070&partnerID=40&md5=0c42c1df1b72886affa9fc3d6af713a7","Deep Learning (DL) has been broadly applied to solve big data problems in biomedical fields, which is most successful in image processing. Recently, many DL methods have been applied to analyze genomic studies. However, genomic data usually has too small a sample size to fit a complex network. They do not have common structural patterns like images to utilize pre-trained networks or take advantage of convolution layers. The concern of overusing DL methods motivates us to evaluate DL methods’ performance versus popular non-deep Machine Learning (ML) methods for analyzing genomic data with a wide range of sample sizes. In this paper, we conduct a benchmark study using the UK Biobank data and its many random subsets with different sample sizes. The original UK Biobank data has about 500k participants. Each patient has comprehensive patient characteristics, disease histories, and genomic information, i.e., the genotypes of millions of Single-Nucleotide Polymorphism (SNPs). We are interested in predicting the risk of three lung diseases: asthma, COPD, and lung cancer. There are 205,238 participants have recorded disease outcomes for these three diseases. Five prediction models are investigated in this benchmark study, including three non-deep machine learning methods (Elastic Net, XGBoost, and SVM) and two deep learning methods (DNN and LSTM). Besides the most popular performance metrics, such as the F1-score, we promote the hit curve, a visual tool to describe the performance of predicting rare events. We discovered that DL methods frequently fail to outperform non-deep ML in analyzing genomic data, even in large datasets with over 200k samples. The experiment results suggest not overusing DL methods in genomic studies, even with biobank-level sample sizes. The performance differences between DL and non-deep ML decrease as the sample size of data increases. This suggests when the sample size of data is significant, further increasing sample sizes leads to more performance gain in DL methods. Hence, DL methods could be better if we analyze genomic data bigger than this study. Copyright © 2022 Dong, Zhou, Xing, Chen, Ren, Dong and Zhang.","deep learning; disease prediction; genomic analysis; hit curve; imbalance data; machine learning","adult; aged; Article; asthma; biobank; chronic obstructive lung disease; decision tree; deep learning; deep neural network; female; forced expiratory volume; genotype; human; learning algorithm; long short term memory network; lung cancer; lung disease; machine learning; male; people by smoking status; recurrent neural network; single nucleotide polymorphism; support vector machine","Chinese State Scholarship Fund, (202108130108); Science, Technology Research Project of Higher Education in Hebei Province of China, (QN2021213); Compute Canada; Natural Sciences and Engineering Research Council of Canada, NSERC, (RGPIN-2017-04722, RGPIN-2021-03530); Canada Research Chairs, (950-231363); National Key Research and Development Program of China, NKRDPC, (2019YFC1904601)","","Frontiers Media S.A.",""
"Bose S.; Sur Chowdhury R.; Das R.; Maulik U.","Bose, Shirsha (57639719800); Sur Chowdhury, Ritesh (57230114200); Das, Rangan (57215627205); Maulik, Ujjwal (6603607810)","57639719800; 57230114200; 57215627205; 6603607810","Dense Dilated Deep Multiscale Supervised U-Network for biomedical image segmentation","2022","143","","105274","","","","10.1016/j.compbiomed.2022.105274","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123837775&doi=10.1016%2fj.compbiomed.2022.105274&partnerID=40&md5=3b7826f5186811ab8949e135692c0509","Biomedical image segmentation is essential for computerized medical image analysis. Deep learning algorithms allow us to design state-of-the-art models for solving segmentation problems. The U-Net and its variants have provided positive results across various datasets. However, the existing networks have the same receptive field at each level and the models are supervised only at the shallow level. Considering these two ideas, we have proposed the D3MSU-Net where the field of view in each level is varied depending upon the depth of the resolution layer and the model is supervised at each resolution level. We have evaluated our network in eight benchmark datasets such as Electron Microscopy, Lung segmentation, Montgomery Chest X-ray, Covid-Radiopaedia, Wound, Medetec, Brain MRI, and Covid-19 lung CT dataset. Additionally, we have provided the performance for various ablations. The experimental results show the superiority of the proposed network. The proposed D3MSU-Net and ablation models are available at www.github.com/shirshabose/D3MSUNET. © 2022 Elsevier Ltd","Biomedical image segmentation; Deep learning; Deep multiscale supervision; Dense dilated convolution","Biological organs; Computerized tomography; Deep learning; Image segmentation; Learning algorithms; Magnetic resonance imaging; Medical imaging; ART model; Biomedical image segmentation; Deep learning; Deep multiscale supervision; Dense dilated convolution; Design state; Medical image analysis; Receptive fields; Shallow levels; State of the art; Article; brain; computer assisted tomography; controlled study; convolutional neural network; coronavirus disease 2019; deep learning; diagnostic imaging; electron microscopy; human; image segmentation; intermethod comparison; medical photography; nuclear magnetic resonance imaging; supervised machine learning; thorax radiography; three-dimensional imaging; Ablation","","","Elsevier Ltd","35123135"
"Ari B.; Sobahi N.; Alçin Ö.F.; Sengur A.; Acharya U.R.","Ari, Berna (57214821334); Sobahi, Nebras (55207271000); Alçin, Ömer F. (56180663900); Sengur, Abdulkadir (12545159900); Acharya, U.Rajendra (7004510847)","57214821334; 55207271000; 56180663900; 12545159900; 7004510847","Accurate detection of autism using Douglas-Peucker algorithm, sparse coding based feature mapping and convolutional neural network techniques with EEG signals","2022","143","","105311","","","","10.1016/j.compbiomed.2022.105311","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124383156&doi=10.1016%2fj.compbiomed.2022.105311&partnerID=40&md5=f06447d1919cb462b94755bce60be6dd","Autism Spectrum Disorders (ASD) is a collection of complicated neurological disorders that first show in early childhood. Electroencephalogram (EEG) signals are widely used to record the electrical activities of the brain. Manual screening is prone to human errors, tedious, and time-consuming. Hence, a novel automated method involving the Douglas-Peucker (DP) algorithm, sparse coding-based feature mapping approach, and deep convolutional neural networks (CNNs) is employed to detect ASD using EEG recordings. Initially, the DP algorithm is used for each channel to reduce the number of samples without degradation of the EEG signal. Then, the EEG rhythms are extracted by using the wavelet transform. The EEG rhythms are coded by using the sparse representation. The matching pursuit algorithm is used for sparse coding of the EEG rhythms. The sparse coded rhythms are segmented into 8 bits length and then converted to decimal numbers. An image is formed by concatenating the histograms of the decimated rhythm signals. Extreme learning machines (ELM)-based autoencoders (AE) are employed at a data augmentation step. After data augmentation, the ASD and healthy EEG signals are classified using pre-trained deep CNN models. Our proposed method yielded an accuracy of 98.88%, the sensitivity of 100% and specificity of 96.4%, and the F1-score of 99.19% in the detection of ASD automatically. Our developed model is ready to be tested with more EEG signals before its clinical application. © 2022","Autism spectrum disorder; Deep learning; Douglas-Peucker algorithm; EEG signals","Biomedical signal processing; Brain; Convolution; Convolutional neural networks; Deep neural networks; Diseases; Feature extraction; Mapping; Wavelet transforms; Autism spectrum disorders; Convolutional neural network; Data augmentation; Deep learning; Douglas-Peucke algorithm; Electroencephalogram signals; Feature mapping; Neural network techniques; Neurological disorders; Sparse coding; Article; autism; automation; coding algorithm; convolutional neural network; diagnostic accuracy; Douglas Peucker algorithm; electric activity; electroencephalogram; histogram; human; image analysis; image reconstruction; machine learning; scoring system; sensitivity and specificity; signal processing; sparse autoencoder; wavelet transform; Electroencephalography","Naive Bayes; King Abdulaziz University, KAU, (498-135-14422); Deanship of Scientific Research, King Saud University","","Elsevier Ltd","35158117"
"Lyu F.; Ma A.J.; Yip T.C.-F.; Wong G.L.-H.; Yuen P.C.","Lyu, Fei (57286325500); Ma, Andy J. (54958223900); Yip, Terry Cheuk-Fung (56735801400); Wong, Grace Lai-Hung (9248570900); Yuen, Pong C. (9250303900)","57286325500; 54958223900; 56735801400; 9248570900; 9250303900","Weakly Supervised Liver Tumor Segmentation Using Couinaud Segment Annotation","2022","41","5","","1138","1149","11","10.1109/TMI.2021.3132905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121367012&doi=10.1109%2fTMI.2021.3132905&partnerID=40&md5=caf5ce7d1435da0c051bc31a70f9784c","Automatic liver tumor segmentation is of great importance for assisting doctors in liver cancer diagnosis and treatment planning. Recently, deep learning approaches trained with pixel-level annotations have contributed many breakthroughs in image segmentation. However, acquiring such accurate dense annotations is time-consuming and labor-intensive, which limits the performance of deep neural networks for medical image segmentation. We note that Couinaud segment is widely used by radiologists when recording liver cancer-related findings in the reports, since it is well-suited for describing the localization of tumors. In this paper, we propose a novel approach to train convolutional networks for liver tumor segmentation using Couinaud segment annotations. Couinaud segment annotations are image-level labels with values ranging from 1 to 8, indicating a specific region of the liver. Our proposed model, namely CouinaudNet, can estimate pseudo tumor masks from the Couinaud segment annotations as pixel-wise supervision for training a fully supervised tumor segmentation model, and it is composed of two components: 1) an inpainting network with Couinaud segment masks which can effectively remove tumors for pathological images by filling the tumor regions with plausible healthy-looking intensities; 2) a difference spotting network for segmenting the tumors, which is trained with healthy-pathological pairs generated by an effective tumor synthesis strategy. The proposed method is extensively evaluated on two liver tumor segmentation datasets. The experimental results demonstrate that our method can achieve competitive performance compared to the fully supervised counterpart and the state-of-the-art methods while requiring significantly less annotation effort.  © 1982-2012 IEEE.","Couinaud segment; Liver tumor segmentation; weakly-supervised learning","Humans; Image Processing, Computer-Assisted; Liver Neoplasms; Neural Networks, Computer; Supervised Machine Learning; Deep neural networks; Diagnosis; Diseases; Image annotation; Medical imaging; Pixels; Tumors; Annotation; Biomedical imaging; Cancer diagnosis; Couinaud segments; Diagnosis planning; Images segmentations; Liver cancers; Liver tumor segmentations; Treatment planning; Weakly supervised learning; analytical parameters; Article; case report; clinical article; comparative study; computer assisted tomography; convolutional neural network; couinaud segment annotation; couinaudnet model; fuzzy c means clustering; human; image segmentation; liver tumor; model; neuroimaging; nuclear magnetic resonance; pseudotumor; segmentation algorithm; supervised machine learning; diagnostic imaging; image processing; liver tumor; procedures; supervised machine learning; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.","34871168"
"Wang S.; Ouyang X.; Liu T.; Wang Q.; Shen D.","Wang, Sheng (57226712325); Ouyang, Xi (57188922178); Liu, Tianming (58741130700); Wang, Qian (57192157811); Shen, Dinggang (7401738392)","57226712325; 57188922178; 58741130700; 57192157811; 7401738392","Follow My Eye: Using Gaze to Supervise Computer-Aided Diagnosis","2022","41","7","","1688","1698","10","10.1109/TMI.2022.3146973","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124088567&doi=10.1109%2fTMI.2022.3146973&partnerID=40&md5=074c848e57368f30cb1711581ad2cb1a","When deep neural network (DNN) was first introduced to the medical image analysis community, researchers were impressed by its performance. However, it is evident now that a large number of manually labeled data is often a must to train a properly functioning DNN. This demand for supervision data and labels is a major bottleneck in current medical image analysis, since collecting a large number of annotations from experienced experts can be time-consuming and expensive. In this paper, we demonstrate that the eye movement of radiologists reading medical images can be a new form of supervision to train the DNN-based computer-aided diagnosis (CAD) system. Particularly, we record the tracks of the radiologists' gaze when they are reading images. The gaze information is processed and then used to supervise the DNN's attention via an Attention Consistency module. To the best of our knowledge, the above pipeline is among the earliest efforts to leverage expert eye movement for deep-learning-based CAD. We have conducted extensive experiments on knee X-ray images for osteoarthritis assessment. The results show that our method can achieve considerable improvement in diagnosis performance, with the help of gaze supervision.  © 1982-2012 IEEE.","computer-aided diagnosis; eye-tracking; machine attention model; Visual attention","Computers; Diagnosis, Computer-Assisted; Humans; Neural Networks, Computer; Radiologists; Behavioral research; Bottles; Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Eye movements; Eye tracking; Image analysis; Knowledge management; Medical imaging; Annotation; Attention model; Biomedical imaging; Deep learning; Eye-tracking; Machine attention model; Medical diagnostic imaging; Solid modelling; Visual Attention; X-ray imaging; Article; classification algorithm; computer assisted diagnosis; computer vision; controlled study; deep learning; deep neural network; diagnostic accuracy; diagnostic imaging; eye movement; eye tracking; gaze; human; image analysis; image quality; knee; osteoarthritis; radiologist; random walk; residual neural network; visual attention; computer; procedures; Deep neural networks","","","Institute of Electrical and Electronics Engineers Inc.","35085074"
"Raghu D.; Tripathy H.K.","Raghu, D. (57715486500); Tripathy, Hrudaya Kumar (56500423700)","57715486500; 56500423700","CNN-GRU-BASED HYBRID APPROACH FOR COVID-19 DETECTION THROUGH CHEST X-RAY IMAGES","2022","100","14","","5281","5291","10","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135579855&partnerID=40&md5=d2ac8df563f047e2d2c06b95b95e9b0d","All intelligent devices using the current world generate a massive amount of data every day. Medical field also facing challenges to classify large datasets to trace out disease cause. Automatic disease detection frame work is suitable to the current world. Programmed discovery of disease has now become an important problem in clinical science as a result of rapid population growth. A programmed location of the disease structure helps professionals identify infections and provides accurate, predictable and rapid results and reduces the rate of passage. Covid (Coronavirus) has probably had the latest and most intense illnesses and has spread all around the world. As the quickest indicative alternative, a mechanized recognition framework should therefore be used to prevent the spread of coronavirus. Coronavirus disease (COVID-19) is a contagious infection caused by a newly identified coronavirus. Automatic Disease Identification is still challenging thing at present situation. COVID-19 outbreak is the most recent risk to global health. There are currently only few COVID-19 collection is available for protecting privacy, while large data sets for CXRs are available. COVID-19 biomedical papers are growing rapidly at the same time, including reports on radiological findings. These massive data were easily identified using convolutional neural networks by classification and object identification. CNN is a popular technique for object recognition using different CNN algorithms. This paper proposes an amalgam of Deep Learning approach based on Convolutional Neural Network-CNN to extract features from Chest X-ray images, it also proposes Gated Recurrent Units GRU which can be used for the purpose of classification of Chest X-ray images. The results generated by our proposed model are as 0.94, 0.96, and 0.97 in terms of Precision. This model can aid the doctors to perform early detection of Covid-19 and makes world as Covid Free. © 2022 Little Lion Scientific.","Chest X-ray image; Classification; Convolutional Neural Network; Covid-19; Detection; Gated Recurrent Units","","","","Little Lion Scientific",""
"Wang M.","Wang, Mincheng (58149388900)","58149388900","A Modified Motor Imagery Classification Method Based on EEGNet","2022","","","","427","431","4","10.1145/3573428.3573502","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150483596&doi=10.1145%2f3573428.3573502&partnerID=40&md5=b3273bca8b81c3a76fe453f4b84b7bad","Brain-computer interfaces (BCIs) are a growing field of scientific research aiming to study how computers interpret human neural signals and take corresponding actions for communication purposes. Motor imagery-related EEG (MI-EEG) signals, generated by humans mentally simulating a given action, can be analyzed and learned by machine learning algorithms and deep learning models. EEGNet is one of the convolutional neural networks (CNNs) robust for different BCI paradigms because of its two-dimensional filters: temporal and spatial filters. In this study, I modified the EEGNet configurations into three new models with double convolutional layers for temporal, spatial, and both filters, respectively. I compared four models' binary classification performances on down-sampling and normalized MI-EEG datasets without prior feature extraction methods. The results show that: 1. All four EEGNet models with max-pooling layers perform better than using their original average-pooling layers. 2. The model with double two-dimensional filters' layers received the highest mean F1 score (71.71%) and the lowest sample standard deviation (0.0168) among all four models after repeated five runs. Compared to the original EEGNet model, only the best-performed model has a statistically significant difference (p < 0.05) in their mean F1 scores. The results suggest doubling layers for both temporal and spatial filters can increase EEGNet performance on MI-EEG classification. Therefore, it can be considered an approach to improve EEGNet in future studies. © 2022 Association for Computing Machinery.","Brain-Computer Interface; EEGNet; Motor Imagery","Beamforming; Biomedical signal processing; Classification (of information); Convolution; Deep learning; Image classification; Learning algorithms; Learning systems; Neural networks; Classification methods; EEGNet; F1 scores; Motor imagery; Motor imagery classification; Scientific researches; Spatial filters; Temporal and spatial; Temporal filters; Two-dimensional filters; Brain computer interface","","","Association for Computing Machinery",""
"Wang A.; Zhang Q.; Han Y.; Megason S.; Hormoz S.; Mosaliganti K.R.; Lam J.C.K.; Li V.O.K.","Wang, Andong (57204011526); Zhang, Qi (57218605829); Han, Yang (57197792758); Megason, Sean (6506248083); Hormoz, Sahand (23968880300); Mosaliganti, Kishore R. (14016148900); Lam, Jacqueline C. K. (57197799258); Li, Victor O. K. (7202621685)","57204011526; 57218605829; 57197792758; 6506248083; 23968880300; 14016148900; 57197799258; 7202621685","A novel deep learning-based 3D cell segmentation framework for future image-based disease detection","2022","12","1","342","","","","10.1038/s41598-021-04048-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122650123&doi=10.1038%2fs41598-021-04048-3&partnerID=40&md5=b5c21e9d1df3d1526839dabe7ae6d4a4","Cell segmentation plays a crucial role in understanding, diagnosing, and treating diseases. Despite the recent success of deep learning-based cell segmentation methods, it remains challenging to accurately segment densely packed cells in 3D cell membrane images. Existing approaches also require fine-tuning multiple manually selected hyperparameters on the new datasets. We develop a deep learning-based 3D cell segmentation pipeline, 3DCellSeg, to address these challenges. Compared to the existing methods, our approach carries the following novelties: (1) a robust two-stage pipeline, requiring only one hyperparameter; (2) a light-weight deep convolutional neural network (3DCellSegNet) to efficiently output voxel-wise masks; (3) a custom loss function (3DCellSeg Loss) to tackle the clumped cell problem; and (4) an efficient touching area-based clustering algorithm (TASCAN) to separate 3D cells from the foreground masks. Cell segmentation experiments conducted on four different cell datasets show that 3DCellSeg outperforms the baseline models on the ATAS (plant), HMS (animal), and LRP (plant) datasets with an overall accuracy of 95.6%, 76.4%, and 74.7%, respectively, while achieving an accuracy comparable to the baselines on the Ovules (plant) dataset with an overall accuracy of 82.2%. Ablation studies show that the individual improvements in accuracy is attributable to 3DCellSegNet, 3DCellSeg Loss, and TASCAN, with the 3DCellSeg demonstrating robustness across different datasets and cell shapes. Our results suggest that 3DCellSeg can serve a powerful biomedical and clinical tool, such as histo-pathological image analysis, for cancer diagnosis and grading. © 2022, The Author(s).","","Animals; Arabidopsis; Cell Membrane; Deep Learning; Embryo, Nonmammalian; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Microscopy; Predictive Value of Tests; Reproducibility of Results; Zebrafish; animal; Arabidopsis; cell membrane; comparative study; computer assisted diagnosis; cytology; embryology; microscopy; nonmammalian embryo; predictive value; reproducibility; three-dimensional imaging; zebra fish","Research Grants Council, University Grants Committee, RGC, UGC, (T41-709/17-N)","","Nature Research","35013443"
"Srivastava G.; Pradhan N.; Saini Y.","Srivastava, Gaurav (57755253400); Pradhan, Nitesh (58892452300); Saini, Yashwin (57872218700)","57755253400; 58892452300; 57872218700","Ensemble of Deep Neural Networks based on Condorcet's Jury Theorem for screening Covid-19 and Pneumonia from radiograph images","2022","149","","105979","","","","10.1016/j.compbiomed.2022.105979","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137168938&doi=10.1016%2fj.compbiomed.2022.105979&partnerID=40&md5=499e4aa730e8d73e79816bc56f6c2e3d","COVID-19 detection using Artificial Intelligence and Computer-Aided Diagnosis has been the subject of several studies. Deep Neural Networks with hundreds or even millions of parameters (weights) are referred to as ”black boxes” because their behavior is difficult to comprehend, even when the model's structure and weights are visible. On the same dataset, different Deep Convolutional Neural Networks perform differently. So, we do not necessarily have to rely on just one model; instead, we can evaluate our final score by combining multiple models. While including multiple models in the voter pool, it is not always true that the accuracy will improve. So, In this regard, the authors proposed a novel approach to determine the voting ensemble score of individual classifiers based on Condorcet's Jury Theorem (CJT). The authors demonstrated that the theorem holds while ensembling the N number of classifiers in Neural Networks. With the help of CJT, the authors proved that a model's presence in the voter pool would improve the likelihood that the majority vote will be accurate if it is more accurate than the other models. Besides this, the authors also proposed a Domain Extended Transfer Learning (DETL) ensemble model as a soft voting ensemble method and compared it with CJT based ensemble method. Furthermore, as deep learning models typically fail in real-world testing, a novel dataset has been used with no duplicate images. Duplicates in the dataset are quite problematic since they might affect the training process. Therefore, having a dataset devoid of duplicate images is considered to prevent data leakage problems that might impede the thorough assessment of the trained models. The authors also employed an algorithm for faster training to save computational efforts. Our proposed method and experimental results outperformed the state-of-the-art with the DETL-based ensemble model showing an accuracy of 97.26%, COVID-19, sensitivity of 98.37%, and specificity of 100%. CJT-based ensemble model showed an accuracy of 98.22%, COVID-19, sensitivity of 98.37%, and specificity of 99.79%. © 2022 Elsevier Ltd","Biomedical imaging; Chest X-ray images; Condorcet's Jury Theorem; COVID-19; Deep feature extraction; Ensemble Learning; Majority voting; Pneumonia","Artificial Intelligence; COVID-19; Deep Learning; Humans; Neural Networks, Computer; Pneumonia; Computation theory; Computer aided diagnosis; Convolutional neural networks; Deep neural networks; Learning systems; Medical imaging; Statistical tests; Transfer learning; Biomedical imaging; Chest X-ray image; Condorcet jury theorem; Deep feature extraction; Ensemble learning; Ensemble models; Features extraction; Majority voting; Multiple-modeling; Pneumonia; artificial intelligence; diagnostic imaging; human; pneumonia; COVID-19","Manipal University Jaipur","","Elsevier Ltd","36063689"
"Siddique N.; Paheding S.; Reyes Angulo A.A.; Alom M.Z.; Devabhaktuni V.K.","Siddique, Nahian (55900730400); Paheding, Sidike (56585990900); Reyes Angulo, Abel A. (57669722600); Alom, Md. Zahangir (35566178100); Devabhaktuni, Vijay K. (6602156750)","55900730400; 56585990900; 57669722600; 35566178100; 6602156750","Fractal, recurrent, and dense U-Net architectures with EfficientNet encoder for medical image segmentation","2022","9","6","064004","","","","10.1117/1.JMI.9.6.064004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148683947&doi=10.1117%2f1.JMI.9.6.064004&partnerID=40&md5=8513945481170c8fbcb7803cc19e1a32","Purpose: U-Net is a deep learning technique that has made significant contributions to medical image segmentation. Although the accomplishments of deep learning algorithms in terms of image processing are evident, many challenges still need to be overcome to achieve human-like performance. One of the main challenges in building deeper U-Nets is black-box problems, such as vanishing gradients. Overcoming this problem allows us to develop neural networks with advanced network designs. Approach: We propose three U-Net variants, namely efficient R2U-Net, efficient dense U-Net, and efficient fractal U-Net, that can create highly accurate segmentation maps. The first part of our contribution makes use of EfficientNet to distribute resources in the network efficiently. The second part of our work applies the following layer connections to design the U-Net decoders: residual connections, dense connections, and fractal expansion. We apply EfficientNet as the encoder to our three decoders to design three conceivable models. Results: The aforementioned three proposed deep learning models were tested on four benchmark datasets, including the CHASE DB1 and digital retinal images for vessel extraction (DRIVE) retinal image databases and the ISIC 2018 and HAM10000 dermoscopy image databases. We obtained the highest Dice coefficient of 0.8013, 0.8808, 0.8019, and 0.9295 for CHASE DB1, ISIC 2018, DRIVE, and HAM10000, respectively, and a Jaccard (JAC) score of 0.6686, 0.7870, 0.6694, and 0.8683 for CHASE DB1, ISIC 2018, DRIVE, and HAM10000, respectively. Statistical analysis revealed that the proposed deep learning models achieved better segmentation results compared with the state-of-the-art models. Conclusions: U-Net is quite an adaptable deep learning framework and can be integrated with other deep learning techniques. The use of recurrent feedback connections, dense convolution, residual skip connections, and fractal convolutional expansions allow for the design of improved deeper U-Net models. With the addition of EfficientNet, we can now leverage the performance of an optimally scaled classifier for U-Net encoders. © 2022 Society of Photo-Optical Instrumentation Engineers (SPIE).","biomedical imaging; deep learning; encoder; image segmentation; U-Net","Convolution; Decoding; Deep learning; Diagnosis; Fractals; Learning algorithms; Learning systems; Medical imaging; Ophthalmology; Signal encoding; Biomedical imaging; Deep learning; Encoder; Images segmentations; Learning techniques; Medical image segmentation; Performance; Retinal image; U-net; Vessels extraction; algorithm; article; classifier; controlled study; deep learning; epiluminescence microscopy; extraction; fractal analysis; human; human experiment; image segmentation; retina image; Image segmentation","","","SPIE",""
"Tayal A.; Gupta J.; Solanki A.; Bisht K.; Nayyar A.; Masud M.","Tayal, Akash (26423434700); Gupta, Jivansha (58282999700); Solanki, Arun (36562669800); Bisht, Khyati (57222603265); Nayyar, Anand (55201442200); Masud, Mehedi (17338820600)","26423434700; 58282999700; 36562669800; 57222603265; 55201442200; 17338820600","DL-CNN-based approach with image processing techniques for diagnosis of retinal diseases","2022","28","4","","1417","1438","21","10.1007/s00530-021-00769-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103412962&doi=10.1007%2fs00530-021-00769-7&partnerID=40&md5=dcdf6f826f0d82409fa25566c3027f39","Artificial intelligence has the potential to revolutionize disease diagnosis, classification, and identification. However, the implementation of clinical-decision support algorithms for medical imaging faces challenges with reliability and interpretability. This study presents a diagnostic tool based on a deep-learning framework for four-class classification of ocular diseases by automatically detecting diabetic macular edema, drusen, choroidal neovascularization, and normal images in optical coherence tomography (OCT) scans of the human eye. The proposed framework utilizes OCT images of the retina and analyses using three different convolution neural network (CNN) models (five, seven, and nine layers) to identify the various retinal layers extracting useful information, observe any new deviations, and predict the multiple eye deformities. The framework utilizes OCT images of the retina, which are preprocessed and processed for noise removal, contrast enhancements, contour-based edge, and detection of retinal layer extraction. This image dataset is analyzed using three different CNN models (of five, seven, and nine layers) to identify the four ocular pathologies. Results obtained from the experimental testing confirm that our model has excellently performed with 0.965 classification accuracy, 0.960 sensitivity, and 0.986 specificities compared with the manual ophthalmological diagnosis. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Biomedical imaging; Deep learning; Disease detection; Image processing; Optical coherence tomography (OCT)","Classification (of information); Computer aided diagnosis; Decision support systems; Deep learning; Image analysis; Image classification; Image enhancement; Medical imaging; Multilayer neural networks; Neural network models; Ophthalmology; Optical data processing; Biomedical imaging; Convolution neural network; Deep learning; Disease detection; Image processing technique; Images processing; Network-based approach; Neural network model; Optical coherence tomography; Retinal layers; Optical tomography","Taif University, TU, (TURSP-2020/10)","","Springer Science and Business Media Deutschland GmbH",""
"","","","Proceedings of the 13th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics, BCB 2022","2022","","","","","","549","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137316562&partnerID=40&md5=6c66de6c8e605216437affa553c4df74","The proceedings contain 67 papers. The topics discussed include: biomedical learning through graph neural networks: a hands-on approach; performance portability study of epistasis detection using SYCL on NVIDIA GPU; an Italian lexicon-based sentiment analysis approach for medical applications; image processing segmentation algorithms evaluation through implementation choices; scoliosis management through apps; scalable deep learning for healthcare: methods and applications; team building without boundaries; NBT (no-boundary thinking): needed to attend to ethical implications of data and AI; new techniques for fair and interpretable AI for biomedical applications; ai transforming drug safety evaluation; SafetAI – an AI framework to facilitate the drug safety review; a novel approach to predict drug DILI potential using FDA drug labeling; and EvoVGM: a deep variational generative model for evolutionary parameter estimation.","","","","","Association for Computing Machinery, Inc",""
"Zhang Y.; Liu S.; He Z.; Zhang Y.; Wang C.","Zhang, Yuan (55971560500); Liu, Sen (57222487791); He, Zhihui (58836460400); Zhang, Yuwei (57203486567); Wang, Changming (56527531200)","55971560500; 57222487791; 58836460400; 57203486567; 56527531200","A CNN Model for Cardiac Arrhythmias Classification Based on Individual ECG Signals","2022","13","4","","548","557","9","10.1007/s13239-021-00599-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122230165&doi=10.1007%2fs13239-021-00599-8&partnerID=40&md5=78776ab76a1388f080cc0c82e88b9bf3","Purpose: Wearable devices in the scenario of connected home healthcare integrated with artificial intelligence have been an effective alternative to the conventional medical devices. Despite various benefits of wearable electrocardiogram (ECG) device, several deficiencies remain unsolved such as noise problem caused by user mobility. Therefore, an insensitive and robust classification model for cardiac arrhythmias detection system needs to be devised. Methods: A one-dimensional seven-layer convolutional neural network (CNN) classification model with dedicated design of structure and parameters is developed to perform automatic feature extraction and classification based on large volume of original noisy signals. Record-based ten-fold cross validation scheme is devised for evaluation to ensure the independence of the training set and test set, and further improve the robustness of our method. Results: The model can effectively detect cardiac arrhythmias, and can reduce the computational workload to a certain extent. Our experimental results outperform most recent literature on the cardiac arrhythmias classification with diagnostic accuracy of 0.9874, sensitivity of 0.9811, and specificity of 0.9905 for original signals; diagnostic accuracy of 0.9876, sensitivity of 0.9813, and specificity of 0.9907 for de-noised signals, respectively. Conclusion: The evaluation indicates that our proposed approach, which performs well on both original signals and de-noised signals, fits well with wearable ECG monitoring and applications. © 2021, Biomedical Engineering Society.","Arrhythmia; Classification; Convolutional neural network (CNN); Electrocardiogram (ECG)","Algorithms; Arrhythmias, Cardiac; Artificial Intelligence; Electrocardiography; Humans; Neural Networks, Computer; Signal Processing, Computer-Assisted; Wearable Electronic Devices; Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Diseases; Heart; Multilayer neural networks; One dimensional; Wearable technology; Arrhythmia; Arrhythmia classification; Cardiac arrhythmia; Classification models; Convolutional neural network; De-noised signals; Diagnostic accuracy; Electrocardiogram; Original signal; adult; algorithm; Article; artificial intelligence; classification algorithm; controlled study; convolutional neural network; cross validation; deep learning; deep neural network; diagnostic accuracy; diagnostic test accuracy study; electrocardiogram; electrocardiography; electrocardiography monitoring; feature extraction; health care personnel; heart arrhythmia; home care; home monitoring; human; image segmentation; learning algorithm; long short term memory network; machine learning; middle aged; pattern recognition; performance; robustness; sensitivity and specificity; signal noise ratio; signal processing; support vector machine; supraventricular premature beat; training; validation process; workload; artificial intelligence; electrocardiography; electronic device; heart arrhythmia; Electrocardiograms","Introduced Talent Program of Southwest University, (SWU020008); Young and Middle-aged Senior Medical Talents Studio of Chongqing, (ZQNYXGDRCGZS2021002); National Natural Science Foundation of China, NSFC, (62172340); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Chongqing, (cstc2021jcyj-msxmX0041); Natural Science Foundation of Chongqing","","Springer","34981316"
"Ara R.K.; Matiolański A.; Dziech A.; Baran R.; Domin P.; Wieczorkiewicz A.","Ara, Rouhollah Kian (57195416442); Matiolański, Andrzej (39061696200); Dziech, Andrzej (6602903785); Baran, Remigiusz (8533456400); Domin, Paweł (57751566000); Wieczorkiewicz, Adam (57751815900)","57195416442; 39061696200; 6602903785; 8533456400; 57751566000; 57751815900","Fast and Efficient Method for Optical Coherence Tomography Images Classification Using Deep Learning Approach","2022","22","13","4675","","","","10.3390/s22134675","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132295127&doi=10.3390%2fs22134675&partnerID=40&md5=43a984e8607c4bc775357261ba77960d","The use of optical coherence tomography (OCT) in medical diagnostics is now common. The growing amount of data leads us to propose an automated support system for medical staff. The key part of the system is a classification algorithm developed with modern machine learning techniques. The main contribution is to present a new approach for the classification of eye diseases using the convolutional neural network model. The research concerns the classification of patients on the basis of OCT B-scans into one of four categories: Diabetic Macular Edema (DME), Choroidal Neovascularization (CNV), Drusen, and Normal. Those categories are available in a publicly available dataset of above 84,000 images utilized for the research. After several tested architectures, our 5-layer neural network gives us a promising result. We compared them to the other available solutions which proves the high quality of our algorithm. Equally important for the application of the algorithm is the computational time, which is reduced by the limited size of the model. In addition, the article presents a detailed method of image data augmentation and its impact on the classification results. The results of the experiments were also presented for several derived models of convolutional network architectures that were tested during the research. Improving processes in medical treatment is important. The algorithm cannot replace a doctor but, for example, can be a valuable tool for speeding up the process of diagnosis during screening tests. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","artificial neural networks; biomedical imaging; convolutional neural network; image analysis; oct; optical coherence tomog-raphy","Deep Learning; Diabetic Retinopathy; Humans; Macular Edema; Neural Networks, Computer; Tomography, Optical Coherence; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Image classification; Learning systems; Medical imaging; Network architecture; Automated support systems; Biomedical imaging; Convolutional neural network; Image-analysis; Images classification; Key parts; Learning approach; Medical diagnostics; Oct; Optical coherence tomog-raphy; diabetic retinopathy; diagnostic imaging; human; macular edema; optical coherence tomography; procedures; Optical tomography","European Commission, EC; European Regional Development Fund, ERDF","","MDPI","35808169"
"A. Mansouri R.; Ragab M.","A. Mansouri, Rasha (58046529600); Ragab, Mahmoud (55932216500)","58046529600; 55932216500","Equilibrium Optimization Algorithm with Ensemble Learning Based Cervical Precancerous Lesion Classification Model","2023","11","1","55","","","","10.3390/healthcare11010055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145889315&doi=10.3390%2fhealthcare11010055&partnerID=40&md5=15c767f1c3a30b882c3bc611765fd2db","Recently, artificial intelligence (AI) with deep learning (DL) and machine learning (ML) has been extensively used to automate labor-intensive and time-consuming work and to help in prognosis and diagnosis. AI’s role in biomedical and biological imaging is an emerging field of research and reveals future trends. Cervical cell (CCL) classification is crucial in screening cervical cancer (CC) at an earlier stage. Unlike the traditional classification method, which depends on hand-engineered or crafted features, convolution neural network (CNN) usually categorizes CCLs through learned features. Moreover, the latent correlation of images might be disregarded in CNN feature learning and thereby influence the representative capability of the CNN feature. This study develops an equilibrium optimizer with ensemble learning-based cervical precancerous lesion classification on colposcopy images (EOEL-PCLCCI) technique. The presented EOEL-PCLCCI technique mainly focuses on identifying and classifying cervical cancer on colposcopy images. In the presented EOEL-PCLCCI technique, the DenseNet-264 architecture is used for the feature extractor, and the EO algorithm is applied as a hyperparameter optimizer. An ensemble of weighted voting classifications, namely long short-term memory (LSTM) and gated recurrent unit (GRU), is used for the classification process. A widespread simulation analysis is performed on a benchmark dataset to depict the superior performance of the EOEL-PCLCCI approach, and the results demonstrated the betterment of the EOEL-PCLCCI algorithm over other DL models. © 2022 by the authors.","cervical cancer; decision making; ensemble learning; healthcare; medical imaging","","King Abdulaziz University, KAU, (246-247-1443); Deanship of Scientific Research, King Saud University","","MDPI",""
"Kasa K.; Burns D.; Goldenberg M.G.; Selim O.; Whyne C.; Hardisty M.","Kasa, Kevin (57226869254); Burns, David (57191851161); Goldenberg, Mitchell G. (57189320337); Selim, Omar (58488449100); Whyne, Cari (57207599956); Hardisty, Michael (18037113600)","57226869254; 57191851161; 57189320337; 58488449100; 57207599956; 18037113600","Multi-Modal Deep Learning for Assessing Surgeon Technical Skill","2022","22","19","7328","","","","10.3390/s22197328","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139964767&doi=10.3390%2fs22197328&partnerID=40&md5=36c1a77b27648c3f857acf5c23c9e016","This paper introduces a new dataset of a surgical knot-tying task, and a multi-modal deep learning model that achieves comparable performance to expert human raters on this skill assessment task. Seventy-two surgical trainees and faculty were recruited for the knot-tying task, and were recorded using video, kinematic, and image data. Three expert human raters conducted the skills assessment using the Objective Structured Assessment of Technical Skill (OSATS) Global Rating Scale (GRS). We also designed and developed three deep learning models: a ResNet-based image model, a ResNet-LSTM kinematic model, and a multi-modal model leveraging the image and time-series kinematic data. All three models demonstrate performance comparable to the expert human raters on most GRS domains. The multi-modal model demonstrates the best overall performance, as measured using the mean squared error (MSE) and intraclass correlation coefficient (ICC). This work is significant since it demonstrates that multi-modal deep learning has the potential to replicate human raters on a challenging human-performed knot-tying task. The study demonstrates an algorithm with state-of-the-art performance in surgical skill assessment. As objective assessment of technical skill continues to be a growing, but resource-heavy, element of surgical education, this study is an important step towards automated surgical skill assessment, ultimately leading to reduced burden on training faculty and institutes. © 2022 by the authors.","biomedical engineering; computer vision; deep learning; human activity recognition; machine learning; multi-modal; surgical education; surgical skills assessment","Algorithms; Clinical Competence; Deep Learning; Humans; Surgeons; Suture Techniques; Computer vision; Kinematics; Learning systems; Long short-term memory; Mean square error; Surgery; Deep learning; Human activity recognition; Knot-tying; Machine-learning; Multi-modal; Performance; Skill assessment; Surgical education; Surgical skill assessment; Technical skills; algorithm; article; biomedical engineering; computer vision; correlation coefficient; deep learning; human; human experiment; machine learning; mean squared error; rating scale; residual neural network; skill; surgeon; surgical training; time series analysis; videorecording; Biomedical engineering","Wyss Medical Foundation","","MDPI","36236424"
"Xie Y.; Zaccagna F.; Rundo L.; Testa C.; Agati R.; Lodi R.; Manners D.N.; Tonon C.","Xie, Yuting (57877824800); Zaccagna, Fulvio (24402331400); Rundo, Leonardo (56624605200); Testa, Claudia (56887437000); Agati, Raffaele (7003567272); Lodi, Raffaele (7006552946); Manners, David Neil (7004151863); Tonon, Caterina (6603945656)","57877824800; 24402331400; 56624605200; 56887437000; 7003567272; 7006552946; 7004151863; 6603945656","Convolutional Neural Network Techniques for Brain Tumor Classification (from 2015 to 2022): Review, Challenges, and Future Perspectives","2022","12","8","1850","","","","10.3390/diagnostics12081850","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137399723&doi=10.3390%2fdiagnostics12081850&partnerID=40&md5=dc5b12c1a7066b709b1d74d4c51aa130","Convolutional neural networks (CNNs) constitute a widely used deep learning approach that has frequently been applied to the problem of brain tumor diagnosis. Such techniques still face some critical challenges in moving towards clinic application. The main objective of this work is to present a comprehensive review of studies using CNN architectures to classify brain tumors using MR images with the aim of identifying useful strategies for and possible impediments in the development of this technology. Relevant articles were identified using a predefined, systematic procedure. For each article, data were extracted regarding training data, target problems, the network architecture, validation methods, and the reported quantitative performance criteria. The clinical relevance of the studies was then evaluated to identify limitations by considering the merits of convolutional neural networks and the remaining challenges that need to be solved to promote the clinical application and development of CNN algorithms. Finally, possible directions for future research are discussed for researchers in the biomedical and machine learning communities. A total of 83 studies were identified and reviewed. They differed in terms of the precise classification problem targeted and the strategies used to construct and train the chosen CNN. Consequently, the reported performance varied widely, with accuracies of 91.63–100% in differentiating meningiomas, gliomas, and pituitary tumors (26 articles) and of 60.0–99.46% in distinguishing low-grade from high-grade gliomas (13 articles). The review provides a survey of the state of the art in CNN-based deep learning methods for brain tumor classification. Many networks demonstrated good performance, and it is not evident that any specific methodological choice greatly outperforms the alternatives, especially given the inconsistencies in the reporting of validation methods, performance metrics, and training data encountered. Few studies have focused on clinical usability. © 2022 by the authors.","brain tumor classification; clinical application; clinical effectiveness; computer-aided diagnosis; convolutional neural network; deep learning; magnetic resonance imaging","brain tumor; cohort analysis; controlled study; convolutional neural network; data quality; deep learning; diagnostic accuracy; diagnostic test accuracy study; false negative result; futurology; glioma; histogram; human; hypophysis tumor; image processing; image registration; information processing; machine learning; meningioma; neuroimaging; nuclear magnetic resonance imaging; performance indicator; publication; quantitative analysis; Review; sensitivity and specificity; statistical bias; systematic review; tumor classification; tumor differentiation; usability; validation study","China Scholarship Council, CSC, (202008320283)","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Hu S.; Liao Z.; Zhang J.; Xia Y.","Hu, Shishuai (57219438105); Liao, Zehui (57221249827); Zhang, Jianpeng (57195070346); Xia, Yong (26427407400)","57219438105; 57221249827; 57195070346; 26427407400","Domain and Content Adaptive Convolution Based Multi-Source Domain Generalization for Medical Image Segmentation","2023","42","1","","233","244","11","10.1109/TMI.2022.3210133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139502891&doi=10.1109%2fTMI.2022.3210133&partnerID=40&md5=d1b73060edb8cb4a7eb55b0de56a007f","The domain gap caused mainly by variable medical image quality renders a major obstacle on the path between training a segmentation model in the lab and applying the trained model to unseen clinical data. To address this issue, domain generalization methods have been proposed, which however usually use static convolutions and are less flexible. In this paper, we propose a multi-source domain generalization model based on the domain and content adaptive convolution (DCAC) for the segmentation of medical images across different modalities. Specifically, we design the domain adaptive convolution (DAC) module and content adaptive convolution (CAC) module and incorporate both into an encoder-decoder backbone. In the DAC module, a dynamic convolutional head is conditioned on the predicted domain code of the input to make our model adapt to the unseen target domain. In the CAC module, a dynamic convolutional head is conditioned on the global image features to make our model adapt to the test image. We evaluated the DCAC model against the baseline and four state-of-the-art domain generalization methods on the prostate segmentation, COVID-19 lesion segmentation, and optic cup/optic disc segmentation tasks. Our results not only indicate that the proposed DCAC model outperforms all competing methods on each segmentation task but also demonstrate the effectiveness of the DAC and CAC modules. Code is available at https://git.io/DCAC.  © 1982-2012 IEEE.","deep learning; Domain generalization; dynamic convolution; medical image segmentation","COVID-19; Humans; Image Processing, Computer-Assisted; Male; Neural Networks, Computer; Optic Disk; Prostate; Codes (symbols); Deep learning; Image segmentation; Medical imaging; Adaptation models; Biomedical imaging; Content-adaptive; Deep learning; Domain generalization; Dynamic convolution; Generalisation; Head; Images segmentations; Medical image segmentation; Article; computer vision; controlled study; convolution algorithm; convolutional neural network; coronavirus disease 2019; deep learning; domain and content adaptive convolution; eye fundus; feature extraction; human; image quality; image segmentation; lung lesion; male; optic disk; optic disk cup; prostate; T2 weighted imaging; x-ray computed tomography; image processing; optic disk; procedures; Convolution","","","Institute of Electrical and Electronics Engineers Inc.","36155434"
"Elmoufidi A.; Ammoun H.","Elmoufidi, Abdelali (56252362600); Ammoun, Hind (57226315963)","56252362600; 57226315963","Diabetic Retinopathy Prevention Using EfficientNetB3 Architecture and Fundus Photography","2023","4","1","78","","","","10.1007/s42979-022-01482-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143389752&doi=10.1007%2fs42979-022-01482-6&partnerID=40&md5=dbb921421744e589793bc923c4c9aeb5","Classification of stages of diabetic retinopathy (DR) is considered a key step in the assessment and management of diabetic retinopathy. Due to damage caused by high blood sugar in the retinal blood vessels, different microscopic structures can be occupied in the retinal area, such as micro-aneurysms, hard exudate, and neovascularization. The convolutional neural network (CNN) based on deep learning has become a promising method for the analysis of biomedical images. In this work, representative images of diabetic retinopathy (DR) are divided into five categories according to the professional knowledge of ophthalmologists. This article focuses on the use of convolutional neural networks to classify background images of DR according to disease severity and on the application of pooling, Softmax activation to achieve greater accuracy. The aptos2019-blindness-detection database makes it possible to verify the performance of the proposed algorithm. © 2022, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.","Convolutional neural networks; Deep learning; Diabetic retinopathy; EfficientNet; Fundus photography","","","","Springer",""
"Rasal T.; Veerakumar T.; Subudhi B.N.; Esakkirajan S.","Rasal, Tushar (57223182545); Veerakumar, T. (24172086600); Subudhi, Badri Narayan (26423349500); Esakkirajan, S. (16051889700)","57223182545; 24172086600; 26423349500; 16051889700","Segmentation and counting of multiple myeloma cells using IEMD based deep neural network","2022","122","","106950","","","","10.1016/j.leukres.2022.106950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138503251&doi=10.1016%2fj.leukres.2022.106950&partnerID=40&md5=6f178b05928840036344b9bd2bff01ef","In biomedical image analysis, segmentation of cell nuclei from microscopic images is a highly challenging research problem. In the computer-assisted health care system, the segmented microscopic cells have been used by many biological researchers for the early prediction of various diseases. Multiple myeloma is one type of disease which is also term as a plasma cell cancer. The segmentation of the nucleus and cell is a very critical step for multiple myeloma detection. Here, In this work, we have designed two modules. One is for recognizing the nucleus of myeloma cells with a deep IEMD neural network, and the other is for differentiating the cell i.e cytoplasm. The different IMFs provides detailed frequency component of an image which are used for feature extraction. This will significantly improves the performance. We proposed a new counting algorithm for counting the myeloma-affected plasma cells in this paper. An algorithm for counting overgrowth plasma cells within the myeloid tissue has been developed using the Python TensorFlow framework. Experimental outcomes on SegPC datasets substantiate that, the proposed deep learning approach outperforms other competitive methods in myeloma recognition and detection. The result of this research indicates that, the proposed image segmentation mechanism can recognize multiple myeloma with superiority. Early detection of multiple myeloma at the initial stage increases the chances to cure patients. © 2022 Elsevier Ltd","Deep learning; Fluorescence microscopy; Image segmentation; Multiple myeloma","Algorithms; Cell Nucleus; Humans; Image Processing, Computer-Assisted; Multiple Myeloma; Neural Networks, Computer; accuracy; algorithm; Article; cell membrane; cell nucleus; controlled study; convolutional neural network; cytoplasm; deep learning; deep neural network; Fourier analysis; health care system; human; human cell; image analysis; image processing; image quality; image segmentation; learning algorithm; leukocyte; mathematical model; mathematical phenomena; multiple myeloma; myeloma cell; prediction; recall; scoring system; training; validation process; vision; diagnostic imaging; procedures","","","Elsevier Ltd","36152502"
"Guarda L.; Tapia J.E.; Droguett E.L.; Ramos M.","Guarda, Luis (57207883475); Tapia, Juan E. (7005419930); Droguett, Enrique López (6508137223); Ramos, Marcelo (7402262363)","57207883475; 7005419930; 6508137223; 7402262363","A novel Capsule Neural Network based model for drowsiness detection using electroencephalography signals","2022","201","","116977","","","","10.1016/j.eswa.2022.116977","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129383089&doi=10.1016%2fj.eswa.2022.116977&partnerID=40&md5=62f209828b78bd65aece83231f8e4e48","The early detection of drowsiness has become vital to ensure the correct and safe development of several industries’ tasks. Due to the transient mental state of a human subject between alertness and drowsiness, automated drowsiness detection is a complex problem to tackle. The electroencephalography signals allow us to record variations in an individual's brain's electrical potential, where each of them gives specific information about a subject's mental state. However, due to this type of signal's nature, its acquisition, in general, is complex, so it is hard to have a large volume of data to apply techniques of Deep Learning for processing and classification optimally. Nevertheless, Capsule Neural Networks are a brand-new Deep Learning algorithm proposed for work with reduced amounts of data. It is a robust algorithm to handle the data's hierarchical relationships, which is an essential characteristic for work with biomedical signals. Therefore, this paper presents a Deep Learning-based method for drowsiness detection with CapsNet by using a concatenation of spectrogram images of the electroencephalography signals channels. The proposed CapsNet model is compared with a Convolutional Neural Network, which is outperformed by the proposed model, which obtains an average accuracy of 86,44 % and 87,57% of sensitivity against an average accuracy of 75,86% and 79,47% sensitivity for the CNN, showing that CapsNet is more suitable for this kind of datasets and tasks. © 2022 Elsevier Ltd","Capsule Neural Network; Convolutional Neural Network; Deep Learning; Drowsiness; Electroencephalography","Bioelectric phenomena; Biomedical signal processing; Complex networks; Convolution; Convolutional neural networks; Deep learning; Electrophysiology; Learning algorithms; Capsule neural network; Complex problems; Convolutional neural network; Deep learning; Drowsiness; Drowsiness detection; Human subjects; Mental state; Network-based modeling; Neural-networks; Electroencephalography","Hessian Ministry of Higher Education, Research, Science and the Arts; National Research Center for Applied Cybersecurity ATHENE; Bundesministerium für Bildung und Forschung, BMBF; Departamento de Ingeniería Mecánica, Universidad de Chile, DIMEC; Universidad de Chile","","Elsevier Ltd",""
"Papadaki E.; Exarchos T.; Vlamos P.; Vrahatis A.","Papadaki, Eugenia (57898086900); Exarchos, Themis (8907555000); Vlamos, Panagiotis (6506847560); Vrahatis, Aristidis (55765557700)","57898086900; 8907555000; 6506847560; 55765557700","A Hybrid Deep Learning model for predicting the early Alzheimer's Disease stages using MRI","2022","","","38","","","","10.1145/3549737.3549779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138425397&doi=10.1145%2f3549737.3549779&partnerID=40&md5=95eb4e2b250172578efd858c5c3c1e15","The continuous evolution of technology in Biomedicine has given satisfactory answers for several complex diseases. Alzheimer's disease (AD), one of the major neurodegenerative diseases that cause dementia, belongs to this category. So far, no cure reverses or stops the biological changes that occur in the brains of patients; however, the early diagnosis and early intervention of Alzheimer's disease is a crucial step in reducing the burden on both the patient and the caregivers. One of the predominant ways to deal with this difficulty is by integrating artificial intelligence and large-scale biomedical data. In this direction, Magnetic resonance imaging (MRI) offers high-resolution data, which can be decrypted through artificial intelligence tools. In recent years, the research community has shifted to deep learning methods applied to medical images for the early diagnosis of Alzheimer's disease. In the present work, we propose a hybrid (called CNN-SVM) model based on Convolutional Neural Networks (CNN) and the Support Vector Machines (SVM) classifier to predict the early AD stages from MRI. Our results showed that the proposed CNN-SVM model outperforms other well-known algorithms supporting the more effective AD diagnosis.  © 2022 ACM.","Alzheimer's Disease; Convolutional Neural Networks; MRI","Bioinformatics; Biology; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Learning systems; Medical imaging; Neurodegenerative diseases; Patient treatment; Support vector machines; Alzheimers disease; Biological changes; Complex disease; Convolutional neural network; Early diagnosis; Early intervention; Evolution of technology; Learning models; Network support; Support vector machine models; Magnetic resonance imaging","European Union and Greece, (MIS 5016115)","","Association for Computing Machinery",""
"Ragab M.; Mahmoud M.M.; Asseri A.H.; Choudhry H.; Yacoub H.A.","Ragab, Mahmoud (55932216500); Mahmoud, Maged Mostafa (55561437100); Asseri, Amer H. (55920715500); Choudhry, Hani (37004303400); Yacoub, Haitham A. (54793779300)","55932216500; 55561437100; 55920715500; 37004303400; 54793779300","Optimal Deep Transfer Learning Based Colorectal Cancer Detection and Classification Model","2023","74","2","","3279","3295","16","10.32604/cmc.2023.031037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141892978&doi=10.32604%2fcmc.2023.031037&partnerID=40&md5=6c0e1cb4ba8ad5586bd57d347cc9be6a","Colorectal carcinoma (CRC) is one such dispersed cancer globally and also prominent one in causing cancer-based death. Conventionally, pathologists execute CRC diagnosis through visible scrutinizing under the microscope the resected tissue samples, stained and fixed through Haematoxylin and Eosin (H&E). The advancement of graphical processing systems has resulted in high potentiality for deep learning (DL) techniques in interpretating visual anatomy from high resolution medical images. This study develops a slime mould algorithm with deep transfer learning enabled colorectal cancer detection and classification (SMADTL-CCDC) algorithm. The presented SMADTL-CCDC technique intends to appropriately recognize the occurrence of colorectal cancer. To accomplish this, the SMADTL-CCDC model initially undergoes pre-processing to improve the input image quality. In addition, a dense-EfficientNet technique was employed to extract feature vectors from the pre-processed images. Moreover, SMA with Discrete Hopfield neural network (DHNN) method was applied for the recognition and classification of colorectal cancer. The utilization of SMA assists in appropriately selecting the parameters involved in the DHNN approach. A wide range of experiments was implemented on benchmark datasets to assess the classification performance. A comprehensive comparative study highlighted the better performance of the SMADTL-CDC model over the recent approaches. © 2023 Tech Science Press. All rights reserved.","biomedical imaging; Colorectal cancer; deep transfer learning; hyperparameter optimization; slime mould algorithm","Benchmarking; Computer aided diagnosis; Diseases; Hopfield neural networks; Image enhancement; Learning algorithms; Learning systems; Medical imaging; Molds; Biomedical imaging; Cancer classification; Cancer detection; Colorectal cancer; Deep transfer learning; Detection models; Hyper-parameter optimizations; Slime mold algorithm; Slime moulds; Transfer learning; Classification (of information)","King Abdulaziz University, KAU, (FP-000-000-1441); Deanship of Scientific Research, King Saud University","","Tech Science Press",""
"Li W.; Li J.; Wang Z.; Polson J.; Sisk A.E.; Sajed D.P.; Speier W.; Arnold C.W.","Li, Wenyuan (57413368200); Li, Jiayun (57202745945); Wang, Zichen (57218110074); Polson, Jennifer (57195351964); Sisk, Anthony E. (57189598326); Sajed, Dipti P. (57015224400); Speier, William (36870001000); Arnold, Corey W. (18436092400)","57413368200; 57202745945; 57218110074; 57195351964; 57189598326; 57015224400; 36870001000; 18436092400","PathAL: An Active Learning Framework for Histopathology Image Analysis","2022","41","5","","1176","1187","11","10.1109/TMI.2021.3135002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121814241&doi=10.1109%2fTMI.2021.3135002&partnerID=40&md5=92159fc8d5c270039e038ce5f606606f","Deep neural networks, in particular convolutional networks, have rapidly become a popular choice for analyzing histopathology images. However, training these models relies heavily on a large number of samples manually annotated by experts, which is cumbersome and expensive. In addition, it is difficult to obtain a perfect set of labels due to the variability between expert annotations. This paper presents a novel active learning (AL) framework for histopathology image analysis, named PathAL. To reduce the required number of expert annotations, PathAL selects two groups of unlabeled data in each training iteration: one 'informative' sample that requires additional expert annotation, and one 'confident predictive' sample that is automatically added to the training set using the model's pseudo-labels. To reduce the impact of the noisy-labeled samples in the training set, PathAL systematically identifies noisy samples and excludes them to improve the generalization of the model. Our model advances the existing AL method for medical image analysis in two ways. First, we present a selection strategy to improve classification performance with fewer manual annotations. Unlike traditional methods focusing only on finding the most uncertain samples with low prediction confidence, we discover a large number of high confidence samples from the unlabeled set and automatically add them for training with assigned pseudo-labels. Second, we design a method to distinguish between noisy samples and hard samples using a heuristic approach. We exclude the noisy samples while preserving the hard samples to improve model performance. Extensive experiments demonstrate that our proposed PathAL framework achieves promising results on a prostate cancer Gleason grading task, obtaining similar performance with 40% fewer annotations compared to the fully supervised learning scenario. An ablation study is provided to analyze the effectiveness of each component in PathAL, and a pathologist reader study is conducted to validate our proposed algorithm. © 1982-2012 IEEE.","active learning; curriculum learning; Histopathology image analysis; noisy label detection","Humans; Image Processing, Computer-Assisted; Male; Neoplasm Grading; Neural Networks, Computer; Prostatic Neoplasms; Computer vision; Deep neural networks; Diseases; Grading; Heuristic methods; Image annotation; Image segmentation; Iterative methods; Medical imaging; Uncertainty analysis; Active Learning; Annotation; Biomedical imaging; Curriculum learning; Histopathology image analyse; Image-analysis; Images segmentations; Noise measurements; Noisy label detection; Noisy labels; Task analysis; Uncertainty; Article; classification algorithm; comparative effectiveness; comparative study; controlled study; cross validation; curriculum; deep neural network; electron microscopy; entropy; Gleason score; histopathology; human; human tissue; image analysis; image segmentation; k means clustering; learning; machine learning; male; mammography; mean squared error; noise measurement; nuclear magnetic resonance imaging; pathologist; prediction; prostate cancer; transfer of learning; cancer grading; diagnostic imaging; image processing; prostate tumor; Image analysis","National Cancer Institute, NCI, (R21CA220352); National Cancer Institute, NCI","","Institute of Electrical and Electronics Engineers Inc.","34898432"
"Ma W.; Gong Y.; Xue H.; Liu Y.; Lin X.; Zhou G.; Li Y.","Ma, Weifeng (8384527000); Gong, Yifei (57226671311); Xue, Haojie (57470236200); Liu, Yang (57219367741); Lin, Xuefen (35107581800); Zhou, Gongxue (57226674981); Li, Yaru (57221249763)","8384527000; 57226671311; 57470236200; 57219367741; 35107581800; 57226674981; 57221249763","A lightweight and accurate double-branch neural network for four-class motor imagery classification","2022","75","","103582","","","","10.1016/j.bspc.2022.103582","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125505439&doi=10.1016%2fj.bspc.2022.103582&partnerID=40&md5=473eae8b959bbdb01423fbc79303f128","Deep learning is an important pathway for investigation of motor imagery signal classification. Nevertheless, maintaining a good compromise between performance and computational cost has been a major challenge in developing deep models for decoding motor imagery EEG. In this paper, a novel shallow double-branch convolutional neural network (DSCNN) is proposed for four-class motor imagery classification. The proposed CNN adopts parallel extraction of two branches to improve classification accuracy. Meanwhile, in order to constrain the depth of the whole network, the left branch only contained two single temporal and spatial convolutional layers to extract common EEG features. Similarly, the right branch first introduced 1D convolution to exploit the channel dependency and temporal features across multiple time-scales, secondly a depth-wise separable convolutional layer was applied for optimizing EEG signal series. Then the feature representation for final classification was obtained by merging intermediate features extracted from the two branches. Also, the DSCNN is an end-to-end decoder, as it employs the raw EEG data as inputs and does not require additional complex preprocessing. The proposed model was evaluated on public benchmark BCI competition IV dataset 2a and achieved in terms of accuracy is 85% and kappa value is 0.79. Compared with other state-of-the-art algorithms, the experiment results reveal that the DSCNN has higher decoding accuracy and robustness, as well as a 10% improvement in accuracy than the single general shallow model. Furthermore, as a lightweight architecture, the DSCNN relies on a lower computational power than similar mainstream models, which is more in line with the requirements of low delay and real-time performance in practical BCI applications. © 2022 Elsevier Ltd","Brain-computer interfaces (BCIs); Deep learning; Electroencephalography (EEG); Feature fusion; Motor imagery (MI)","Biomedical signal processing; Brain computer interface; Convolution; Convolutional neural networks; Decoding; Deep learning; Electrophysiology; Image classification; Brain-computer interface; Deep learning; Electroencephalography; Features fusions; Motor imagery; Motor imagery classification; Neural-networks; Performance costs; Signal classification; Article; classification; convolutional neural network; cross validation; deep learning; electroencephalogram; electroencephalography; feature extraction; four class motor imagery classification; human; image artifact; image processing; imagery; kernel method; learning algorithm; mathematical analysis; motor performance; support vector machine; Electroencephalography","Ministry of Education of the People's Republic of China, MOE, (20YJA880034); Ministry of Education of the People's Republic of China, MOE","","Elsevier Ltd",""
"Schilling M.P.; Ahuja N.; Rettenberger L.; Scherr T.; Reischl M.","Schilling, Marcel P. (57221699120); Ahuja, Niket (57888644700); Rettenberger, Luca (57361094700); Scherr, Tim (57211299072); Reischl, Markus (6602490688)","57221699120; 57888644700; 57361094700; 57211299072; 6602490688","Impact of Annotation Noise on Histopathology Nucleus Segmentation","2022","8","2","","197","200","3","10.1515/cdbme-2022-1051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137934248&doi=10.1515%2fcdbme-2022-1051&partnerID=40&md5=576fc3b0dc2fcb6783a408e023f4a48d","Deep learning is often used for automated diagnosis support in biomedical image processing scenarios. Annotated datasets are essential for the supervised training of deep neural networks. The problem of consistent and noise-free annotation remains for experts such as pathologists. The variability within an annotator (intra) and the variability between annotators (inter) are current challenges. In clinical practice or biology, instance segmentation is a common task, but a comprehensive and quantitative study regarding the impact of noisy annotations lacks. In this paper, we present a concept to categorize and simulate various types of annotation noise as well as an evaluation of the impact on deep learning pipelines. Thereby, we use the multi-organ histology image dataset MoNuSeg to discuss the influence of annotator variability. We provide annotation recommendations for clinicians to achieve high-quality automated diagnostic algorithms. © 2022 The Author(s), published by De Gruyter.","Annotator Variability; Deep Learning; Image Processing; Instance Segmentation","Image annotation; Image segmentation; 'current; Annotated datasets; Annotator variability; Automated diagnosis; Deep learning; Diagnosis support; Images processing; Instance segmentation; Nucleus segmentation; Supervised trainings; Deep neural networks","","","Walter de Gruyter GmbH",""
"Sharma S.; Gupta S.; Gupta D.; Rashid J.; Juneja S.; Kim J.; Elarabawy M.M.","Sharma, Sandhya (57226023345); Gupta, Sheifali (57072019200); Gupta, Deepali (57208714508); Rashid, Junaid (57203222981); Juneja, Sapna (57210408722); Kim, Jungeun (56600264800); Elarabawy, Mahmoud M. (56294009900)","57226023345; 57072019200; 57208714508; 57203222981; 57210408722; 56600264800; 56294009900","Performance Evaluation of the Deep Learning Based Convolutional Neural Network Approach for the Recognition of Chest X-Ray Images","2022","12","","932496","","","","10.3389/fonc.2022.932496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134156021&doi=10.3389%2ffonc.2022.932496&partnerID=40&md5=f02ddfb99735a5764fe4d3a3d30ca686","Recent advancement in the field of deep learning has provided promising performance for the analysis of medical images. Every year, pneumonia is the leading cause for death of various children under the age of 5 years. Chest X-rays are the first technique that is used for the detection of pneumonia. Various deep learning and computer vision techniques can be used to determine the virus which causes pneumonia using Chest X-ray images. These days, it is possible to use Convolutional Neural Networks (CNN) for the classification and analysis of images due to the availability of a large number of datasets. In this work, a CNN model is implemented for the recognition of Chest X-ray images for the detection of Pneumonia. The model is trained on a publicly available Chest X-ray images dataset having two classes: Normal chest X-ray images and Pneumonic Chest X-ray images, where each class has 5000 Samples. 80% of the collected data is used for the purpose to train the model, and the rest for testing the model. The model is trained and validated using two optimizers: Adam and RMSprop. The maximum recognition accuracy of 98% is obtained on the validation dataset. The obtained results are further compared with the results obtained by other researchers for the recognition of biomedical images. Copyright © 2022 Sharma, Gupta, Gupta, Rashid, Juneja, Kim and Elarabawy.","biomedical images; chest X-rays; convolutional neural network; deep learning; optimizers","ADAM protein; accuracy; area under the curve; Article; biomedical image; computer model; computer vision; convolutional neural network; deep learning; human; image analysis; image segmentation; learning algorithm; lung infection; machine learning; pneumonia; radiodiagnosis; support vector machine; thorax radiography; training; validation process","Ministry of Science, ICT and Future Planning, MSIP, (2021R1A4A1031509); National Research Foundation of Korea, NRF; Ministry of SMEs and Startups, MSS, (S3033853)","","Frontiers Media S.A.",""
"Prezioso E.; Izzo S.; Giampaolo F.; Piccialli F.; Dell'aversana Orabona G.; Cuocolo R.; Abbate V.; Ugga L.; Califano L.","Prezioso, Edoardo (57216155830); Izzo, Stefano (57310591900); Giampaolo, Fabio (57211201856); Piccialli, Francesco (42762051900); Dell'aversana Orabona, Giovanni (58250154000); Cuocolo, Renato (55253274100); Abbate, Vincenzo (56925112400); Ugga, Lorenzo (57189683020); Califano, Luigi (7006209535)","57216155830; 57310591900; 57211201856; 42762051900; 58250154000; 55253274100; 56925112400; 57189683020; 7006209535","Predictive Medicine for Salivary Gland Tumours Identification Through Deep Learning","2022","26","10","","4869","4879","10","10.1109/JBHI.2021.3120178","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117831880&doi=10.1109%2fJBHI.2021.3120178&partnerID=40&md5=cb728f8982c5946c101f999887f86778","Nowadays, predictive medicine begins to become a reality thanks to Artificial Intelligence (AI) which allows, through the processing of huge amounts of data, to identify correlations not perceptible to the human brain. The application of AI in predictive diagnostics is increasingly pervasive; through the use and interpretation of data, the first signs of some diseases (i.e.Tumours) can be detected to help physicians make more accurate diagnoses to reduce the errors and develop methods for individualized medical treatment. In this perspective, salivary gland tumours (SGTs) are rare cancers with variable malignancy representing less than 1% of all cancer diagnoses and about 5% of head and neck cancers. The clinical management of SGTs is complicated by a high rate of preclinical diagnostic errors. Today, fine needle aspiration cytology (FNAC) represents the primary diagnostic tool in the hands of clinicians. However, it provides information that about 25% of cases are dubious or inconclusive, complicating therapeutic choices. Thus, finding new tools supporting clinicians to make the right choices in doubtful cases is necessary. This research work presents and discusses a Deep Learning-based framework for automatic segmentation and classification of salivary gland tumours. Furthermore, we propose an explainable segmentation learning approach supporting the effectiveness of the proposed framework through a per-epoch learning process analysis and the attention map mechanism. The proposed framework was evaluated with a collected CT dataset of patients with salivary gland tumours. Experimental results show that our methodology achieves significant scores on both segmentation and classification tasks.  © 2013 IEEE.","3D segmentation; Artificial Intelligence; deep learning; diagnostic medical imaging; salivary gland tumours","Artificial Intelligence; Deep Learning; Humans; Precision Medicine; Retrospective Studies; Salivary Gland Neoplasms; Computerized tomography; Cytology; Deep learning; Diagnosis; Diseases; Image segmentation; Three dimensional displays; Tumors; 3D segmentation; Biomedical imaging; Computed tomography; Deep learning; Diagnostic medical imaging; Images segmentations; Lesion; Medical diagnostic imaging; Salivary gland tumor; Salivary glands; Three-dimensional display; Article; artificial intelligence; artificial neural network; cancer diagnosis; computer assisted diagnosis; computer assisted tomography; computer language; computer model; cytology; data processing; deep learning; diagnostic error; fine needle aspiration biopsy; human; image segmentation; learning algorithm; machine learning; prediction; python language; salivary gland tumor; u net 3d; diagnostic imaging; pathology; personalized medicine; retrospective study; Medical imaging","","","Institute of Electrical and Electronics Engineers Inc.","34648462"
"Shankar A.; Dandapat S.; Barma S.","Shankar, Anand (57218874213); Dandapat, Samarendra (15922221700); Barma, Shovan (55787081200)","57218874213; 15922221700; 55787081200","Seizure Types Classification by Generating Input Images With in-Depth Features From Decomposed EEG Signals for Deep Learning Pipeline","2022","26","10","","4903","4912","9","10.1109/JBHI.2022.3159531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126533274&doi=10.1109%2fJBHI.2022.3159531&partnerID=40&md5=64bc434966ab8d0139964176b24c6b57","Electroencephalogram (EEG) based seizure types classification has not been addressed well, compared to seizure detection, which is very important for the diagnosis and prognosis of epileptic patients. The minuscule changes reflected in EEG signals among different seizure types make such tasks more challenging. Therefore, in this work, underlying features in EEG have been explored by decomposing signals into multiple subcomponents which have been further used to generate 2D input images for deep learning (DL) pipeline. The Hilbert vibration decomposition (HVD) has been employed for decomposing the EEG signals by preserving phase information. Next, 2D images have been generated considering the first three subcomponents having high energy by involving continuous wavelet transform and converting them into 2D images for DL inputs. For classification, a hybrid DL pipeline has been constructed by combining the convolution neural network (CNN) followed by long short-term memory (LSTM) for efficient extraction of spatial and time sequence information. Experimental validation has been conducted by classifying five types of seizures and seizure-free, collected from the Temple University EEG dataset (TUH v1.5.2). The proposed method has achieved the highest classification accuracy up to 99% along with an F1-score of 99%. Further analysis shows that the HVD-based decomposition and hybrid DL model can efficiently extract in-depth features while classifying different types of seizures. In a comparative study, the proposed idea demonstrates its superiority by displaying the uppermost performance.  © 2013 IEEE.","continuous wavelet transform; Convolution neural network; electroencephalogram; hilbert vibration decomposition; long short-term memory; seizure types","Deep Learning; Electroencephalography; Epilepsy; Humans; Seizures; Wavelet Analysis; Biomedical signal processing; Brain; Classification (of information); Computer aided diagnosis; Convolution; Electroencephalography; Electrophysiology; Extraction; Feature extraction; Image segmentation; Pipelines; Wavelet decomposition; Continuous Wavelet Transform; Convolution neural network; Convolutional neural network; Features extraction; Hilbert; Hilbert vibration decomposition; Images segmentations; Images synthesis; Seizure type; accuracy; algorithm; Article; artificial intelligence; artificial neural network; continuous wavelet transform; convolutional neural network; decomposition; deep learning; diagnostic accuracy; electroencephalography; entropy; epilepsy; feature extraction; histogram; human; image processing; image quality; image segmentation; learning algorithm; principal component analysis; quality control; receiver operating characteristic; seizure; sensitivity and specificity; signal noise ratio; signal processing; support vector machine; three-dimensional imaging; visual field; diagnostic imaging; electroencephalography; epilepsy; procedures; seizure; wavelet analysis; Long short-term memory","","","Institute of Electrical and Electronics Engineers Inc.","35294366"
"Ghosh A.; Jana N.D.; Mallik S.; Zhao Z.","Ghosh, Arjun (57219433879); Jana, Nanda Dulal (54795488300); Mallik, Saurav (56213777000); Zhao, Zhongming (57755838500)","57219433879; 54795488300; 56213777000; 57755838500","Designing optimal convolutional neural network architecture using differential evolution algorithm","2023","","","100567","","","","10.1016/j.patter.2022.100567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141740726&doi=10.1016%2fj.patter.2022.100567&partnerID=40&md5=e3c68f927cd38442a20565a288744ac9","Convolutional neural networks (CNNs) are deep learning models used widely for solving various tasks like computer vision and speech recognition. CNNs are developed manually based on problem-specific domain knowledge and tricky settings, which are laborious, time consuming, and challenging. To solve these, our study develops an improved differential evolution of convolutional neural network (IDECNN) algorithm to design CNN layer architectures for image classification. Variable-length encoding is utilized to represent the flexible layer architecture of a CNN model in IDECNN. An efficient heuristic mechanism is proposed in IDECNN to evolve CNN architecture through mutation and crossover to prevent premature convergence during the evolutionary process. Eight well-known imaging datasets were utilized. The results showed that IDECNN could design suitable architecture compared with 20 existing CNN models. Finally, CNN architectures are applied to pneumonia and coronavirus disease 2019 (COVID-19) X-ray biomedical image data. The results demonstrated the usefulness of the proposed approach to generate a suitable CNN model. © 2022 The Author(s)","CNN; convolutional neural network; DE; differential evolution; DSML3: Development/pre-production: data science output has been rolled out/validated across multiple domains/problems; image classification; NAS; neural architecture search; neuroevolution; optimal neural architecture","Convolution; Convolutional neural networks; Deep learning; Domain Knowledge; Evolutionary algorithms; Image enhancement; Multilayer neural networks; Network architecture; Optimization; Speech recognition; Convolutional neural network; DE; Differential Evolution; Domain problems; DSML3: development/pre-production: data science output have been rolled out/validated across multiple domain/problem; Images classification; Multiple domains; NAS; Neural architecture search; Neural architectures; Neuro evolutions; Optimal neural architecture; Pre-production; Production data; Image classification","Cancer Prevention and Research Institute of Texas, CPRIT, (180734); Cancer Prevention and Research Institute of Texas, CPRIT","","Cell Press",""
"Wang K.; Zhang X.; Lu Y.; Zhang X.; Zhang W.","Wang, Kun (57213024990); Zhang, Xiaohong (55276997400); Lu, Yuting (57221641587); Zhang, Xiangbo (57219114472); Zhang, Wei (57225164170)","57213024990; 55276997400; 57221641587; 57219114472; 57225164170","CGRNet: Contour-guided graph reasoning network for ambiguous biomedical image segmentation","2022","75","","103621","","","","10.1016/j.bspc.2022.103621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125710797&doi=10.1016%2fj.bspc.2022.103621&partnerID=40&md5=885d0cb7f8b7928b8336770d11e69113","In this work, we propose to address the existing problem of biomedical image segmentation that often produces results, which fail to capture the exact contours of the target and suffer from ambiguity. Most previous techniques are suboptimal because they often simply concatenate contour information to alleviate this problem, while ignoring the correlation between regions and contours. As a matter of fact, the relationship between cross-domain features is an important clue for ambiguous pixel segmentation in biomedical images. To this end, we contribute a simple yet effective framework called Contour-Guided Graph Reasoning Network (CGRNet) for more accurate segmentation against ambiguity, which is capable of capturing the semantic relations between object regions and contours through graph reasoning. Specifically, we first perform a global graph representation of the low-level and high-level features extracted by the feature extractor, where clusters of pixels with similar features are mapped to each vertex. Further, we explicitly combine contour information as the geometric prior, which can aggregate features of contour pixels to graph vertices and focus on features along the boundaries. Then, the cross-domain features propagate information through the vertices on the graph to efficiently learn and reason about the semantic relations. Finally, the learned refinement graph features are projected back to the original pixel coordinate space for the final pixel-wise segmentation task. Extensive experiments on the three publicly available Kvasir, CVC-612, and COVID19-100 datasets show the effectiveness of our CGRNet with superior performance to existing state-of-the-art methods. Our code is publicly available at: https://github.com/DLWK/CGRNet. © 2022 Elsevier Ltd","Biomedical image segmentation; Computer-aided diagnosis (CAD); Contour-guided; Deep learning; Graph convolution network","Computer aided instruction; Deep learning; Graph theory; Medical imaging; Pixels; Semantic Segmentation; Semantics; Biomedical image segmentation; Computer-aided diagnose; Contour information; Contour-guided; Cross-domain; Deep learning; Domain feature; Existing problems; Graph convolution network; Semantic relations; Article; colonoscopy; computer assisted tomography; computer model; conceptual framework; contour guided graph reasoning network; controlled study; convolution algorithm; convolutional neural network; coronavirus disease 2019; data accuracy; data aggregation; feature extraction; image analysis; image segmentation; interferometry; measurement precision; reasoning; semantic web; sensitivity and specificity; Computer aided diagnosis","Chongqing Major Theme Projects, (cstc2018jszx-cyzt-zxX0017); Special key project of Chongqing technology innovation and application development, (cstc2019jscx-mbdxX0064); National Key Research and Development Program of China, NKRDPC, (2018YFB2101200); Fundamental Research Funds for the Central Universities, (2019CDYGYB014)","","Elsevier Ltd",""
"Han Q.; Hou M.; Wang H.; Wu C.; Tian S.; Qiu Z.; Zhou B.","Han, Qi (57194164653); Hou, Mingyang (57562010000); Wang, Hongyi (57764970100); Wu, Chen (59107922800); Tian, Sheng (57285659400); Qiu, Zicheng (57219636168); Zhou, Baoping (26637874000)","57194164653; 57562010000; 57764970100; 59107922800; 57285659400; 57219636168; 26637874000","EHDFL: Evolutionary hybrid domain feature learning based on windowed fast Fourier convolution pyramid for medical image classification","2023","152","","106353","","","","10.1016/j.compbiomed.2022.106353","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143121640&doi=10.1016%2fj.compbiomed.2022.106353&partnerID=40&md5=8870737cf4a7635d4ff8d72f07e539b0","With the development of modern medical technology, medical image classification has played an important role in medical diagnosis and clinical practice. Medical image classification algorithms based on deep learning emerge in endlessly, and have achieved amazing results. However, most of these methods ignore the feature representation based on frequency domain, and only focus on spatial features. To solve this problem, we propose a hybrid domain feature learning (HDFL) module based on windowed fast Fourier convolution pyramid, which combines the global features with a wide range of receptive fields in frequency domain and the local features with multiple scales in spatial domain. In order to prevent frequency leakage, we construct a Windowed Fast Fourier Convolution (WFFC) structure based on Fast Fourier Convolution (FFC). In order to learn hybrid domain features, we combine ResNet, FPN, and attention mechanism to construct a hybrid domain feature learning module. In addition, a super-parametric optimization algorithm is constructed based on genetic algorithm for our classification model, so as to realize the automation of our super-parametric optimization. We evaluated the newly published medical image classification dataset MedMNIST, and the experimental results show that our method can effectively learning the hybrid domain feature information of frequency domain and spatial domain. © 2022 Elsevier Ltd","Fast Fourier convolution; Feature extraction; Frequency domain learning; Genetic algorithm; Medical image","Algorithms; Automation; Biomedical engineering; Classification (of information); Computer aided diagnosis; Convolution; Deep learning; Frequency domain analysis; Image classification; Learning algorithms; Learning systems; Medical imaging; Domain feature; Domain learning; Fast fourier; Fast fourier convolution; Features extraction; Frequency domain learning; Frequency domains; Hybrid domain; Medical image; Medical image classification; article; attention; automation; feature extraction; genetic algorithm; learning; receptive field; residual neural network; algorithm; Genetic algorithms","Bingtuan Science and Technology Program in China, (2021AB026); Research Foundation of Natural Foundation of Chongqing City, (cstc2021jcyj-msxmX0146); Scientific and Technological Research Program of Luzhou City, (2021-JYJ-92); Chinese Academy of Sciences, CAS; Shanxi Scholarship Council of China, SXSCC, (2020-139); Shanxi Scholarship Council of China, SXSCC; Chongqing Municipal Education Commission, CQMEC, (KJQN201901537, KJZD-K201901504); Chongqing Municipal Education Commission, CQMEC; West Light Foundation of the Chinese Academy of Sciences","","Elsevier Ltd","36473339"
"Herzog N.J.; Magoulas G.D.","Herzog, Nitsa J (57221706307); Magoulas, George D. (26642991300)","57221706307; 26642991300","Convolutional Neural Networks-Based Framework for Early Identification of Dementia Using MRI of Brain Asymmetry","2022","32","12","2250053","","","","10.1142/S0129065722500538","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139064992&doi=10.1142%2fS0129065722500538&partnerID=40&md5=b6d8452fdc2624c0dae608bfcb7a330a","Computer-aided diagnosis of health problems and pathological conditions has become a substantial part of medical, biomedical, and computer science research. This paper focuses on the diagnosis of early and progressive dementia, building on the potential of deep learning (DL) models. The proposed computational framework exploits a magnetic resonance imaging (MRI) brain asymmetry biomarker, which has been associated with early dementia, and employs DL architectures for MRI image classification. Identification of early dementia is accomplished by an eight-layered convolutional neural network (CNN) as well as transfer learning of pretrained CNNs from ImageNet. Different instantiations of the proposed CNN architecture are tested. These are equipped with Softmax, support vector machine (SVM), linear discriminant (LD), or k -nearest neighbor (KNN) classification layers, assembled as a separate classification module, which are attached to the core CNN architecture. The initial imaging data were obtained from the MRI directory of the Alzheimer's disease neuroimaging initiative 3 (ADNI3) database. The independent testing dataset was created using image preprocessing and segmentation algorithms applied to unseen patients' imaging data. The proposed approach demonstrates a 90.12% accuracy in distinguishing patients who are cognitively normal subjects from those who have Alzheimer's disease (AD), and an 86.40% accuracy in detecting early mild cognitive impairment (EMCI).  © 2022 World Scientific Publishing Company.","brain asymmetry; CNN architecture; dementia; MRI; transfer learning","Alzheimer Disease; Brain; Cognitive Dysfunction; Humans; Magnetic Resonance Imaging; Neural Networks, Computer; Neuroimaging; Computer aided diagnosis; Convolution; Deep learning; Image segmentation; Magnetic resonance imaging; Multilayer neural networks; Nearest neighbor search; Network architecture; Network layers; Neurodegenerative diseases; Neuroimaging; Statistical tests; Support vector machines; Alzheimers disease; Brain asymmetry; Convolutional neural network; Convolutional neural network architecture; Dementia; Imaging data; Network-based framework; Neural network architecture; Pathological conditions; Transfer learning; Alzheimer disease; brain; cognitive defect; diagnostic imaging; human; neuroimaging; nuclear magnetic resonance imaging; pathology; procedures; Convolutional neural networks","","","World Scientific","36106446"
"Djenouri Y.; Belhadi A.; Srivastava G.; Lin J.C.-W.","Djenouri, Youcef (55652929600); Belhadi, Asma (56820083800); Srivastava, Gautam (57202588447); Lin, Jerry Chun-Wei (56449520400)","55652929600; 56820083800; 57202588447; 56449520400","Secure Collaborative Augmented Reality Framework for Biomedical Informatics","2022","26","6","","2417","2424","7","10.1109/JBHI.2021.3139575","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122585046&doi=10.1109%2fJBHI.2021.3139575&partnerID=40&md5=c371fbc852fd231d4aa490df9dffd81f","Augmented reality is currently of interest in biomedical health informatics. At the same time, several challenges have appeared, in particular with the rapid progress of smart sensor technologies, and medical artificial intelligence. This yields the necessity of new needs in biomedical health informatics. Collaborative learning and privacy are just some of the challenges of augmented reality technology in biomedical health informatics. This paper introduces a novel secure collaborative augmented reality framework for biomedical health informatics-based applications. Distributed deep learning is performed across a multi-agent system platform. The privacy strategy is then developed for ensuring better communications of the different intelligent agents in the system. In this research work, a system of multiple agents is created for the simulation of the collective behaviours of the smart components of biomedical health informatics. Augmented reality is also incorporated for better visualization of medical patterns. A novel privacy strategy based on blockchain is investigated for ensuring the confidentiality of the learning process. Experiments are conducted on real use cases of the biomedical segmentation process. Our strong experimental analysis reveals the strength of the proposed framework when directly compared to state-of-the-art biomedical health informatics solutions.  © 2013 IEEE.","augmented reality; Biomedical health informatics; distributed deep learning; multi-agent system; privacy","Artificial Intelligence; Augmented Reality; Blockchain; Confidentiality; Humans; Medical Informatics; Augmented reality; Bioinformatics; Data privacy; Deep learning; Diagnosis; Intelligent agents; Biomedical health informatic; Biomedical informatics; Collaborative augmented realities; Deep learning; Distributed deep learning; Health informatics; Intelligent sensors; Medical diagnostic imaging; Privacy; Article; artificial intelligence; artificial neural network; augmented reality; bioinformatician; blockchain; collaborative learning; computer assisted tomography; confidentiality; deep learning; echomammography; glioma; hippocampus; histology; human; image segmentation; learning algorithm; machine learning; mathematical model; mathematical parameters; mobile application; nerve cell network; nuclear magnetic resonance imaging; signal processing; skin conductance; time series analysis; traffic accident; visual memory; medical informatics; Multi agent systems","","","Institute of Electrical and Electronics Engineers Inc.","34971546"
"Morís D.I.; Hervella Á.S.; Rouco J.; Novo J.; Ortega M.","Morís, Daniel I. (57226478610); Hervella, Álvaro S. (57204014400); Rouco, José (23475243900); Novo, Jorge (57695901400); Ortega, Marcos (24475406900)","57226478610; 57204014400; 23475243900; 57695901400; 24475406900","Context encoder transfer learning approaches for retinal image analysis","2023","152","","106451","","","","10.1016/j.compbiomed.2022.106451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144614337&doi=10.1016%2fj.compbiomed.2022.106451&partnerID=40&md5=89d0cd40210315db135ec150a75daaa7","During the last years, deep learning techniques have emerged as powerful alternatives to solve biomedical image analysis problems. However, the training of deep neural networks usually needs great amounts of labeled data to be done effectively. This is even more critical in the case of biomedical imaging due to the added difficulty of obtaining data labeled by experienced clinicians. To mitigate the impact of data scarcity, one of the most commonly used strategies is transfer learning. Nevertheless, the success of this approach depends on the effectiveness of the available pre-training techniques for learning from little or no labeled data. In this work, we explore the application of the Context Encoder paradigm for transfer learning in the domain of retinal image analysis. To this aim, we propose several approaches that allow to work with full resolution images and improve the recognition of the retinal structures. In order to validate the proposals, the Context Encoder pre-trained models are fine-tuned to perform two relevant tasks in the domain: vessels segmentation and fovea localization. The experiments performed on different public datasets demonstrate that the proposed Context Encoder approaches allow mitigating the impact of data scarcity, being superior to previous alternatives in this domain. © 2022 The Author(s)","Biomedical imaging; Context Encoder; Deep learning; Eye fundus; Self-supervised learning; Transfer learning","Diagnostic Imaging; Image Processing, Computer-Assisted; Machine Learning; Neural Networks, Computer; Retina; Deep neural networks; Image analysis; Learning algorithms; Learning systems; Medical imaging; Ophthalmology; Signal encoding; Biomedical imaging; Context encoder; Data scarcity; Deep learning; Eye fundus; Labeled data; Learning approach; Retinal image analysis; Self-supervised learning; Transfer learning; article; deep learning; eye fundus; human; image analysis; learning; retina fovea; retina image; transfer of learning; diagnostic imaging; image processing; machine learning; procedures; retina; Image enhancement","CITIC; Centro de Investigación de Galicia, (ED431G 2019/01); Consellería de Educación, Universidade e Formación Profesional; Ministerio de Ciencia e Innovación y Universidades, Government of Spain, (RTI2018-095894-B-I00); Secretaría Xeral de Universidades; Instituto de Salud Carlos III, ISCIII, (DTS18/00136); Instituto de Salud Carlos III, ISCIII; Ministerio de Ciencia e Innovación, MICINN, (PID2019-108435RB-I00); Ministerio de Ciencia e Innovación, MICINN; Consellería de Cultura, Educación e Ordenación Universitaria, Xunta de Galicia, (ED431C 2020/24, ED481A 2021/196, ED481B-2022-025); Consellería de Cultura, Educación e Ordenación Universitaria, Xunta de Galicia; European Regional Development Fund, ERDF; Axencia Galega de Innovación, GAIN; Xunta de Galicia, (IN845D 2020/38); Xunta de Galicia; Universidade da Coruña","","Elsevier Ltd","36571941"
"Güler M.; Namlı E.","Güler, Mustafa (58984022900); Namlı, Ersin (55499104800)","58984022900; 55499104800","Skin Cancer Detection with Deep Learning Methods Using Medical Image; [Medikal Görüntüler Kullanılarak Derin Öğrenme Yöntemleriyle Cilt Kanseri Tespiti]","2022","2","2","","1","10","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200895608&partnerID=40&md5=0222909f46514a14afa0dbdd2033f009","With the development of machine learning and deep learning models, very successful results have been obtained in recent years, especially in the field of biomedical image processing. Medical imaging techniques such as computed tomography (CT), magnetic resonance imaging (MR), mammography, X-ray, and ultrasound serve as a preliminary reference for specialists for the diagnosis and treatment of diseases. However, in recent years, deep learning techniques have been used in the field of health in order to diagnose diseases earlier and to reduce the density of specialists, as well as to minimize the mistakes that can be made in diagnosis and diagnosis. With the increasing amount of data and the development of mathematical models, deep learning techniques have started to be preferred a lot. In this study, the application of deep learning methods in the field of medical image processing is examined. The skin cancer dataset, which is considered as a dataset, classification and disease diagnosis, image creation, improvement and transformation processes are examined, and the classification results obtained with four different pre-trained Convolutional neural network architectures (CNN) are examined. The results obtained are also classified by classical machine learning techniques. As a result, an accuracy rate of 87% was obtained in the classification made with ResNet, one of the CNN algorithms, and the Support vector machines (SVM) algorithm, which had the highest rate in the classification made with machine learning techniques, achieved success with an accuracy rate of 0.848%. © 2022, Ebru Bagci. All rights reserved.","Classification; Convolutional Neural Network; Deep Learning; Image Processing","","","","Ebru Bagci",""
"Rajput G.; Agrawal S.; Biyani K.; Vishvakarma S.K.","Rajput, Gunjan (57212573692); Agrawal, Shashank (57224899713); Biyani, Kunika (57415320400); Vishvakarma, Santosh Kumar (6506346978)","57212573692; 57224899713; 57415320400; 6506346978","Early breast cancer diagnosis using cogent activation function-based deep learning implementation on screened mammograms","2022","32","4","","1101","1118","17","10.1002/ima.22701","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122957265&doi=10.1002%2fima.22701&partnerID=40&md5=f3ea1d48334fcd75f2a4551f353d08ae","Breast cancer is detected in one out of eight females worldwide. Principally biomedical image processing techniques work with images captured by a microscope and then analyzed with the help of different algorithms and methods. Instead of microscopic image diagnosis, machine learning algorithms are now incorporated to detect and diagnose therapeutic imagery. Computer-aided mechanisms are used for better efficiency and reliability compared with manual pathological detection systems. Machine learning algorithms detect tumors by extracting features through a convolutional neural network (CNN) and then classifying them using a fully connected network. As Machine learning does not require prior expertise, it is profoundly used in biomedical imaging. This article has customized a convolutional neural network by mathematical modeling of a proposed activation function. We have obtained an appreciable prediction accuracy of up to 99%, along with a precision of 0.97. © 2022 Wiley Periodicals LLC.","breast cancer classification; convolutional neural network; deep learning; detection; Mias dataset","Bioinformatics; Chemical activation; Convolutional neural networks; Deep learning; Diagnosis; Diseases; Functions; Learning algorithms; Medical imaging; Activation functions; Breast Cancer; Breast cancer diagnosis; Computer-aided; Convolutional neural network; Early breast cancer; Image diagnosis; Image processing technique; Machine learning algorithms; Microscopic image; Convolution","Council of Scientific and Industrial Research, India, CSIR, (09/1022(0026)/2016‐EMR‐I)","","John Wiley and Sons Inc",""
"Melanthota S.K.; Gopal D.; Chakrabarti S.; Kashyap A.A.; Radhakrishnan R.; Mazumder N.","Melanthota, Sindhoora Kaniyala (57213160242); Gopal, Dharshini (57211640570); Chakrabarti, Shweta (57218394179); Kashyap, Anirudh Ameya (57387777200); Radhakrishnan, Raghu (7103113006); Mazumder, Nirmal (55033976900)","57213160242; 57211640570; 57218394179; 57387777200; 7103113006; 55033976900","Deep learning-based image processing in optical microscopy","2022","14","2","","463","481","18","10.1007/s12551-022-00949-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127710075&doi=10.1007%2fs12551-022-00949-3&partnerID=40&md5=04945e69c16b1b93840a247aa6b5add9","Optical microscopy has emerged as a key driver of fundamental research since it provides the ability to probe into imperceptible structures in the biomedical world. For the detailed investigation of samples, a high-resolution image with enhanced contrast and minimal damage is preferred. To achieve this, an automated image analysis method is preferable over manual analysis in terms of both speed of acquisition and reduced error accumulation. In this regard, deep learning (DL)-based image processing can be highly beneficial. The review summarises and critiques the use of DL in image processing for the data collected using various optical microscopic techniques. In tandem with optical microscopy, DL has already found applications in various problems related to image classification and segmentation. It has also performed well in enhancing image resolution in smartphone-based microscopy, which in turn enablse crucial medical assistance in remote places. Graphical abstract: [Figure not available: see fulltext.]. © 2022, The Author(s).","Deep learning; Image processing; Machine learning; Optical microscopy","actin; eosin; hematoxylin; microsphere; adenocarcinoma; artificial neural network; bright field microscopy; cell nucleus; cell vacuole; convolutional neural network; cytoplasm; deep learning; diagnostic accuracy; endoplasmic reticulum; endosome; fluorescence imaging; fluorescence microscopy; Golgi complex; health care system; human; hyperkeratosis; image analysis; image processing; image quality; keratosis; learning algorithm; light-sheet microscopy; machine learning; microfluidics; microscopy; mitochondrion; mouth cancer; multiphoton microscopy; non small cell lung cancer; nucleolus; phase contrast microscopy; predictive value; quantitative phase microscopy; raman microscopy; Raman spectrometry; receiver operating characteristic; Review; squamous cell carcinoma","Manipal Academy of Higher Education; Manipal School of Life Sciences; Department of Science and Technology, Ministry of Science and Technology, India, डीएसटी, (DST/INT/BLG/P-03/2019, DST/INT/Thai/P-10/2019)","","Springer Science and Business Media Deutschland GmbH",""
"Müller H.; Holzinger A.; Plass M.; Brcic L.; Stumptner C.; Zatloukal K.","Müller, Heimo (7404944998); Holzinger, Andreas (23396282000); Plass, Markus (57190968111); Brcic, Luka (7801511896); Stumptner, Cornelia (36954777000); Zatloukal, Kurt (23989863900)","7404944998; 23396282000; 57190968111; 7801511896; 36954777000; 23989863900","Explainability and causability for artificial intelligence-supported medical image analysis in the context of the European In Vitro Diagnostic Regulation","2022","70","","","67","72","5","10.1016/j.nbt.2022.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129985136&doi=10.1016%2fj.nbt.2022.05.002&partnerID=40&md5=f248f5c84d52aee66a2002b997c3264e","Artificial Intelligence (AI) for the biomedical domain is gaining significant interest and holds considerable potential for the future of healthcare, particularly also in the context of in vitro diagnostics. The European In Vitro Diagnostic Medical Device Regulation (IVDR) explicitly includes software in its requirements. This poses major challenges for In Vitro Diagnostic devices (IVDs) that involve Machine Learning (ML) algorithms for data analysis and decision support. This can increase the difficulty of applying some of the most successful ML and Deep Learning (DL) methods to the biomedical domain, just by missing the required explanatory components from the manufacturers. In this context, trustworthy AI has to empower biomedical professionals to take responsibility for their decision-making, which clearly raises the need for explainable AI methods. Explainable AI, such as layer-wise relevance propagation, can help in highlighting the relevant parts of inputs to, and representations in, a neural network that caused a result and visualize these relevant parts. In the same way that usability encompasses measurements for the quality of use, the concept of causability encompasses measurements for the quality of explanations produced by explainable AI methods. This paper describes both concepts and gives examples of how explainability and causability are essential in order to demonstrate scientific validity as well as analytical and clinical performance for future AI-based IVDs. © 2022","Causability; Explainability; In vitro diagnostic device regulation; IVDR; Medical AI; Regulatory requirements; Retractability; Scientific validity","Algorithms; Artificial Intelligence; Machine Learning; Neural Networks, Computer; Software; Backpropagation; Decision making; Decision support systems; Deep learning; Diagnosis; Medical imaging; Causability; Diagnostic device; Explainability; In vitro diagnostic device regulation; In-vitro diagnostic; IVDR; Medical artificial intelligence; Regulatory requirements; Retractability; Scientific validity; Article; artificial intelligence; decision making; decision support system; deep learning; human; image analysis; immunohistochemistry; in vitro study; machine learning; medical device regulation; survival prediction; algorithm; software; Multilayer neural networks","CY-Biobank, (824087); EOSC-Life, (733112, 874662, 945358); Google; European Commission, EC; Austrian Science Fund, FWF, (P-32554); Österreichische Forschungsförderungsgesellschaft, FFG, (879881); Horizon 2020, (857122); Bundesministerium für Bildung, Wissenschaft und Forschung, BMBWF, (10.470/0010-V/3c/2018-2023)","","Elsevier B.V.","35526802"
"Georgescu M.-I.; Ionescu R.T.; Miron A.-I.; Savencu O.; Ristea N.-C.; Verga N.; Khan F.S.","Georgescu, Mariana-Iuliana (57209136035); Ionescu, Radu Tudor (55201293400); Miron, Andreea-Iuliana (57311038400); Savencu, Olivian (57311409800); Ristea, Nicolae-Catalin (57212104343); Verga, Nicolae (36118439000); Khan, Fahad Shahbaz (36100204000)","57209136035; 55201293400; 57311038400; 57311409800; 57212104343; 36118439000; 36100204000","Multimodal Multi-Head Convolutional Attention with Various Kernel Sizes for Medical Image Super-Resolution","2023","","","","2194","2204","10","10.1109/WACV56688.2023.00223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141169935&doi=10.1109%2fWACV56688.2023.00223&partnerID=40&md5=ced13d131878b6a58493456cc66a00eb","Super-resolving medical images can help physicians in providing more accurate diagnostics. In many situations, computed tomography (CT) or magnetic resonance imaging (MRI) techniques capture several scans (modes) during a single investigation, which can jointly be used (in a multimodal fashion) to further boost the quality of super-resolution results. To this end, we propose a novel multi-modal multi-head convolutional attention module to super-resolve CT and MRI scans. Our attention module uses the convolution operation to perform joint spatial-channel attention on multiple concatenated input tensors, where the kernel (receptive field) size controls the reduction rate of the spatial attention, and the number of convolutional filters controls the reduction rate of the channel attention, respectively. We introduce multiple attention heads, each head having a distinct receptive field size corresponding to a particular reduction rate for the spatial attention. We integrate our multimodal multi-head convolutional attention (MMHCA) into two deep neural architectures for super-resolution and conduct experiments on three data sets. Our empirical results show the superiority of our attention module over the state-of-the-art attention mechanisms used in super-resolution. Moreover, we conduct an ablation study to assess the impact of the components involved in our attention module, e.g. the number of inputs or the number of heads. Our code is freely available at https://github.com/lilygeorgescu/MHCA. © 2023 IEEE.","Algorithms: Computational photography; and algorithms (including transfer, low-shot, semi-, self-, and un-supervised learning); Biomedical/healthcare/medicine; formulations; image and video synthesis; Machine learning architectures","Bioinformatics; Color photography; Computerized tomography; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Medical imaging; Optical resolving power; Algorithm: computational photography; And algorithm (including transfer, low-shot, semi-, self-, and un-supervised learning); Biomedical/healthcare/medicine; Computational photography; Formulation; Images synthesis; Learning architectures; Machine learning architecture; Machine-learning; Un-supervised learning; Video synthesis; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"Li S.; Guo Y.; Pang Z.; Song W.; Hao A.; Xia B.; Qin H.","Li, Shuai (35107382000); Guo, Yuting (57205690678); Pang, Zhennan (57216704122); Song, Wenfeng (57200110246); Hao, Aimin (36445833300); Xia, Bin (57206428500); Qin, Hong (56161957400)","35107382000; 57205690678; 57216704122; 57200110246; 36445833300; 57206428500; 56161957400","Automatic Dental Plaque Segmentation Based on Local-to-Global Features Fused Self-Attention Network","2022","26","5","","2240","2251","11","10.1109/JBHI.2022.3141773","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123378561&doi=10.1109%2fJBHI.2022.3141773&partnerID=40&md5=90c6218a496d6c3fef15fe255fe0eeb7","The accurate detection of dental plaque at an early stage will definitely prevent periodontal diseases and dental caries. However, it remains difficult for the current dental examination to accurately recognize dental plaque without using medical dyeing reagent due to the low contrast between dental plaque and healthy teeth. To combat this problem, this paper proposes a novel network enhanced by a self-attention module for intelligent dental plaque segmentation. The key motivation is to directly utilize oral endoscope images (bypassing the need for dyeing reagent) and get accurate pixel-level dental plaque segmentation results. The algorithm needs to conduct self-attention at the super-pixel level and fuse the super-pixels' local-to-global features. Our newly-designed network architecture will afford the simultaneous fusion of multiple-scale complementary information guided by the powerful deep learning paradigm. The critical fused information includes the statistical distribution of the plaques color, the heat kernel signature (HKS) based local-to-global structure relationship, and the circle-LBP based local texture pattern in the nearby regions centering around the plaque area. To further refine the fuzed multiple-scale features, we devise an attention module based on CNN, which could focalize the regions of interest in plaque more easily, especially for many challenging cases. Extensive experiments and comprehensive evaluations confirm that, for a small-scale training dataset, our method could outperform the state-of-the-art methods. Meanwhile, the user studies verify the claim that our method is more accurate than conventional dental practice conducted by experienced dentists.  © 2013 IEEE.","Automatic segmentation; dental plaque; feature fusion; self-attention based deep network","Algorithms; Dental Caries; Dental Plaque; Humans; Image Processing, Computer-Assisted; Plaque, Atherosclerotic; Deep learning; Dyeing; Feature extraction; Medical imaging; Network architecture; Pixels; Automatic segmentations; Biomedical imaging; Dental plaques; Features extraction; Features fusions; Images segmentations; Self-attention based deep network; Shape; Task analysis; Tooth; Article; attention network; classification algorithm; convolutional neural network; deep learning; endoscopy; feature learning (machine learning); human; image analysis; image segmentation; information processing; kernel method; learning algorithm; machine learning; natural language processing; network learning; tooth plaque; algorithm; atherosclerotic plaque; dental caries; diagnostic imaging; image processing; procedures; Image segmentation","Beijing Advanced Innovation Center for Biomedical Engineering, (ZF138G1714); Beijing Natural Science Foundation-Haidian Primitive Innovation Joint Fund, (L182016); National Natural Science Foundation of China, NSFC, (62102036)","","Institute of Electrical and Electronics Engineers Inc.","35015655"
"Rezayi S.; Ghazisaeedi M.; Kalhori S.R.N.; Saeedi S.","Rezayi, Sorayya (57211579661); Ghazisaeedi, Marjan (56070775700); Kalhori, Sharareh Rostam Niakan (36495265100); Saeedi, Soheila (57202498917)","57211579661; 56070775700; 36495265100; 57202498917","Artificial intelligence approaches on X-ray-oriented images process for early detection of COVID-19","2022","12","3","","233","253","20","10.4103/jmss.jmss_111_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135704725&doi=10.4103%2fjmss.jmss_111_21&partnerID=40&md5=f463a92fe0b3b652b09748449d7bc783","Background: COVID-19 is a global public health problem that is crucially important to be diagnosed in the early stages. This study aimed to investigate the use of artificial intelligence (AI) to process X-ray-oriented images to diagnose COVID-19 disease. Methods: A systematic search was conducted in Medline (through PubMed), Scopus, ISI Web of Science, Cochrane Library, and IEEE Xplore Digital Library to identify relevant studies published until 21 September 2020. Results: We identified 208 papers after duplicate removal and filtered them into 60 citations based on inclusion and exclusion criteria. Direct results sufficiently indicated a noticeable increase in the number of published papers in July-2020. The most widely used datasets were, respectively, GitHub repository, hospital-oriented datasets, and Kaggle repository. The Keras library, Tensorflow, and Python had been also widely employed in articles. X-ray images were applied more in the selected articles. The most considerable value of accuracy, sensitivity, specificity, and Area under the ROC Curve was reported for ResNet18 in reviewed techniques; all the mentioned indicators for this mentioned network were equal to one (100%). Conclusion: This review revealed that the application of AI can accelerate the process of diagnosing COVID-19, and these methods are effective for the identification of COVID-19 cases exploiting Chest X-ray images.  © 2022 Journal of Medical Signals & Sensors.","2019-nCoV disease; artificial intelligence; computed tomography; deep learning; image processing; X-ray images","algorithm; artificial intelligence; biomedical engineering; controlled study; coronavirus disease 2019; deep learning; deep neural network; diagnostic accuracy; human; image processing; machine learning; receiver operating characteristic; Review; sensitivity and specificity; software; supervised machine learning; support vector machine; systematic review; X ray","","","Isfahan University of Medical Sciences(IUMS)",""
"Bian Y.; Xing T.; Jiao K.; Kong Q.; Wang J.; Yang X.; Yang S.; Jiang Y.; Shen R.; Shen H.; Kuang C.","Bian, Yinxu (57072684500); Xing, Tao (57219968307); Jiao, Kerong (57205208249); Kong, Qingqing (57200230096); Wang, Jiaxiong (56509743300); Yang, Xiaofei (36083718500); Yang, Shenmin (55368197000); Jiang, Yannan (58400003300); Shen, Renbing (57221844314); Shen, Hua (35220441600); Kuang, Cuifang (9238610600)","57072684500; 57219968307; 57205208249; 57200230096; 56509743300; 36083718500; 55368197000; 58400003300; 57221844314; 35220441600; 9238610600","Computational Portable Microscopes for Point-of-Care-Test and Tele-Diagnosis","2022","11","22","3670","","","","10.3390/cells11223670","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142446944&doi=10.3390%2fcells11223670&partnerID=40&md5=eb1bd4308cb277fc4f740b3cb4e731cc","In bio-medical mobile workstations, e.g., the prevention of epidemic viruses/bacteria, outdoor field medical treatment and bio-chemical pollution monitoring, the conventional bench-top microscopic imaging equipment is limited. The comprehensive multi-mode (bright/dark field imaging, fluorescence excitation imaging, polarized light imaging, and differential interference microscopy imaging, etc.) biomedical microscopy imaging systems are generally large in size and expensive. They also require professional operation, which means high labor-cost, money-cost and time-cost. These characteristics prevent them from being applied in bio-medical mobile workstations. The bio-medical mobile workstations need microscopy systems which are inexpensive and able to handle fast, timely and large-scale deployment. The development of lightweight, low-cost and portable microscopic imaging devices can meet these demands. Presently, for the increasing needs of point-of-care-test and tele-diagnosis, high-performance computational portable microscopes are widely developed. Bluetooth modules, WLAN modules and 3G/4G/5G modules generally feature very small sizes and low prices. And industrial imaging lens, microscopy objective lens, and CMOS/CCD photoelectric image sensors are also available in small sizes and at low prices. Here we review and discuss these typical computational, portable and low-cost microscopes by refined specifications and schematics, from the aspect of optics, electronic, algorithms principle and typical bio-medical applications. © 2022 by the authors.","computational imaging; point-of-care-test; portable microscope","Algorithms; Lenses; Microscopy; Microscopy, Interference; Point-of-Care Systems; eosin; hematoxylin; biocompatibility; chemical structure; computer model; confocal laser scanning microscopy; convolutional neural network; deep learning; fluorescence imaging; fluorescence microscopy; human; illumination; image analysis; image quality; image reconstruction; interference microscopy; measurement accuracy; microfluidic analysis; phase contrast microscopy; point of care testing; refraction index; Review; signal noise ratio; telecommunication; telediagnosis; three-dimensional imaging; video microscopy; algorithm; lens; microscopy; point of care system; procedures","Biopharmaceutical Industry Innovation, (SLJ2022019); National Natural Science Foundation of China, NSFC, (62005120); Natural Science Foundation of Jiangsu Province, (BK2019045, BK20201305); Suzhou University of Science and Technology, (SYSD2020132)","","MDPI","36429102"
"Kamble A.; Ghare P.H.; Kumar V.","Kamble, Ashwin (57437694200); Ghare, Pradnya H. (37019961100); Kumar, Vinay (57688390300)","57437694200; 37019961100; 57688390300","Deep-Learning-Based BCI for Automatic Imagined Speech Recognition Using SPWVD","2023","72","","4001110","","","","10.1109/TIM.2022.3216673","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141538915&doi=10.1109%2fTIM.2022.3216673&partnerID=40&md5=856e9707a176cf07878af94443dfa5a5","The electroencephalogram (EEG)-based brain-computer interface (BCI) has potential applications in neuroscience and rehabilitation. It benefits a person with neurological impairment to communicate their thoughts to the external world without using any appendages. Decoding imagined speech had limited success, mainly because neural signals are weak and more variable than overt speech, hence challenging to decode by machine-learning (ML)-based algorithms. In recent years, deep learning (DL) with convolutional neural networks (CNNs) has transformed computer vision and can perform pattern recognition better than the traditional ML-based algorithms. The objective of this article is to design a smoothed pseudo-Wigner-Ville distribution (SPWVD) and CNN-based automatic imagined speech recognition (AISR) system to recognize imagined words. This article uses a publically available 64-channel EEG dataset, collected from 15 healthy subjects for three categories: long words, short words, and vowels. The EEG signals were transformed into time-frequency representation (TFR) using SPWVD, which are used as an input to CNN such that the EEG dataset was identified and classified into binary and multiclass categories. In addition, the CNN model was optimized using a recently developed Keras-tuner library to achieve optimal performance. The performance of the SPWVD-CNN-driven AISR system is evaluated using seven performance evaluation metrics: accuracy (ACC), recall (REC), precision (PREC), Mathew's correlation coefficient (MCC), Cohen's kappa ( $\kappa $ ), F1-score, and area under the curve (AUC). It is found that the proposed system achieved the maximum classification ACCs of 94.82%, 94.26%, 94.68%, and 84.50% for long words, short-long words, short words, and vowels, respectively. The proposed AISR strengthens the possibility of using imagined speech recognition as a future BCI application.  © 1963-2012 IEEE.","Automatic imagined speech recognition (AISR); brain computer interface (BCI); convolutional neural networks (CNNs); deep learning (DL); electroencephalogram (EEG); smoothed pseudo-Wigner-Ville distribution (SPWVD); time-frequency representation (TFR)","Biomedical signal processing; Brain computer interface; Convolution; Decoding; Deep learning; Electroencephalography; Electrophysiology; Image recognition; Learning algorithms; Linguistics; Neural networks; Neurology; Wavelet transforms; Wigner-Ville distribution; Automatic imagined speech recognition; Brain-computer interface; Continuous Wavelet Transform; Convolutional neural network; Deep learning; Electroencephalogram; Features extraction; Smoothed pseudo Wigner Ville distribution; Smoothed pseudo Wigner-Ville distributions; Smoothed pseudo-wigne-ville distribution; Time-frequency Analysis; Time-frequency representation; Time-frequency representations; Speech recognition","","","Institute of Electrical and Electronics Engineers Inc.",""
"Yang Q.; Geng C.; Chen R.; Pang C.; Han R.; Lyu L.; Zhang Y.","Yang, Qinghan (57226687891); Geng, Chong (58894356800); Chen, Ruyue (57679297900); Pang, Chen (57242601700); Han, Run (57388803600); Lyu, Lei (57204062203); Zhang, Yuang (24451415400)","57226687891; 58894356800; 57679297900; 57242601700; 57388803600; 57204062203; 24451415400","DMU-Net: Dual-route mirroring U-Net with mutual learning for malignant thyroid nodule segmentation","2022","77","","103805","","","","10.1016/j.bspc.2022.103805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130414984&doi=10.1016%2fj.bspc.2022.103805&partnerID=40&md5=75ff24c29c2638fd1d0d31f0596e285c","It is meaningful for radiologists to segment thyroid nodules in ultrasound images quickly and accurately using an effective segmentation algorithm. With the rise of deep learning in computer vision, many deep learning-based methods have been proposed to assist radiologists in diagnosing thyroid diseases, such as thyroid nodule classification, detection and segmentation, but there exist few methods paying attention to malignant thyroid nodule segmentation. The goal of thyroid nodule segmentation is to identify the type of thyroid nodule. However, the identification of thyroid nodule type has been relatively well developed and the identification work almost can't bother radiologists. The more important for radiologists is to detect the inconspicuous malignant nodules precisely in ultrasonic images, avoiding radiologists confusing tissues and malignant thyroid nodules during their diagnosis. This paper proposes a deep learning-based CAD (Computer-aided diagnosis) method called Dual-route Mirroring U-Net (DMU-Net) to segment malignant thyroid nodules automatically. The method uses two subnets (U-shape subnet, inversed U-shape subnet) and three modules (pyramid attention module (PAM), margin refinement module (MRM), aggregation module (AM)) to extract contextual information of thyroid nodules and margin details in ultrasonic images. Further, the strategy of mutual learning is introduced from the natural image classification task to enhance the performance of DMU-Net. We train and evaluate our method on the self-built Malignant Thyroid Nodule Segmentation (MTNS) dataset. Finally, we compare the DMU-Net with several classical deep learning-based methods on the MTNS dataset and other public datasets. The results show our DMU-Net can achieve superior performance on these datasets. © 2022 Elsevier Ltd","Biomedical image segmentation; Convolutional neural network; Malignant thyroid nodule; Margin details extraction; U-Net","Computer aided instruction; Convolutional neural networks; Deep learning; Image enhancement; Image segmentation; Learning systems; Ultrasonic imaging; Biomedical image segmentation; Convolutional neural network; Details extractions; Dual route; Malignant thyroid nodule; Margin detail extraction; Nodule segmentation; Subnets; Thyroid nodule; U-net; Article; convolutional neural network; deep learning; feature extraction; human; image segmentation; methodology; radiologist; thyroid cancer; thyroid gland; thyroid nodule; ultrasound; Computer aided diagnosis","Jinan Science and technology innovation development Foundation, (202126003); National Natural Science Foundation of China, NSFC, (61976127); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Shandong Province, (ZR2019MF071, ZR2021LZL012); Natural Science Foundation of Shandong Province","","Elsevier Ltd",""
"Tajmirriahi M.; Amini Z.; Rabbani H.; Kafieh R.","Tajmirriahi, Mahnoosh (57222904254); Amini, Zahra (57208252371); Rabbani, Hossein (16643769100); Kafieh, Rahele (24577053200)","57222904254; 57208252371; 16643769100; 24577053200","An Interpretable Convolutional Neural Network for P300 Detection: Analysis of Time Frequency Features for Limited Data","2022","22","9","","8685","8692","7","10.1109/JSEN.2022.3159475","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126512880&doi=10.1109%2fJSEN.2022.3159475&partnerID=40&md5=cf86c4d9280e91d50f766514a0a100f4","In this study, a new deep learning-based methodology is developed for P300 detection in brain computer interface (BCI) systems based on time-frequency (TF) features of EEG signals coupled to deep learning. The TF distributions can transform EEG signals to the TF images by simultaneous representation of time and frequency properties of the signal. However, they do not display the energy distribution of signals at different scales identically and their advantages may be greatly incorporated by using them together. Here, four TF images of single-trail EEG signal are computed and the concatenation of the TF (cTF) images of each signal is developed to be used as training data for a simple and lightweight deep learning-based classifier. The applied TF distributions are spectrogram, Wigner-Ville distribution, Morlet-scalogram, and Bertrand distribution. Performance of method is evaluated over limited data acquired from the normal and amyotrophic lateral sclerosis (ALS) datasets and accuracy of 96.56%, and 96.84% are achieved respectively, which is superior to the other comparing algorithms. Moreover, results of cross-subject classification indicate the promising ability of the method in eliminating calibration in BCI systems. Furthermore, the heat maps of the P300 and non-P300 classes are produced to explain important regions of cTF image for classifier decision and investigate which TF may help better classification. Results revealed the efficiency of cTF images for accurate P300 detection in simple structure classifiers having the advantage of fewer data and less memory requirement. This method can be employed in P300 speller BCI systems to improve the character recognition performance in. © 2001-2012 IEEE.","amyotrophic lateral sclerosis (ALS); brain computer interface; convolutional neural network; P300 detection; Time-frequency analysis","Bandpass filters; Biomedical signal processing; Character recognition; Classification (of information); Convolution; Deep learning; Electroencephalography; Electrophysiology; Feature extraction; Interfaces (computer); Neural networks; Neurodegenerative diseases; Wavelet transforms; Wigner-Ville distribution; Amyotrophic lateral sclerose; Amyotrophic lateral sclerosis; Convolutional neural network; Features extraction; P300 detection; Support vectors machine; Time-frequency Analysis; Wavelets transform; Brain computer interface","","","Institute of Electrical and Electronics Engineers Inc.",""
"Yoo J.; Yoo I.; Youn I.; Kim S.-M.; Yu R.; Kim K.; Kim K.; Lee S.-B.","Yoo, Jaesung (57221148546); Yoo, Ilhan (57192396953); Youn, Ina (57911599000); Kim, Sung-Min (57837876800); Yu, Ri (57089569800); Kim, Kwangsoo (57210575084); Kim, Keewon (7409321771); Lee, Seung-Bo (57417738100)","57221148546; 57192396953; 57911599000; 57837876800; 57089569800; 57210575084; 7409321771; 57417738100","Residual one-dimensional convolutional neural network for neuromuscular disorder classification from needle electromyography signals with explainability","2022","226","","107079","","","","10.1016/j.cmpb.2022.107079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139062697&doi=10.1016%2fj.cmpb.2022.107079&partnerID=40&md5=5aedf2c443f2917633dc0636e7a3d703","Background and Objective: Neuromuscular disorders are diseases that damage our ability to control body movements. Needle electromyography (nEMG) is often used to diagnose neuromuscular disorders, which is an electrophysiological test measuring electric signals generated from a muscle using an invasive needle. Characteristics of nEMG signals are manually analyzed by an electromyographer to diagnose the types of neuromuscular disorders, and this process is highly dependent on the subjective experience of the electromyographer. Contemporary computer-aided methods utilized deep learning image classification models to classify nEMG signals which are not optimized for classifying signals. Additionally, model explainability was not addressed which is crucial in medical applications. This study aims to improve prediction accuracy, inference time, and explain model predictions in nEMG neuromuscular disorder classification. Methods: This study introduces the nEMGNet, a one-dimensional convolutional neural network with residual connections designed to extract features from raw signals with higher accuracy and faster speed compared to image classification models from previous works. Next, the divide-and-vote (DiVote) algorithm was designed to integrate each subject's heterogeneous nEMG signal data structures and to utilize muscle subtype information for higher accuracy. Finally, feature visualization was used to identify the causality of nEMGNet diagnosis predictions, to ensure that nEMGNet made predictions on valid features, not artifacts. Results: The proposed method was tested using 376 nEMG signals measured from 57 subjects between June 2015 to July 2020 in Seoul National University Hospital. The results from the three-class classification task demonstrated that nEMGNet's prediction accuracy of nEMG signal segments was 62.35%, and the subject diagnosis prediction accuracy of nEMGNet and the DiVote algorithm was 83.69 %, over 5-fold cross-validation. nEMGNet outperformed all models from previous works on nEMG diagnosis classification, and heuristic analysis of feature visualization results indicate that nEMGNet learned relevant nEMG signal characteristics. Conclusions: This study introduced nEMGNet and DiVote algorithm which demonstrated fast and accurate performance in predicting neuromuscular disorders based on nEMG signals. The proposed method may be applied in medicine to support real-time electrophysiologic diagnosis. © 2022 The Authors","Convolutional Neural Network; Deep Learning; Electrophysiologic Diagnosis; Feature Visualization; Needle Electromyography; Neuromuscular Disorder","Algorithms; Electromyography; Humans; Movement; Neural Networks, Computer; Biomedical signal processing; Computer aided analysis; Computer aided diagnosis; Convolutional neural networks; Deep learning; Disease control; Electrophysiology; Forecasting; Image classification; Medical applications; Medical imaging; Muscle; Needles; Three dimensional computer graphics; Visualization; Convolutional neural network; Deep learning; Electromyography signals; Electrophysiologic diagnose; Feature visualization; Images classification; Needle electromyography; Neuromuscular disorders; One-dimensional; Prediction accuracy; algorithm; Article; artifact; controlled study; convolutional neural network; cross validation; deep learning; diagnostic accuracy; electromyogram; human; major clinical study; needle electromyography; neuromuscular disease; prediction; South Korea; velocity; algorithm; electromyography; movement (physiology); procedures; Convolution","Ministry of Trade, Industry and Energy, MOTIE; Ministry of Food and Drug Safety, MFDS, (202011B23); Ministry of Food and Drug Safety, MFDS; Ministry of Science, ICT and Future Planning, MSIP; Ministry of Health and Welfare, MOHW","","Elsevier Ireland Ltd","36191354"
"Mughal N.E.; Khan M.J.; Khalil K.; Javed K.; Sajid H.; Naseer N.; Ghafoor U.; Hong K.-S.","Mughal, Nabeeha Ehsan (57238776700); Khan, Muhammad Jawad (55607228600); Khalil, Khurram (57216786839); Javed, Kashif (24776418700); Sajid, Hasan (35148450600); Naseer, Noman (55607545300); Ghafoor, Usman (57196318212); Hong, Keum-Shik (7402515710)","57238776700; 55607228600; 57216786839; 24776418700; 35148450600; 55607545300; 57196318212; 7402515710","EEG-fNIRS-based hybrid image construction and classification using CNN-LSTM","2022","16","","873239","","","","10.3389/fnbot.2022.873239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138249974&doi=10.3389%2ffnbot.2022.873239&partnerID=40&md5=fa4413dcdd299009aa2364d606d6a705","The constantly evolving human–machine interaction and advancement in sociotechnical systems have made it essential to analyze vital human factors such as mental workload, vigilance, fatigue, and stress by monitoring brain states for optimum performance and human safety. Similarly, brain signals have become paramount for rehabilitation and assistive purposes in fields such as brain–computer interface (BCI) and closed-loop neuromodulation for neurological disorders and motor disabilities. The complexity, non-stationary nature, and low signal-to-noise ratio of brain signals pose significant challenges for researchers to design robust and reliable BCI systems to accurately detect meaningful changes in brain states outside the laboratory environment. Different neuroimaging modalities are used in hybrid settings to enhance accuracy, increase control commands, and decrease the time required for brain activity detection. Functional near-infrared spectroscopy (fNIRS) and electroencephalography (EEG) measure the hemodynamic and electrical activity of the brain with a good spatial and temporal resolution, respectively. However, in hybrid settings, where both modalities enhance the output performance of BCI, their data compatibility due to the huge discrepancy between their sampling rate and the number of channels remains a challenge for real-time BCI applications. Traditional methods, such as downsampling and channel selection, result in important information loss while making both modalities compatible. In this study, we present a novel recurrence plot (RP)-based time-distributed convolutional neural network and long short-term memory (CNN-LSTM) algorithm for the integrated classification of fNIRS EEG for hybrid BCI applications. The acquired brain signals are first projected into a non-linear dimension with RPs and fed into the CNN to extract essential features without performing any downsampling. Then, LSTM is used to learn the chronological features and time-dependence relation to detect brain activity. The average accuracies achieved with the proposed model were 78.44% for fNIRS, 86.24% for EEG, and 88.41% for hybrid EEG-fNIRS BCI. Moreover, the maximum accuracies achieved were 85.9, 88.1, and 92.4%, respectively. The results confirm the viability of the RP-based deep-learning algorithm for successful BCI systems. Copyright © 2022 Mughal, Khan, Khalil, Javed, Sajid, Naseer, Ghafoor and Hong.","brain computer interface (BCI); convolutional neural networks (CNN); long-short term memory (LSTM); recurrence plots (RP); time distributional layers","Biomedical signal processing; Brain; Brain computer interface; Convolution; Convolutional neural networks; Electrophysiology; Feature extraction; Functional neuroimaging; Image classification; Infrared devices; Long short-term memory; Multilayer neural networks; Near infrared spectroscopy; Neurophysiology; Signal sampling; Signal to noise ratio; Brain computer interface; Brain signals; Brain state; Convolutional neural network; Functional near infrared spectroscopy; Long-short term memory; Recurrence plot; Time distributional layer; acceleration; accuracy; Article; artificial neural network; brain blood flow; brain function; convolutional neural network; decision tree; deep learning; electroencephalography; functional near-infrared spectroscopy; human; human experiment; imagery; k nearest neighbor; memory cell; nerve cell network; neuroimaging; neuromodulation; predictive value; sensitivity and specificity; short term memory; signal noise ratio; speech discrimination; stimulus; support vector machine; task performance; Electroencephalography","Ministry of Trade, Industry and Energy, MOTIE","","Frontiers Media S.A.",""
"Wang F.; Zheng K.; Lu L.; Xiao J.; Wu M.; Kuo C.-F.; Miao S.","Wang, Fakai (57221839762); Zheng, Kang (56335957600); Lu, Le (55474685200); Xiao, Jing (57190986110); Wu, Min (55264847200); Kuo, Chang-Fu (23025197800); Miao, Shun (36629063700)","57221839762; 56335957600; 55474685200; 57190986110; 55264847200; 23025197800; 36629063700","Lumbar Bone Mineral Density Estimation From Chest X-Ray Images: Anatomy-Aware Attentive Multi-ROI Modeling","2023","42","1","","257","267","10","10.1109/TMI.2022.3209648","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139528821&doi=10.1109%2fTMI.2022.3209648&partnerID=40&md5=41b799d68e2b4c73bf2c9c765bc2430c","Osteoporosis is a common chronic metabolic bone disease often under-diagnosed and under-treated due to the limited access to bone mineral density (BMD) examinations, e.g., via Dual-energy X-ray Absorptiometry (DXA). This paper proposes a method to predict BMD from Chest X-ray (CXR), one of the most commonly accessible and low-cost medical imaging examinations. The proposed method first automatically detects Regions of Interest (ROIs) of local CXR bone structures. Then a multi-ROI deep model with transformer encoder is developed to exploit both local and global information in the chest X-ray image for accurate BMD estimation. The proposed method is evaluated on 13719 CXR patient cases with ground truth BMD measured by the gold standard DXA. The model predicted BMD has a strong correlation with the ground truth (Pearson correlation coefficient 0.894 on lumbar 1). When applied in osteoporosis screening, it achieves a high classification performance (average AUC of 0.968). As the first effort of using CXR scans to predict the BMD, the proposed algorithm holds strong potential to promote early osteoporosis screening and public health.  © 1982-2012 IEEE.","Bone mineral density; chest X-ray imaging; deep self-attention; multi-ROI modeling; osteoporosis screening","Absorptiometry, Photon; Bone Density; Humans; Lumbar Vertebrae; Osteoporosis; Radiography; X-Rays; Correlation methods; Diagnosis; Diseases; Medical imaging; Biomedical imaging; Bone mineral density; Chest X-ray imaging; Deep self-attention; Features extraction; Multi-region of interest modeling; Osteoporosis; Osteoporosis screenings; Region-of-interest; Regions of interest; Transformer; X-ray imaging; adult; aged; anatomy; Article; attentive multi region of interest modeling; autoencoder; bone density; bone structure; controlled study; convolutional neural network; correlation coefficient; diagnostic test accuracy study; disease classification; dual energy X ray absorptiometry; feature extraction; female; human; lumbar spine; lumbar vertebra; machine learning; major clinical study; male; measurement accuracy; osteopenia; osteoporosis; receiver operating characteristic; screening; sensitivity and specificity; thorax radiography; diagnostic imaging; osteoporosis; photon absorptiometry; procedures; radiography; X ray; Bone","","","Institute of Electrical and Electronics Engineers Inc.","36155432"
"Ershadi M.M.; Rise Z.R.; Niaki S.T.A.","Ershadi, Mohammad Mahdi (57212585059); Rise, Zeinab Rahimi (57537988300); Niaki, Seyed Taghi Akhavan (57193316997)","57212585059; 57537988300; 57193316997","A hierarchical machine learning model based on Glioblastoma patients' clinical, biomedical, and image data to analyze their treatment plans","2022","150","","106159","","","","10.1016/j.compbiomed.2022.106159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141769257&doi=10.1016%2fj.compbiomed.2022.106159&partnerID=40&md5=e81bf1e4aa7f537f826ccdfeb0e7222d","Aim of study: Glioblastoma Multiforme (GBM) is an aggressive brain cancer in adults that kills most patients in the first year due to ineffective treatment. Different clinical, biomedical, and image data features are needed to analyze GBM, increasing complexities. Besides, they lead to weak performances for machine learning models due to ignoring physicians' knowledge. Therefore, this paper proposes a hierarchical model based on Fuzzy C-mean (FCM) clustering, Wrapper feature selection, and twelve classifiers to analyze treatment plans. Methodology/Approach: The proposed method finds the effectiveness of previous and current treatment plans, hierarchically determining the best decision for future treatment plans for GBM patients using clinical data, biomedical data, and different image data. A case study is presented based on the Cancer Genome Atlas Glioblastoma Multiforme dataset to prove the effectiveness of the proposed model. This dataset is analyzed using data preprocessing, experts' knowledge, and a feature reduction method based on the Principal Component Analysis. Then, the FCM clustering method is utilized to reinforce classifier learning. Outcomes of study: The proposed model finds the best combination of Wrapper feature selection and classifier for each cluster based on different measures, including accuracy, sensitivity, specificity, precision, F-score, and G-mean according to a hierarchical structure. It has the best performance among other reinforced classifiers. Besides, this model is compatible with real-world medical processes for GBM patients based on clinical, biomedical, and image data. © 2022 Elsevier Ltd","Classification & clustering; Feature reduction & feature selection; Glioblastoma; Hierarchical model; Image processing","Adult; Algorithms; Brain; Brain Neoplasms; Deep Learning; Glioblastoma; Humans; Machine Learning; Cluster analysis; Diseases; Feature Selection; Hierarchical systems; Image analysis; Learning systems; Medical imaging; Patient treatment; Principal component analysis; Reduction; Biomedical data; Classification/clustering; Clinical data; Feature reduction & feature selection; Features reductions; Features selection; Glioblastoma multiforme; Glioblastomas; Hierarchical model; Images processing; Article; Bayesian learning; bleeding; brain cortex; cancer patient; case based reasoning; classifier; clinical assessment; clinical effectiveness; clinical feature; clinical study; compression; cyst; data processing; decision tree; discriminant analysis; feature extraction; feature selection; fuzzy c means clustering; fuzzy system; fuzzy type i inference system; genome analysis; glioblastoma; Hopfield neural network; human; image analysis; image processing; k means clustering; k nearest neighbor; learning vector quantization; logistic regression analysis; machine learning; methodology; multilayer perceptron; nuclear magnetic resonance imaging; principal component analysis; professional knowledge; radial basis function neural network; random forest; signal noise ratio; support vector machine; treatment planning; tumor localization; tumor volume; wrapper feature selection; x-ray computed tomography; adult; algorithm; brain; brain tumor; deep learning; diagnostic imaging; glioblastoma; machine learning; Classification (of information)","","","Elsevier Ltd","36257277"
"Kamal U.; Zunaed M.; Nizam N.B.; Hasan T.","Kamal, Uday (57205448206); Zunaed, Mohammad (57221919111); Nizam, Nusrat Binta (57221542455); Hasan, Taufiq (24779538100)","57205448206; 57221919111; 57221542455; 24779538100","Anatomy-XNet: An Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification in Chest X-Rays","2022","26","11","","5518","5528","10","10.1109/JBHI.2022.3199594","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136618596&doi=10.1109%2fJBHI.2022.3199594&partnerID=40&md5=cb340b6ce031334d2d6530be1d38296c","Thoracic disease detection from chest radiographs using deep learning methods has been an active area of research in the last decade. Most previous methods attempt to focus on the diseased organs of the image by identifying spatial regions responsible for significant contributions to the model's prediction. In contrast, expert radiologists first locate the prominent anatomical structures before determining if those regions are anomalous. Therefore, integrating anatomical knowledge within deep learning models could bring substantial improvement in automatic disease classification. Motivated by this, we propose Anatomy-XNet, an anatomy-aware attention-based thoracic disease classification network that prioritizes the spatial features guided by the pre-identified anatomy regions. We adopt a semi-supervised learning method by utilizing available small-scale organ-level annotations to locate the anatomy regions in large-scale datasets where the organ-level annotations are absent. The proposed Anatomy-XNet uses the pre-trained DenseNet-121 as the backbone network with two corresponding structured modules, the Anatomy Aware Attention (A3) and Probabilistic Weighted Average Pooling, in a cohesive framework for anatomical attention learning. We experimentally show that our proposed method sets a new state-of-the-art benchmark by achieving an AUC score of 85.78%, 92.07%, and, 84.04% on three publicly available large-scale CXR datasets-NIH, Stanford CheXpert, and MIMIC-CXR, respectively. This not only proves the efficacy of utilizing the anatomy segmentation knowledge to improve the thoracic disease classification but also demonstrates the generalizability of the proposed framework.  © 2013 IEEE.","anatomical segmenta- tion; Anatomy-aware attention; chest radio- graphy; semi-supervised learning; thoracic disease classification","Humans; Neural Networks, Computer; Radiography; Thoracic Diseases; Tomography, X-Ray Computed; X-Rays; Convolution; Deep learning; Large dataset; Medical imaging; Neural networks; Radiography; Supervised learning; Anatomical segmentation; Anatomy-aware attention; Biomedical imaging; Chest radiography; Convolutional neural network; Deep learning; Disease classification; Images segmentations; Lesion; Lung; Semi-supervised learning; Thoracic disease classification; accuracy; algorithm; anatomy; area under the curve; Article; classification algorithm; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; disease classification; human; image quality; image segmentation; mathematical analysis; medical practice; probabilistic neural network; receiver operating characteristic; signal processing; supervised machine learning; thorax disease; thorax radiography; training; procedures; radiography; X ray; x-ray computed tomography; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.","35976847"
"Chen Y.; Jin D.; Guo B.; Bai X.","Chen, Ying (57788458200); Jin, Darui (57202117813); Guo, Bin (56903500400); Bai, Xiangzhi (23466338600)","57788458200; 57202117813; 56903500400; 23466338600","Attention-Assisted Adversarial Model for Cerebrovascular Segmentation in 3D TOF-MRA Volumes","2022","41","12","","3520","3532","12","10.1109/TMI.2022.3186731","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133568204&doi=10.1109%2fTMI.2022.3186731&partnerID=40&md5=bc2b6b9cf01c318e4442dd7a50171335","Cerebrovascular segmentation in time-of-flight magnetic resonance angiography (TOF-MRA) volumes is essential for a variety of diagnostic and analytical applications. However, accurate cerebrovascular segmentation in 3D TOF-MRA is faced with multiple issues, including vast variations in cerebrovascular morphology and intensity, noisy background, and severe class imbalance between foreground cerebral vessels and background. In this work, a 3D adversarial network model called A-SegAN is proposed to segment cerebral vessels in TOF-MRA volumes. The proposed model is composed of a segmentation network A-SegS to predict segmentation maps, and a critic network A-SegC to discriminate predictions from ground truth. Based on this model, the aforementioned issues are addressed by the prevailing visual attention mechanism. First, A-SegS is incorporated with feature-attention blocks to filter out discriminative feature maps, though the cerebrovascular has varied appearances. Second, a hard-example-attention loss is exploited to boost the training of A-SegS on hard samples. Further, A-SegC is combined with an input-attention layer to attach importance to foreground cerebrovascular class. The proposed methods were evaluated on a self-constructed voxel-wise annotated cerebrovascular TOF-MRA segmentation dataset, and experimental results indicate that A-SegAN achieves competitive or better cerebrovascular segmentation results compared to other deep learning methods, effectively alleviating the above issues.  © 1982-2012 IEEE.","adversarial training; Cerebrovascular segmentation; deep learning; TOF-MRA","Algorithms; Magnetic Resonance Angiography; Behavioral research; Deep learning; Image segmentation; Magnetic resonance; Medical imaging; Three dimensional computer graphics; Adversarial training; Biomedical imaging; Cerebrovascular segmentation; Deep learning; Features extraction; Images segmentations; Magnetic resonance Angiography; Task analysis; Three-dimensional display; Time-of flight; Time-of-flight magnetic resonance angiography; adversarial network; Article; brain blood vessel; cross validation; deep learning; false negative result; false positive result; feature extraction; feature learning (machine learning); image processing; image segmentation; intermethod comparison; magnetic resonance angiography; neuroimaging; residual neural network; segmentation algorithm; three-dimensional imaging; time of flight magnetic resonance angiography; type I error; type II error; visual attention; algorithm; procedures; Three dimensional displays","","","Institute of Electrical and Electronics Engineers Inc.","35759584"
"Arpaia P.; Esposito A.; Natalizio A.; Parvis M.","Arpaia, Pasquale (7006199525); Esposito, Antonio (57203163851); Natalizio, Angela (57210819515); Parvis, Marco (7004099740)","7006199525; 57203163851; 57210819515; 7004099740","How to successfully classify EEG in motor imagery BCI: A metrological analysis of the state of the art","2022","19","3","031002","","","","10.1088/1741-2552/ac74e0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132456130&doi=10.1088%2f1741-2552%2fac74e0&partnerID=40&md5=8c183100ac6795a51f1861c4f4b5a1ea","Objective. Processing strategies are analyzed with respect to the classification of electroencephalographic signals related to brain-computer interfaces (BCIs) based on motor imagery (MI). A review of literature is carried out to understand the achievements in MI classification, the most promising trends, and the challenges in replicating these results. Main focus is placed on performance by means of a rigorous metrological analysis carried out in compliance with the international vocabulary of metrology. Hence, classification accuracy and its uncertainty are considered, as well as repeatability and reproducibility. Approach. The paper works included in the review concern the classification of electroencephalographic signals in motor-imagery-based BCIs. Article search was carried out in accordance with the Preferred Reporting Items for Systematic reviews and Meta-Analyses standard and 89 studies were included. Main results. Statistically-based analyses show that brain-inspired approaches are increasingly proposed, and that these are particularly successful in discriminating against multiple classes. Notably, many proposals involve convolutional neural networks. Instead, classical machine learning approaches are still effective for binary classifications. Many proposals combine common spatial pattern, least absolute shrinkage and selection operator, and support vector machines. Regarding reported classification accuracies, performance above the upper quartile is in the 85%-100% range for the binary case and in the 83%-93% range for multi-class one. Associated uncertainties are up to 6% while repeatability for a predetermined dataset is up to 8%. Reproducibility assessment was instead prevented by lack of standardization in experiments. Significance. By relying on the analyzed studies, the reader is guided towards the development of a successful processing strategy as a crucial part of a BCI. Moreover, it is suggested that future studies should extend these approaches on data from more subjects and with custom experiments, even by investigating online operation. This would also enable the quantification of the results reproducibility. © 2022 IOP Publishing Ltd.","brain inspired network; brain-computer interface (BCI); classification; deep learning; electroencephalogram (EEG); machine learning; motor imagery (MI)","Algorithms; Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Movement; Reproducibility of Results; Biomedical signal processing; Brain; Brain computer interface; Classification (of information); Convolutional neural networks; Deep learning; Image analysis; Image classification; Learning systems; Support vector machines; Brain inspired network; Brain-computer interface; Brain-inspired; Deep learning; Electroencephalogram; Machine-learning; Metrological analysis; Motor imagery; Reproducibilities; binary classification; convolutional neural network; electroencephalogram; electroencephalography; imagery; least absolute shrinkage and selection operator; machine learning; motor imagery; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; Review; support vector machine; algorithm; brain computer interface; human; imagination; movement (physiology); procedures; reproducibility; Electroencephalography","ICT for Health; Università degli Studi di Napoli Federico II, UNINA; Ministero dell’Istruzione, dell’Università e della Ricerca, MIUR, (232/2016); Ministero dell’Istruzione, dell’Università e della Ricerca, MIUR","","Institute of Physics","35640554"
"Qin X.; Wang B.; Boegner D.; Gaitan B.; Zheng Y.; Du X.; Chen Y.","Qin, Xi (58832049200); Wang, Bohan (56029024600); Boegner, David (57226436268); Gaitan, Brandon (56307946700); Zheng, Yingning (57557530500); Du, Xian (37028027600); Chen, Yu (57562796500)","58832049200; 56029024600; 57226436268; 56307946700; 57557530500; 37028027600; 57562796500","Indoor Localization of Hand-Held OCT Probe Using Visual Odometry and Real-Time Segmentation Using Deep Learning","2022","69","4","","1378","1385","7","10.1109/TBME.2021.3116514","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116859908&doi=10.1109%2fTBME.2021.3116514&partnerID=40&md5=4242b25b0c3c28a1f536f69e2caeab46","Objective: Optical coherence tomography (OCT) is an established medical imaging modality that has found widespread use due to its ability to visualize tissue structures at a high resolution. Currently, OCT hand-held imaging probes lack positional information, making it difficult or even impossible to link a specific image to the location it was originally obtained. In this study, we propose a camera-based localization method to track and record the scanner position in real-time, as well as providing a deep learning-based segmentation method. Methods: We used camera-based visual odometry (VO) and simultaneous mapping and localization (SLAM) to compute and visualize the location of a hand-held OCT imaging probe. A deep convolutional neural network (CNN) was used for kidney tubule lumens segmentation. Results: The mean absolute error (MAE) and the standard deviation (STD) for 1D translation were found to be 0.15 mm and 0.26mm respectively. For 2D translation, the MAE and STD were found to be 0.85 mm and 0.50 mm, respectively. The dice coefficient of the segmentation method was 0.7. The t-statistic of the T-test between predicted and actual average densities and predicted and actual average diameters were 7.7547e-13 and 2.2288e-15 respectively. We also experimented on a preserved kidney utilizing our localization method with automatic segmentation. Comparisons of the average density maps and average diameter maps were made between the 3D comprehensive scan and VO system scan. Conclusion: Our results demonstrate that VO can track the probe location at high accuracy, and provides a user-friendly visualization tool to review OCT 2D images in 3D space. It also indicates that deep learning can provide high accuracy and high speed for segmentation. Significance: The proposed methods can be potentially used to predict delayed graft function (DGF) in kidney transplantation.  © 1964-2012 IEEE.","deep learning; kidney; optical coherence tomography (OCT); segmentation; simultaneous mapping and localization (SLAM); Visual odometry","Deep Learning; Humans; Neural Networks, Computer; Sexually Transmitted Diseases; Tomography, Optical Coherence; Cameras; Computer vision; Deep neural networks; Image reconstruction; Indoor positioning systems; Location; Mapping; Medical imaging; Optical tomography; Robotics; Semantic Segmentation; Three dimensional computer graphics; Vision; Visualization; Biomedical measurements; Deep learning 1; Images segmentations; Kidney; Location awareness; Mapping and localization; Optical coherence tomography; Segmentation; Simultaneous mapping and localization; Visual odometry; Article; calibration; computer vision; deep learning; delayed graft function; detection algorithm; handheld device; human; image analysis; image processing; image segmentation; imaging and display; kidney transplantation; kidney tubule; mean absolute error; optical coherence tomography; prediction; segmentation algorithm; videorecording; virtual reality; visual odometry; optical coherence tomography; sexually transmitted disease; Probes","National Institutes of Health, NIH; National Institute of Diabetes and Digestive and Kidney Diseases, NIDDK, (R01DK094877); National Institute of Diabetes and Digestive and Kidney Diseases, NIDDK","","IEEE Computer Society","34587002"
"Li Y.; Zhang Y.; Cui W.; Lei B.; Kuang X.; Zhang T.","Li, Yang (56075073900); Zhang, Yue (58747418800); Cui, Weigang (57194527865); Lei, Baiying (26422280400); Kuang, Xihe (57219007314); Zhang, Teng (57213164472)","56075073900; 58747418800; 57194527865; 26422280400; 57219007314; 57213164472","Dual Encoder-Based Dynamic-Channel Graph Convolutional Network With Edge Enhancement for Retinal Vessel Segmentation","2022","41","8","","1975","1989","14","10.1109/TMI.2022.3151666","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124825303&doi=10.1109%2fTMI.2022.3151666&partnerID=40&md5=14803d224b9506a3050a8379e5af5be0","Retinal vessel segmentation with deep learning technology is a crucial auxiliary method for clinicians to diagnose fundus diseases. However, the deep learning approaches inevitably lose the edge information, which contains spatial features of vessels while performing down-sampling, leading to the limited segmentation performance of fine blood vessels. Furthermore, the existing methods ignore the dynamic topological correlations among feature maps in the deep learning framework, resulting in the inefficient capture of the channel characterization. To address these limitations, we propose a novel dual encoder-based dynamic-channel graph convolutional network with edge enhancement (DE-DCGCN-EE) for retinal vessel segmentation. Specifically, we first design an edge detection-based dual encoder to preserve the edge of vessels in down-sampling. Secondly, we investigate a dynamic-channel graph convolutional network to map the image channels to the topological space and synthesize the features of each channel on the topological map, which solves the limitation of insufficient channel information utilization. Finally, we study an edge enhancement block, aiming to fuse the edge and spatial features in the dual encoder, which is beneficial to improve the accuracy of fine blood vessel segmentation. Competitive experimental results on five retinal image datasets validate the efficacy of the proposed DE-DCGCN-EE, which achieves more remarkable segmentation results against the other state-of-the-art methods, indicating its potential clinical application.  © 1982-2012 IEEE.","deep learning; dual encoder; dynamic graph convolution network; edge enhancement; Retinal vessel segmentation","Algorithms; Fundus Oculi; Image Processing, Computer-Assisted; Neural Networks, Computer; Retinal Vessels; Blood vessels; Deep learning; Edge detection; Feature extraction; Image enhancement; Image segmentation; Medical imaging; Network coding; Ophthalmology; Signal sampling; Signal to noise ratio; Topology; Biomedical imaging; Decoding; Deep learning; Dual encoder; Dynamic graph; Dynamic graph convolution network; Edge enhancements; Features extraction; Image edge detection; Images segmentations; Retinal vessel segmentations; Article; comparative study; convolutional neural network; deep learning; edge detection; feature extraction; human; image enhancement; image processing; image segmentation; parameters; retina blood vessel; retina image; spatial analysis; validation process; algorithm; diagnostic imaging; eye fundus; procedures; retina blood vessel; Convolution","","","Institute of Electrical and Electronics Engineers Inc.","35167444"
"Arslan Ö.","Arslan, Özkan (57203165669)","57203165669","Automated detection of heart valve disorders with time-frequency and deep features on PCG signals","2022","78","","103929","","","","10.1016/j.bspc.2022.103929","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132753161&doi=10.1016%2fj.bspc.2022.103929&partnerID=40&md5=8192fa9c25f0a7453c1671c789b67fb7","Heart valve diseases (HVDs) can cause cardiac arrhythmias, heart attacks, and sudden cardiac death if not diagnosed early. Therefore, the detection of HVDs is critical in order to avoid heart-related mortality. The focus of this research is to establish an efficient computer-aided diagnosis approach that detects HVDs using phonocardiogram (PCG) signals. The proposed approach uses traditional time–frequency and deep features with machine learning models. The time–frequency features are extracted from non-linear measurements using discrete wavelet transform (DWT), wavelet packet transform (WPT), perceptual wavelet packet transform (PWPT) and empirical mode decomposition (EMD) methods. Deep features are extracted from VGG16, ResNet50 and MobileNetV2 pre-trained CNN models, and multilayer extreme learning machine (ML-ELM) model using scalogram images of PCG signals. Recursive feature elimination (RFE) algorithm is applied to all features and the most distinctive features are selected. Experimental results show that the PWPT + EMD features selected by RFE and the random forest (RF) classification model achieve the highest performance with accuracy of 99.4%, Matthews correlation coefficient (MCC) and G-mean of 99.3%. In another proposed approach, ML-ELM deep features selected by RFE algorithm and RF classification model provide accuracy and G-mean of 98.9%, and MCC values of 98.6%. It was observed that the time–frequency features have outperformed compared to deep features for the detection of HVDs. The proposed approach is compared with the existing studies and it has obtained higher performance values ​​than the approaches using the same database. The proposed approach can be considered as an easily integrated system on the embedded platform. © 2022 Elsevier Ltd","Deep features; Heart valve diseases (HVDs); Multilayer extreme learning machine; Phonocardiography (PCG); Time-frequency analysis","Biomedical signal processing; Computer aided diagnosis; Decision trees; Deep learning; Discrete wavelet transforms; Feature extraction; Knowledge acquisition; Learning systems; Multilayer neural networks; Multilayers; Phonocardiography; Signal reconstruction; Wavelet analysis; Wavelet decomposition; Deep feature; Heart valve disease; Learning machines; Multilayer extreme learning machine; Phonocardiography; Recursive feature elimination; Time frequency; Time-frequency Analysis; Wavelet packet transforms; Article; clinical feature; controlled study; diagnostic accuracy; machine learning; phonocardiography; recursive feature elimination; valvular heart disease; Heart","","","Elsevier Ltd",""
"Alsheikhy A.A.; Said Y.; Shawly T.; Alzahrani A.K.; Lahza H.","Alsheikhy, Ahmed A. (57188633729); Said, Yahia (53867137900); Shawly, Tawfeeq (56114723800); Alzahrani, A. Khuzaim (57222669831); Lahza, Husam (57191161213)","57188633729; 53867137900; 56114723800; 57222669831; 57191161213","Biomedical Diagnosis of Breast Cancer Using Deep Learning and Multiple Classifiers","2022","12","11","2863","","","","10.3390/diagnostics12112863","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148095526&doi=10.3390%2fdiagnostics12112863&partnerID=40&md5=479b5349612c9b6fb1ac84cef77bb96b","Breast cancer is considered one of the deadliest diseases in women. Due to the risk and threat it poses, the world has agreed to hold a breast cancer awareness day in October, encouraging women to perform mammogram inspections. This inspection may prevent breast-cancer-related deaths or reduce the death rate. The identification and classification of breast cancer are challenging tasks. The most commonly known procedure of breast cancer detection is performed by using mammographic images. Recently implemented algorithms suffer from generating accuracy below expectations, and their computational complexity is high. To resolve these issues, this paper proposes a fully automated biomedical diagnosis system of breast cancer using an AlexNet, a type of Convolutional Neural Network (CNN), and multiple classifiers to identify and classify breast cancer. This system utilizes a neuro-fuzzy method, a segmentation algorithm, and various classifiers to reach a higher accuracy than other systems have achieved. Numerous features are extracted to detect and categorize breast cancer. Three datasets from Kaggle were tested to validate the proposed system. The performance evaluation is performed with quantitative and qualitative accuracy, precision, recall, specificity, and F-score. In addition, a comparative assessment is performed between the proposed system and some works of literature. This assessment shows that the presented algorithm provides better classification results and outperforms other systems in all parameters. Its average accuracy is over 98.6%, while other metrics are more than 98%. This research indicates that this approach can be applied to assist doctors in diagnosing breast cancer correctly. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","BCIC; biomedical diagnosis; breast cancer; CNN; fuzzy algorithm","Article; Bayesian learning; breast cancer; cancer classification; cancer diagnosis; classifier; comparative study; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; feature extraction; fuzzy system; human; k nearest neighbor; model; qualitative analysis; quantitative analysis; segmentation algorithm; sensitivity and specificity; validation process","Institutional Fund Projects, (135-829-1443); Deanship of Scientific Research, Prince Sattam bin Abdulaziz University, DSR; King Abdulaziz University, KAU; Ministry of Education – Kingdom of Saudi Arabi, MOE","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Almogadwy B.; Taylor N.K.; Burger A.","Almogadwy, B. (57210389437); Taylor, N.K. (35618784700); Burger, A. (7202055375)","57210389437; 35618784700; 7202055375","Multimodal Machine Learning for 2D to 3D Mapping in Biomedical Atlases","2022","10","2","","64","69","5","10.18178/joig.10.2.64-69","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130069460&doi=10.18178%2fjoig.10.2.64-69&partnerID=40&md5=cfb763009643a3841014e99905b0916f","2D to 3D image registration has a vital role in medical imaging and remains a significant challenge. It primarily relates to the use and analysis of multimodal data. We address the issue by developing a multimodal machine learning algorithm that predicts the position of a 2D slice in a 3D biomedical atlas dataset based on textual annotation and image data. Our algorithm first separately analyses images and textual information using base models and then combines the outputs of the base models using a Meta-learner model. To evaluate learning models, we have built a custom accuracy function. We tested different variants of Convolutional Neural Network architectures and different transfer learning techniques to build an optimal image base model for image analysis. To analyze textual information, we used tree-based ensemble models, namely, Random Forest and XGBoost algorithms. We applied the grid search to find optimal hyperparameters for tree-based methods. We have found that the XGBoost model showed the best performance in combining predictions from different base models. Testing the developed method showed 99.55% accuracy in predicting 2D slice position in a 3D atlas model. © 2022 Journal of Image and Graphics.","deep learning; EMAP atlas. CNN; image registration; multimodal data","","","","University of Portsmouth",""
"Shen W.X.; Liu Y.; Chen Y.; Zeng X.; Tan Y.; Jiang Y.Y.; Chen Y.Z.","Shen, Wan Xiang (56704068800); Liu, Yu (57209775591); Chen, Yan (57188765740); Zeng, Xian (55553039600); Tan, Ying (54390132800); Jiang, Yu Yang (7404833059); Chen, Yu Zong (57192422482)","56704068800; 57209775591; 57188765740; 55553039600; 54390132800; 7404833059; 57192422482","AggMapNet: Enhanced and explainable low-sample omics deep learning with feature-aggregated multi-channel networks","2022","50","8","","E45","","","10.1093/nar/gkac010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130043091&doi=10.1093%2fnar%2fgkac010&partnerID=40&md5=6967f83b73a216ea9dc73b8a2be2bd83","Omics-based biomedical learning frequently relies on data of high-dimensions (up to thousands) and low-sample sizes (dozens to hundreds), which challenges efficient deep learning (DL) algorithms, particularly for low-sample omics investigations. Here, an unsupervised novel feature aggregation tool AggMap was developed to Aggregate and Map omics features into multi-channel 2D spatial-correlated image-like feature maps (Fmaps) based on their intrinsic correlations. AggMap exhibits strong feature reconstruction capabilities on a randomized benchmark dataset, outperforming existing methods. With AggMap multi-channel Fmaps as inputs, newly-developed multi-channel DL AggMapNet models outperformed the state-of-the-art machine learning models on 18 low-sample omics benchmark tasks. AggMapNet exhibited better robustness in learning noisy data and disease classification. The AggMapNet explainable module Simply-explainer identified key metabolites and proteins for COVID-19 detections and severity predictions. The unsupervised AggMap algorithm of good feature restructuring abilities combined with supervised explainable AggMapNet architecture establish a pipeline for enhanced learning and interpretability of low-sample omics data. © 2022 The Author(s) 2022. Published by Oxford University Press on behalf of Nucleic Acids Research.","","analytic method; Article; benchmarking; clinical article; cohort analysis; convolutional neural network; coronavirus disease 2019; correlational study; deep learning; disease classification; disease severity; human; metabolic regulation; prediction; protein analysis; two-dimensional imaging","","","Oxford University Press",""
"Groh R.; Dürr S.; Schützenberger A.; Semmler M.; Kist A.M.","Groh, René (57419859500); Dürr, Stephan (59049362100); Schützenberger, Anne (26655068600); Semmler, Marion (57188981646); Kist, Andreas M. (57204454654)","57419859500; 59049362100; 26655068600; 57188981646; 57204454654","Long-term performance assessment of fully automatic biomedical glottis segmentation at the point of care","2022","17","9 September","e0266989","","","","10.1371/journal.pone.0266989","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138459177&doi=10.1371%2fjournal.pone.0266989&partnerID=40&md5=702a318dacc4a5793b247ae8e5f2ff38","Deep Learning has a large impact on medical image analysis and lately has been adopted for clinical use at the point of care. However, there is only a small number of reports of long-term studies that show the performance of deep neural networks (DNNs) in such an environment. In this study, we measured the long-term performance of a clinically optimized DNN for laryngeal glottis segmentation. We have collected the video footage for two years from an AI-powered laryngeal high-speed videoendoscopy imaging system and found that the footage image quality is stable across time. Next, we determined the DNN segmentation performance on lossy and lossless compressed data revealing that only 9% of recordings contain segmentation artifacts. We found that lossy and lossless compression is on par for glottis segmentation, however, lossless compression provides significantly superior image quality. Lastly, we employed continual learning strategies to continuously incorporate new data into the DNN to remove the aforementioned segmentation artifacts. With modest manual intervention, we were able to largely alleviate these segmentation artifacts by up to 81%. We believe that our suggested deep learning-enhanced laryngeal imaging platform consistently provides clinically sound results, and together with our proposed continual learning scheme will have a long-lasting impact on the future of laryngeal imaging. © 2022 Groh et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Artifacts; Glottis; Image Processing, Computer-Assisted; Larynx; Neural Networks, Computer; Point-of-Care Systems; adult; aged; Article; automatic biomedical glottis segmentation; automation; controlled study; data quality; deep neural network; female; glottis; human; image analysis; image artifact; image enhancement; image quality; image segmentation; laryngeal imaging; larynx; learning; long term performance assessment; lossless compression; lossy compression; male; peak signal to noise ratio; performance measurement system; point of care testing; practice guideline; segmentation algorithm; signal noise ratio; velocity; videoendoscopy; videorecording; artifact; diagnostic imaging; glottis; image processing; larynx; point of care system; procedures","Deutsche Forschungsgemeinschaft, DFG, (SCHU 3441/3-2); Deutsche Forschungsgemeinschaft, DFG","","Public Library of Science","36129922"
"Noshad A.; Fallahi S.","Noshad, Ali (57222065732); Fallahi, Saeed (36902871300)","57222065732; 36902871300","A new hybrid framework based on deep neural networks and JAYA optimization algorithm for feature selection using SVM applied to classification of acute lymphoblastic Leukaemia","2023","11","4","","1549","1566","17","10.1080/21681163.2022.2157748","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145402343&doi=10.1080%2f21681163.2022.2157748&partnerID=40&md5=0a4085a5c69143657748f5d724d6227c","Identification of Acute lymphoblastic leukemia (ALL) in microscopic images is one of the most challenging tasks in medical image analysis. Despite a wide variety of image processing and deep learning techniques, the task of extracting features from ALL images and selecting the proper features from these redundant and high-dimensional feature space set, and then detecting ALL cells is still a complex issue. In this study, we present a new hybrid two-layer framework to construct an appropriate subset of features. In the first layer of the proposed method, image segmentation is implemented using an improved modified First-Spike-based approach integrated with a Gaussian function. Then a developed deep residual architecture is employed to extract the features. In the second layer, a powerful and reliable meta-heuristic algorithm known as the JAYA optimization algorithm is adopted for feature selection due to its computational efficiency. Finally, a support vector machine (SVM) is used to classify ALL images. To show the effectiveness of the proposed model, it is applied on microscopic images of blood samples from ALL images (ALL-IDB) and ISBI-2019 C-NMC dataset. The results show the superiority of the model to be an appropriate choice for future biomedical imaging tasks. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","classification; deep learning; JAYA algorithm; Leukemia; residual learning","Classification (of information); Computational efficiency; Deep neural networks; Diseases; Feature Selection; Heuristic algorithms; Heuristic methods; Image enhancement; Image segmentation; Learning algorithms; Learning systems; Medical imaging; Optimization; Acute lymphoblastic leukaemias; Deep learning; Features selection; Hybrid framework; JAYA algorithm; Leukemia; Microscopic image; Optimization algorithms; Residual learning; Support vectors machine; acute lymphoblastic leukemia; algorithm; area under the curve; Article; blood sampling; cancer cell; convolutional neural network; cross validation; deep neural network; feature selection; human; image analysis; image segmentation; lymphoblast; receiver operating characteristic; sensitivity and specificity; Support vector machines","","","Taylor and Francis Ltd.",""
"Eren F.; Aslan M.; Kanarya D.; Uysalli Y.; Aydin M.; Kiraz B.; Aydin O.; Kiraz A.","Eren, Furkan (57226398182); Aslan, Mete (57887542100); Kanarya, Dilek (57472035500); Uysalli, Yigit (56815123200); Aydin, Musa (56369220000); Kiraz, Berna (36959472600); Aydin, Omer (56622455400); Kiraz, Alper (58903933900)","57226398182; 57887542100; 57472035500; 56815123200; 56369220000; 36959472600; 56622455400; 58903933900","DeepCAN: A Modular Deep Learning System for Automated Cell Counting and Viability Analysis","2022","26","11","","5575","5583","8","10.1109/JBHI.2022.3203893","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137869001&doi=10.1109%2fJBHI.2022.3203893&partnerID=40&md5=e423b35c7ff7b3836084211ca44fd311","Precise and quick monitoring of key cytometric features such as cell count, size, morphology, and DNA content is crucial in life science applications. Traditionally, image cytometry relies on visual inspection of hemocytometers. This approach is error-prone due to operator subjectivity. Recently, deep learning approaches have emerged as powerful tools enabling quick and accurate image cytometry applicable to different cell types. Leading to simpler, compact, and affordable solutions, these approaches revealed image cytometry as a viable alternative to flow cytometry or Coulter counting. In this study, we demonstrate a modular deep learning system, DeepCAN, providing a complete solution for automated cell counting and viability analysis. DeepCAN employs three different neural network blocks called Parallel Segmenter, Cluster CNN, and Viability CNN that are trained for initial segmentation, cluster separation, and viability analysis. Parallel Segmenter and Cluster CNN blocks achieve accurate segmentation of individual cells while Viability CNN block performs viability classification. A modified U-Net network, a well-known deep neural network model for bioimage analysis, is used in Parallel Segmenter while LeNet-5 architecture and its modified version Opto-Net are used for Cluster CNN and Viability CNN, respectively. We train the Parallel Segmenter using 15 images of A2780 cells and 5 images of yeasts cells, containing, in total, 14742 individual cell images. Similarly, 6101 and 5900 A2780 cell images are employed for training Cluster CNN and Viability CNN models, respectively. 2514 individual A2780 cell images are used to test the overall segmentation performance of Parallel Segmenter combined with Cluster CNN, revealing high Precision/Recall/F1-Score values of 96.52%/96.45%/98.06%, respectively. Cell counting/viability performance of DeepCAN is tested with A2780 (2514 cells), A549 (601 cells), Colo (356 cells), and MDA-MB-231 (887 cells) cell images revealing high analysis accuracies of 96.76%/99.02%, 93.82%/95.93%, and 92.18%/97.90%, 85.32%/97.40%, respectively.  © 2013 IEEE.","Bioimage segmentation; bright field imaging; cell counting; convolutional neural network; viability analysis","Cell Line, Tumor; Deep Learning; Female; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Ovarian Neoplasms; Cell culture; Cells; Cluster computing; Computer aided diagnosis; Convolution; Deep neural networks; Image analysis; Medical imaging; Network architecture; Parallel architectures; Bioimage segmentations; Biomedical imaging; Bright field imaging; Bright-fields; Cell counting; Convolutional neural network; Deep learning; Field imaging; Images segmentations; Viability analyse; A-549 cell line; A2780 cell line; accuracy; algorithm; Article; artificial neural network; bright field microscopy; cell count; cell counting; cell culture; cell viability; convolutional neural network; deep learning; deep neural network; DNA content; entropy; female; human; human cell; image analysis; image cytometry; image segmentation; learning algorithm; machine learning; MDA-MB-231 cell line; microscopy; ovarian cancer cell line; receiver operating characteristic; scientific literature; sensitivity and specificity; signal processing; support vector machine; image processing; ovary tumor; procedures; tumor cell line; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.","36054399"
"Song H.; Wang Y.; Zeng S.; Guo X.; Li Z.","Song, Haojie (57844924600); Wang, Yuefei (57192436981); Zeng, Shijie (57723196300); Guo, Xiaoyan (59289170900); Li, Zheheng (57844408200)","57844924600; 57192436981; 57723196300; 59289170900; 57844408200","OAU-net: Outlined Attention U-net for biomedical image segmentation","2023","79","","104038","","","","10.1016/j.bspc.2022.104038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135930269&doi=10.1016%2fj.bspc.2022.104038&partnerID=40&md5=7f92b6650e927c165c5385eef100507f","In this paper, we propose an Outlined Attention U-network (OAU-net) with bypass branching strategy to solve biomedical image segmentation tasks, which is capable of sensing shallow and deep features. Unlike previous studies, we use residual convolution and res2convolution as encoders. In particular, the outline filter and attention module are embedded in the skip connection part, respectively. Shallow features will enhance the edge information after being processed by the outline filter. Meanwhile, in the depths of the network, to better realize feature fusion, our attention module will simultaneously emphasize the independence between feature map channels (channel attention module) and each position information (spatial attention module), that is, the hybrid domain attention module. Finally, we conducted ablation experiments and comparative experiments according to three public data sets (pulmonary CT lesions, Kaggle 2018 data science bowl, skin lesions), and analyzed them with classical evaluation indexes. Experimental results show that our proposed method improves segmentation accuracy effectively. Our code is public at https://github.com/YF-W/OAU-net. © 2022 Elsevier Ltd","Biomedical image segmentation; Bypass branching strategy; Hybrid attention module; Outlined filter kernel","Computerized tomography; Biomedical image segmentation; Bypass branching strategy; Edge information; Feature map; Features fusions; Hybrid attention module; Hybrid domain; Outlined filter kernel; Position information; Spatial attention; Article; convolution algorithm; deep learning; deep neural network; diagnostic imaging; edge detection; feature extraction; human; image processing; image segmentation; machine learning; outlined attention U network; receptive field; skin defect; visual attention; Image segmentation","","","Elsevier Ltd",""
"Eltrass A.S.; Tayel M.B.; EL-Qady A.F.","Eltrass, Ahmed S. (56288407600); Tayel, Mazhar B. (6701864292); EL-Qady, Ahmed F. (57226733759)","56288407600; 6701864292; 57226733759","Identification and classification of epileptic EEG signals using invertible constant-Q transform-based deep convolutional neural network","2022","19","6","066035","","","","10.1088/1741-2552/aca82c","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144332996&doi=10.1088%2f1741-2552%2faca82c&partnerID=40&md5=224e50ffea7b34317c37b4407768501e","Context. Epilepsy is the most widespread disorder of the nervous system, affecting humans of all ages and races. The most common diagnostic test in epilepsy is the electroencephalography (EEG). Objective. In this paper, a novel automated deep learning approach based on integrating a pre-trained convolutional neural network (CNN) structure, called AlexNet, with the constant-Q non-stationary Gabor transform (CQ-NSGT) algorithm is proposed for classifying seizure versus seizure-free EEG records. Approach. The CQ-NSGT method is introduced to transform the input 1D EEG signal into 2D spectrogram which is sent to the AlexNet CNN model. The AlexNet architecture is utilized to capture the discriminating features of the 2D image corresponding to each EEG signal in order to distinguish seizure and non-seizure subjects using multi-layer perceptron algorithm. Main results. The robustness of the introduced CQ-NSGT technique in transforming the 1D EEG signals into 2D spectrograms is assessed by comparing its classification results with the continuous wavelet transform method, and the results elucidate the high performance of the CQ-NSGT technique. The suggested epileptic seizure classification framework is investigated with clinical EEG data acquired from the Bonn University database, and the experimental results reveal the superior performance of the proposed framework over other state-of-the-art approaches with an accuracy of 99.56%, sensitivity of 99.12%, specificity of 99.67%, and precision of 98.69%. Significance. This elucidates the importance of the proposed automated system in helping neurologists to accurately interpret and classify epileptic EEG records without necessitating tedious visual inspection or massive data analysis for long-term EEG signals. © 2022 IOP Publishing Ltd.","Constant-Q Non-Stationary Gabor Transform (CQ-NSGT); convolutional neural network (CNN); deep learning (DL); electroencephalography (EEG)","Algorithms; Electroencephalography; Epilepsy; Humans; Neural Networks, Computer; Seizures; Signal Processing, Computer-Assisted; Automation; Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Electrophysiology; Neurology; Spectrographs; Wavelet transforms; Constant-Q non-stationary gabor transform; Convolutional neural network; Deep learning; Electroencephalography; Gabor transform; Nonstationary; Performance; Spectrograms; Transform methods; alexnet; Article; classification algorithm; clinical assessment; constant q non stationary gabor transform; continuous wavelet transform; convolutional neural network; data base; diagnostic accuracy; electroencephalography; epilepsy; feature extraction; Gabor transform; hippocampus; human; image analysis; image processing; intermethod comparison; multilayer perceptron; seizure; sensitivity and specificity; two-dimensional imaging; algorithm; electroencephalography; epilepsy; procedures; signal processing; Electroencephalography","","","Institute of Physics","36541556"
"Marzorati D.; Dorizza A.; Bovio D.; Salito C.; Mainardi L.; Cerveri P.","Marzorati, Davide (56574013300); Dorizza, Andrea (57443791800); Bovio, Dario (26631742000); Salito, Caterina (26321937900); Mainardi, Luca (7007078486); Cerveri, Pietro (55912385600)","56574013300; 57443791800; 26631742000; 26321937900; 7007078486; 55912385600","Hybrid Convolutional Networks for End-to-End Event Detection in Concurrent PPG and PCG Signals Affected by Motion Artifacts","2022","69","8","","2512","2523","11","10.1109/TBME.2022.3148171","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124227796&doi=10.1109%2fTBME.2022.3148171&partnerID=40&md5=4a466d7dba93614dd0791f2ab2359b52","The accurate detection of physiologically-related events in photopletismographic (PPG) and phonocardiographic (PCG) signals, recorded by wearable sensors, is mandatory to perform the estimation of relevant cardiovascular parameters like the heart rate and the blood pressure. However, the measurement performed in uncontrolled conditions without clinical supervision leaves the detection quality particularly susceptible to noise and motion artifacts. This work proposes a new fully-automatic computational framework, based on convolutional networks, to identify and localize fiducial points in time as the foot, maximum slope and peak in PPG signal and the S1 sound in the PCG signal, both acquired by a custom chest sensor, described recently in the literature by our group. The event detection problem was reframed as a single hybrid regression-classification problem entailing a custom neural architecture to process sequentially the PPG and PCG signals. Tests were performed analysing four different acquisition conditions (rest, cycling, rest recovery and walking). Cross-validation results for the three PPG fiducial points showed identification accuracy greater than 93 % and localization error (RMSE) less than 10 ms. As expected, cycling and walking conditions provided worse results than rest and recovery, however reaching an accuracy greater than 90 % and a localization error less than 15 ms. Likewise, the identification and localization error for S1 sound were greater than 90 % and less than 25 ms. Overall, this study showcased the ability of the proposed technique to detect events with high accuracy not only for steady acquisitions but also during subject movements. We also showed that the proposed network outperformed traditional Shannon-energy-envelope method in the detection of S1 sound, reaching detection performance comparable to state of the art algorithms. Therefore, we argue that coupling chest sensors and deep learning processing techniques may disclose wearable devices to unobtrusively acquire health information, being less affected by noise and motion artifacts.  © 1964-2012 IEEE.","Deep convolutional networks; heart sounds; phonocardiography; photoplethismography; pulse arrival time; wearable sensors","Algorithms; Artifacts; Heart Rate; Motion; Photoplethysmography; Signal Processing, Computer-Assisted; Biomedical signal processing; Blood pressure; Cardiology; Computer system recovery; Convolution; Deep learning; Electrocardiography; Errors; Hidden Markov models; Phonocardiography; Timing circuits; Wearable sensors; Biomedical monitoring; Computational modelling; Convolutional networks; Deep convolutional network; Heart sounds; Heart-rate; Hidden-Markov models; Motion artifact; Photoplethismography; Pulse arrival time; Timing; adult; Article; back propagation; blood pressure; cardiovascular parameters; controlled study; convolutional neural network; cross validation; deep learning; heart beat; heart rate; heart sound; human; human experiment; image artifact; medical information; normal human; phonocardiography; photoelectric plethysmography; signal detection; sound detection; algorithm; artifact; motion; physiology; procedures; signal processing; Heart","","","IEEE Computer Society","35119997"
"Ameh Joseph A.; Abdullahi M.; Junaidu S.B.; Hassan Ibrahim H.; Chiroma H.","Ameh Joseph, Agaba (57464308700); Abdullahi, Mohammed (56926469300); Junaidu, Sahalu Balarabe (56458735000); Hassan Ibrahim, Hayatu (58671610200); Chiroma, Haruna (55583663400)","57464308700; 56926469300; 56458735000; 58671610200; 55583663400","Improved multi-classification of breast cancer histopathological images using handcrafted features and deep neural network (dense layer)","2022","14","","200066","","","","10.1016/j.iswa.2022.200066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125135980&doi=10.1016%2fj.iswa.2022.200066&partnerID=40&md5=e02b19ab6d7f3db1c303f37cf8560804","Breast cancer (BC) classification has become a point of concern within the field of biomedical informatics in the health care sector in recent years. This is because it is the second-largest cause of cancer-related fatalities among women. The medical field has attracted the attention of researchers in applying machine learning techniques to the detection, and monitoring of life-threatening diseases such as breast cancer (BC). Proper detection and monitoring contribute immensely to the survival of BC patients, which is largely dependent on the analysis of pathological images. Automatic detection of BC based on pathological images and the use of a Computer-Aided Diagnosis (CAD) system allow doctors to make a more reliable decision. Recently, Deep Learning algorithms like Convolution Neural Network have been proven to be reliable in detecting BC targets from pathological images. Several research efforts have been undertaken in the binary classification of histopathological images. However, few approaches have been proposed for the multi-classification of histopathological images. The classification accuracy produced by these approaches are inefficient since they considered only texture-based extracted features and they used some techniques that cannot extract some of the main features from the images. Also, these techniques still suffered from the issue of overfitting. In this work, handcrafted feature extraction techniques (Hu moment, Haralick textures, and color histogram) and Deep Neural Network (DNN) are employed for breast cancer multi-classification using histopathological images on the BreakHis dataset. The features extracted using the handcrafted techniques are used to train the DNN classifiers with four dense layers and Softmax. Further, the data augmentation method was employed to address the issue of overfitting. The results obtained reveal that the use of handcrafted approach as feature extractors and DNN classifiers had a better performance in breast cancer multi-classification than other approaches in the literature. Moreover, it was also noted that augmentation of data plays a key role in further improvement of classification accuracy. The proposed method achieved an accuracy score of 97.87% for 40x, 97.60% for 100x, 96.10% for 200x, and 96.84% for 400x for the magnification-dependent histopathological images classification. The results also showed that the proposed method for using the Handcrafted feature extraction method with DNN classifier had a better performance in multi-classification of breast cancer using histopathological images than most of the related works in the literature. © 2022 The Author(s)","Breast cancer; Deep neural network; Handcrafted features; Histopathological image; Multi-classification","Classification (of information); Computer aided diagnosis; Diseases; Extraction; Feature extraction; Image classification; Image enhancement; Learning algorithms; Medical imaging; Multilayer neural networks; Network layers; Textures; Breast Cancer; Classification accuracy; Dense layer; Handcrafted feature; Histopathological images; Multi-classification; Neural networks classifiers; Overfitting; Pathological images; Performance; Deep neural networks","","","Elsevier B.V.",""
"Yevtushenko P.; Goubergrits L.; Gundelwein L.; Setio A.; Ramm H.; Lamecker H.; Heimann T.; Meyer A.; Kuehne T.; Schafstedde M.","Yevtushenko, Pavlo (55804052100); Goubergrits, Leonid (6603944840); Gundelwein, Lina (57204003869); Setio, Arnaud (53264801600); Ramm, Heiko (55307653700); Lamecker, Heiko (6506463974); Heimann, Tobias (55861182300); Meyer, Alexander (56308158300); Kuehne, Titus (6603086969); Schafstedde, Marie (57216336157)","55804052100; 6603944840; 57204003869; 53264801600; 55307653700; 6506463974; 55861182300; 56308158300; 6603086969; 57216336157","Deep Learning Based Centerline-Aggregated Aortic Hemodynamics: An Efficient Alternative to Numerical Modeling of Hemodynamics","2022","26","4","","1815","1825","10","10.1109/JBHI.2021.3116764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118617063&doi=10.1109%2fJBHI.2021.3116764&partnerID=40&md5=83a0fab4c2bb7b422878f5996d068669","Image-based patient-specific modelling of hemodynamics are gaining increased popularity as a diagnosis and outcome prediction solution for a variety of cardiovascular diseases. While their potential to improve diagnostic capabilities and thereby clinical outcome is widely recognized, these methods require considerable computational resources since they are mostly based on conventional numerical methods such as computational fluid dynamics (CFD). As an alternative to the numerical methods, we propose a machine learning (ML) based approach to calculate patient-specific hemodynamic parameters. Compared to CFD based methods, our approach holds the benefit of being able to calculate a patient-specific hemodynamic outcome instantly with little need for computational power. In this proof-of-concept study, we present a deep artificial neural network (ANN) capable of computing hemodynamics for patients with aortic coarctation in a centerline aggregated (i.e., locally averaged) form. Considering the complex relation between vessels shape and hemodynamics on the one hand and the limited availability of suitable clinical data on the other, a sufficient accuracy of the ANN may however not be achieved with available data only. Another key aspect of this study is therefore the successful augmentation of available clinical data. Using a statistical shape model, additional training data was generated which substantially increased the ANN's accuracy, showcasing the ability of ML based methods to perform in-silico modelling tasks previously requiring resource intensive CFD simulations.  © 2013 IEEE.","Aritficial neural networks; biomedical engineering; fluid dynamics; medical simulation","Aorta; Computer Simulation; Deep Learning; Hemodynamics; Humans; Models, Cardiovascular; Patient-Specific Modeling; Blood vessels; Computational fluid dynamics; Deep neural networks; Diagnosis; Hemodynamics; Image segmentation; Medical imaging; Numerical methods; Biomedical imaging; Centerlines; Clinical data; Computational modelling; Haemodynamics; Image-based; Images segmentations; Patient specific; Patient-specific modeling; Shape; adult; aortic flow; aortic pressure; Article; artificial neural network; blood flow velocity; clinical outcome; computational fluid dynamics; computer model; controlled study; deep learning; deep neural network; female; heart cycle; hemodynamics; human; image segmentation; learning algorithm; machine learning; male; mathematical model; nuclear magnetic resonance imaging; signal noise ratio; simulation; steady state; support vector machine; training; aorta; biological model; computer simulation; hemodynamics; Numerical models","","","Institute of Electrical and Electronics Engineers Inc.","34591773"
"Nematzadeh S.; Kiani F.; Torkamanian-Afshar M.; Aydin N.","Nematzadeh, Sajjad (57215199789); Kiani, Farzad (36662461100); Torkamanian-Afshar, Mahsa (57215200734); Aydin, Nizamettin (7005593269)","57215199789; 36662461100; 57215200734; 7005593269","Tuning hyperparameters of machine learning algorithms and deep neural networks using metaheuristics: A bioinformatics study on biomedical and biological cases","2022","97","","107619","","","","10.1016/j.compbiolchem.2021.107619","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122778514&doi=10.1016%2fj.compbiolchem.2021.107619&partnerID=40&md5=1abb8e1060ed11d0305a77d83f70356d","The performance of a model in machine learning problems highly depends on the dataset and training algorithms. Choosing the right training algorithm can change the tale of a model. While some algorithms have a great performance in some datasets, they may fall into trouble in other datasets. Moreover, by adjusting hyperparameters of an algorithm, which controls the training processes, the performance can be improved. This study contributes a method to tune hyperparameters of machine learning algorithms using Grey Wolf Optimization (GWO) and Genetic algorithm (GA) metaheuristics. Also, 11 different algorithms including Averaged Perceptron, FastTree, FastForest, Light Gradient Boost Machine (LGBM), Limited memory Broyden Fletcher Goldfarb Shanno algorithm Maximum Entropy (LbfgsMxEnt), Linear Support Vector Machine (LinearSVM), and a Deep Neural Network (DNN) including four architectures are employed on 11 datasets in different biological, biomedical, and nature categories such as molecular interactions, cancer, clinical diagnosis, behavior related predictions, RGB images of human skin, and X-rays images of Covid19 and cardiomegaly patients. Our results show that in all trials, the performance of the training phases is improved. Also, GWO demonstrates a better performance with a p-value of 2.6E-5. Moreover, in most experiment cases of this study, the metaheuristic methods demonstrate better performance and faster convergence than Exhaustive Grid Search (EGS). The proposed method just receives a dataset as an input and suggests the best-explored algorithm with related arguments. So, it is appropriate for datasets with unknown distribution, machine learning algorithms with complex behavior, or users who are not experts in analytical statistics and data science algorithms. © 2022 Elsevier Ltd","Bioinformatics; Deep learning; Hyperparameters; Machine learning; Metaheuristics; Tuning","Algorithms; Computational Biology; COVID-19; Humans; Machine Learning; Neural Networks, Computer; SARS-CoV-2; Deep neural networks; Diagnosis; Genetic algorithms; Heuristic algorithms; Learning algorithms; Support vector machines; Deep learning; Gray wolves; Hyper-parameter; Machine learning algorithms; Machine learning problem; Metaheuristic; Performance; Training algorithms; Training process; Tuning; algorithm; biology; human; machine learning; Bioinformatics","","","Elsevier Ltd","35033837"
"Balaji C.; Suresh D.S.","Balaji, Chetan (57292820500); Suresh, D.S. (56736003100)","57292820500; 56736003100","Multi-class Recognition of Alzheimer’s and Parkinson’s diseases using Bag of Deep reduced Features (BoDrF) with Improved Chaotic Multi Verse Harris Hawks Optimization (CMVHHO) and Random Forest (RF) based classification for early diagnosis","2023","11","3","","774","785","11","10.1080/21681163.2022.2111721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136584119&doi=10.1080%2f21681163.2022.2111721&partnerID=40&md5=1cf19ef6998dd3e3f13948c4b9fdf67e","This manuscript proposes a multi-class recognition system with improved classification accuracy using machine-learning techniques by considering electroencephalogram (EEG) and speech signal analysis to classify and detect patients affected by Alzheimer’s disease (AD) and Parkinson’s disease (PD) in its initial stages. Acquired raw EEG and speech signal are pre-processed utilising wavelet filters to eliminate noises, then the features impedivity, phase angle, higher frequency slope of phase angle, standard deviation, minimal pitch, maximal pitch, count of voice breaks are extracted from EEG and speech signal using bag of deep reduced features. Optimal features mean absolute values, enhanced wavelength, wavelength, zeros crossing are selected using an improved chaotic multi-verse Harris Hawks optimisation (CMVHHO) algorithm. Finally, Random Forest (RF) classifier is employed to classify patients suffered by AD with PD. Experimental results show 95.17%, 96.31% and 97.48% higher accuracy for AD compared with existing methods, like MCR-AD-PD-SPWVD-CNN, MCR-AD-PD-ICA-DSCHN and MCR-AD-DWT-KNN-RLDA, respectively. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Alzheimer’s disease; Bag of Deep reduced Features; Chaotic Multi-Verse Harris Hawks Optimisation; Electroencephalography; Parkinson’s disease; Random forest classifier; wavelet filters","Biomedical signal processing; Classification (of information); Computer aided diagnosis; Continuous speech recognition; Decision trees; Electrophysiology; Learning systems; Speech communication; Alzheimer; Alzheimer’s disease; Bag of deep reduced feature; Chaotic multi-verse harris hawk optimization; Chaotics; Electroencephalogram signals; Optimisations; Parkinson’s disease; Random forest classifier; Wavelet filters; Alzheimer disease; Article; artificial intelligence; artificial neural network; Bag of Deep  reduced Features; Chaotic Multi Verse Harris Hawks  Optimization; controlled study; data mining; diagnostic accuracy; diagnostic test accuracy study; discriminant analysis; electroencephalogram; electroencephalography; genetic algorithm; human; image segmentation; learning algorithm; limit of detection; limit of quantitation; machine learning; nuclear magnetic resonance imaging; operation duration; positron emission tomography; quantitative structure activity relation; random forest; receiver operating characteristic; sensitivity analysis; sensitivity and specificity; support vector machine; Electroencephalography","","","Taylor and Francis Ltd.",""
"Pham V.; Nguyen H.; Pham B.; Nguyen T.; Nguyen H.","Pham, Vuong (57189026927); Nguyen, Hai (58775378000); Pham, Bao (59025843200); Nguyen, Thien (57754156100); Nguyen, Hien (37081576100)","57189026927; 58775378000; 59025843200; 57754156100; 37081576100","Robust Engineering-based Unified Biomedical Imaging Framework for Liver Tumor Segmentation","2023","19","1","","37","45","8","10.2174/1573405617666210804151024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137996412&doi=10.2174%2f1573405617666210804151024&partnerID=40&md5=383bbb2bcc14c3186797c10b2c4d1d00","Background: Computer vision in general and semantic segmentation has experienced many achievements in recent years. Consequently, the emergence of medical imaging has provided new opportunities for conducting artificial intelligence research. Since cancer is the second-leading cause of death in the world, early-stage diagnosis is an essential process that directly slows down the development speed of cancer. Methods: Deep neural network-based methods are anticipated to reduce diagnosis time for patholo-gists. Results: In this research paper, an approach to liver tumor identification based on two types of medical images has been presented: computed tomography scans and whole-slide. It is constructed based on the improvement of U-Net and GLNet architectures. It also includes sub-modules that are combined with segmentation models to boost up the overall performance during inference phases. Conclusion: Based on the experimental results, the proposed unified framework has been emerging to be used in the production environment. © 2023 Bentham Science Publishers.","deep learning; framework; histopathology; neural networks; radiology; Tumor segmentation","Artificial Intelligence; Humans; Liver Neoplasms; Neural Networks, Computer; Semantics; Computerized tomography; Deep neural networks; Diagnosis; Diseases; Semantic Segmentation; Semantics; Tumors; Artificial intelligence research; Biomedical imaging; Deep learning; Framework; Histopathology; Liver tumor segmentations; Neural-networks; Robust engineering; Semantic segmentation; Tumor segmentation; Article; artificial intelligence; augmentation index; bleeding; computer assisted tomography; computer simulation; computer vision; conceptual framework; controlled study; convolutional neural network; data Augmentation; deep learning; deep neural network; diabetic retinopathy; diagnosis time; diagnostic imaging; histopathology; human; human tissue; image processing; image quality; image reconstruction; image segmentation; learning algorithm; liver tumor; machine learning; nerve cell network; Robust  Engineering; stroma; x-ray computed tomography; artificial intelligence; semantics; Medical imaging","","","Bentham Science Publishers","34348633"
"Fang F.; Yao Y.; Zhou T.; Xie G.; Lu J.","Fang, Feiyi (57255603100); Yao, Yazhou (57072144300); Zhou, Tao (56367644000); Xie, Guosen (56401452700); Lu, Jianfeng (55547138819)","57255603100; 57072144300; 56367644000; 56401452700; 55547138819","Self-Supervised Multi-Modal Hybrid Fusion Network for Brain Tumor Segmentation","2022","26","11","","5310","5320","10","10.1109/JBHI.2021.3109301","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114719283&doi=10.1109%2fJBHI.2021.3109301&partnerID=40&md5=c8e877450d0b10d7dfc95ad76cda23c0","Accurate medical image segmentation of brain tumors is necessary for the diagnosing, monitoring, and treating disease. In recent years, with the gradual emergence of multi-sequence magnetic resonance imaging (MRI), multi-modal MRI diagnosis has played an increasingly important role in the early diagnosis of brain tumors by providing complementary information for a given lesion. Different MRI modalities vary significantly in context, as well as in coarse and fine information. As the manual identification of brain tumors is very complicated, it usually requires the lengthy consultation of multiple experts. The automatic segmentation of brain tumors from MRI images can thus greatly reduce the workload of doctors and buy more time for treating patients. In this paper, we propose a multi-modal brain tumor segmentation framework that adopts the hybrid fusion of modality-specific features using a self-supervised learning strategy. The algorithm is based on a fully convolutional neural network. Firstly, we propose a multi-input architecture that learns independent features from multi-modal data, and can be adapted to different numbers of multi-modal inputs. Compared with single-modal multi-channel networks, our model provides a better feature extractor for segmentation tasks, which learns cross-modal information from multi-modal data. Secondly, we propose a new feature fusion scheme, named hybrid attentional fusion. This scheme enables the network to learn the hybrid representation of multiple features and capture the correlation information between them through an attention mechanism. Unlike popular methods, such as feature map concatenation, this scheme focuses on the complementarity between multi-modal data, which can significantly improve the segmentation results of specific regions. Thirdly, we propose a self-supervised learning strategy for brain tumor segmentation tasks. Our experimental results demonstrate the effectiveness of the proposed model against other state-of-the-art multi-modal medical segmentation methods.  © 2013 IEEE.","Attention; hybrid feature fusion; multi-modal learning; self-supervised learning","Algorithms; Brain Neoplasms; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Brain; Deep learning; Diagnosis; Image fusion; Image segmentation; Medical imaging; Modal analysis; Neural networks; Supervised learning; Tumors; Attention; Biomedical imaging; Deep learning; Features extraction; Features fusions; Hybrid feature fusion; Hybrid features; Images segmentations; Multi-modal learning; Self-supervised learning; Task analysis; Article; brain tumor; convolutional neural network; deep learning; diffusion tensor imaging; feature extraction; fluid-attenuated inversion recovery imaging; functional magnetic resonance imaging; fusion gene; human; hybrid; image segmentation; learning; major clinical study; multimodal imaging; supervised machine learning; support vector machine; algorithm; diagnostic imaging; image processing; nuclear magnetic resonance imaging; procedures; Magnetic resonance imaging","National Natural Science Foundation of China, NSFC, (61976116, 62102182, 62172228); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Jiangsu Province, (BK20210327); Natural Science Foundation of Jiangsu Province; Fundamental Research Funds for the Central Universities, (30920021135); Fundamental Research Funds for the Central Universities","","Institute of Electrical and Electronics Engineers Inc.","34478389"
"Cleatus T.S.; Thungamani M.","Cleatus, T. Saneesh (56441646500); Thungamani, M. (57198886198)","56441646500; 57198886198","Epileptic Seizure Detection using Spectral Transformation and Convolutional Neural Networks","2022","103","4","","1115","1125","10","10.1007/s40031-021-00693-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124255541&doi=10.1007%2fs40031-021-00693-4&partnerID=40&md5=9c2cbbfb8a1a71ee9b08857ac995ffe5","Automatic seizure detection and classification of seizures, as well as identification of pre-ictal activity in the electroencephalogram (EEG), are extremely important in clinical research. This decreases the time it takes to identify seizures and, as a result, improves seizure activity prediction. We propose a computer-aided method to detect the pre-ictal and ictal activity from a multichannel EEG signal. Three pre-processing techniques that are applied to EEG time-domain signals to generate an image database are proposed here. This image database is given as input to the machine learning algorithm for classification. Conversion of a time domain EEG signal to an image is accomplished by extracting EEG signal features such as correlation coefficient, short-time Fourier transform (spectrogram), and mutual information. The processed EEG waveform, which is represented as images, is used to train a convolutional neural network (CNN). The CNN classifies input signals into three classes—Seizure, Normal and Pre-ictal. We used the transfer learning method, which uses Alexnet, a pre-trained CNN architecture, for image training and classification. After training on the Spectrogram, Mutual Information, and Correlation coefficient image representations of the EEG signals, we have obtained a validation accuracy of 99.33%, 95.33%, and 97.5%, respectively. © 2022, The Institution of Engineers (India).","Alexnet; CNN; EEG; Epilepsy","Biomedical signal processing; Classification (of information); Clinical research; Convolution; Convolutional neural networks; Deep learning; Image processing; Learning algorithms; Learning systems; Spectrographs; Time domain analysis; Transfer learning; Alexnet; Convolutional neural network; Correlation coefficient; Electroencephalogram signals; Epilepsy; Epileptic seizure detection; Image database; Mutual informations; Spectral transformations; Spectrograms; Electroencephalography","","","Springer",""
"Niu C.; Cong W.; Fan F.-L.; Shan H.; Li M.; Liang J.; Wang G.","Niu, Chuang (57202950909); Cong, Wenxiang (7005402309); Fan, Feng-Lei (57222365585); Shan, Hongming (57191481929); Li, Mengzhou (57211524125); Liang, Jimin (57403161700); Wang, Ge (7407148134)","57202950909; 7005402309; 57222365585; 57191481929; 57211524125; 57403161700; 7407148134","Low-Dimensional Manifold-Constrained Disentanglement Network for Metal Artifact Reduction","2022","6","6","","656","666","10","10.1109/TRPMS.2021.3122071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128580939&doi=10.1109%2fTRPMS.2021.3122071&partnerID=40&md5=67d1bf722e1fd5f05c1c5bf274e26c3b","Deep neural network-based methods have achieved promising results for computed tomography (CT) metal artifact reduction (MAR), most of which use many synthesized paired images for supervised learning. As synthesized metal artifacts in CT images may not accurately reflect the clinical counterparts, an artifact disentanglement network (ADN) was proposed with unpaired clinical images directly, producing promising results on clinical datasets. However, as the discriminator can only judge if large regions semantically look artifact-free or artifact-affected, it is difficult for ADN to recover small structural details of artifact-affected CT images based on adversarial losses only without sufficient constraints. To overcome the illposedness of this problem, here we propose a low-dimensional manifold (LDM)-constrained disentanglement network (DN), leveraging the image characteristics that the patch manifold of CT images is generally low dimensional. Specifically, we design an LDM-DN learning algorithm to empower the DN through optimizing the synergistic loss functions used in ADN while constraining the recovered images to be on a low-dimensional patch manifold. Moreover, learning from both paired and unpaired data, an efficient hybrid optimization scheme is proposed to further improve the MAR performance on clinical datasets. Extensive experiments demonstrate that the proposed LDM-DN approach can consistently improve the MAR performance in paired and/or unpaired learning settings, outperforming competing methods on synthesized and clinical datasets.  © 2017 IEEE.","Disentanglement network (DN); low-dimensional manifold (LDM); metal artifact reduction (MAR)","Computer vision; Computerized tomography; Deep neural networks; Image reconstruction; Learning algorithms; Medical imaging; Biomedical imaging; Computed tomography; CT Image; Deep learning; Disentanglement network.; Images reconstruction; Lower dimensional manifolds; Manifold; Metal artifact reduction; Synthesised; Metals","Shanghai Municipal of Science and Technology Project, (20JC1419500); Shanghai Sailing Program, (21YF1402800); National Institutes of Health, NIH; National Cancer Institute, NCI, (R01CA233888, R01CA237267); National Cancer Institute, NCI; National Institute of Biomedical Imaging and Bioengineering, NIBIB, (R01EB026646, R01EB031102, R01HL151561); National Institute of Biomedical Imaging and Bioengineering, NIBIB; Natural Science Foundation of Shanghai, (21ZR1403600); Natural Science Foundation of Shanghai; National Natural Science Foundation of China, NSFC, (62101136); National Natural Science Foundation of China, NSFC","","Institute of Electrical and Electronics Engineers Inc.",""
"Wen Y.; He W.; Zhang Y.","Wen, Yintang (36678382800); He, Wenjing (57917771800); Zhang, Yuyan (36629686500)","36678382800; 57917771800; 36629686500","A new attention-based 3D densely connected cross-stage-partial network for motor imagery classification in BCI","2022","19","5","056026","","","","10.1088/1741-2552/ac93b4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139380579&doi=10.1088%2f1741-2552%2fac93b4&partnerID=40&md5=4880caf1017f2bdba560e448a22eb089","Objective. The challenge for motor imagery (MI) in brain-computer interface (BCI) systems is finding a reliable classification model that has high classification accuracy and excellent robustness. Currently, one of the main problems leading to degraded classification performance is the inaccuracy caused by nonstationarities and low signal-to-noise ratio in electroencephalogram (EEG) signals. Approach. This study proposes a novel attention-based 3D densely connected cross-stage-partial network (DCSPNet) model to achieve efficient EEG-based MI classification. This is an end-to-end classification model framework based on the convolutional neural network (CNN) architecture. In this framework, to fully utilize the complementary features in each dimension, the optimal features are extracted adaptively from the EEG signals through the spatial-spectral-temporal (SST) attention mechanism. The 3D DCSPNet is introduced to reduce the gradient loss by segmenting the extracted feature maps to strengthen the network learning capability. Additionally, the design of the densely connected structure increases the robustness of the network. Main results. The performance of the proposed method was evaluated using the BCI competition IV 2a and the high gamma dataset, achieving an average accuracy of 84.45% and 97.88%, respectively. Our method outperformed most state-of-the-art classification algorithms, demonstrating its effectiveness and strong generalization ability. Significance. The experimental results show that our method is promising for improving the performance of MI-BCI. As a general framework based on time-series classification, it can be applied to BCI-related fields.  © 2022 IOP Publishing Ltd.","attention mechanism; convolutional neural networks (CNN); electroencephalogram (EEG); motor imagery (MI)","Algorithms; Brain-Computer Interfaces; Electroencephalography; Imagination; Neural Networks, Computer; Biomedical signal processing; Brain computer interface; Convolution; Convolutional neural networks; Image classification; Signal to noise ratio; Attention mechanisms; Classification models; Convolutional neural network; Electroencephalogram; Electroencephalogram signals; Motor imagery; Motor imagery classification; Performance; Article; attention; classification algorithm; convolutional neural network; cross validation; data accuracy; data visualization; deep learning; electroencephalogram; experiment; feature extraction; human; human experiment; imagery; information processing; motor imagery; motor performance; network learning; normal human; performance; three-dimensional imaging; algorithm; brain computer interface; electroencephalography; imagination; procedures; Electroencephalography","Hebei Provincial Department of Bureau of Science and Technology, (20310401D, 216Z1704G)","","Institute of Physics","36130589"
"Nanammal V.S.R.; Jayagopalan V.G.","Nanammal, Venkata Samy Raja (56586269000); Jayagopalan, Venu Gopalakrishnan (57696453800)","56586269000; 57696453800","A secured biomedical image processing scheme to detect pneumonia disease using dynamic learning principles","2022","30","3","","245","252","7","10.1177/1063293X221097447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130227794&doi=10.1177%2f1063293X221097447&partnerID=40&md5=431ba77a0b124ad8739c7d03a27c28e4","Now-a-days, the medical industry is growing a lot with the adaptation of latest technologies as well as the logical evaluation and security norms provides a robust platform to enhance the effectiveness of the industry at a drastic level. In this paper, a digital bio-medical image processing based Pneumonia disease identification system is introduced with enhanced security features. Due to improving the efficiency of the application, a well-known watermarking based security constraint is included to provide the protection to the respective hospital environment and patients as well. To avoid these issues, some sort of security aspects need to be followed so that this paper included watermarking based security to provide a rich level of protection to the images going to be tested. The main intention of this paper is to introduce a novel security enabled digital image processing scheme to identify the Pneumonic disease in earlier stages with respect to the proper classification principles. In this paper, a novel deep learning algorithm is introduced called enhanced Dynamic Learning Neural Network in which it is a hybrid algorithm with the combinations of conventional DLNN algorithm and the Support Vector Classification algorithm. This proposed approach effectively identifies the Pneumonia disease in earlier stages but the security inspection on the testing stage is so important to analyze the disease. The respective testing image is properly watermarked with the logo of the corresponding hospital; the image is processed otherwise the proposed approach skips the image to process. These kinds of security features emphasize the medical industry and boost up the levels more as well as the patients can get an appropriate error free care with the help of such technology. A proper Chest X-Ray based Kaggle dataset is considered to process the system as well as which contains 5856 Chest X-Ray images under two different categories such as Pneumonia and Normal. With respect to processing these images and identifying the Pneumonia disease effectively as well as the proposed watermarking enabled security features provide a good impact in the medical field protection system. The resulting section provides the proper proof to the effectiveness of the proposed approach and its prediction efficiency. © The Author(s) 2022.","deep learning; enhanced dynamic learning neural network; pneumonia; security; support vector classification; watermarking","Deep learning; Efficiency; Hospitals; Image classification; Image watermarking; Learning algorithms; Learning systems; Medical imaging; Network security; Security systems; Support vector machines; Watermarking; Deep learning; Dynamic learning; Enhanced dynamic learning neural network; Latest technology; Learning neural networks; Medical industries; Pneumonia; Security; Security features; Support vector classification; Image enhancement","","","SAGE Publications Ltd",""
"Achuthan S.; Chatterjee R.; Kotnala S.; Mohanty A.; Bhattacharya S.; Salgia R.; Kulkarni P.","Achuthan, Srisairam (13002699200); Chatterjee, Rishov (57226083520); Kotnala, Sourabh (57222041522); Mohanty, Atish (57215902692); Bhattacharya, Supriyo (8899119600); Salgia, Ravi (7006089971); Kulkarni, Prakash (16022382600)","13002699200; 57226083520; 57222041522; 57215902692; 8899119600; 7006089971; 16022382600","Leveraging deep learning algorithms for synthetic data generation to design and analyze biological networks","2022","47","3","43","","","","10.1007/s12038-022-00278-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134050399&doi=10.1007%2fs12038-022-00278-3&partnerID=40&md5=fbe9ca16bff58775d1d604798ceb6d74","The use of synthetic data is gaining an increasingly prominent role in data and machine learning workflows to build better models and conduct analyses with greater statistical inference. In the domains of healthcare and biomedical research, synthetic data may be seen in structured and unstructured formats. Concomitant with the adoption of synthetic data, a sub-discipline of machine learning known as deep learning has taken the world by storm. At a larger scale, deep learning methods tend to outperform traditional methods in regression and classification tasks. These techniques are also used in generative modeling and are thus prime candidates for generating synthetic data in both structured and unstructured formats. Here, we emphasize the generation of synthetic data in healthcare and biomedical research using deep learning methods for unstructured data formats such as text and images. Deep learning methods leverage the neural network algorithm, and in the context of generative modeling, several neural network architectures can create new synthetic data for a problem at hand including, but not limited to, recurrent neural networks (RNNs), variational autoencoders (VAEs), and generative adversarial networks (GANs). To better understand these methods, we will look at specific case studies such as generating realistic clinical notes of a patient, the generation of synthetic DNA sequences, as well as to enrich experimental data collected during the study of heterotypic cultures of cancer cells. © 2022, Indian Academy of Sciences.","Artificial intelligence; deep learning; generative adversarial networks; machine learning; synthetic data; variational autoencoders","Algorithms; Deep Learning; Humans; Machine Learning; Neural Networks, Computer; antibiotic agent; antineoplastic agent; DNA; polypeptide antibiotic agent; algorithm; artificial intelligence; artificial neural network; biological analysis; cancer; cell; classification; data processing; machine learning; network analysis; numerical model; regression analysis; antibiotic resistance; artificial neural network; autoencoder; cancer cell culture; classification; data analysis; deep learning; DNA sequence; electronic medical record; generative adversarial network; human; image processing; information processing; intermethod comparison; long short term memory network; machine learning; malignant neoplasm; medical record review; medical research; patient information; recurrent neural network; regression analysis; Review; statistical analysis; variational autoencoder; algorithm","","","Springer","36222162"
"Mahyari T.L.; Dansereau R.M.","Mahyari, Tayebeh Lotfi (24528912800); Dansereau, Richard M. (7003511066)","24528912800; 7003511066","Multi-layer random walker image segmentation for overlapped cervical cells using probabilistic deep learning methods","2022","16","11","","2959","2972","13","10.1049/ipr2.12531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129668195&doi=10.1049%2fipr2.12531&partnerID=40&md5=56449496edbfd731e2a5d9bc06cfe5bf","A method for overlapping cell image segmentation is presented with a focus on multi-layer image processing in a three-phase scheme. In the first phase, a convolutional neural network is developed to provide a coarse cell segmentation with multiple output layers to identify cell cytoplasm, locations of cell nuclei, and the background, all as probabilistic image maps for the layer outputs. In the second phase, the probabilistic image maps from the convolutional neural network are used to identify locations of cell nuclei and cell cytoplasm. Then, multi-layer random walker image segmentation is used with cell nuclei as hard initial seeds and the cytoplasm estimates as soft seeds in a diffusion graph-based segmentation of the cells. With rough cell segmentation from both the trained convolutional neural network and the multi-layer random walker graph-based technique, a third phase combines and refines the cell segmentation using the Hungarian algorithm to optimise the assignment of individual pixel locations for the final cell segmentation. We evaluate the proposed method on cervical cell images generated from the International Symposium on Biomedical Imaging 2014 dataset with results that give a Dice similarity coefficient of 97.2% (compared to 93.2% for competitors) when trained on the generated dataset. © 2022 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.","","Cells; Convolution; Convolutional neural networks; Cytology; Deep learning; Graphic methods; Location; Medical imaging; Multilayer neural networks; Random processes; Cell cytoplasm; Cell nucleus; Cell segmentation; Cervical cells; Convolutional neural network; Image maps; Images segmentations; Multi-layers; Probabilistic images; Random walkers; Image segmentation","Natural Sciences and Engineering Research Council of Canada, NSERC","","John Wiley and Sons Inc",""
"Panda R.; Kalmady S.V.; Greiner R.","Panda, Rohan (57545593800); Kalmady, Sunil Vasu (26657946700); Greiner, Russell (7102873710)","57545593800; 26657946700; 7102873710","Multi-Source Domain Adaptation Techniques for Mitigating Batch Effects: A Comparative Study","2022","16","","805117","","","","10.3389/fninf.2022.805117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129553603&doi=10.3389%2ffninf.2022.805117&partnerID=40&md5=d5fefe517aab352e301d85137ddf6839","The past decade has seen an increasing number of applications of deep learning (DL) techniques to biomedical fields, especially in neuroimaging-based analysis. Such DL-based methods are generally data-intensive and require a large number of training instances, which might be infeasible to acquire from a single acquisition site, especially for data, such as fMRI scans, due to the time and costs that they demand. We can attempt to address this issue by combining fMRI data from various sites, thereby creating a bigger heterogeneous dataset. Unfortunately, the inherent differences in the combined data, known as batch effects, often hamper learning a model. To mitigate this issue, techniques such as multi-source domain adaptation [Multi-source Domain Adversarial Networks (MSDA)] aim at learning an effective classification function that uses (learned) domain-invariant latent features. This article analyzes and compares the performance of various popular MSDA methods [MDAN, Domain AggRegation Networks (DARN), Multi-Domain Matching Networks (MDMN), and Moment Matching for MSDA (M3SDA)] at predicting different labels (illness, age, and sex) of images from two public rs-fMRI datasets: ABIDE 1and ADHD-200. It also evaluates the impact of various conditions such as class imbalance, the number of sites along with a comparison of the degree of adaptation of each of the methods, thereby presenting the effectiveness of MSDA models in neuroimaging-based applications. Copyright © 2022 Panda, Kalmady and Greiner.","ADHD; ASD; batch effects; deep learning; multi-source domain adaptation; resting-state fMRI","Article; artificial neural network; attention deficit hyperactivity disorder; auditory stimulation; autism; connectome; deep learning; demography; electroencephalogram; functional connectivity; functional magnetic resonance imaging; gray matter; human; learning algorithm; machine learning; mental disease; neuroimaging; phenotype; signal noise ratio; support vector machine; training; visual field","","","Frontiers Media S.A.",""
"Kim K.","Kim, Kisoo (59082228400)","59082228400","Single-Shot Light-Field Microscopy: An Emerging Tool for 3D Biomedical Imaging","2022","16","4","","397","408","11","10.1007/s13206-022-00077-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145015449&doi=10.1007%2fs13206-022-00077-w&partnerID=40&md5=49ecb0235bf5e7dc29a4d9e69374b379","3D microscopy is a useful tool to visualize the detailed structures and mechanisms of biomedical specimens. In particular, biophysical phenomena such as neural activity require fast 3D volumetric imaging because fluorescence signals degrade quickly. A light-field microscope (LFM) has recently attracted attention as a high-speed volumetric imaging technique by recording 3D information in a single-snapshot. This review highlighted recent progress in LFM techniques for 3D biomedical applications. In detail, various image reconstruction algorithms according to LFM configurations are explained, and several biomedical applications such as neuron activity localization, live-cell imaging, locomotion analysis, and single-molecule visualization are introduced. We also discuss deep learning-based LFMs to enhance image resolution and reduce reconstruction artifacts. © 2022, The Author(s).","3D biomedical imaging; Deep learning-enhanced LFM; Light-field microscope (LFM); Neuron activity","Deep learning; Fluorescence; Image enhancement; Image reconstruction; Medical applications; Medical imaging; Neurons; green fluorescent protein; nuclear protein; 3d biomedical imaging; Biomedical applications; Biomedical imaging; Deep learning-enhanced light-field microscope; Light fields; Light-field microscope; Neuron activity; Single-shot; Volumetric Imaging; bleaching; Caenorhabditis elegans; calcium imaging; combined selective illumination microscopy; confocal laser scanning microscopy; convolutional neural network; COS-7 cell line; deep learning; fibroblast; fluorescence; functional magnetic resonance imaging; HeLa cell line; human; image artifact; image processing; image quality; image reconstruction; imaging algorithm; live cell imaging; locomotion; lysosome; microscopy; molecular imaging; nonhuman; phototoxicity; positron emission tomography; Review; signal noise ratio; single molecule imaging; single shot light field microscopy; structured illumination microscopy; synapse; three dimensional imaging volumetric imaging; three-dimensional imaging; zebra fish; Image resolution","Ministry of Trade, Industry and Energy, MOTIE, (20020866); Ministry of Trade, Industry and Energy, MOTIE; National Research Foundation of Korea, NRF, (2021R1F1A1048603); National Research Foundation of Korea, NRF; Ministry of SMEs and Startups, MSS, (S3103859); Ministry of SMEs and Startups, MSS","","SpringerOpen",""
"McLane I.; Lauwers E.; Stas T.; Busch-Vishniac I.; Ides K.; Verhulst S.; Steckel J.","McLane, Ian (57221959335); Lauwers, Eline (57203148564); Stas, Toon (57325038600); Busch-Vishniac, Ilene (56990240300); Ides, Kris (35388649500); Verhulst, Stijn (12762009000); Steckel, Jan (25958439900)","57221959335; 57203148564; 57325038600; 56990240300; 35388649500; 12762009000; 25958439900","Comprehensive Analysis System for Automated Respiratory Cycle Segmentation and Crackle Peak Detection","2022","26","4","","1847","1860","13","10.1109/JBHI.2021.3123353","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118582479&doi=10.1109%2fJBHI.2021.3123353&partnerID=40&md5=3c4f6840f8b925d70795347adde5a9a1","Digital auscultation is a well-known method for assessing lung sounds, but remains a subjective process in typical practice, relying on the human interpretation. Several methods have been presented for detecting or analyzing crackles but are limited in their real-world application because few have been integrated into comprehensive systems or validated on non-ideal data. This work details a complete signal analysis methodology for analyzing crackles in challenging recordings. The procedure comprises five sequential processing blocks: (1) motion artifact detection, (2) deep learning denoising network, (3) respiratory cycle segmentation, (4) separation of discontinuous adventitious sounds from vesicular sounds, and (5) crackle peak detection. This system uses a collection of new methods and robustness-focused improvements on previous methods to analyze respiratory cycles and crackles therein. To validate the accuracy, the system is tested on a database of 1000 simulated lung sounds with varying levels of motion artifacts, ambient noise, cycle lengths and crackle intensities, in which ground truths are exactly known. The system performs with average F-score of 91.07% for detecting motion artifacts and 94.43% for respiratory cycle extraction, and an overall F-score of 94.08% for detecting the locations of individual crackles. The process also successfully detects healthy recordings. Preliminary validation is also presented on a small set of 20 patient recordings, for which the system performs comparably. These methods provide quantifiable analysis of respiratory sounds to enable clinicians to distinguish between types of crackles, their timing within the respiratory cycle, and the level of occurrence. Crackles are one of the most common abnormal lung sounds, presenting in multiple cardiorespiratory diseases. These features will contribute to a better understanding of disease severity and progression in an objective, simple and non-invasive way.  © 2013 IEEE.","Algorithm design and analysis; biomedical coustics; machine learning; medicine; signal processing","Auscultation; Humans; Lung; Respiratory Rate; Respiratory Sounds; Signal Processing, Computer-Assisted; Acoustic noise; Biological organs; Crack detection; Motion analysis; Respiratory mechanics; Respiratory system; Analysis system; Annotation; Comprehensive analysis; Deep learning; F-score; Lung sounds; Motion artifact; Noise measurements; Peak detection; Respiratory cycle; abnormal respiratory sound; Article; artifact; artificial neural network; audiometry; breathing pattern; breathing rate; convolutional neural network; crackle; crackle peak detection; deep learning; disease severity; human; image segmentation; machine learning; mathematical model; measurement accuracy; medical parameters; noise measurement; noise reduction; predictive value; respiratory cycle segmentation; sensitivity and specificity; signal noise ratio; signal processing; abnormal respiratory sound; auscultation; lung; procedures; signal processing; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.","34705660"
"Lee K.; Cavalcanti T.C.; Kim S.; Lew H.M.; Suh D.H.; Lee D.H.; Hwang J.Y.","Lee, Kyungsu (57215845124); Cavalcanti, T.C. (57215845871); Kim, Sewoong (57192317648); Lew, Hah Min (57221926012); Suh, Dae Hun (7202639556); Lee, Dong Hun (55649570908); Hwang, Jae Youn (57838218600)","57215845124; 57215845871; 57192317648; 57221926012; 7202639556; 55649570908; 57838218600","Multi-Task and Few-Shot Learning-Based Fully Automatic Deep Learning Platform for Mobile Diagnosis of Skin Diseases","2023","27","1","","176","187","11","10.1109/JBHI.2022.3193685","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135759668&doi=10.1109%2fJBHI.2022.3193685&partnerID=40&md5=12cd1163b487a45572bd3ab5f55e88bf","Fluorescence imaging-based diagnostic systems have been widely used to diagnose skin diseases due to their ability to provide detailed information related to the molecular composition of the skin compared to conventional RGB imaging. In addition, recent advances in smartphones have made them suitable for application in biomedical imaging, and therefore various smartphone-based optical imaging systems have been developed for mobile healthcare. However, an advanced analysis algorithm is required to improve the diagnosis of skin diseases. Various deep learning-based algorithms have recently been developed for this purpose. However, deep learning-based algorithms using only white-light reflectance RGB images have exhibited limited diagnostic performance. In this study, we developed an auxiliary deep learning network called fluorescence-aided amplifying network (FAA-Net) to diagnose skin diseases using a developed multi-modal smartphone imaging system that offers RGB and fluorescence images. FAA-Net is equipped with a meta-learning-based algorithm to solve problems that may occur due to the insufficient number of images acquired by the developed system. In addition, we devised a new attention-based module that can learn the location of skin diseases by itself and emphasize potential disease regions, and incorporated it into FAA-Net. We conducted a clinical trial in a hospital to evaluate the performance of FAA-Net and to compare various evaluation metrics of our developed model and other state-of-the-art models for the diagnosis of skin diseases using our multi-modal system. Experimental results demonstrated that our developed model exhibited an 8.61% and 9.83% improvement in mean accuracy and area under the curve in classifying skin diseases, respectively, compared with other advanced models.  © 2013 IEEE.","Deep learning; few-shot learning; fluorescence imaging; multi-modal system; skin diagnosis","Algorithms; Deep Learning; Diagnostic Imaging; Humans; Neural Networks, Computer; Skin Diseases; Deep learning; Fluorescence imaging; Imaging systems; Learning algorithms; Learning systems; mHealth; Modal analysis; Smartphones; Deep learning; Few-shot learning; Fluorescence imaging; Learning-based algorithms; Multimodal system; Skin diagnose; Skin disease; Smart phones; Task analysis; area under the curve; Article; classification algorithm; cross validation; data processing; deep learning; diagnostic accuracy; disease classification; feature extraction; feature selection; few-shot learning; fluorescence imaging; fluorescence-aided amplifying network; human; learning algorithm; mathematical model; multi-task learning; qualitative analysis; quantitative analysis; receiver operating characteristic; skin disease; algorithm; clinical trial; diagnostic imaging; skin disease; Diagnosis","Ministry of Science, ICT and Future Planning, MSIP, (2017M3A9G8084463); National Research Foundation of Korea, NRF, (NRF-2020R1A2B5B01002786)","","Institute of Electrical and Electronics Engineers Inc.","35877797"
"Jiang M.; Qiu Y.; Zhang W.; Zhang J.; Wang Z.; Ke W.; Wu Y.; Wang Z.","Jiang, Mingfeng (16175216000); Qiu, Yujie (57851028600); Zhang, Wei (57735203700); Zhang, Jucheng (55581543800); Wang, Zhefeng (57851448600); Ke, Wei (57207833441); Wu, Yongquan (7406891450); Wang, Zhikang (14526073400)","16175216000; 57851028600; 57735203700; 55581543800; 57851448600; 57207833441; 7406891450; 14526073400","Visualization deep learning model for automatic arrhythmias classification","2022","43","8","085003","","","","10.1088/1361-6579/ac8469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136242400&doi=10.1088%2f1361-6579%2fac8469&partnerID=40&md5=8a104e1b421a92fb42d1d8a7ffdf1d5e","Objective. With the improvement of living standards, heart disease has become one of the common diseases that threaten human health. Electrocardiography (ECG) is an effective way of diagnosing cardiovascular diseases. With the rapid growth of ECG examinations and the shortage of cardiologists, accurate and automatic arrhythmias classification has become a research hotspot. The main purpose of this paper is to improve accuracy in detecting abnormal ECG patterns. Approach. A hybrid 1D Resnet-GRU method, consisting of the Resnet and gated recurrent unit (GRU) modules, is proposed to implement classification of arrhythmias from 12-lead ECG recordings. In addition, the focal Loss function is used to solve the problem of unbalanced datasets. Based on the proposed 1D Resnet-GRU model, we use class-discriminative visualization to improve interpretability and transparency as an additional step. In this paper, the Grad-CAM++ mechanism has been employed to the trained network model and generate thermal images superimposed on raw signals to explore underlying explanations of various ECG segments. Main results. The experimental results show that the proposed method can achieve a high score of 0.821 (F1-score) in classifying 9 kinds of arrythmias, and Grad-CAM++ not only provides insight into the predictive power of the model, but is also consistent with the diagnostic approach of the arrhythmia classification. Significance. The proposed method can effectively select and integrate ECG features to achieve the goal of end-to-end arrhythmia classification by using 12-lead ECG signals, which can serve a promising and useful way for automatic arrhythmia classification, and can provide an explainable deep leaning model for clinical diagnosis. © 2022 Institute of Physics and Engineering in Medicine.","arrhythmia classification; gated recurrent unit; interpretability; res-net","Algorithms; Arrhythmias, Cardiac; Deep Learning; Electrocardiography; Humans; Neural Networks, Computer; Signal Processing, Computer-Assisted; Biomedical signal processing; Cams; Cardiology; Computer aided diagnosis; Deep learning; Diseases; Heart; Learning systems; Visualization; Arrhythmia classification; Cardiovascular disease; Common disease; Gated recurrent unit; Heart disease; Human health; Interpretability; Learning models; Living standards; Res-net; algorithm; electrocardiography; heart arrhythmia; human; signal processing; Electrocardiography","","","Institute of Physics","35882225"
"Balasubramanian K.; Ramya K.; Gayathri Devi K.","Balasubramanian, Kishore (57188969156); Ramya, K. (57733230300); Gayathri Devi, K. (56574176700)","57188969156; 57733230300; 56574176700","Improved swarm optimization of deep features for glaucoma classification using SEGSO and VGGNet","2022","77","","103845","","","","10.1016/j.bspc.2022.103845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131408028&doi=10.1016%2fj.bspc.2022.103845&partnerID=40&md5=a24d8d07273f53bcbe4313d2938230cf","Efficient classification of glaucoma from fundus images remains crucial and a challenging task as the retinal anatomical structure is so complex in nature with varying contrast and boundaries. As a result, there is a chance that expert systems will misclassify the data. As a way to reduce the misclassification rate, a methodology wherein a deep learning approach integrated with an evolutionary algorithm is proposed. First, the relevant features are extracted using a pre-trained ImageNet model, the VGGNet. The features extorted are subsequently filtered using statistically enhanced Glow-worm Swarm Optimization (SEGSO). The algorithm identifies the most important and relevant features, while excluding those that are noisy or highly correlated. The efficiency of this fully automated system is evaluated on public and private retinal fundus image databases (totally 18,879 images) and the experiments demonstrated a high accuracy of 99.6% with less computational complexity, better sensitivity and specificity. SEGSO algorithm selected comparatively lesser features than the similar algorithms and when, employed with VGGNet outperform several other convolutional network models. The proposed method is robust against salt-pepper noise and achieved an accuracy of 97.2% when applied on degraded images. Feature extraction using Convolutional Neural Network and SEGSO feature optimization could prove to be a good combination to be used for other biomedical image classification processes. © 2022 Elsevier Ltd","Classification; CNN; Deep learning; Fundus image; Glaucoma; Swarm intelligence","Automation; Classification (of information); Convolution; Deep learning; Evolutionary algorithms; Image classification; Image enhancement; Ophthalmology; Swarm intelligence; Anatomical structures; CNN; Deep learning; Fundus image; Highly-correlated; Important features; Learning approach; Misclassification rates; Relevant features; Swarm optimization; anatomical concepts; Article; cancer classification; comparative study; controlled study; convolutional neural network; data availability; deep learning; diagnostic test accuracy study; evolutionary algorithm; expert system; eye fundus; feature extraction; feature selection; genetic algorithm; glaucoma; image processing; nonhuman; particle swarm optimization; pattern recognition; sensitivity and specificity; Complex networks","","","Elsevier Ltd",""
"Roy A.M.","Roy, Arunabha M. (56291186200)","56291186200","An efficient multi-scale CNN model with intrinsic feature integration for motor imagery EEG subject classification in brain-machine interfaces","2022","74","","103496","","","","10.1016/j.bspc.2022.103496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122946849&doi=10.1016%2fj.bspc.2022.103496&partnerID=40&md5=9c09a1d59cbed2359bef21eba3d3fde2","Objective: Electroencephalogram (EEG) based motor imagery (MI) classification is an important aspect in brain-machine interfaces (BMIs) which bridges between neural system and computer devices decoding brain signals into recognizable machine commands. However, the MI classification task is challenging due to inherent complex properties, inter-subject variability, and low signal-to-noise ratio (SNR) of EEG signals. To overcome the above-mentioned issues, the current work proposes an efficient multi-scale convolutional neural network (MS-CNN) which can extract the distinguishable features of several non-overlapping canonical frequency bands of EEG signals from multiple scales for MI-BCI classification. Approach: In the framework, discriminant user-specific features have been extracted and integrated to improve the accuracy and performance of the CNN classifier. Additionally, different data augmentation methods have been implemented to further improve the accuracy and robustness of the model. Main results: The model achieves an average classification accuracy of 93.74% and Cohen's kappa-coefficient of 0.92 on the BCI competition IV2b dataset outperforming several baseline and current state-of-the-art EEG-based MI classification models. Significance: The proposed algorithm effectively addresses the shortcoming of existing CNN-based EEG-MI classification models and significantly improves the classification accuracy. The current framework can provide a stimulus for designing efficient and robust real-time human-robot interaction. © 2022 Elsevier Ltd","Brain-computer interfaces (BCIs); Convolutional neural network (CNN); Electroencephalogram (EEG); Feature extraction; Motor imagery (MI); Signal classification","Aspect ratio; Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Electroencephalography; Feature extraction; Human robot interaction; Image classification; Signal to noise ratio; 'current; Brain-computer interface; Convolutional neural network; Electroencephalogram; Features extraction; Motor imagery; Motor imagery classification; Signal classification; Article; Boltzmann machine; controlled study; convolutional neural network; deep learning; diagnostic test accuracy study; discriminant analysis; electroencephalography; electroencephalography phase synchronization; evoked brain stem auditory response; Fourier transform spectroscopy; guided imagery; human; human experiment; k nearest neighbor; kernel method; receiver operating characteristic; signal noise ratio; support vector machine; Brain computer interface","","","Elsevier Ltd",""
"Maqsood S.; Damaševičius R.; Maskeliūnas R.","Maqsood, Sarmad (57212142651); Damaševičius, Robertas (6603451290); Maskeliūnas, Rytis (27467587600)","57212142651; 6603451290; 27467587600","TTCNN: A Breast Cancer Detection and Classification towards Computer-Aided Diagnosis Using Digital Mammography in Early Stages","2022","12","7","3273","","","","10.3390/app12073273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127380874&doi=10.3390%2fapp12073273&partnerID=40&md5=853c3ce2c58f2fc4f4d87679354d58a6","Breast cancer is a major research area in the medical image analysis field; it is a dangerous disease and a major cause of death among women. Early and accurate diagnosis of breast cancer based on digital mammograms can enhance disease detection accuracy. Medical imagery must be detected, segmented, and classified for computer-aided diagnosis (CAD) systems to help the radiologists for accurate diagnosis of breast lesions. Therefore, an accurate breast cancer detection and classification approach is proposed for screening of mammograms. In this paper, we present a deep learning system that can identify breast cancer in mammogram screening images using an “end-to-end” training strategy that efficiently uses mammography images for computer-aided breast cancer recognition in the early stages. First, the proposed approach implements the modified contrast enhancement method in order to refine the detail of edges from the source mammogram images. Next, the transferable texture convolutional neural network (TTCNN) is presented to enhance the performance of classification and the energy layer is integrated in this work to extract the texture features from the convolutional layer. The proposed approach consists of only three layers of convolution and one energy layer, rather than the pooling layer. In the third stage, we analyzed the performance of TTCNN based on deep features of convolutional neural network models (InceptionResNet-V2, Inception-V3, VGG-16, VGG-19, GoogLeNet, ResNet-18, ResNet-50, and ResNet-101). The deep features are extracted by determining the best layers which enhance the classification accuracy. In the fourth stage, by using the convolutional sparse image decomposition approach, all the extracted feature vectors are fused and, finally, the best features are selected by using the entropy controlled firefly method. The proposed approach employed on DDSM, INbreast, and MIAS datasets and attained the average accuracy of 97.49%. Our proposed transferable texture CNN-based method for classifying screening mammograms has outperformed prior methods. These findings demonstrate that automatic deep learning algorithms can be easily trained to achieve high accuracy in diverse mammography images, and can offer great potential to improve clinical tools to minimize false positive and false negative screening mammography results. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","biomedical image processing; breast cancer detection; computer aided diagnosis; deep learning; digital mammograms","","","","MDPI",""
"Iqbal S.; Qureshi A.N.; Ullah A.; Li J.; Mahmood T.","Iqbal, Saeed (55976364700); Qureshi, Adnan N. (57197854424); Ullah, Amin (57575963400); Li, Jianqiang (56494861500); Mahmood, Tariq (57208210697)","55976364700; 57197854424; 57575963400; 56494861500; 57208210697","Improving the Robustness and Quality of Biomedical CNN Models through Adaptive Hyperparameter Tuning","2022","12","22","11870","","","","10.3390/app122211870","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142663409&doi=10.3390%2fapp122211870&partnerID=40&md5=cda2d49e66aeac7c6ddc7997d44ade14","Deep learning is an obvious method for the detection of disease, analyzing medical images and many researchers have looked into it. However, the performance of deep learning algorithms is frequently influenced by hyperparameter selection, the question of which combination of hyperparameters are best emerges. To address this challenge, we proposed a novel algorithm for Adaptive Hyperparameter Tuning (AHT) that automates the selection of optimal hyperparameters for Convolutional Neural Network (CNN) training. All of the optimal hyperparameters for the CNN models were instantaneously selected and allocated using a novel proposed algorithm Adaptive Hyperparameter Tuning (AHT). Using AHT, enables CNN models to be highly autonomous to choose optimal hyperparameters for classifying medical images into various classifications. The CNN model (Deep-Hist) categorizes medical images into basic classes: malignant and benign, with an accuracy of 95.71%. The most dominant CNN models such as ResNet, DenseNet, and MobileNetV2 are all compared to the already proposed CNN model (Deep-Hist). Plausible classification results were obtained using large, publicly available clinical datasets such as BreakHis, BraTS, NIH-Xray and COVID-19 X-ray. Medical practitioners and clinicians can utilize the CNN model to corroborate their first malignant and benign classification assessment. The recommended Adaptive high F1 score and precision, as well as its excellent generalization and accuracy, imply that it might be used to build a pathologist’s aid tool. © 2022 by the authors.","adaptive hyperparameter tuning; convolutional neural network; grid search; hyperparameter; optimization; random search","","National Key Research and Development Program of China, NKRDPC, (2020YFB2104402); National Key Research and Development Program of China, NKRDPC","","MDPI",""
"Zhang X.; Cao X.; Zhang P.; Song F.; Zhang J.; Zhang L.; Zhang G.","Zhang, Xuanxuan (56461715800); Cao, Xu (46660903600); Zhang, Peng (57200292296); Song, Fan (57222238887); Zhang, Jiulou (56627008700); Zhang, Lin (57607044500); Zhang, Guanglei (55536868400)","56461715800; 46660903600; 57200292296; 57222238887; 56627008700; 57607044500; 55536868400","Self-Training Strategy Based on Finite Element Method for Adaptive Bioluminescence Tomography Reconstruction","2022","41","10","","2629","2643","14","10.1109/TMI.2022.3167809","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128613686&doi=10.1109%2fTMI.2022.3167809&partnerID=40&md5=529797c784c0ece3000e2412ad5ae3f8","Bioluminescence tomography (BLT) is a promising pre-clinical imaging technique for a wide variety of biomedical applications, which can non-invasively reveal functional activities inside living animal bodies through the detection of visible or near-infrared light produced by bioluminescent reactions. Recently, reconstruction approaches based on deep learning have shown great potential in optical tomography modalities. However, these reports only generate data with stationary patterns of constant target number, shape, and size. The neural networks trained by these data sets are difficult to reconstruct the patterns outside the data sets. This will tremendously restrict the applications of deep learning in optical tomography reconstruction. To address this problem, a self-training strategy is proposed for BLT reconstruction in this paper. The proposed strategy can fast generate large-scale BLT data sets with random target numbers, shapes, and sizes through an algorithm named random seed growth algorithm and the neural network is automatically self-trained. In addition, the proposed strategy uses the neural network to build a map between photon densities on surface and inside the imaged object rather than an end-to-end neural network that directly infers the distribution of sources from the photon density on surface. The map of photon density is further converted into the distribution of sources through the multiplication with stiffness matrix. Simulation, phantom, and mouse studies are carried out. Results show the availability of the proposed self-training strategy.  © 1982-2012 IEEE.","Bioluminescence tomography; deep learning; finite element method; image reconstruction; self-training","Algorithms; Animals; Finite Element Analysis; Mice; Phantoms, Imaging; Tomography; Tomography, Optical; Tomography, X-Ray Computed; Adaptive optics; Bioluminescence; Deep learning; Finite element method; Infrared devices; Medical applications; Medical imaging; Optical tomography; Photons; chloral hydrate; Bioluminescence tomography; Biomedical imaging; Deep learning; Images reconstruction; Neural-networks; Self-training; Tomography reconstruction; Training strategy; algorithm; animal experiment; Article; bioluminescence; bioluminescence tomography; controlled study; data processing; deep learning; finite element analysis; image reconstruction; in vivo study; male; model; mouse; nonhuman; photon; simulation; tomography; animal; finite element analysis; imaging phantom; optical tomography; procedures; x-ray computed tomography; Image reconstruction","Natural Science Foundation of Shanghai, (2021JQ-707); National Natural Science Foundation of China, NSFC, (61871022, 62001379, 62101278)","","Institute of Electrical and Electronics Engineers Inc.","35436185"
"Xue C.; Yu L.; Chen P.; Dou Q.; Heng P.-A.","Xue, Cheng (57211426336); Yu, Lequan (56903335400); Chen, Pengfei (57211276797); Dou, Qi (56903795500); Heng, Pheng-Ann (7006677755)","57211426336; 56903335400; 57211276797; 56903795500; 7006677755","Robust Medical Image Classification from Noisy Labeled Data with Global and Local Representation Guided Co-Training","2022","41","6","","1371","1382","11","10.1109/TMI.2021.3140140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122559824&doi=10.1109%2fTMI.2021.3140140&partnerID=40&md5=1c47491c8f8aabb528aa20196ec020ee","Deep neural networks have achieved remarkable success in a wide variety of natural image and medical image computing tasks. However, these achievements indispensably rely on accurately annotated training data. If encountering some noisy-labeled images, the network training procedure would suffer from difficulties, leading to a sub-optimal classifier. This problem is even more severe in the medical image analysis field, as the annotation quality of medical images heavily relies on the expertise and experience of annotators. In this paper, we propose a novel collaborative training paradigm with global and local representation learning for robust medical image classification from noisy-labeled data to combat the lack of high quality annotated medical data. Specifically, we employ the self-ensemble model with a noisy label filter to efficiently select the clean and noisy samples. Then, the clean samples are trained by a collaborative training strategy to eliminate the disturbance from imperfect labeled samples. Notably, we further design a novel global and local representation learning scheme to implicitly regularize the networks to utilize noisy samples in a self-supervised manner. We evaluated our proposed robust learning strategy on four public medical image classification datasets with three types of label noise, i.e., random noise, computer-generated label noise, and inter-observer variability noise. Our method outperforms other learning from noisy label methods and we also conducted extensive experiments to analyze each component of our method. © 1982-2012 IEEE.","collaborative training; Noisy label; representation learning; self-supervision","Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Observer Variation; Classification (of information); Computer vision; Deep neural networks; Diagnosis; Image classification; Medical imaging; Quality control; Biomedical imaging; Collaborative training; Deep learning; Image-analysis; Medical diagnostic imaging; Noise measurements; Noisy labels; Representation learning; Self-supervision; Training data; Article; classification algorithm; cutaneous melanoma; data accuracy; data analysis; deep learning; diagnostic imaging; epiluminescence microscopy; feature learning (machine learning); Gleason score; histopathology; human; human tissue; image analysis; image quality; intermethod comparison; learning algorithm; lymph node; male; noise measurement; prostate cancer; tissue microarray; image processing; observer variation; procedures; Image analysis","","","Institute of Electrical and Electronics Engineers Inc.","34982680"
"Ajai A.K.; Anitha A.","Ajai, Ajni K. (57191488323); Anitha, A. (57211773955)","57191488323; 57211773955","Clustering based lung lobe segmentation and optimization based lung cancer classification using CT images","2022","78","","103986","","","","10.1016/j.bspc.2022.103986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134694723&doi=10.1016%2fj.bspc.2022.103986&partnerID=40&md5=34c52ed65431eba6e3d0a5b112132750","A serious condition with a high death and morbidity rate worldwide is lung cancer. To increase the likelihood that a person will survive, early diagnosis is urgently required. Various existing approaches are modeled to detect lung cancer, but low visibility of tumor region and the negative rates of images still result a complex task to recognize infected regions. Also, the traditional methods failed to enhance the accuracy of the lung cancer classification. Hence, this research developed a method named Shuffled Social Sky Optimizer-based Multi-Object Rectified Attention Network (SSSO-based MORAN) to effectively classify lung cancer disease. The proposed SSSO algorithm is the integration of the Shuffled Shepherd Optimization Algorithm (SSOA) and social ski-driver (SSD) algorithm, respectively. The input computed tomography (CT) image is supplied to the pre-processing phase, where the Gaussian filtering is employed to pre-process the image, and thereby the Region of Interest (ROI) is acquired from the input image. Then, the lung lobes are segmented using the proposed Deep Renyi entropy fuzzy clustering (DREFC). With the segmented lung lobes, the nodule region is identified from the lung image, and the process of cancer classification is done based on features. The features considered for the lung cancer classification are Local Gabor XOR Pattern (LGXP), Gray-Level Co-occurrence Matrix (GLCM) features, Global Binary Pattern (GBP), Tetrolet transform, and statistical features. The proposed algorithm effectively showed higher performance of accuracy, Mean Absolute Error (MAE), sensitivity, and specificity of 0.896, 0.104, 0.8969, and 0.845, respectively. © 2022","Biomedical image processing; Deep learning; Diagnosis system; Lung cancer; Lung lobe segmentation","Biological organs; Classification (of information); Computer aided diagnosis; Computerized tomography; Deep learning; Image classification; Image segmentation; Local binary pattern; Cancer classification; Clusterings; Computed tomography images; Condition; Deep learning; Diagnose system; Early diagnosis; Lung Cancer; Lung lobe segmentations; Optimisations; Article; attention network; cancer classification; clustering algorithm; comparative study; computer assisted tomography; contrast enhancement; deep renyi entropy fuzzy clustering; diagnostic accuracy; feasibility study; feature extraction; fuzzy c means clustering; fuzzy clustering; global binary pattern; gray level co occurrence matrix; human; human tissue; image processing; image segmentation; kernel method; local gabor xor pattern; lung cancer; lung lobe; lung nodule; lung parenchyma; mean absolute error; multi object rectified attention network; recurrent neural network; sensitivity and specificity; shuffled shepherd optimization algorithm; shuffled social sky optimizer; social ski driver algorithm; tetrolet transform; Diseases","","","Elsevier Ltd",""
"Kim S.; Jiang Z.; Zambrano B.A.; Jang Y.; Baek S.; Yoo S.; Chang H.-J.","Kim, Sekeun (57201361840); Jiang, Zhenxiang (57200994797); Zambrano, Byron A. (55830978800); Jang, Yeonggul (56680596100); Baek, Seungik (7201371677); Yoo, Sunkook (7401970791); Chang, Hyuk-Jae (8893464800)","57201361840; 57200994797; 55830978800; 56680596100; 7201371677; 7401970791; 8893464800","Deep Learning on Multiphysical Features and Hemodynamic Modeling for Abdominal Aortic Aneurysm Growth Prediction","2023","42","1","","196","208","12","10.1109/TMI.2022.3206142","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139416652&doi=10.1109%2fTMI.2022.3206142&partnerID=40&md5=9e2e8e9b173db29b55599c9ac6cba394","Prediction of abdominal aortic aneurysm (AAA) growth is of essential importance for the early treatment and surgical intervention of AAA. Capturing key features of vascular growth, such as blood flow and intraluminal thrombus (ILT) accumulation play a crucial role in uncovering the intricated mechanism of vascular adaptation, which can ultimately enhance AAA growth prediction capabilities. However, local correlations between hemodynamic metrics, biological and morphological characteristics, and AAA growth rates present high inter-patient variability that results in that the temporal-spatial biochemical and mechanical processes are still not fully understood. Hence, this study aims to integrate the physics-based knowledge with deep learning with a patch-based convolutional neural network (CNN) approach by incorporating important multiphysical features relating to its pathogenesis for validating its impact on AAA growth prediction. For this task, we observe that the unstructured multiphysical features cannot be directly employed in the kernel-based CNN. To tackle this issue, we propose a parameterization of features to leverage the spatio-temporal relations between multiphysical features. The proposed architecture was tested on different combinations of four features including radius, intraluminal thrombus thickness, time-average wall shear stress, and growth rate from 54 patients with 5-fold cross-validation with two metrics, a root mean squared error (RMSE) and relative error (RE). We conduct extensive experiments on AAA patients, the results show the effect of leveraging multiphysical features and demonstrate the superiority of the presented architecture to previous state-of-the-art methods in AAA growth prediction.  © 1982-2012 IEEE.","Abdominal aortic aneurysm growth prediction; convolutional neural network; deep learning","Aorta, Abdominal; Aortic Aneurysm, Abdominal; Deep Learning; Hemodynamics; Humans; Thrombosis; Blood vessels; Computerized tomography; Convolution; Deep learning; Forecasting; Image segmentation; Mean square error; Medical image processing; Network architecture; Neural networks; Shear stress; Abdominal aortic aneurysm growth prediction; Abdominal aortic aneurysms; Aneurysm growth; Biomedical imaging; Computed tomography; Convolutional neural network; Deep learning; Haemodynamics; Images segmentations; Predictive models; abdominal aortic aneurysm; aged; Article; biomechanics; blood flow; body mass; clinical feature; comparative study; computational fluid dynamics; computed tomographic angiography; convolutional neural network; cross validation; deep learning; demographics; diabetes mellitus; diastolic blood pressure; female; follow up; geometry; health physics; heart cycle; hemodynamic parameters; human; hypertension; image registration; intraluminal thrombus; kernel method; knowledge; Korea; major clinical study; male; pathogenesis; prediction; predictive model; segmentation algorithm; shear stress; spatiotemporal analysis; systolic blood pressure; three-dimensional imaging; thrombus; time average wall shear stress; abdominal aorta; abdominal aortic aneurysm; diagnostic imaging; hemodynamics; pathology; thrombosis; Hemodynamics","","","Institute of Electrical and Electronics Engineers Inc.","36094984"
"Shrivastava A.; Chakkaravathy M.; Shah M.A.","Shrivastava, Anurag (58035982500); Chakkaravathy, Midhun (58175875900); Shah, Mohd Asif (58090397100)","58035982500; 58175875900; 58090397100","A Comprehensive Analysis of Machine Learning Techniques in Biomedical Image Processing Using Convolutional Neural Network","2022","","","","1363","1369","6","10.1109/IC3I56241.2022.10072911","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152086993&doi=10.1109%2fIC3I56241.2022.10072911&partnerID=40&md5=910d2a83febf45b399f1ab034c9fc34b","Deep learning is a branch of machine learning that has grown by leaps and bounds since it was first used in computer vision. The 'Olympics' of computer vision, ImageNet Classification, was won by a system that used deep learning and convolutional neural networks in December 2012. Because of how important it is in the field, this competition is sometimes called the 'Olympics' of computer vision. (CNN). Since then, people in many different fields, such as medical image analysis, have looked into deep learning. We are going to look into whether or not it would be possible to use deep learning algorithms to analyse medical images. This poll asked people what they thought about the four following topics related to machine learning: 1) How it is now used in computer vision, 2) How machine learning has changed before and after deep learning, 3) What role ML models play in deep learning, and 4) How deep learning can be used to analyse medical photos. Before the invention of deep learning, most machine learning systems relied on inputs called 'features.' This type of machine learning is called feature-based ML by some (also known as feature-based ML). Studying photographic data can be used to learn through deep learning without the need to separate objects or pull out features. The main difference between the two was this. This was pretty clear when we looked at MLs made before and after deep learning became very popular. This part, along with the model's huge scope, makes deep learning work well. Even though the term 'deep learning' is still new, a study on the topic found that photo-input deep-learning algorithms have been available in the field of machine learning for a long time. Even though 'deep learning' is a term that has only been around for a short time, this was seen. Even though the idea of 'deep learning' is still in its early stages, discoveries like this one have been made. Even before the term 'deep learning' was invented, machine learning techniques that used pictures as input were already showing promise for solving a wide range of medical image interpretation problems. Even before the term 'deep learning' was made up, this was the case. One of these jobs is to Figure out how lesions are different from other organs and tissues. To solve the problem, an approach to machine learning that is based on images was used. In the next few decades, it is expected that deep learning will completely replace all of the traditional ways that medical images are currently interpreted. This is because applying deep learning and other machine learning techniques to the study of picture data could make medical image analysis much better. 'Deep learning,' which is the process of teaching computers to 'learn' from images, is one of the most promising and quickly growing areas of medical image analysis. Traditional ways of figuring out what a medical image means are likely to be replaced in the next few decades by machine learning that works from pictures.  © 2022 IEEE.","Analysis of medical images; CNN - Convolutional neural network; Deep and Machine learning; Medical image","Computer vision; Convolution; Deep neural networks; Image analysis; Learning algorithms; Learning systems; Medical imaging; Analyse of medical image; CNN - convolutional neural network; Convolutional neural network; Deep and machine learning; Feature-based; Machine learning techniques; Machine-learning; Medical image; Medical image analysis; Olympics; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","3rd International Conference on Neural Computing for Advanced Applications, NCAA 2022","2022","1637 CCIS","","","","","1050","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142690131&partnerID=40&md5=4a62d81afeb31f7d309afb36f54cf866","The proceedings contain 77 papers. The special focus in this conference is on Neural Computing for Advanced Applications. The topics include: A Multi-channel Fusion Method Based on Tensor for Rolling Bearing Fault Diagnosis; a Perception Method Based on Point Cloud Processing in Autonomous Driving; many-Objective Artificial Bee Colony Algorithm Based on Decomposition and Dimension Learning; LCSW: A Novel Indoor Localization System Based on CNN-SVM Model with WKNN in Wi-Fi Environments; large Parallax Image Stitching via Structure Preservation and Multi-matching; traffic Congestion Event Mining Based on Trajectory Data; many-Objective Evolutionary Algorithm Based on Dominance and Objective Space Decomposition; a New Unified Control Approach for Finite-/Fixed-Time Synchronisation of Multi-weighted Dynamical Networks; aperiodic Sampling Based Event-Triggering for Synchronization of Nonlinear Systems; two-Stream 3D MobileNetV3 for Pedestrians Intent Prediction Based on Monocular Camera; Research on Non-intrusive Household Load Identification Method Applying LightGBM; design of Portrait System for Road Safety Based on a Dynamic Density Clustering Algorithm; an Ensemble Deep Learning Model Based on Transformers for Long Sequence Time-Series Forecasting; multi-layer Integrated Extreme Learning Machine for Mechanical Fault Diagnosis of High-Voltage Circuit Breaker; wind Power Forecast Based on Multiple Echo States; UAV-Assisted Blind Area Pedestrian Detection via Terminal-Edge-Cloud Cooperation in VANETs; a Survey of Optimal Design of Antenna (Array) by Evolutionary Computing Methods; a Span-Based Joint Model for Measurable Quantitative Information Extraction; bayesian Optimization Based Seq2Seq Network Models for Real Estate Price Prediction in Hong Kong; ensemble Learning for Crowdfunding Dynamics: JingDong Crowdfunding Projects; Cage Mass Center Capture for Whirl Analysis Using an Improved MultiResUNet from the Multimodal Biomedical Image Segmentation; master Multiple Real-Time Strategy Games with a Unified Learning Model Using Multi-agent Reinforcement Learning; vehicle Re-identification via Spatio-temporal Multi-instance Learning.","","","","Zhang H.; Chen Y.; Chu X.; Zhang Z.; Hao T.; Wu Z.; Yang Y.","Springer Science and Business Media Deutschland GmbH",""
"Taha B.; Liza F.R.; Moniruzzaman M.; Samsuzzaman M.","Taha, Bahauddin (57461608800); Liza, Fahmida Rahman (57461319700); Moniruzzaman, Md (57863305400); Samsuzzaman, Md (55329920200)","57461608800; 57461319700; 57863305400; 55329920200","Comparative Analysis of Fine-Tuned MobileNet versions to Detect Brain Tumors from MRI images","2022","","","","","","","10.1109/STI56238.2022.10103254","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159076233&doi=10.1109%2fSTI56238.2022.10103254&partnerID=40&md5=c553616a74e0347513e80adcec30a086","A prominent area of research in the realm of medical imaging is the categorization of brain tumors into multiple classes. Researchers have devised a variety of strategies to improve categorization accuracy. Brain tumor diagnosis and classification using standard medical data analysis is a difficult and time-consuming job. Biomedical investigation demonstrates that systematic categorization with human involvement may result in erroneous diagnosis and prognosis. One of the most remarkable approaches for dealing with this issue is to utilize deep learning algorithms. This study examines an intra-version comparison of MobileNet models with the goal of identifying brain tumors using MRI images. This research aims to evaluate the effectiveness of each version of MobileNet - MobileNetV1, MobileNetV2, and MobileNetV3, to pinpoint the three distinct forms of brain tumors which are pituitary, glioma, and meningioma. Multiple evaluation metrics, including sensitivity, specificity, F1-score, accuracy, and negative likelihood ratio have been used to evaluate the effectiveness of these models. According to a comparative analysis of these models, MobileNetV2 tends to perform better than other versions achieving a train and test accuracy of 99.73% and 97.86%.  © 2022 IEEE.","Brain tumor; Deep neural network; MobileNet; MRI images; Transfer learning","Brain; Computer aided diagnosis; Deep neural networks; Learning algorithms; Magnetic resonance imaging; Tumors; Biomedical investigations; Brain tumors; Comparative analyzes; Medical data analysis; Mobilenet; MRI Image; Multiple class; Transfer learning; Tumor classification; Tumor diagnosis; Medical imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"Reyes A.A.; Paheding S.; Deo M.; Audette M.","Reyes, Abel A. (57669722600); Paheding, Sidike (56585990900); Deo, Makarand (7102166133); Audette, Michel (57195774826)","57669722600; 56585990900; 7102166133; 57195774826","Gabor Filter-Embedded U-Net with Transformer-Based Encoding for Biomedical Image Segmentation","2022","13594 LNCS","","","76","88","12","10.1007/978-3-031-18814-5_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141829849&doi=10.1007%2f978-3-031-18814-5_8&partnerID=40&md5=5eef604edfb2d00d84fc28f7e3d3da2d","Medical image segmentation involves a process of categorization of target regions that are typically varied in terms of shape, orientation and scales. This requires highly accurate algorithms as marginal segmentation errors in medical images may lead to inaccurate diagnosis in subsequent procedures. The U-Net framework has become one of the dominant deep neural network architectures for medical image segmentation. Due to complex and irregular shape of objects involved in medical images, robust feature representations that correspond to various spatial transformations are key to achieve successful results. Although U-Net-based deep architectures can perform feature extraction and localization, the design of specialized architectures or layer modifications is often an intricate task. In this paper, we propose an effective solution to this problem by introducing Gabor filter banks into the U-Net encoder, which has not yet been well explored in existing U-Net-based segmentation frameworks. In addition, global self-attention mechanisms and Transformer layers are also incorporated into the U-Net framework to capture global contexts. Through extensive testing on two benchmark datasets, we show that the Gabor filter-embedded U-Net with Transformer encoders can enhance the robustness of deep-learned features, and thus achieve a more competitive performance. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Biomedical image; Deep learning; Gabor filters; Segmentation; U-Net; Vision transformers","Benchmarking; Deep neural networks; Diagnosis; Encoding (symbols); Image segmentation; Medical imaging; Network architecture; Signal encoding; Biomedical image segmentation; Biomedical images; Deep learning; Encodings; Medical image segmentation; NET framework; Segmentation; Target regions; U-net; Vision transformer; Gabor filters","","Li X.; Li Q.; Lv J.; Huo Y.; Dong B.; Leahy R.M.","Springer Science and Business Media Deutschland GmbH",""
"Cannata S.; Paviglianiti A.; Pasero E.; Cirrincione G.; Cirrincione M.","Cannata, Sergio (57959936000); Paviglianiti, Annunziata (57211255168); Pasero, Eros (6701684952); Cirrincione, Giansalvo (7003417210); Cirrincione, Maurizio (7004554691)","57959936000; 57211255168; 6701684952; 7003417210; 7004554691","Deep Learning Algorithms for Automatic COVID-19 Detection on Chest X-Ray Images","2022","10","","","119905","119913","8","10.1109/ACCESS.2022.3221531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141606398&doi=10.1109%2fACCESS.2022.3221531&partnerID=40&md5=9018eb3323a813490aca75285d22aa80","Coronavirus disease (COVID-19) was confirmed as a pandemic disease on February 11, 2020. The pandemic has already caused thousands of victims and infected several million people around the world. The aim of this work is to provide a Covid-19 infection screening tool. Currently, the most widely used clinical tool for detecting the presence of infection is the reverse transcription polymerase chain reaction (RT-PCR), which is expensive, less sensitive and requires the resource of specialized medical personnel. The use of X-ray images represents one of the latest challenges for the rapid diagnosis of the Covid-19 infection. This work involves the use of advanced artificial intelligence techniques for diagnosis using algorithms for classification purposes. The goal is to provide an automatic infection detection method while maximizing detection accuracy. A public database was used which includes images of COVID-19 patients, patients with viral pneumonia, patients with pulmonary opacity, and healthy patients. The methodology used in this study is based on transfer learning of pre-trained networks to alleviate the complexity of calculation. In particular, three different types of convolutional neural networks, namely, InceptionV3, ResNet50 and Xception, and the Vision Transformer are implemented. Experimental results show that the Vision Transformer outperforms convolutional architectures with a test accuracy of 99.3% vs 85.58% for ResNet50 (best among CNNs). Moreover, it is able to correctly distinguish among four different classes of chest X-ray images, whereas similar works only stop at three categories at most. The high accuracy of this computer-assisted diagnostic tool can significantly improve the speed and accuracy of COVID-19 diagnosis.  © 2013 IEEE.","Biomedical imaging; COVID; deep learning; image classification; medical diagnostic imaging; vision transformer","Computer aided diagnosis; Convolution; Deep learning; Image classification; Learning algorithms; Medical imaging; Neural networks; Polymerase chain reaction; X ray analysis; Biomedical imaging; Chest X-ray image; Clinical tools; Coronaviruses; COVID; Deep learning; Images classification; Medical diagnostic imaging; Screening tool; Vision transformer; COVID-19","","","Institute of Electrical and Electronics Engineers Inc.",""
"Al Duhayyim M.; Mengash H.A.; Marzouk R.; Nour M.K.; Mahgoub H.; Althukair F.; Mohamed A.","Al Duhayyim, Mesfer (57204360566); Mengash, Hanan Abdullah (56201890800); Marzouk, Radwa (35749022100); Nour, Mohamed K (56027613700); Mahgoub, Hany (57063016800); Althukair, Fahd (57796451000); Mohamed, Abdullah (57213606201)","57204360566; 56201890800; 35749022100; 56027613700; 57063016800; 57796451000; 57213606201","Hybrid Rider Optimization with Deep Learning Driven Biomedical Liver Cancer Detection and Classification","2022","2022","","6162445","","","","10.1155/2022/6162445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133974950&doi=10.1155%2f2022%2f6162445&partnerID=40&md5=632999f314fb7f5c5f6a0a809c39b66f","Biomedical engineering is the application of the principles and problem-solving methods of engineering to biology along with medicine. Computation intelligence is the study of design of intelligent agents which are systems acting perceptively. The computation intelligence paradigm offers more advantages to the enhancement and maintenance of the field of biomedical engineering. Liver cancer is the major reason of mortality worldwide. Earlier-stage diagnosis and treatment might increase the survival rate of liver cancer patients. Manual recognition of the cancer tissue is a time-consuming and difficult task. Hence, a computer-aided diagnosis (CAD) is employed in decision making procedures for accurate diagnosis and effective treatment. In contrast to classical image-dependent ""semantic""feature evaluation from human expertise, deep learning techniques could learn feature representation automatically from sample images using convolutional neural network (CNN). This study introduces a Hybrid Rider Optimization with Deep Learning Driven Biomedical Liver Cancer Detection and Classification (HRO-DLBLCC) model. The proposed HRO-DLBLCC model majorly focuses on the identification of liver cancer in the medical images. To do so, the proposed HRO-DLBLCC model employs preprocessing in two stages, namely, Gabor filtering (GF) based noise removal and watershed transform based segmentation. In addition, the proposed HRO-DLBLCC model involves NAdam optimizer with DenseNet-201 based feature extractor to generate an optimal set of feature vectors. Finally, the HRO algorithm with recurrent neural network-long short-term memory (RNN-LSTM) model is applied for liver cancer classification, in which the hyperparameters of the RNN-LSTM model are tuned by the use of HRO algorithm. The HRO-DLBLCC model is experimentally validated and compared with existing models. The experimental results assured the promising performance of the HRO-DLBLCC model over recent approaches.  © 2022 Mesfer Al Duhayyim et al.","","Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Humans; Liver Neoplasms; Neural Networks, Computer; Biomedical engineering; Convolutional neural networks; Decision making; Gabor filters; Learning systems; Long short-term memory; Medical imaging; Patient treatment; Semantics; Cancer classification; Classification models; Computation intelligences; Detection models; Early-stage diagnosis; Liver cancer detection; Liver cancers; Memory modeling; Optimisations; Problem Solving methods; algorithm; computer assisted diagnosis; human; liver tumor; procedures; Diseases","","","Hindawi Limited","35814569"
"Li H.; Lin Z.; An Z.; Zuo S.; Zhu W.; Zhang Z.; Mu Y.; Cao L.; Prades García J.D.","Li, Hongqiang (9839420700); Lin, Zifeng (57403404700); An, Zhixuan (57250257600); Zuo, Shasha (57219560820); Zhu, Wei (57318413400); Zhang, Zhen (57219328166); Mu, Yuxin (57250605200); Cao, Lu (57056819000); Prades García, Juan Daniel (21733473300)","9839420700; 57403404700; 57250257600; 57219560820; 57318413400; 57219328166; 57250605200; 57056819000; 21733473300","Automatic electrocardiogram detection and classification using bidirectional long short-term memory network improved by Bayesian optimization","2022","73","","103424","","","","10.1016/j.bspc.2021.103424","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122435078&doi=10.1016%2fj.bspc.2021.103424&partnerID=40&md5=7a1f24b1790bf8dfc28a35013d6080d3","Electrocardiogram (ECG) signals contain a significant amount of subtle information that can be used to detect some types of heart dysfunction. The widespread availability of digital ECG and the algorithmic paradigm of the long short-term memory (LSTM) network present an opportunity to substantially improve the accuracy and scalability of automated ECG analysis. However, the number of hidden units and initial learning rate of an LSTM neural network for ECG classification are currently preset based on prior knowledge, which causes the model to reach a sub-optimal state. In this study, an automated ECG detection and classification method using a bidirectional LSTM (BiLSTM) network modified by Bayesian optimization is developed. Bayesian optimization is used to optimize the two hyperparameters of the BiLSTM network: the initial learning rate and the number of hidden layers. By classifying five ECG signals in the MIT-BIH arrhythmia database, the accuracy of the modified network reaches 99.00%, which is 0.86% higher than that before optimization. The results demonstrate that Bayesian optimization can be an effective approach to improving the quality of classifiers based on deep learning. The presented approach can also be considered for generalization to other quasi-periodical biometric signal-based classification tasks in future studies, which may have practical applications. © 2021 Elsevier Ltd","Bayesian optimization; BiLSTM network; Classification; ECG; Signal segmentation","Biomedical signal processing; Brain; Classification (of information); Learning algorithms; Long short-term memory; Signal detection; Algorithmics; Bayesian optimization; Bidirectional LSTM network; Electrocardiogram analysis; Electrocardiogram signal; Heart dysfunction; Hidden units; Learning rates; Memory network; Signal segmentation; Article; artificial neural network; deep learning; electrocardiogram; heart arrhythmia; human; image segmentation; long short term memory network; measurement accuracy; nerve cell network; QRS complex; sensitivity and specificity; support vector machine; Electrocardiography","Tianjin Distinguished University; Tianjin Major Project for Civil-Military Integration of Science and Technology, (18ZXJMTG00260); Tianjin Municipal Special Foundation for Key Cultivation of China, (XB202007); Tianjin Talent Special Support Program; National Natural Science Foundation of China, NSFC, (61675154); National Natural Science Foundation of China, NSFC; Institució Catalana de Recerca i Estudis Avançats, ICREA; Shanxi Provincial Key Research and Development Project, (19YFZCSY00180); Shanxi Provincial Key Research and Development Project; Tianjin Science and Technology Program, (20YDTPJC01380); Tianjin Science and Technology Program","","Elsevier Ltd",""
"Lim Y.W.; Adler A.S.; Johnson D.S.","Lim, Yoong Wearn (57200800881); Adler, Adam S. (35847495400); Johnson, David S. (57214167638)","57200800881; 35847495400; 57214167638","Predicting antibody binders and generating synthetic antibodies using deep learning","2022","14","1","2069075","","","","10.1080/19420862.2022.2069075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129268611&doi=10.1080%2f19420862.2022.2069075&partnerID=40&md5=b8b23736cb7c9ed628b9b80b5ded579e","The antibody drug field has continually sought improvements to methods for candidate discovery and engineering. Historically, most such methods have been laboratory-based, but informatics methods have recently started to make an impact. Deep learning, a subfield of machine learning, is rapidly gaining prominence in the biomedical research. Recent advances in microfluidics technologies and next-generation sequencing have not only revolutionized therapeutic antibody discovery, but also contributed to a vast amount of antibody repertoire sequencing data, providing opportunities for deep learning-based applications. Previously, we used microfluidics, yeast display, and deep sequencing to generate a panel of binder and non-binder antibody sequences to the cancer immunotherapy targets PD-1 and CTLA-4. Here we encoded the antibody light and heavy chain complementarity-determining regions (CDR3s) into antibody images, then built and trained convolutional neural network models to classify binders and non-binders. To improve model interpretability, we performed in silico mutagenesis to identify CDR3 residues that were important for binder classification. We further built generative deep learning models using generative adversarial network models to produce synthetic antibodies against PD-1 and CTLA-4. Our models generated variable length CDR3 sequences that resemble real sequences. Overall, our study demonstrates that deep learning methods can be leveraged to mine and learn patterns in antibody sequences, offering insights into antibody engineering, optimization, and discovery. © 2022 GigaGen, Inc. Published with license by Taylor & Francis Group, LLC.","Antibody repertoires; convolutional neural networks; deep learning; deep sequencing; generative adversarial networks; machine learning","Antibodies; Complementarity Determining Regions; CTLA-4 Antigen; Deep Learning; Programmed Cell Death 1 Receptor; amino acid; antibody drug conjugate; cytotoxic T lymphocyte antigen 4; programmed death 1 receptor; antibody; cytotoxic T lymphocyte antigen 4; programmed death 1 receptor; antibody combining site; antibody engineering; antigen binding; antigen recognition; area under the curve; Article; B lymphocyte; body image; cancer immunotherapy; cluster analysis; complementarity determining region; complementarity determining region 3; complementarity determining region 3H; complementarity determining region 3k; controlled study; convolutional neural network; deep learning; diagnostic test accuracy study; false negative result; false positive result; fluorescence activated cell sorting; heavy chain; immunization; immunoglobulin structure; learning algorithm; light chain; machine learning; microfluidics; mouse; mutagenesis; mutation; nonhuman; overlap extension polymerase chain reaction; prediction; receiver operating characteristic; reverse transcription polymerase chain reaction; reverse transcription recombinase polymerase amplification; sensitivity analysis; sensitivity and specificity; validation process; chemistry","","","Taylor and Francis Ltd.","35482911"
"Yuan W.","Yuan, Weizheng (58169020200)","58169020200","Features Domains and Classification Algorithms in Motor Imagery Brain Computer Interface","2022","","","","381","385","4","10.1109/EIECT58010.2022.00081","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151570387&doi=10.1109%2fEIECT58010.2022.00081&partnerID=40&md5=21d8a2a820e0c0bf3a4bd72da7cc7e02","Motor imagery brain-computer interface (MI-BCI) is well approved to help people with movement impairments due to neural disorders. The procedure for MI-BCI to translate MI brain signals to understandable instructions for external devices involves extracting features from recorded signals and predicting desired movements. This paper summarizes and compares feature extraction methods and classification algorithms and their modifications that are commonly used for MI EEG signals. Feature extraction techniques are discussed based on their feature domains: time, frequency, and spatial. Classification algorithms are divided into classical machine learning and deep learning. This paper aims to provide a straightforward view of common ways to extract features and classifying movements in MI-BCI and show difficulties in MI-BCI signal processing. The nature of MI EEG signals and MI-BCI applications points to several promising field such as transfer learning and deep learning neural networks.  © 2022 IEEE.","Brain-computer interface; EEG; feature extraction; machine learning; motor imagery","Biomedical signal processing; Classification (of information); Deep learning; Extraction; Feature extraction; Image classification; Learning algorithms; Learning systems; Brain signals; Classification algorithm; EEG signals; Extracting features; Feature classification; Feature domain; Features extraction; Machine-learning; Motor imagery; Neural disorders; Brain computer interface","","","Institute of Electrical and Electronics Engineers Inc.",""
"Mehta K.; Subramanian K.","Mehta, Kush (57890698900); Subramanian, Kirtana (57216418140)","57890698900; 57216418140","Heart Disease Diagnosis using Deep Learning","2022","","","","","","","10.1109/INDISCON54605.2022.9862847","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138026039&doi=10.1109%2fINDISCON54605.2022.9862847&partnerID=40&md5=23624eef7fc8dd5d30b2cc67a378a5dd","This paper deals with the design and implementation of an automated algorithm which will efficiently calculate Ejection Fraction of Left Ventricle (LV) of the heart from its MRI. For several years, cardiac Magnetic Resonance Imaging (MRI) has been used by medical professionals to treat patients with various cardiovascular ailments. This is because Magnetic Resonance Imaging is a great non-invasive medical imaging technique. Due to the variability of MRIs, it is very time consuming and strenuous for medical professionals to manually analyze them in order to diagnose and treat patients. This study deals with the automated segmentation of the LV in order to calculate ejection fraction which is in turn used to diagnose the patients.Images obtained from MRIs are generally in DICOM format, hence basic pre-processing techniques have been used to convert the DICOM images into PNG format. Then segmentation of Left Ventricle is performed, and required volumes are calculated which are utilized to compute ejection fraction. This algorithm will reduce the time taken to analyze MRIs by providing better accuracy and ease to specialists. To develop this automated algorithm, image processing along with deep learning (convolutional neural networks) has been used and an accuracy of over eighty-one percent has been achieved. © 2022 IEEE.","Biomedical; Deep Learning; DICOM and Cardiovascular disease diagnosis; Ejection fraction; Heart; Image processing; Left Ventricle; LVEF; magnetic resonance imaging; MRI; Neural Network","Automation; Cardiology; Convolutional neural networks; Deep learning; Diagnosis; Diseases; Heart; Magnetism; Medical imaging; Resonance; Biomedical; Cardiovascular disease; Deep learning; DICOM and cardiovascular disease diagnose; Disease diagnosis; Ejection fraction; Images processing; Left ventricles; LVEF; Neural-networks; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"Montalbo F.J.P.","Montalbo, Francis Jesmar P. (57212309186)","57212309186","Fusing compressed deep ConvNets with a self-normalizing residual block and alpha dropout for a cost-efficient classification and diagnosis of gastrointestinal tract diseases","2022","9","","101925","","","","10.1016/j.mex.2022.101925","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142171251&doi=10.1016%2fj.mex.2022.101925&partnerID=40&md5=f0dfdb64653aef7d7b59f580f55f9e28","The challenging task of diagnosing gastrointestinal (GI) tracts recently became a popular research topic, where most researchers performed extraordinary feats using numerous deep learning (DL) and computer vision techniques to achieve state-of-the-art (SOTA) diagnostic performance based on accuracy. However, most proposed methods relied on combining complex computational methods and algorithms, causing a significant increase in production difficulty, parameter size, and even training cost. Therefore, this method proposes a straightforward approach to developing a vision-based DL model without requiring heavy computing resources or reliance on other complex feature processing and learning algorithms. This paper included the step-by-step procedure consisting of network compression, layer-wise fusion, and the addition of a modified residual layer (MResBlock) with a self-normalizing attribute and a more robust regularization. In addition, the paper also presents the performance of the proposed method toward the diagnosis of four GI tract conditions, including polyps, ulcers, esophagitis, and healthy mucosa. The paper concludes that the proposed method did radiate a significant improvement in the overall performance, cost-efficiency, and especially practicality compared to most current SOTA methods. • The proposed method combined profound techniques like feature fusion, residual learning, and self-normalization to develop a lightweight model that accurately diagnoses gastrointestinal (GI) tract conditions. • The model produced from the proposed method generated better performance than most pre-existing state-of-the-art Deep Convolutional Neural Networks that diagnosed the presented four GI tract conditions. • Aside from its competitive performance, the model based on the proposed method only had 1.2M parameters and only consumed 1.5 GFLOPS, making it significantly more cost-efficient than most existing solutions. © 2022 The Author(s)","A Novel approach to reducing the cost of training for a feature fused Deep Convolutional Neural Network using network compression, residual learning, and self-normalization techniques; Alpha dropout; Biomedical Imaging; Deep convolutional neural networks; Endoscopy; Feature fusion; Image classification; Residual learning; Self-normalization; SeLU","Article; artificial neural network; classification algorithm; computer vision; controlled study; convolutional neural network; cost effectiveness analysis; deep learning; diagnostic accuracy; diagnostic test accuracy study; digestive system ulcer; esophagitis; feature extraction; gastrointestinal disease; gastrointestinal endoscopy; human; instrument validation; intermethod comparison; intestine polyp; learning algorithm; machine learning; modified residual layer; residual neural network","Batangas State University","","Elsevier B.V.",""
"Murad N.; Pan M.-C.; Hsu Y.-F.","Murad, Nazish (57657064700); Pan, Min-Chun (55580008800); Hsu, Ya-Fen (42961708900)","57657064700; 55580008800; 42961708900","Reconstruction and Localization of Tumors in Breast Optical Imaging via Convolution Neural Network Based on Batch Normalization Layers","2022","10","","","57850","57864","14","10.1109/ACCESS.2022.3177893","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130799460&doi=10.1109%2fACCESS.2022.3177893&partnerID=40&md5=55eadbc4d1712a9e54117bbe48946514","The Near-Infrared (NIR) Diffuse Optical Tomography (DOT) aims to reconstruct optical-property images of tissue and identify and localize breast tumors. This study has developed an efficient and fast DOT reconstruction method based on Deep Learning (DL) algorithm. The DL has already been applied in DOT application with limitations such as a limited dataset and the reconstruction of absorption coefficients only. We solve the problem of a limited dataset by generating a large dataset with multiple phantoms and inclusions at various positions. Moreover, a single Deep Neural Network (DNN) model has been designed to reconstruct absorption coefficients and scattering coefficients. For evaluation of the proposed DNN models, the phantom experimental dataset has been used where the results of the proposed DNN models outperform the results of the Tikhonov Regularization (TR) method and other Artificial Neural Networks (ANN). Moreover, it is shown that the DNN model with batch normalization layer results in improved spatial resolution, based on Contrast-and-Size Detail (CSD) analysis, as compared to DNN models without batch normalization layers.  © 2013 IEEE.","Batch normalization; Convolution deep neural networks; Diffuse optical imaging; Inverse problem; Sensor to image domain","Convolution; Deep neural networks; Infrared devices; Inverse problems; Medical imaging; Optical properties; Optical tomography; Phantoms; Tumors; Batch normalization; Biomedical optical imaging; Convolution deep neural network; Diffuse optical imaging; Image domain; Images reconstruction; Inverse problem; Normalisation; Optical imaging; Optical scattering; Sensor to image domain; U.S. Department of Transportation; US Department of Transportation; Image reconstruction","NCU-LSH Research and Development Office; Ministry of Science and Technology, Taiwan, MOST, (109-2221-E-008-085-MY2, NCU-LSH-108-B-02, NCU-LSH-110-B-02); Ministry of Science and Technology, Taiwan, MOST","","Institute of Electrical and Electronics Engineers Inc.",""
"Chaabane M.; Elrharras A.; Chehri A.; Saadane R.; Sadok H.","Chaabane, Mohamed (58728490200); Elrharras, Abdessamad (56449206500); Chehri, Abdellah (55666436200); Saadane, Rachid (56074327000); Sadok, Hicham (55030069000)","58728490200; 56449206500; 55666436200; 56074327000; 55030069000","Medical Internet of Things for Classification of Pathological ECG Beats Based on Fractional Fourier Transform and Hyperparameter Tuning","2022","","","","","","","10.1109/ISPACS57703.2022.10082841","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152274093&doi=10.1109%2fISPACS57703.2022.10082841&partnerID=40&md5=decfba7a0619d9c1e71fbf8f2973f67d","The Medical Internet of Things (MIoT) has recently played a key role in developing functional health systems. As a result, automatic detection and prediction of future risks such as heart valve diseases and arrhythmias are still being researched and studied. Additionally, early detection of heart problems can improve treatment and reduce patient mortality. On the other hand, traditional approaches did not produce good results for accurate diagnosis. This paper proposes electrocardiogram (ECG) beat classification using Deep Transfer Learning (DTL) and hyperparameter tuning. After a frequency domain transformation with the Fractional Fourier Transform, images of ECG signals were captured (FrFT). The framework uses multi-access edge computing technology, allowing end users to access available resources and our DTL Model in the cloud. The proposed automated model incorporates a Convolutional Neural Network (CNN) structure with hyperparameter tuning. Our model is validated using the MIT-BIH database. Finally, we classified heart disease into five categories. According to the experimental results, the developed framework could classify ECG signals with 99.68 percent accuracy. The proposed method is more accurate and efficient than other well-known and popular algorithms when compared to other current methods.  © 2022 IEEE.","CNN; Deep learning; ECG; Fractional Fourier Transform; Hyperparameter Tuning","Biomedical signal processing; Convolutional neural networks; Deep learning; Diseases; Fourier transforms; Frequency domain analysis; Internet of things; Patient treatment; Tuning; Automatic Detection; Automatic prediction; Convolutional neural network; Deep learning; Electrocardiogram signal; Fractional Fourier transforms; Health systems; Hyper-parameter; Hyperparameter tuning; Transfer learning; Electrocardiograms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Thai P.L.T.; Merry Geisa J.","Thai, Pon L.T. (58043329900); Merry Geisa, J. (54401600100)","58043329900; 54401600100","Classification of microscopic cervical blood cells using inception ResNet V2 with modified activation function","2022","43","6","","8041","8056","15","10.3233/JIFS-220511","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145657796&doi=10.3233%2fJIFS-220511&partnerID=40&md5=2f659ac327e13262ab5517b5066fd980","Cervical cancer is the most frequent and fatal malignancy among women worldwide. If this tumor is detected and treated early enough, the complications it causes can be minimized. Deep learning demonstrated significant promise when imposed on biomedical difficulties such as medical image processing and disease prognostication. Therefore, in this paper, an automatic cervical cell classification approach named IR-PapNet is developed based on Inception-ResNet which is an optimized version of Inception. The learning model's conventional ReLu activation is replaced with the parametric-rectified linear unit (PReLu) to overcome the nullification of negative values and dying ReLu. Finally, the model loss function is minimized with the SGD optimization model by modifying the attributes of the neural network. Furthermore, we present a simple but efficient noise removal technique called 2D-Discrete Wavelet Transform (2D-DWT) algorithm for enhancing image quality. Experimental results show that this model can achieve a top-1 average identification accuracy of 99.8% on the pap smear cervical Herlev datasets, which verifies its satisfactory performance. The restructured Inception-ResNet network model can obtain significant improvements over most of the state-of-the-art models in 2-class classification, and it achieves a high learning rate without experiencing dead nodes.  © 2022 - IOS Press.","2D-DWT; Cervical cancer; deep learning; medical image processing; ResNet model","Blood; Chemical activation; Deep learning; Discrete wavelet transforms; Image classification; Image enhancement; Learning systems; Medical imaging; Signal reconstruction; 2-d discrete wavelet transforms; Activation functions; Blood cells; Cell classification; Cervical cancers; Cervical cells; Classification approach; Deep learning; Medical images processing; Resnet model; Diseases","","","IOS Press BV",""
"Sies K.; Winkler J.K.; Fink C.; Bardehle F.; Toberer F.; Buhl T.; Enk A.; Blum A.; Stolz W.; Rosenberger A.; Haenssle H.A.","Sies, Katharina (57217086727); Winkler, Julia K. (57191580858); Fink, Christine (56844769800); Bardehle, Felicitas (57203822239); Toberer, Ferdinand (37262045600); Buhl, Timo (24463656700); Enk, Alexander (57217521840); Blum, Andreas (55644610100); Stolz, Wilhelm (55422932100); Rosenberger, Albert (7006701973); Haenssle, Holger A. (6603657821)","57217086727; 57191580858; 56844769800; 57203822239; 37262045600; 24463656700; 57217521840; 55644610100; 55422932100; 7006701973; 6603657821","Does sex matter? Analysis of sex-related differences in the diagnostic performance of a market-approved convolutional neural network for skin cancer detection","2022","164","","","88","94","6","10.1016/j.ejca.2021.12.034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124599912&doi=10.1016%2fj.ejca.2021.12.034&partnerID=40&md5=27c3dae4ed043ffbb1666f0e9ccc3902","Background: Advances in biomedical artificial intelligence may introduce or perpetuate sex and gender discriminations. Convolutional neural networks (CNN) have proven a dermatologist-level performance in image classification tasks but have not been assessed for sex and gender biases that may affect training data and diagnostic performance. In this study, we investigated sex-related imbalances in training data and diagnostic performance of a market-approved CNN for skin cancer classification (Moleanalyzer Pro®, Fotofinder Systems GmbH, Bad Birnbach, Germany). Methods: We screened open-access dermoscopic image repositories widely used for CNN training for distribution of sex. Moreover, the sex-related diagnostic performance of the market-approved CNN was tested in 1549 dermoscopic images stratified by sex (female n = 773; male n = 776). Results: Most open-access repositories showed a marked under-representation of images originating from female (40%) versus male (60%) patients. Despite these imbalances and well-known sex-related differences in skin anatomy or skin-directed behaviour, the tested CNN achieved a comparable sensitivity of 87.0% [80.9%–91.3%] versus 87.1% [81.1%–91.4%], specificity of 98.7% [97.4%–99.3%] versus 96.9% [95.2%–98.0%] and ROC-AUC of 0.984 [0.975–0.993] versus 0.979 [0.969–0.988] in dermoscopic images of female versus male origin, respectively. In the sample at hand, sex-related differences in ROC-AUCs were not statistically significant in the per-image analysis nor in an additional per-individual analysis (p ≥ 0.59). Conclusion: Design and training of artificial intelligence algorithms for medical applications should generally acknowledge sex and gender dimensions. Despite sex-related imbalances in open-access training data, the diagnostic performance of the tested CNN showed no sex-related bias in the classification of skin lesions. © 2022 Elsevier Ltd","Automated melanoma detection; Bias; Computer-assisted diagnostics; Convolutional neural network; Deep learning; Dermoscopy; Melanoma; Nevi; Pigmented skin lesions; Sex","Artificial Intelligence; Dermoscopy; Female; Humans; Male; Melanoma; Neural Networks, Computer; Skin Neoplasms; adult; angioma; Article; basal cell carcinoma; cancer classification; cancer diagnosis; convolutional neural network; deep learning; diagnostic value; epiluminescence microscopy; female; Germany; human; image analysis; major clinical study; male; malignant lentigo; melanoma; mucosal melanoma; pigmented nevus; sensitivity and specificity; sex difference; skin cancer; squamous cell skin carcinoma; superficial spreading melanoma; artificial intelligence; diagnostic imaging; melanoma; pathology; procedures; skin tumor","","","Elsevier Ltd","35182926"
"Berezsky O.; Liashchynskyi P.; Pitsun O.; Liashchynskyi P.; Berezkyy M.","Berezsky, Oleh (16479742300); Liashchynskyi, Petro (57202448801); Pitsun, Oleh (57190575875); Liashchynskyi, Pavlo (57202448800); Berezkyy, Mykola (58810798700)","16479742300; 57202448801; 57190575875; 57202448800; 58810798700","Comparison of Deep Neural Network Learning Algorithms for Biomedical Image Processing","2022","3302","","","135","145","10","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144236311&partnerID=40&md5=2478c69b18570feaf3c9fcececde6d84","In recent years, the popularity of deep neural networks used for various problem-solving tasks has increased dramatically. The main tasks include image classification and synthesis using convolutional and generative-adversarial neural networks. These types of networks need large amounts of training data to achieve the required accuracy and performance. In addition, these networks have a long training time. The authors of the paper analyzed and compared the gradient-based neural network learning algorithms. The biomedical image classification with the use of a convolutional neural network of a given architecture was carried out. A comparison of learning algorithms (SGD, Adadelta, RMSProp, Adam, Adamax, Adagrad, and Nadam) was made according to the following parameters: training time, training loss, training accuracy, test loss, and test accuracy. For the experiments, the authors used the Python programming language, the Keras machine learning library, and the Google Colaboratory development environment, which provides free use of the Nvidia Tesla K80 graphics processor. For the experiments tracking and logging the authors used the Weights & Biases service. © 2022 Copyright for this paper by its authors.","biomedical images; CNN; GAN; Machine learning; optimization algorithms","Bioinformatics; Convolution; Convolutional neural networks; Deep neural networks; Generative adversarial networks; Learning algorithms; Learning systems; Biomedical images; GAN; Images classification; Images synthesis; Machine-learning; Main tasks; Neural network learning algorithm; Optimization algorithms; Problem-solving; Training time; Image classification","","Shakhovska N.; Chretien S.; Izonin I.; Campos J.","CEUR-WS",""
"","","","9th International Work-Conference on Bioinformatics and Biomedical Engineering, IWBBIO 2022","2022","13346 LNBI","","","","","922","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133019280&partnerID=40&md5=d8d629a8ec3396b9d6ad59db57b69e04","The proceedings contain 75 papers. The special focus in this conference is on Bioinformatics and Biomedical Engineering. The topics include: Automated TTC Image-Based Analysis of Mouse Brain Lesions; PET-Neuroimaging and Neuropsychological Study for Early Cognitive Impairment in Parkinson’s Disease; architecture and Calibration of a Multi-channel Electrical Impedance Myographer; advanced Incremental Attribute Learning Clustering Algorithm for Medical and Healthcare Applications; Assessment of Inflammation in Non-calcified Artery Plaques with Dynamic 18F-FDG-PET/CT: CT Alone, Does-It Detect the Vulnerable Plaque?; Comparative Analysis of the Spatial Structure Chloroplasts and Cyanobacteria Photosynthetic Systems I and II Genes; Unsupervised Classification of Some Bacteria with 16S RNA Genes; modern Approaches to Cancer Treatment; a Service for Flexible Management and Analysis of Heterogeneous Clinical Data; linear Predictive Modeling for Immune Metabolites Related to Other Metabolites; reconfigurable Arduino Shield for Biosignal Acquisition; smart Watch for Smart Health Monitoring: A Literature Review; Data Quality Enhancement for Machine Learning on Wearable ECGs; Measurable Difference Between Malignant and Benign Tumor of the Thyroid Gland Recognizable Using Echogenicity Index in Ultrasound B-MODE Imaging: An Experimental Blind Study; initial Prototype of Low-Cost Stool Monitoring System for Early Detection of Diseases; Cerebral Activation in Subjects with Developmental Coordination Disorder: A Pilot Study with PET Imaging; on the Use of Explainable Artificial Intelligence for the Differential Diagnosis of Pigmented Skin Lesions; estimating Frontal Body Landmarks from Thermal Sensors Using Residual Neural Networks; NMF for Quality Control of Multi-modal Retinal Images for Diagnosis of Diabetes Mellitus and Diabetic Retinopathy; radiomic-Based Lung Nodule Classification in Low-Dose Computed Tomography; modelling of Arbitrary Shaped Channels and Obstacles by Distance Function; Segmentation of Brain MR Images Using Quantum Inspired Firefly Algorithm with Mutation; a Deep Learning Framework for the Prediction of Conversion to Alzheimer Disease.","","","","Rojas I.; Valenzuela O.; Rojas F.; Herrera L.J.; Ortuño F.","Springer Science and Business Media Deutschland GmbH",""
"","","","3rd International Conference on Neural Computing for Advanced Applications, NCAA 2022","2022","1638 CCIS","","","","","1050","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142671295&partnerID=40&md5=cbeb257de829b7b6a62d59099acfd60e","The proceedings contain 77 papers. The special focus in this conference is on Neural Computing for Advanced Applications. The topics include: A Multi-channel Fusion Method Based on Tensor for Rolling Bearing Fault Diagnosis; a Perception Method Based on Point Cloud Processing in Autonomous Driving; many-Objective Artificial Bee Colony Algorithm Based on Decomposition and Dimension Learning; LCSW: A Novel Indoor Localization System Based on CNN-SVM Model with WKNN in Wi-Fi Environments; large Parallax Image Stitching via Structure Preservation and Multi-matching; traffic Congestion Event Mining Based on Trajectory Data; many-Objective Evolutionary Algorithm Based on Dominance and Objective Space Decomposition; a New Unified Control Approach for Finite-/Fixed-Time Synchronisation of Multi-weighted Dynamical Networks; aperiodic Sampling Based Event-Triggering for Synchronization of Nonlinear Systems; two-Stream 3D MobileNetV3 for Pedestrians Intent Prediction Based on Monocular Camera; Research on Non-intrusive Household Load Identification Method Applying LightGBM; design of Portrait System for Road Safety Based on a Dynamic Density Clustering Algorithm; an Ensemble Deep Learning Model Based on Transformers for Long Sequence Time-Series Forecasting; multi-layer Integrated Extreme Learning Machine for Mechanical Fault Diagnosis of High-Voltage Circuit Breaker; wind Power Forecast Based on Multiple Echo States; UAV-Assisted Blind Area Pedestrian Detection via Terminal-Edge-Cloud Cooperation in VANETs; a Survey of Optimal Design of Antenna (Array) by Evolutionary Computing Methods; a Span-Based Joint Model for Measurable Quantitative Information Extraction; bayesian Optimization Based Seq2Seq Network Models for Real Estate Price Prediction in Hong Kong; ensemble Learning for Crowdfunding Dynamics: JingDong Crowdfunding Projects; Cage Mass Center Capture for Whirl Analysis Using an Improved MultiResUNet from the Multimodal Biomedical Image Segmentation; master Multiple Real-Time Strategy Games with a Unified Learning Model Using Multi-agent Reinforcement Learning; vehicle Re-identification via Spatio-temporal Multi-instance Learning.","","","","Zhang H.; Chen Y.; Chu X.; Zhang Z.; Hao T.; Wu Z.; Yang Y.","Springer Science and Business Media Deutschland GmbH",""
"Winfree S.","Winfree, Seth (6504628773)","6504628773","User-Accessible Machine Learning Approaches for Cell Segmentation and Analysis in Tissue","2022","13","","833333","","","","10.3389/fphys.2022.833333","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127455809&doi=10.3389%2ffphys.2022.833333&partnerID=40&md5=56ad1467c817f9f325137fec4f177d80","Advanced image analysis with machine and deep learning has improved cell segmentation and classification for novel insights into biological mechanisms. These approaches have been used for the analysis of cells in situ, within tissue, and confirmed existing and uncovered new models of cellular microenvironments in human disease. This has been achieved by the development of both imaging modality specific and multimodal solutions for cellular segmentation, thus addressing the fundamental requirement for high quality and reproducible cell segmentation in images from immunofluorescence, immunohistochemistry and histological stains. The expansive landscape of cell types-from a variety of species, organs and cellular states-has required a concerted effort to build libraries of annotated cells for training data and novel solutions for leveraging annotations across imaging modalities and in some cases led to questioning the requirement for single cell demarcation all together. Unfortunately, bleeding-edge approaches are often confined to a few experts with the necessary domain knowledge. However, freely available, and open-source tools and libraries of trained machine learning models have been made accessible to researchers in the biomedical sciences as software pipelines, plugins for open-source and free desktop and web-based software solutions. The future holds exciting possibilities with expanding machine learning models for segmentation via the brute-force addition of new training data or the implementation of novel network architectures, the use of machine and deep learning in cell and neighborhood classification for uncovering cellular microenvironments, and the development of new strategies for the use of machine and deep learning in biomedical research. Copyright © 2022 Winfree.","bio-imaging tools; classification; deep learning—artificial neural network; machine learning; microenviroment; neighborhoods; segmentation","artificial neural network; biomedicine; cell segmentation; classification algorithm; deep learning; human; image segmentation; machine learning; microenvironment; neighborhood analysis; Review; single cell analysis; statistical analysis; technology; tissues","","","Frontiers Media S.A.",""
"Arshad J.; Salim S.; Khokhar A.; Zulfiqar Z.; Younas T.; Rehman A.U.; Bajaj M.; Choudhury S.","Arshad, Jehangir (57115188200); Salim, Saqib (57216413924); Khokhar, Amna (57216410883); Zulfiqar, Zanib (57279348900); Younas, Talha (57193924048); Rehman, Ateeq Ur (57210246601); Bajaj, Mohit (57189048184); Choudhury, Subhashree (55658726700)","57115188200; 57216413924; 57216410883; 57279348900; 57193924048; 57210246601; 57189048184; 55658726700","Classification of Human Facial Portrait Using EEG Signal Processing and Deep Learning Algorithms","2022","286","","","607","618","11","10.1007/978-981-16-9873-6_55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128929088&doi=10.1007%2f978-981-16-9873-6_55&partnerID=40&md5=4657aae8508f5dff00085f963dc5ce78","An electroencephalogram (EEG) is used to evaluate the electrical activity of the brain. While a person sees something, the brain creates a mental precept, this precept captures the use of EEG to get an instantaneous example of what is happening inside the brain all through the precise technique. This study aims to design an automated convolutional neural network (CNN)-based deep learning algorithm that can be employed for the visual classification of a human facial portrait using electroencephalography processing. Moreover, EEG information evoked through visible photograph stimuli has been employed through the convolution neural network (CNN) to realize a discriminatory mind recreation manifold of image classifications within the mind-reading process. We have used a 9-channel EEG Mindwave Mobile 2 headset to record the brain activity of subjects while looking at images of four persons from the dataset. The presented results validate the proposed algorithm as it shows a precision of 80% that has greatly outshined the existing techniques. In further, this study shows that the learned capabilities by CNN-based deep learning models can be employed for automated visual classification that can be used for disabled persons and criminal investigation with further few improvements. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Convolutional neural network (CNN); First electroencephalogram (EEG); Mindwave mobile","Biomedical signal processing; Brain; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Disabled persons; Electrophysiology; Learning algorithms; Convolution neural network; Convolutional neural network; Electrical activities; Electroencephalogram signals; First electroencephalogram; Mindwave mobile; Network-based; Signal-processing; Visual classification; Electroencephalography","","Mishra D.; Buyya R.; Mohapatra P.; Patnaik S.","Springer Science and Business Media Deutschland GmbH",""
"Bao Z.; Cao L.; Yan L.; Shen C.","Bao, Zhiqiang (57212622598); Cao, Lei (58439224500); Yan, Luping (57918279800); Shen, Chuqi (57919261800)","57212622598; 58439224500; 57918279800; 57919261800","Heart Rhythm Anomaly Recognition Based on ECG Lorenz Plot","2022","","","","299","303","4","10.1109/ICNLP55136.2022.00054","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139417969&doi=10.1109%2fICNLP55136.2022.00054&partnerID=40&md5=8d7f9ce95b12e5f2c46eabc88ce5cfc6","Heart disease has become one of the important diseases threatening people's life and health. Therefore, automatic recognition and classification of arrhythmia has gradually become a research hotspot. The traditional machine learning identification methods need to manually extract the feature information of one-dimensional ECG signal, which is time-consuming and labor-intensive and affects the accuracy. To solve this problem, this paper proposes to transform one-dimensional ECG data into two-dimensional image ECG lorenz plot, which can better use the feature information of spatial ECG lorenz plot for learning. Secondly, a two-dimensional convolution neural network model is designed to automatically learn the characteristics of graphics, and train and identify five types of abnormal heart rhythm images. Finally, the recognition accuracy of the proposed algorithm for five types of ECG signals can reach 86.5%, which can prove the feasibility of the algorithm.  © 2022 IEEE.","convolutional neural network; deep learning; ECG signal; Lorenz plot","Biomedical signal processing; Computerized tomography; Convolution; Convolutional neural networks; Deep learning; Diseases; Learning systems; Anomaly recognition; Automatic classification; Automatic recognition; Convolutional neural network; Deep learning; ECG signals; Feature information; Heart disease; Lorenz plots; One-dimensional; Electrocardiograms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Sharma A.; Kumar R.","Sharma, Ajay (57210974822); Kumar, Raj (57217189034)","57210974822; 57217189034","Recent Advancement and Challenges in Deep Learning, Big Data in Bioinformatics","2022","105","","","251","284","33","10.1007/978-3-030-95419-2_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127835715&doi=10.1007%2f978-3-030-95419-2_12&partnerID=40&md5=fb261fefcffcf2e94b989f3ecd06ceda","More data have been produced in recent years than in the thousands of years of human history. This data represents an important gold mine for policymakers in terms of commercial value and reference material. But much of this value is untapped, worse, wrongly comprehended as long as it is impossible to use the tools needed to process the stunning amount of information. In this book chapter, we will examine how machine learning can give us a glimpse of the patterns in Big Data and obtain key information in all fields of biology, healthcare. An analysis, ineffectiveness storage, and depth of learning algorithms in this field are essential to the electronic equipment which generates an anonymous scale of data referring to diversity and veracity. The architecture of Hadoop-based maps and deep learning algorithms like Convolutional Neural Network, Recurrent Neural Network have transformed the way we analyze massive data. The role, impact, and prospect of deep learning algorithms, reinforcement learning to manage big data in the area of bioinformatics, computer aided drug design, structural biology and computational biology are discussed in this book chapter. In last section author has discussed about the role of deep learning in next generation sequencing, biomedical image processing and drug discovery and molecular modelling and dynamics studies. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Big Data; Bioinformatics; Convolutional neural network (CNN); Deep learning; Drug design; Hadoop; Healthcare; Map-reduce; Reinforcement learning; Structural biology","Bioinformatics; Convolution; Convolutional neural networks; Deep neural networks; Digital storage; Health care; Image processing; Information management; Learning algorithms; Oscillators (electronic); Recurrent neural networks; Reinforcement learning; Amount of information; Convolutional neural network; Deep learning; Drug Design; Hadoop; Map-reduce; Policy makers; Reference material; Structural biology; Big data","","","Springer Science and Business Media Deutschland GmbH",""
"Rudman W.; Merullo J.; Mercurio L.; Eickhoff C.","Rudman, William (57239031900); Merullo, Jack (57216692762); Mercurio, Laura (57205624554); Eickhoff, Carsten (36767177300)","57239031900; 57216692762; 57205624554; 36767177300","ACQuA: Anomaly Classification with Quasi-Attractors","2022","2022-September","","","","","","10.22489/CinC.2022.201","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152907642&doi=10.22489%2fCinC.2022.201&partnerID=40&md5=b44ac1cea5d74257f5523da9d72fa4ed","In recent years, deep learning has redefined algorithms for detecting cardiac abnormalities. However, many state of the art algorithms still rely on calculating handcrafted features from a given heart signal that are then fed into shallow 1D convolutional networks or transformer architectures. We propose ACQuA (Anomaly Classification with Quasi Attractors), a task agnostic algorithm that can be used in a wide variety of cardiac settings, from classifying cardiac arrhythmias from ECG signals to detecting heart murmurs from PCG signals. Using theorems from dynamical analysis and topological data analysis, we create informative attractor images that 1) are human distinguishable and 2) can be used to train neural networks for anomaly classification. In the George B. Moody 2022 Challenge, our team, BrownBAI, received an official score of 0.406 (38/40) for murmur classification and a score of 16773 (39/40) for outcome classification. Additionally, we evaluate our model on the CinC 2017 Challenge data that tasks practitioners to classify cardiac arrhythmias from ECG signals. On the CinC 2017 Challenge data, we improve upon the winning F1 scores by approximately 14% on the hidden validation data. © 2022 Creative Commons.","","Biomedical signal processing; Cardiology; Deep learning; Diseases; Dynamical systems; Heart; Cardiac arrhythmia; Convolutional networks; Dynamical analysis; ECG signals; Heart Murmur; Heart signal; Neural-networks; PCG signal; State-of-the-art algorithms; Topological data analysis; Electrocardiography","National Science Foundation, NSF, (IIS-1956221, T32 GM128596)","","IEEE Computer Society",""
"Zhang Y.; Zhang L.; Liu H.; Wang P.; Hou A.; Wang G.; Sun S.","Zhang, Yanqi (56644204100); Zhang, Limin (57411055900); Liu, Han (57209844255); Wang, Ping (57211195003); Hou, Ailin (57849848500); Wang, Guohe (56144184900); Sun, Shaokai (56949454800)","56644204100; 57411055900; 57209844255; 57211195003; 57849848500; 56144184900; 56949454800","Fluorescence pharmacokinetic parametric imaging method based on dynamic diffuse fluorescence tomography and deep learning","2022","12320","","123201M","","","","10.1117/12.2637777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146682444&doi=10.1117%2f12.2637777&partnerID=40&md5=38f8ab72a269ab7feca25c2894667e43","At present, the imaging of fluorescence pharmacokinetic parameters based on dynamic diffuse fluorescence tomography (D-DFT) technology have limitations in some aspects including the accuracy of physical model and the quantification of method. In this work, we propose a fluorescence pharmacokinetic parametric imaging method of tumor tissues based on D-DFT and deep learning. It mainly includes: a more realistic training and test simulation data set can be established by combining non-uniform tissue photon transport model and biological tissue fluorescence kinetics method. A fluorescence pharmacokinetic parametric reconstruction algorithm that involves an improved U-Net architecture based on the fully convolutional neural network is developed to break through the complexity bottleneck of imaging physical model. The numerical simulation results show that the method can realize image reconstruction of pharmacokinetic parameters with high spatial resolution and high quantitative accuracy. © 2022 SPIE.","Biomedical optical imaging; Deep learning; Diffuse fluorescence tomography; Image reconstruction","Bioinformatics; Deep learning; Fluorescence imaging; Learning algorithms; Medical imaging; Numerical methods; Optical tomography; Pharmacokinetics; Statistical tests; Tissue; Biomedical optical imaging; Deep learning; Diffuse fluorescence tomographies; Images reconstruction; Imaging method; ON dynamics; Parametric imaging; Pharmacokinetic parameters; Physical modelling; Tumour tissue; Image reconstruction","scientific research project of Tianjin municipal education commission, (2021KJ264)","Luo Q.; Li X.; Gu Y.; Zhu D.","SPIE",""
"","","","ISBIC 2022 - International Symposium on Biomedical Imaging Challenges, Proceedings","2022","","","","","","70","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137324449&partnerID=40&md5=c67f1218c0d17ea34cc5f3449d0f786c","The proceedings contain 15 papers. The topics discussed include: a multi-task multiple instance learning algorithm to analyze large whole slide images from Bright Challenge 2022; breast tumor image classification in bright challenge via multiple instance learning and deep transformers; class-controlling copy-paste augmentation for nuclear segmentation; panoptic segmentation with highly imbalanced semantic labels; deep Dirichlet uncertainty for unsupervised out-of-distribution detection of eye fundus photographs in glaucoma screening; elevating fundoscopic evaluation to expert level - automatic glaucoma detection using data from the Airogs Challenge; multi-modal information fusion for classification of kidney abnormalities; risk score classification of renal masses on CT imaging data using a convolutional neural network; deep learning-based methods for directing the management of renal cancer using CT scan and clinical information; and nuclei instance segmentation and classification in histopathology images with Stardist.","","","","","Institute of Electrical and Electronics Engineers Inc.",""
"Ashok M.; Gupta A.","Ashok, Malvika (57219146342); Gupta, Abhishek (55430473100)","57219146342; 55430473100","Comparative Study of TRANS - GAN Architecture for Bio-Medical Image Semantic Segmentation","2022","","","","1564","1570","6","10.1109/ICCES54183.2022.9835992","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136319840&doi=10.1109%2fICCES54183.2022.9835992&partnerID=40&md5=dbf693663a1d3e649cd47a4e7a57e494","In the area of biomedical image processing, medical image segmentation plays a crucial role. Today due to the deep sculptures of deep neural networks and innovative by-passes like the Transformers this field has rejuvenated. This paper analyzes various algorithmic advancements regarding Transformers and Generative Adversarial Networks (GAN) which have paved the anatomy of image segmentation. The GAN network is not only able to regenerate feature spaces but also can transpose the inputs from the transformer. These algorithms are not only at par with the bifurcation of networks like U-net and ResNet but showcase a strong and more intuitive idea of human neural intelligence. Finally, all methods are compared based on accuracy, dice score, architectural evaluation, etc. The ability of these networks are deduced to regenerate and recreate the feature spaces for the given input image and thus can segment high features for prediction.  © 2022 IEEE.","Automatic segmentation; Bio-Medical Imaging; CT segmentation; Deep learning; Generative Adversarial Networks Convolutional Neural Network; Medical modalities; Supervised and Unsupervised Transformers; Traditional Architecture; Transformers","Computerized tomography; Convolutional neural networks; Deep neural networks; Medical imaging; Network architecture; Semantic Segmentation; Semantics; Automatic segmentations; Bio-medical; Bio-medical imaging; Convolutional neural network; CT segmentation; Deep learning; Generative adversarial network convolutional neural network; Medical modality; Supervised and unsupervised transformer; Traditional architecture; Transformer; Generative adversarial networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Ghaleb M.S.; Ebied H.M.; Shedeed H.A.; Tolba M.F.","Ghaleb, Moshira S. (57216397948); Ebied, Hala M. (25640793000); Shedeed, Howida A. (8275377800); Tolba, Mohamed F. (24541714400)","57216397948; 25640793000; 8275377800; 24541714400","Image Retrieval Based on Deep Learning","2022","12","2","","483","502","19","10.33168/JSMS.2022.0226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132584704&doi=10.33168%2fJSMS.2022.0226&partnerID=40&md5=f08dcd49b6f7273596fbc13e0143dd19","The digital image has an important role in many fields such as biomedical, robotics, weather forecasting and object recognition. Due to the widespread use of social media sites, cloud services, and cellphones, large image databases are easily accessible. Searching by text is a common and simple method, however if the algorithm is running properly, searching by visual content will be much more sensitive. The goal of this research is to create a content-based image retrieval method that is more accurate in image retrieval. In this approach, intelligent systems can assist and work successfully. This study analyses three deep learning-based proposal methodologies: CNN, convolutional layers fused with LSTM, and Convolutional layers fused with GRU. The models were tested on four distinct databases of varying sizes, including Corel1K, Cifar-10, Cifar-100, and Mnist 70K. In comparison to state-of-the-art models, the three presented algorithms have significantly reduced computation time and provided very high picture retrieval levels of accuracy. For Corel1K, Cifar-10, Cifar-100, and Mnist 70k, CNN's proposed model scored 93.3, 94%, 85.5 %, and 99.9 %, respectively. the second proposed model scored 94.5%, 95%, 86.5%, and 99.9 for Corel1K, Cifar-10, Cifar-100, and Mnist 70k, respectively. Finally, for Corel1K, Cifar-10, Cifar-100, and Mnist 70k, the third proposed model reached 95.5%, 96%, 87.5 %, and 99.9%, respectively. © 2022, Success Culture Press. All rights reserved.","CBIR; convolution neural network; deep learning; gate recurrent unit; long short time memory","","","","Success Culture Press",""
"Feyisa D.W.; Debelee T.G.; Ayano Y.M.; Kebede S.R.; Assore T.F.","Feyisa, Degaga Wolde (57846119700); Debelee, Taye Girma (57202946910); Ayano, Yehualashet Megersa (57252901900); Kebede, Samuel Rahimeto (57210161483); Assore, Tariku Fekadu (57845890100)","57846119700; 57202946910; 57252901900; 57210161483; 57845890100","Lightweight Multireceptive Field CNN for 12-Lead ECG Signal Classification","2022","2022","","8413294","","","","10.1155/2022/8413294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136004569&doi=10.1155%2f2022%2f8413294&partnerID=40&md5=a9cc793d85d9932ef683ff0c0876c969","The electrical activity produced during the heartbeat is measured and recorded by an ECG. Cardiologists can interpret the ECG machine's signals and determine the heart's health condition and related causes of ECG signal abnormalities. However, cardiologist shortage is a challenge in both developing and developed countries. Moreover, the experience of a cardiologist matters in the accurate interpretation of the ECG signal, as the interpretation of ECG is quite tricky even for experienced doctors. Therefore, developing computer-aided ECG interpretation is required for its wide-reaching effect. 12-lead ECG generates a 1D signal with 12 channels among the well-known time-series data. Classical machine learning can develop automatic detection, but deep learning is more effective in the classification task. 1D-CNN is being widely used for CVDS detection from ECG datasets. However, adopting a deep learning model designed for computer vision can be problematic because of its massive parameters and the need for many samples to train. In many detection tasks ranging from semantic segmentation of medical images to time-series data classification, multireceptive field CNN has improved performance. Notably, the nature of the ECG dataset made performance improvement possible by using a multireceptive field CNN (MRF-CNN). Using MRF-CNN, it is possible to design a model that considers semantic context information within ECG signals with different sizes. As a result, this study has designed a multireceptive field CNN architecture for ECG classification. The proposed multireceptive field CNN architecture can improve the performance of ECG signal classification. We have achieved a 0.72 F1 score and 0.93 AUC for 5 superclasses, a 0.46 F1 score and 0.92 AUC for 20 subclasses, and a 0.31 F1 score and 0.92 AUC for all the diagnostic classes of the PTB-XL dataset.  © 2022 Degaga Wolde Feyisa et al.","","Algorithms; Arrhythmias, Cardiac; Electrocardiography; Humans; Machine Learning; Neural Networks, Computer; Biomedical signal processing; Classification (of information); Deep learning; Image enhancement; Learning systems; Magnetorheological fluids; Markov processes; Medical imaging; Semantic Segmentation; Semantics; Structural frames; Time series; Computer-aided; Developed countries; ECG interpretation; ECG signals; Electrical activities; F1 scores; Health condition; Performance; Signal classification; Time-series data; algorithm; electrocardiography; heart arrhythmia; human; machine learning; Electrocardiograms","","","Hindawi Limited","35978890"
"Amin M.; Ullah K.; Asif M.; Waheed A.; Haq S.U.; Zareei M.; Biswal R.R.","Amin, Muhammad (57652783400); Ullah, Khalil (57190384525); Asif, Muhammad (57215812503); Waheed, Abdul (57219595367); Haq, Sana Ul (56567653800); Zareei, Mahdi (48762315500); Biswal, R.R. (56260644700)","57652783400; 57190384525; 57215812503; 57219595367; 56567653800; 48762315500; 56260644700","ECG-Based Driver's Stress Detection Using Deep Transfer Learning and Fuzzy Logic Approaches","2022","10","","","29788","29809","21","10.1109/ACCESS.2022.3158658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126296071&doi=10.1109%2fACCESS.2022.3158658&partnerID=40&md5=eb6cf6e65b5d59a98851ccba21c682ee","Driver's stress detection is a critical research area that helps reduce the likelihood of traffic accidents and driver's health complexities due to prolonged stress. Previous work in this area is heavily based on traditional machine learning models that classify the driver's stress levels using handcrafted features extraction techniques. Extracting the best features using these approaches is always a challenging task. Recently, deep learning techniques have emerged for constructing reliable features automatically and classifying the classes with high accuracy. However, large deep learning models face gradient exploding or vanishing problems. Moreover, acquiring a large dataset for training an entire network from scratch is also a challenging task. This paper is based on the deep transfer learning technique to avoid these problems and to reduce computational cost and time. Seven models are proposed for real-world driver's stress levels detection using Electrocardiogram (ECG) signals. Different Convolutional Neural Network (CNN)-based pre-trained networks are used to classify the driver's three stress levels. The time-frequency ECG components for the three stress levels are obtained as scalogram images using a normalized Continuous Wavelet Transform (CWT) filter bank and Morse wavelet. Results show that Model 5 based on Xception outperforms the GoogLeNet, DarkNet-53, ResNet-101, InceptionResNetV2, DenseNet-201, and InceptionV3 based models by 11.32%, 11.32%, 9.45%, 7.54%, 5.66%, and 1.88% respectively and achieves 98.11% overall validation accuracy. Ranking estimation using fuzzy logic approach shows that Xception based Model 5 achieves the highest rank for driver's high and medium stress levels, while DenseNet-201 based Model 4 achieves the highest rank for low-stress level detection among the other models.  © 2013 IEEE.","continuous wavelet transform; deep transfer learning; Drivers stress detection; ECG signals; fuzzy logic; pre-trained networks; signal processing","Biomedical signal processing; Computer circuits; Deep learning; Electrocardiography; Extraction; Fuzzy logic; Fuzzy neural networks; Large dataset; Learning algorithms; Signal detection; Stresses; Wavelet transforms; Biomedical monitoring; Continuous Wavelet Transform; Deep learning; Deep transfer learning; Driver&#x2019;; Electrocardiogram signal; Features extraction; Fuzzy-Logic; Pre-trained network; S stress detection; Signal-processing; Stress detection; Transfer learning; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.",""
"Radig J.; Paysan P.; Scheib S.","Radig, Jean (57961986600); Paysan, Pascal (15058293100); Scheib, Stefan (6701657547)","57961986600; 15058293100; 6701657547","Deep Learning based Respiratory Surrogate Signal Extraction","2022","12304","","123041N","","","","10.1117/12.2647098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141763961&doi=10.1117%2f12.2647098&partnerID=40&md5=566aee8810d2a442fd67904b577d2e7c","We present a feasibility study on extracting the respiratory surrogate signal (RSS) from cone-beam computed tomography (CBCT) projections using a supervised convolutional neural network (CNN) model. Determining the intrinsic RSS instead of using an external surrogate signal, provided by optical tracing hardware such as the Real-time Position Management (RPM) system, has the advantage that it spares patient setup time and hence permits faster 4D CBCT acquisition. Another convenience of such an approach is that it can be applied retrospectively without special preparation or equipment. For the implementation, we made use of the MONAI open source library. Our model is based on a modified version of the MONAI regressor class. We trained the model using CBCT projections with the corresponding RSS as recorded by an external marker block using the RPM system. The model is to deduce the RSS given the CBCT. Using a specific dataset with CBCT from anesthetized animals breathing with the help of a mechanical ventilator, results show a good correlation between the actual and predicted RSS. Unlike the Amsterdam Shroud algorithm, our method shows promising results to predict the normalized amplitude of the breathing signal. Further work could extend the model to permit RSS prediction for its online use in radiation therapy or detection of sudden motion deteriorating CBCT image quality. To conclude, we have made a first step towards proving the concept which consists in using a deep learning model to extract the RSS out of acquired CBCT projection images. The approach is promising but requires more work for robustness, i.e. for sufficient accuracy both in the frequency and normalized amplitude extraction. © 2022 SPIE.","CBCT; convolutional neural network; MONAI; respiratory amplitude; respiratory phase","Biomedical signal processing; Computerized tomography; Convolution; Convolutional neural networks; Deep learning; Extraction; Image quality; Learning systems; Medical imaging; Cone-beam computed tomography; Convolutional neural network; Feasibility studies; Management systems; MONAI; Real- time; Respiratory amplitude; Respiratory phasis; Respiratory surrogates; Signal extraction; Neural network models","","Stayman J.W.","SPIE",""
"Gao Y.; Zhang Y.; Jiang X.","Gao, Yalan (57218452855); Zhang, Yanqiong (57205725582); Jiang, Xianwei (57211990320)","57218452855; 57205725582; 57211990320","An Optimized Convolutional Neural Network with Combination Blocks for Chinese Sign Language Identification","2022","132","1","","95","117","22","10.32604/cmes.2022.019970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138463147&doi=10.32604%2fcmes.2022.019970&partnerID=40&md5=dbf1db6cfa369b745c128c141ccd9992","(Aim) Chinese sign language is an essential tool for hearing-impaired to live, learn and communicate in deaf communities. Moreover, Chinese sign language plays a significant role in speech therapy and rehabilitation. Chinese sign language identification can provide convenience for those hearing impaired people and eliminate the communication barrier between the deaf community and the rest of society. Similar to the research of many biomedical image processing (such as automatic chest radiograph processing, diagnosis of chest radiological images, etc.), with the rapid development of artificial intelligence, especially deep learning technologies and algorithms, sign language image recognition ushered in the spring. This study aims to propose a novel sign language image recognition method based on an optimized convolutional neural network. (Method) Three different combinations of blocks: Conv-BN-ReLU-Pooling, Conv-BN-ReLU, Conv-BN-ReLU-BN were employed, including some advanced technologies such as batch normalization, dropout, and Leaky ReLU. We proposed an optimized convolutional neural network to identify 1320 sign language images, which was called as CNN-CB method. Totally ten runs were implemented with the hold-out randomly set for each run. (Results) The results indicate that our CNN-CB method gained an overall accuracy of 94.88 ± 0.99%. (Conclusion) Our CNN-CB method is superior to thirteen state-of-the-art methods: eight traditional machine learning approaches and five modern convolutional neural network approaches. © 2022 Tech Science Press. All rights reserved.","batch normalization; Chinese sign language; combination blocks; Convolutional neural network; dropout; Leaky ReLU; M-fold cross-validation","Audition; Bioinformatics; Convolution; Deep learning; Image processing; Image recognition; Learning systems; Natural language processing systems; Batch normalization; Chinese sign language; Combination block; Convolutional neural network; Cross validation; Dropout; Leaky ReLU; M-fold cross-validation; Normalisation; Sign language image; Convolutional neural networks","WITH Foundation, (20BTQ065); Philosophy and Social Science Foundation of Hunan Province","","Tech Science Press",""
"Mahbub M.K.; Biswas M.; Miah M.A.M.; Kaiser M.S.","Mahbub, Md. Kawsher (57226568338); Biswas, Milon (57188669162); Miah, Md. Abdul Mozid (57457237200); Kaiser, M. Shamim (56446362000)","57226568338; 57188669162; 57457237200; 56446362000","Deep Neural Networks for Brain Tumor Detection from MRI Images","2022","348","","","473","485","12","10.1007/978-981-16-7597-3_39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126204210&doi=10.1007%2f978-981-16-7597-3_39&partnerID=40&md5=c9d45debe4c827ad0e69269fa75d24e8","Brain tumor patients have a significant mortality rate. If the tumors are misdiagnosed, it may result in ineffective medical treatment and reduce their life chances. As the risk of brain tumors increases with age and the world’s population ages, there is an urgent need to develop low-cost, easy-to-use early detection technologies. MRI scans are commonly used to visualize a patient’s brain. Artificial intelligence (AI), deep learning (DL), and its sub-domain have recently reduced the need for human judgment in detecting disorders. DL models are increasingly being employed in traditional supervised learning algorithms due to their inherent advantages of automatically obtaining the required features from images. The detection of brain tumors is one of the most challenging tasks in biomedical imaging. This study is intended to propose a deep neural network (DNN) based solution with a limited number of epochs and parameters. The experiment was conducted on two different datasets, and the proposed DNN obtained 99.22% accuracy, 98.94% sensitivity, 99.53% specificity, 99.57% precision, and 99.26% F1-Score for Dataset (D1) and 99.43% accuracy, 98.86% sensitivity, 100.0% specificity, 100.0% precision, and 99.43% F1-Score for dataset (D2). The results are comparable with the current state-of-the-art. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Brain tumor; Deep learning; MRI","","","Kaiser M.S.; Ray K.; Bandyopadhyay A.; Jacob K.; Long K.S.","Springer Science and Business Media Deutschland GmbH",""
"Pavan B.V.V.S.R.K.K.; Rani P.E.","Pavan, B.V.V.S.R.K.K. (57264768600); Rani, P. Esther (55135907300)","57264768600; 55135907300","An Analysis of Electro Encephalo Gram Recording Systems and Signal Processing Techniques","2022","","","","","","","10.1109/ICDCECE53908.2022.9793190","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133435850&doi=10.1109%2fICDCECE53908.2022.9793190&partnerID=40&md5=9ea9d543ed673b5d0e6fc9d98435febb","Electroencephalography (EEG), a monitoring technique for recording the electrical activity of the brain, is typically non-invasive and involves the implantation of electrodes along the scalp to capture the electrical activity. Artifacts are undesirable signals recorded by the EEG that are not created by the brain and are thus not considered to be normal. These artefacts reproduce or imitate real epileptiform abnormalities or seizures in a way that is accurate. This anomaly has the potential to lead to erroneous data analysis. Therefore, it is critical to differentiate between artefacts and the electrical activity of the brain. Establishing an artifact-free EEG recording system is a difficult endeavor since the recorded EEG data is processed to remove artefacts and noisy lines before being used for research. This paper proposes the fejer-korovkin filtering with deep learning LSTM) method. The knowledge-based neural network on the artefacts removed from the fejer-Korovkin filtering data must be utilised to extract the features from the DLN LSTM. In order to improve the accuracy of the previously trained data as well as relevant photos, the PSO naive bayes classifier algorithm must be used for this data. Because of this, it is possible to recover the EEG signal with high accuracy using the classified output that has been generated. From the simulation results the proposed methods shows better results.  © 2022 IEEE.","Artifact's removal; electroencephalogram; Pre-processing; recording system","Biomedical signal processing; Brain; Electrophysiology; Image enhancement; Knowledge based systems; Long short-term memory; Recording instruments; Artifact removal; Classifier algorithms; Electrical activities; Erroneous datum; Knowledge based neural networks; Monitoring techniques; Naive Bayes classifiers; Pre-processing; Recording systems; Signal processing technique; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Maiello L.; Ball L.; Micali M.; Iannuzzi F.; Scherf N.; Hoffmann R.-T.; Gama de Abreu M.; Pelosi P.; Huhle R.","Maiello, Lorenzo (57222163638); Ball, Lorenzo (55667696400); Micali, Marco (57215719490); Iannuzzi, Francesca (8672810400); Scherf, Nico (22935625000); Hoffmann, Ralf-Thorsten (55263364700); Gama de Abreu, Marcelo (57205413819); Pelosi, Paolo (7006547963); Huhle, Robert (55192776400)","57222163638; 55667696400; 57215719490; 8672810400; 22935625000; 55263364700; 57205413819; 7006547963; 55192776400","Automatic Lung Segmentation and Quantification of Aeration in Computed Tomography of the Chest Using 3D Transfer Learning","2022","12","","725865","","","","10.3389/fphys.2021.725865","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124901369&doi=10.3389%2ffphys.2021.725865&partnerID=40&md5=278d2df56926a150cd69fa0770170ab3","Background: Identification of lung parenchyma on computer tomographic (CT) scans in the research setting is done semi-automatically and requires cumbersome manual correction. This is especially true in pathological conditions, hindering the clinical application of aeration compartment (AC) analysis. Deep learning based algorithms have lately been shown to be reliable and time-efficient in segmenting pathologic lungs. In this contribution, we thus propose a novel 3D transfer learning based approach to quantify lung volumes, aeration compartments and lung recruitability. Methods: Two convolutional neural networks developed for biomedical image segmentation (uNet), with different resolutions and fields of view, were implemented using Matlab. Training and evaluation was done on 180 scans of 18 pigs in experimental ARDS (u2NetPig) and on a clinical data set of 150 scans from 58 ICU patients with lung conditions varying from healthy, to COPD, to ARDS and COVID-19 (u2NetHuman). One manual segmentations (MS) was available for each scan, being a consensus by two experts. Transfer learning was then applied to train u2NetPig on the clinical data set generating u2NetTransfer. General segmentation quality was quantified using the Jaccard index (JI) and the Boundary Function score (BF). The slope between JI or BF and relative volume of non-aerated compartment (SJI and SBF, respectively) was calculated over data sets to assess robustness toward non-aerated lung regions. Additionally, the relative volume of ACs and lung volumes (LV) were compared between automatic and MS. Results: On the experimental data set, u2NetPig resulted in JI = 0.892 [0.88 : 091] (median [inter-quartile range]), BF = 0.995 [0.98 : 1.0] and slopes SJI = −0.2 {95% conf. int. −0.23 : −0.16} and SBF = −0.1 {−0.5 : −0.06}. u2NetHuman showed similar performance compared to u2NetPig in JI, BF but with reduced robustness SJI = −0.29 {−0.36 : −0.22} and SBF = −0.43 {−0.54 : −0.31}. Transfer learning improved overall JI = 0.92 [0.88 : 0.94], P < 0.001, but reduced robustness SJI = −0.46 {−0.52 : −0.40}, and affected neither BF = 0.96 [0.91 : 0.98] nor SBF = −0.48 {−0.59 : −0.36}. u2NetTransfer improved JI compared to u2NetHuman in segmenting healthy (P = 0.008), ARDS (P < 0.001) and COPD (P = 0.004) patients but not in COVID-19 patients (P = 0.298). ACs and LV determined using u2NetTransfer segmentations exhibited < 5% volume difference compared to MS. Conclusion: Compared to manual segmentations, automatic uNet based 3D lung segmentation provides acceptable quality for both clinical and scientific purposes in the quantification of lung volumes, aeration compartments, and recruitability. Copyright © 2022 Maiello, Ball, Micali, Iannuzzi, Scherf, Hoffmann, Gama de Abreu, Pelosi and Huhle.","ARDS; COVID-19; deep learning; Jaccard index; lung recruitment; lung segmentation; transfer learning; uNet","adult respiratory distress syndrome; Article; automation; chronic obstructive lung disease; clinical evaluation; cohort analysis; comparative study; computer assisted tomography; consensus; controlled study; convolutional neural network; coronavirus disease 2019; data analysis software; human; image quality; image segmentation; intensive care unit; lung volume; major clinical study; mathematical computing; mathematical model; quantitative analysis; thorax radiography; three-dimensional imaging; transfer of learning","Centre for Information Services; Deutsche Forschungsgemeinschaft, DFG, (GA 1256/8-1)","","Frontiers Media S.A.",""
"Saadain S.; Shah J.A.; Wahid A.; Kadir K.","Saadain, Syyed (57235219200); Shah, Jawad Ali (54930956400); Wahid, Abdul (58028307700); Kadir, Kushsairy (37079357500)","57235219200; 54930956400; 58028307700; 37079357500","Comparative Analysis of ML-CSC Based CS-MRI Framework With State of the Art","2022","","","","175","180","5","10.1109/ICSIMA55652.2022.9928873","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141843895&doi=10.1109%2fICSIMA55652.2022.9928873&partnerID=40&md5=74fb2d7600b371442bfe406832d867fa","Deep neural networks have been used extensively for inverse problems in image processing research. Subsequently the interest has been shown to theoretically model deep nets with celebrated sparse coding theory resulting in emergence of convolutional sparse coding (CSC) theory. The CSC theory which is a peculiar case of sparse coding works on the premise of representing underlying data (natural or biomedical images) with learned filters/dictionaries and their corresponding sparse feature maps. The dictionaries have special structure unlike their counter part of sparse coding and pursuit algorithms works on global scale instead of patches. This global pursuit results in mitigating the effects of patch aggregation process during traditional regularization-based techniques. Further extending the CSC model, the learning features are again processed through the CSC model representing them with another layer of filters/dictionaries and their corresponding sparse maps. This process is continued until the last layers of model making the multi-layer convolutional sparse coding model. The pursuit algorithms can be employed layer wise of a global pursuit settings utilizing iterative thresholding algorithms. In this work we have implemented a ML-CSC model for the reconstruction of Knee MR images on different CS ratios. The results have been compared with state of the art ISTA-Net+ model in terms of PSNR/SSIM and restoration times for different CS ratios. It is shown that ML-CSC has better quality results than the state of the art ISTA-Net+model.  © 2022 IEEE.","Compressed Sensing; MRI; Multi-layer Convolutional Sparse Coding","Computer programming; Convolution; Deep neural networks; Inverse problems; Iterative methods; Coding models; Coding Theory; Comparative analyzes; Compressed-Sensing; Multi-layer convolutional sparse coding; Multi-layers; Net model; Pursuit algorithms; Sparse coding; State of the art; Magnetic resonance imaging","Ministry of Higher Education, Malaysia, MOHE, (FRGS/1/2019/TK04/UNIKL/02/6); Ministry of Higher Education, Malaysia, MOHE","","Institute of Electrical and Electronics Engineers Inc.",""
"Hossain S.M.; Jamal Z.; Noshin A.A.; Khan M.M.","Hossain, Syed Maaher (57997963900); Jamal, Zeeshan (57364497700); Noshin, Aurik Anjum (57998609400); Khan, Mohammad Monirujjaman (36350785300)","57997963900; 57364497700; 57998609400; 36350785300","Comparative Study of Deep Learning Algorithms for the Detection of Facial Paralysis","2022","","","","368","377","9","10.1109/IEMCON56893.2022.9946491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143611193&doi=10.1109%2fIEMCON56893.2022.9946491&partnerID=40&md5=865e519f0c6ad8f470b3105358821f91","Statistical analysis has shown a noteworthy escalation in the rate of brain strokes in recent times. But the time required to carry out the conventional methods to detect brain stroke on a patient requires both trained personnel and time. Any discrepancy in the process might also lead to fatal consequences. Facial paralysis is among the most frequent signs of stroke. Currently, there are not many effective models for detecting facial paralysis. To help make the stroke detection technique less formidable to at least a certain extent, this report presents a comparative analysis of deep learning algorithms for the efficient detection of facial paralysis. We have compared three different pre-trained Convolutional neural networks (CNN) to find the one best suitable for detecting facial paralysis. The models include ResNet50, InceptionV3 and VGG-16. The models were trained using datasets from Kaggle consisting of facial images. Five different evaluation metrics, which are accuracy, precision, recall, F1-score, and area under the ROC (receiver operating characteristic) curve were used. We were able to attain the highest accuracy using ResNet50, which was 96.63%, while InceptionV3 yielded an accuracy of 95.38% and VGG-16 gave an accuracy of 93.50%. Overall, we can say that this research can aid in implementing models that can increase the efficiency and accuracy in the detection of facial paralysis in biomedical fields.  © 2022 IEEE.","Brain stroke; deep learning algorithms; facial images; facial paralysis; pre-trained models","Convolutional neural networks; Deep learning; Face recognition; Brain strokes; Comparative analyzes; Comparatives studies; Conventional methods; Deep learning algorithm; Efficient detection; Facial images; Facial paralysis; Pre-trained model; Stroke detection; Learning algorithms","","Chakrabarti S.; Paul R.","Institute of Electrical and Electronics Engineers Inc.",""
"Krikid F.; Karfoul A.; Kachouri A.; Le Bouquin Jeannes R.","Krikid, Fatma (57219441383); Karfoul, Ahmad (24479661600); Kachouri, Abdennaceur (56017242900); Le Bouquin Jeannes, Regine (6602829468)","57219441383; 24479661600; 56017242900; 6602829468","Multi-Classification of epileptic High Frequency Oscillations using a Time-Frequency image-based CNN","2022","","","","663","667","4","10.1109/SSD54932.2022.9955931","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143786862&doi=10.1109%2fSSD54932.2022.9955931&partnerID=40&md5=e2ee8e0dd2d14445bf6ccd979352289b","High Frequency Oscillations (HFOs) in intracranial ElectroEncephaloGraphic (iEEG) signals are considered as promising biomarkers for localizing the epileptogenic zone. Visual marking of these particular activities is the typical way not only for the identification of HFOs but also for their discrimination from other transient events such as Interictal Epileptic Spikes (IESs). However, this remains a highly time-consuming process. To cope with this issue, several approaches have been already proposed for an automatic detection of HFOs. Most of these approaches are based on machine learning algorithms where relevant features are to be extracted for efficient classification. Looking for these relevant features is however a challenging task and can be avoided by resorting to deep learning. In this paper, a new method for HFOs multi-classification based on a convolutional neural network (CNN) is proposed. The proposed CNN model is based on Time-Frequency representation of HFOs computed using Stockwell transform. The efficiency of the proposed method is confirmed using real iEEG signals and compared with a supervised machine learning approach based on support vector machine (SVM) as classifier.  © 2022 IEEE.","Convolutional neural network; Deep learning; ElectroEncephaloGraphy; Epilepsy; High Frequency Oscillations; Time-Frequency representation","Biomedical signal processing; Convolution; Convolutional neural networks; Deep learning; Electrophysiology; Image classification; Learning algorithms; Learning systems; Support vector machines; Convolutional neural network; Deep learning; Electroencephalographic signals; Epilepsy; High frequency oscillations; Image-based; Multi-classification; Relevant features; Time-frequency images; Time-frequency representations; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Ahmed I.; Balestrieri E.; Carni D.L.; Lamonaca F.","Ahmed, Imran (58833622300); Balestrieri, Eulalia (8105381900); Carni, Domenico Luca (6603245529); Lamonaca, Francesco (21933997900)","58833622300; 8105381900; 6603245529; 21933997900","Comparison of U -NET backbones for morphometric measurements of white blood cell","2022","","","","","","","10.1109/MeMeA54994.2022.9856479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137890022&doi=10.1109%2fMeMeA54994.2022.9856479&partnerID=40&md5=1ff791e8664687a79a450099fc64f552","Measurements of Morphometric Parameters of Blood Cells (MPBC) playa key role in haematological examination, and it is considered as one of the principal needs for clinicians in the diagnosis of various diseases in human and animals. Obliviously, the correctness of the diagnosis, and, as a consequence, the effectiveness of clinician actions is highly dependent on the accuracy of MPBC measurements. In this context, deep learning based MPBC measurement systems are a promising solution. In recent studies, researchers have applied semantic segmentation with various backbone networks for white blood cell measurements. Vice versa, few investigations were done about the achieved accuracy. Indeed, accurate segmentation of white blood cell remains a challenging task because of the complex nature of cell images, staining techniques, and imaging conditions which strongly affects the accuracy of the MPBC measurements. This paper presents a comparison among the segmentation performance carried out by U-Net deep learning algorithm with different backbones typically used for MPBC. The goal is to make a first step towards a whole MPBC measurement system capable of evaluating the effects of the influencing magnitudes, attenuate them (if possible), and evaluate the accuracy of the measurements. The aims are to increase measurement reliability and to give clinicians further information to take their decisions.  © 2022 IEEE.","backbone networks; biomedical image segmentation; convolution neural network; morphometric measurement of blood cells; U-Net; white blood cell size measurement","Blood; Cells; Cytology; Deep learning; Learning algorithms; Semantic Segmentation; Semantics; Back-bone network; Biomedical image segmentation; Blood cells; Cell-size; Convolution neural network; Measurements of; Morphometric measurement of blood cell; Morphometric measurements; Size measurements; U-net; White blood cell size measurement; White blood cells; Diagnosis","","","Institute of Electrical and Electronics Engineers Inc.",""
"Yang Y.; Gao Q.; Song Y.; Song X.; Mao Z.; Liu J.","Yang, Yi (57217078240); Gao, Qiang (56486664800); Song, Yu (57191511945); Song, Xiaolin (57211620347); Mao, Zemin (57204600538); Liu, Junjie (57074204900)","57217078240; 56486664800; 57191511945; 57211620347; 57204600538; 57074204900","Investigating of Deaf Emotion Cognition Pattern by EEG and Facial Expression Combination","2022","26","2","","589","599","10","10.1109/JBHI.2021.3092412","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113226248&doi=10.1109%2fJBHI.2021.3092412&partnerID=40&md5=2026238a071ab761dbc4c770503ba4f1","With the development of sensor technology and learning algorithms, multimodal emotion recognition has attracted widespread attention. Many existing studies on emotion recognition mainly focused on normal people. Besides, due to hearing loss, deaf people cannot express emotions by words, which may have a greater need for emotion recognition. In this paper, the deep belief network (DBN) was utilized to classify three category emotions through the electroencephalograph (EEG) and facial expressions. Signals from 15 deaf subjects were recorded when they watched the emotional movie clips. Our system uses a 1-s window without overlap to segment the EEG signals in five frequency bands, then the differential entropy (DE) feature is extracted. The DE feature of EEG and facial expression images plays as multimodal input for subject-dependent emotion recognition. To avoid feature redundancy, the top 12 major EEG electrode channels (FP2, FP1, FT7, FPZ, F7, T8, F8, CB2, CB1, FT8, T7, TP8) in the gamma band and 30 facial expression features (the areas around the eyes and eyebrow) which are selected by the largest weight values. The results show that the classification accuracy is 99.92% by feature selection in deaf emotion reignition. Moreover, investigations on brain activities reveal deaf brain activity changes mainly in the beta and gamma bands, and the brain regions that are affected by emotions are mainly distributed in the prefrontal and outer temporal lobes.  © 2013 IEEE.","deaf; EEG; Emotion recognition; facial expression","Brain; Cognition; Electroencephalography; Emotions; Facial Expression; Humans; Audition; Brain; Electroencephalography; Learning algorithms; Neurophysiology; Speech recognition; Classification accuracy; Deep belief network (DBN); Differential entropy; Emotion recognition; Facial Expressions; Feature redundancy; Multimodal emotion recognition; Sensor technologies; accuracy; adult; algorithm; Article; artificial intelligence; artificial neural network; brain depth stimulation; brain region; classification algorithm; cognition; deep belief network; disgust; electrodermal response; electroencephalogram; electroencephalography; emotion; entropy; eye movement; eyebrow; facial expression; facial recognition; feature extraction; feature selection; female; functional magnetic resonance imaging; hearing impaired person; hearing impairment; heart rate variability; hip; human; human experiment; imagery; learning algorithm; machine learning; male; physical activity; sensitivity and specificity; skin conductance; speech intelligibility; support vector machine; task performance; temporal lobe; training; brain; cognition; electroencephalography; emotion; procedures; Biomedical signal processing","Fundamental Research on Advanced Technology and Engineering Application Team, Tianjin, China, (20160524); Natural Science Foundation of Tianjin City, (18JCYBJC87700)","","Institute of Electrical and Electronics Engineers Inc.","34170836"
"Lamia A.; Fawaz A.","Lamia, Alhazmi (57820324200); Fawaz, Alassery (56122445800)","57820324200; 56122445800","Detection of Pneumonia Infection by Using Deep Learning on a Mobile Platform","2022","2022","","7925668","","","","10.1155/2022/7925668","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135548331&doi=10.1155%2f2022%2f7925668&partnerID=40&md5=034cdf56603cb7fa1ec04b6a5bffbd6f","Pneumonia is a disease that spreads quickly and poses a serious risk to the health and well-being of its victims. An accurate biomedical diagnosis of pneumonia necessitates the use of various diagnostic tools and the evaluation of various clinical features, all of which are hindered by the lack of available experts and tools. According to the research presented here, a mobile app that uses deep learning techniques to classify whether or not a patient has pneumonia is being developed. It was hoped that a mobile application prototype for detecting pneumonia using neural networks would be developed as part of this study. The use of a high-level tool such as Create ML makes this process easier and eliminates issues such as how many layers a neural network has, initializing the model parameters, or which algorithms to use. The model can now be accessed by anyone, anywhere, via a mobile application. The dataset of more than 5,000 real images was used to train an image classification model using Create ML, a tool with a graphical interface, and there was no need for specialized knowledge.  © 2022 Alhazmi Lamia and Alassery Fawaz.","","Algorithms; Deep Learning; Humans; Neural Networks, Computer; Pneumonia; Classification (of information); Deep learning; Health risks; Learning systems; mHealth; Mobile computing; Multilayer neural networks; Network layers; Software prototyping; Biomedical diagnosis; Clinical features; Diagnostics tools; Learning techniques; Mobile app; Mobile applications; Mobile platform; Modeling parameters; Neural-networks; Well being; algorithm; human; pneumonia; Diagnosis","","","Hindawi Limited","35942467"
"Niepceron B.; Grassia F.; Moh A.N.S.","Niepceron, Brad (57207355587); Grassia, Filippo (6602483737); Moh, Ahmed Nait Sidi (7801328784)","57207355587; 6602483737; 7801328784","BRAIN TUMOR DETECTION USING SELECTIVE SEARCH AND PULSE-COUPLED NEURAL NETWORK FEATURE EXTRACTION","2022","41","1","","253","270","17","10.31577/cai_2022_1_253","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130621229&doi=10.31577%2fcai_2022_1_253&partnerID=40&md5=37c6ca0c74f06fedb1915cfae9ecaa2a","The identification of tumorous tissues in the brain based on Magnetic Resonance Images (MRI) analysis is a challenging and time consuming task that highly depends on radiologists expertise. As prompt diagnosis of tumors can often be inherent to the patient’s survival, it is however crucial to decrease the amount of time spent on the manual analysis of MRI while increasing the accuracy of the detection process. To tackle these issues, many research works have already investigated efficient computer vision systems. They offer new opportunities to assist health care providers in the establishment of fast and more accurate tumor detection, classification and segmentation. However, often based on deep learning methods, the development and tuning of these solutions remains time and energy consuming while inducing a lack of explainability in the decision making system. In this study, we respond to these issues by solving a brain tumor detection task using the Selective Search (SS) algorithm coupled with a simplified Pulse-Coupled Neural Network (PCNN) for visual feature extraction and detection validation. The performed experiments showed promising results in terms of computational cost and detection accuracy. This leads to the development of a light-weight brain tumor detection system. © 2022 Slovak Academy of Sciences. All rights reserved.","Biomedical imaging; brain tumor detection; differential evolution; pulse-coupled neural network; selective search","Decision making; Deep learning; Diagnosis; Evolutionary algorithms; Extraction; Feature extraction; Magnetic resonance; Magnetic resonance imaging; Medical imaging; Neural networks; Optimization; Tumors; Biomedical imaging; Brain tumor detection; Brain tumors; Differential Evolution; Image-analysis; Neural network feature extractions; Pulse coupled neural network; Selective search; Time-consuming tasks; Tumour detection; Brain","","","Slovak Academy of Sciences",""
"Wang Z.; Zhang X.; Wang D.; Fu R.; Chen X.; Wang H.","Wang, Zichen (57219866782); Zhang, Xinyu (57221516078); Wang, Di (57226301931); Fu, Rong (57226315871); Chen, Xiaoyan (55739042600); Wang, Huaxiang (56416211500)","57219866782; 57221516078; 57226301931; 57226315871; 55739042600; 56416211500","Shape Reconstruction for Electrical Impedance Tomography with V2D-Net Deep Convolutional Neural Network","2022","","","","","","","10.1109/I2MTC48687.2022.9806671","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134432875&doi=10.1109%2fI2MTC48687.2022.9806671&partnerID=40&md5=67d2678ce782d73ce684baef0b6581f9","Electrical impedance tomography (EIT) has been widely used in industrial and biomedical fields due to its visual and non-invasive natures. EIT reconstructions based on numerical algorithms are sensitive to the measurement noise and suffer from the low spatial resolution. In this paper, A novel image reconstruction method, as referred to V2D-Net is proposed inspired by deep learning method. The method consists of a trainable regularized pre-reconstructor and a multi-channel post-process convolution neural network(CNN). The pre-reconstructor learns a regularization pattern with prior information base on Newton-Raphson iteration methods, which could provide an initial medium distribution and solve the problem of parameter selection. And the multi-level CNN post-processor extracts features of initial results and reconstructs high resolution images with accurate shape information. The pre-reconstructor and deep CNN block are trained and optimized together. Compared with the traditional numerical methods and the related deep learning methods, V2D-Net is superior at robustness and generalization ability, while the reconstructions have more clear boundary shape and accurate impedance distribution information.  © 2022 IEEE.","convolutional neural network; dense connection; electrical impedance tomography; image reconstruction; pre-reconstructor regularization","Convolution; Convolutional neural networks; Deep neural networks; Electric impedance; Electric impedance measurement; Electric impedance tomography; Iterative methods; Learning systems; Numerical methods; Convolution neural network; Convolutional neural network; Dense connection; Electrical impe dance tomography (EIT); Images reconstruction; Learning methods; Pre-reconstructor regularization; Reconstructors; Regularisation; Shape reconstruction; Image reconstruction","National Natural Science Foundation of China, NSFC, (61301246, 61903274)","","Institute of Electrical and Electronics Engineers Inc.",""
"Khan M.A.; Sadman N.; Gupta K.D.; Ovi J.A.","Khan, Md Amit (57564371500); Sadman, Nafiz (57216852877); Gupta, Kishor Datta (57205211355); Ovi, Jesan Ahammed (57209212090)","57564371500; 57216852877; 57205211355; 57209212090","Interpretable Learning Model for Lower Dimensional Feature Space: A Case study with Brown Spot Detection in Rice Leaf","2022","","","","428","434","6","10.1109/CCWC54503.2022.9720882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127689097&doi=10.1109%2fCCWC54503.2022.9720882&partnerID=40&md5=6cb53aa59d815c71d35faca4f2ae0e4f","Detecting brown spot in rice leaf is an urgent complication in the agricultural field as Brown Spot disease lessen the rice yield remarkably. Several segmentation techniques have been applied to identify and extract the infected portion of the rice-leaf and machine learning algorithms such as decision trees, support vector machines are applied to detect this infection. In particular, a combination of Convolution Neural Networks with these algorithms has also tried to resolve this problem. Although this attempt has achieved success in providing accuracy (96.8%), these kinds of approaches raise issues regarding the size and interpretability of feature space and interpretability of the decision model. Indeed, Deep learning networks automatically create a feature space that usually contains a massive number of features (numerous of them are not necessarily appropriate). This vast number of features extends the non-interpretability of the machine learning model. Furthermore, training the model with these many features is computationally expensive. To resolve these issues, we propose a method to extract a few interpretable features from rice-leaf images and construct a low-dimensional feature space; however, interpretation shows that they deserve significant credit for the decent accuracy of our classification model. © 2022 IEEE.","Artificial Intelligence; Bioinformatics; Biomedical Computing; Explainablity; Image Processing; Interpretabiltiy","Bioinformatics; Deep learning; Image processing; Learning algorithms; Support vector machines; Biomedical computing; Brown spots; Explainablity; Feature space; Images processing; Interpretability; Interpretabiltiy; Learning models; Low dimensional; Rice leaves; Decision trees","","Paul R.","Institute of Electrical and Electronics Engineers Inc.",""
"","","","1st Conference on Biomedical Photonics and Cross-Fusion, BPC 2022","2022","12461","","","","","47","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142082919&partnerID=40&md5=12f7ab8667b97efdd418f3dd92829e3b","The proceedings contain 6 papers. The topics discussed include: photoacoustic blood glucose multiple factors measurement based on bp neural network algorithm; automatic image registration of optoacoustic tomography and magnetic resonance imaging based on deep learning; analysis of prostate cancer using serum surface-enhanced Raman spectroscopy and multivariate statistical algorithm; rhodamine 6g and adenine were detected based on HAP/Ag SERS matrix; design of LED light therapy device based on free-form lens; and a graphical digital processing platform for photoacoustic signal based on GUI.","","","","Zhang Z.; Qu J.; Li B.","SPIE",""
"Zhang W.; Li Z.; Sun Z.; Jia K.; Feng J.","Zhang, Wanlong (57561548600); Li, Zhe (57040021800); Sun, Zhonghua (56035911600); Jia, Kebin (8659887500); Feng, Jinchao (55990624400)","57561548600; 57040021800; 56035911600; 8659887500; 55990624400","A novelty convolutional neural network based direct reconstruction for MRI guided diffuse optical tomography","2022","11952","","119520B","","","","10.1117/12.2606836","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129183459&doi=10.1117%2f12.2606836&partnerID=40&md5=cf7215310351b7ae79cd081de91e5689","Diffuse Optical Tomography (DOT) is a promising non-invasive and relatively low-cost biomedical image technology. The aim of DOT is to reconstruct optical properties of the tissue from boundary measurements. However, the DOT reconstruction is a severely ill-posed problem. To reduce the ill-posedness of DOT and to improve image quality, imageguided DOT has attracted more attention. In this paper, a reconstruction algorithm for DOT is proposed based on the convolutional neural network (CNN). It uses both optical measurements and magnetic resonance imaging (MRI) images as the input of the CNN, and directly reconstructs the distribution of absorption coefficient. The merits of the proposed algorithm are without segmenting MRI images and modeling light propagation. The performance of the proposed algorithm is evaluated using numerical simulation experiments. Our results reveal that the proposed method can achieve superior performance compared with conventional reconstruction algorithms and other deep learning methods. Our result shows that the average SSIM of reconstructed images is above 0.88, and the average PSNR is more than 35 dB.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Convolutional neural network; Deep learning; Diffuse optical tomography; Image-guided reconstruction","Convolution; Convolutional neural networks; Deep learning; Image enhancement; Image reconstruction; Image segmentation; Optical data processing; Optical properties; Optical tomography; Biomedical images; Convolutional neural network; Deep learning; Diffuse optical tomography; Image-guided; Image-guided reconstruction; Low-costs; Network-based; Performance; Reconstruction algorithms; Magnetic resonance imaging","National Natural Science Foundation of China, NSFC, (82171992)","Azar F.S.; Intes X.; Fang Q.","SPIE",""
"Egambaram A.; Badruddin N.","Egambaram, Ashvaany (57193675263); Badruddin, Nasreen (18133252200)","57193675263; 18133252200","An Investigation to Detect Driver Drowsiness from Eye blink Artifacts Using Deep Learning Models","2022","","","","23","29","6","10.1109/IECBES54088.2022.10079592","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152437223&doi=10.1109%2fIECBES54088.2022.10079592&partnerID=40&md5=2df3b78840bb6741cbdbf67d0a1e6d65","Driver drowsiness is a well known problem that depreciates road safety that could cause road accidents, worldwide. Researchers are increasingly using the eye/eyelid images or the electroencephalogram's (EEG) spectral information to detect drowsiness in drivers. However, no attempt has been made to detect drowsiness using the eye blink artifact features that contaminates EEG signals, which are typically regarded noise and undesired. Therefore, in this study, we have investigated whether the eye blink artifacts that were originally intended to be eliminated from EEG signals could be used to detect drowsiness among drivers. The eye blink artifacts and their features are extracted from EEG signals via the BLINKER algorithm. The deep learning classifiers, multilayer perceptron (MLP) and Recurrent Neural Network with Long-Short-Term-Memory (RNN-LSTM) are trained, validated, and tested to confirm if the eye blink artifacts can be used as an indicator of drowsiness. The investigation has demonstrated that using eye blink artifacts as an indicator of drowsiness is viable, with a classification accuracy of 94.91% achieved through RNN-LSTM.  © 2022 IEEE.","","Biomedical signal processing; Learning systems; Long short-term memory; Motor transportation; Multilayer neural networks; Roads and streets; Classification accuracy; Driver drowsiness; Electroencephalogram signals; Eye-blink artifacts; Eyes-blink artifacts; Learning classifiers; Learning models; Multilayers perceptrons; Road safety; Spectral information; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Nie X.; Zhou X.; Li Z.; Wang L.; Lin X.; Tong T.","Nie, Xingqing (57734381900); Zhou, Xiaogen (57210120226); Li, Zhiqiang (59067610400); Wang, Luoyan (57734668400); Lin, Xingtao (57734193300); Tong, Tong (55625986800)","57734381900; 57210120226; 59067610400; 57734668400; 57734193300; 55625986800","LogTrans: Providing Efficient Local-Global Fusion with Transformer and CNN Parallel Network for Biomedical Image Segmentation","2022","","","","769","776","7","10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152242975&doi=10.1109%2fHPCC-DSS-SmartCity-DependSys57074.2022.00128&partnerID=40&md5=60e730cbd07d16a103cd4bab3eb5c961","Accurate biomedical image segmentation is a prerequisite for excellent computer-aided diagnosis (CAD) systems. A series of researches have shown that convolutional neural networks (CNNs) have made impressive progress in segmentation tasks. Nevertheless, owing to the finite receptive field of CNN-based algorithms, such networks are focused too much on local area features rather than global context. While the Transformer architecture can encode global dependencies information through the self-attention mechanism, this mechanism typically ignores the local pixel-level structural information within each divided patch. Therefore, a better solution is still needed for how to integrate CNN architecture with Transformer architecture efficiently. In this essay, we propose an originative parallel segmentation algorithm called LogTrans. First, in the encoder path, the local details and global contour dependencies on the entire image are captured by the CNN branch and the Transformer branch, respectively. Then these two branches complement each other by a novel separate-combiner (SeCo) module, leading to better fused features. Moreover, we attempt to further enhance the segmentation properties by using a residual stackable dilated (ReSD) block, which applies residual shortcut connections to resolve dimension alterations in the target region and stacks dilated convolutions to capture more spatial information. The proposed LogTrans framework was evaluated on two biomedical datasets, including ISIC-2017 and UITNS-2022 datasets. Collectively, multiple results have indicated that our LogTrans performs superior with other state-of-the-art architectures in both visual comparison and quantitative appraisal.  © 2022 IEEE.","Biomedical image segmentation; Convolutional neural networks; Deep Learning; Global context; Transformer","Bioinformatics; Computer aided diagnosis; Convolution; Deep learning; Image segmentation; Network architecture; Biomedical image segmentation; Computer aided diagnosis systems; Convolutional neural network; Deep learning; Global context; Local areas; Network-based algorithm; Parallel network; Receptive fields; Transformer; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Lu H.; Tian S.; Yu L.; Liu L.; Cheng J.; Wu W.; Kang X.; Zhang D.","Lu, Hongchun (57214780414); Tian, Shengwei (35119846500); Yu, Long (55272883600); Liu, Lu (57365898200); Cheng, Junlong (57217079223); Wu, Weidong (57226092151); Kang, Xiaojing (58729267200); Zhang, Dezhi (57274431700)","57214780414; 35119846500; 55272883600; 57365898200; 57217079223; 57226092151; 58729267200; 57274431700","DCACNet: Dual context aggregation and attention-guided cross deconvolution network for medical image segmentation","2022","214","","106566","","","","10.1016/j.cmpb.2021.106566","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120821466&doi=10.1016%2fj.cmpb.2021.106566&partnerID=40&md5=8e7891fddfb51791027b5740e4bd98d8","Background and Objective: Segmentation is a key step in biomedical image analysis tasks. Recently, convolutional neural networks (CNNs) have been increasingly applied in the field of medical image processing; however, standard models still have some drawbacks. Due to the significant loss of spatial information at the coding stage, it is often difficult to restore the details of low-level visual features using simple deconvolution, and the generated feature maps are sparse, which results in performance degradation. This prompted us to study whether it is possible to better preserve the deep feature information of the image in order to solve the sparsity problem of image segmentation models. Methods: In this study, we (1) build a reliable deep learning network framework, named DCACNet, to improve the segmentation performance for medical images; (2) propose a multiscale cross-fusion encoding network to extract features; (3) build a dual context aggregation module to fuse the context features at different scales and capture more fine-grained deep features; and (4) propose an attention-guided cross deconvolution decoding network to generate dense feature maps. We demonstrate the effectiveness of the proposed method on two publicly available datasets. Results: DCACNet was trained and tested on the prepared dataset, and the experimental results show that our proposed model has better segmentation performance than previous models. For 4-class classification (CHAOS dataset), the mean DSC coefficient reached 91.03%. For 2-class classification (Herlev dataset), the accuracy, precision, sensitivity, specificity, and Dice score reached 96.77%, 90.40%, 94.20%, 97.50%, and 97.69%, respectively. The experimental results show that DCACNet can improve the segmentation effect for medical images. Conclusion: DCACNet achieved promising results on the prepared dataset and improved segmentation performance. It can better retain the deep feature information of the image than other models and solve the sparsity problem of the medical image segmentation model. © 2021","Attention mechanism; Convolutional neural network; Cross deconvolution; Dual context aggregation; Medical image segmentation","Attention; Data Collection; Image Processing, Computer-Assisted; Neural Networks, Computer; Convolution; Convolutional neural networks; Deep learning; Image enhancement; Image segmentation; Medical image processing; Attention mechanisms; Convolutional neural network; Cross deconvolution; Deconvolutions; Dual context aggregation; Feature information; Feature map; Medical image segmentation; Segmentation performance; Sparsity problems; Article; convolutional neural network; deconvolution algorithm; deep learning; image segmentation; information processing; sensitivity and specificity; attention; image processing; Classification (of information)","Xinjiang Autonomous Region key research and development project, (2020E0234, 2021B01-002); National Natural Science Foundation of China, NSFC, (62162058, U2003208); National Natural Science Foundation of China, NSFC; Xinjiang Uygur Autonomous Region Department of Education, (XJ2020G072, XJ2020G073); Xinjiang Uygur Autonomous Region Department of Education","","Elsevier Ireland Ltd","34890992"
"Dhivya P.; Kumaresan T.; Subramanian P.; Gunasekaran K.; Kumar G.S.","Dhivya, P. (56448997200); Kumaresan, T. (56878942000); Subramanian, P. (57387323700); Gunasekaran, K. (57219427870); Kumar, G. Sathish (57217065933)","56448997200; 56878942000; 57387323700; 57219427870; 57217065933","HYBRID FIREFLY META OPTIMIZATION FOR BIO MEDICAL IMAGE PROCESSING USING DEEP LEARNING","2022","13","4","","1199","1209","10","10.47750/pnr.2022.13.04.169","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143281766&doi=10.47750%2fpnr.2022.13.04.169&partnerID=40&md5=03e21276b811afec63a51b88dbc89d27","Signal and image processing is a part of biomedical science. In that, Biomedical image processing have a great value such as recognition, segmentation and classification for disease diagnosis. In one part of biomedical science, brain tumor classification is considered with Magnetic Resonance Images (MRI) images using state of art models. Initially, the Convolutional Neural Network (CNN), Fast Convolutional Neural Network (FCNN), U-Net and M-Net model was considered for classification. Further, the Hybrid Firefly Meta Optimization (HFMO) is proposed for the better prediction purpose. The proposed work has three phases like normalization with augmentation, deep attention segmentation and classification. In the first phase, data augmentation is applied to increase the scope of the dataset. In the second phase, a deep attention technique is applied to concentrate on hotspot in the image during segmentation. Finally, a hybrid firefly optimization is applied to enhance the performance of the model in convolution neural network by backtracking the process. The measuring parameters like Dice coefficient, Jaccard index, Positive Projected Value (PPV), True Positive Rate and False Positive Rate were evaluated. The comparative analysis of various state of art models with proposed classifier were demonstrated. Thus the proposed technique produces the training accuracy as 98.62%, testing accuracy as 95.31 % and 1 % of loss. © 2022 Wolters Kluwer Medknow Publications. All rights reserved.","Augmentation; Central Nervous System; Dice Coefficient,Firefly optimization; Jaccard Index; Meta Learning; MRI","Article; classification; classifier; comparative study; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic imaging; diagnostic test accuracy study; false negative result; false positive result; firefly algorithm; glioma; human; hypophysis tumor; image processing; image segmentation; meningioma; nuclear magnetic resonance imaging","","","ResearchTrentz Academy Publishing Education Services",""
"Deleruyelle A.; Klein J.; Versari C.","Deleruyelle, Arnaud (57456693200); Klein, John (57199428576); Versari, Cristian (16647629300)","57456693200; 57199428576; 16647629300","SODA: SELF-ORGANIZING DATA AUGMENTATION IN DEEP NEURAL NETWORKS - APPLICATION TO BIOMEDICAL IMAGE SEGMENTATION TASKS","2022","2022-May","","","6517","6521","4","10.1109/ICASSP43922.2022.9747744","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134063176&doi=10.1109%2fICASSP43922.2022.9747744&partnerID=40&md5=3a9bcf614616aa6c26f26e392bc89196","In practice, data augmentation is assigned a predefined budget in terms of newly created samples per epoch. When using several types of data augmentation, the budget is usually uniformly distributed over the set of augmentations but one can wonder if this budget should not be allocated to each type in a more efficient way. This paper leverages online learning to allocate on the fly this budget as part of neural network training. This meta-algorithm can be run at almost no extra cost as it exploits gradient based signals to determine which type of data augmentation should be preferred. Experiments suggest that this strategy can save computation time and thus goes in the way of greener machine learning practices. © 2022 IEEE","data augmentation; deep learning; HEDGE; online learning; segmentation","Budget control; E-learning; Image segmentation; Biomedical image segmentation; Data augmentation; Deep learning; HEDGE; Neural network application; Neural networks trainings; On-the-fly; Online learning; Segmentation; Self-organising; Deep neural networks","GENCI-IDRIS","","Institute of Electrical and Electronics Engineers Inc.",""
"Yu Z.; Rahman A.; Jha A.K.","Yu, Zitong (57222238475); Rahman, Ashequr (57667594200); Jha, Abhinav K. (36238167200)","57222238475; 57667594200; 36238167200","Investigating the limited performance of a deep-learning-based SPECT denoising approach: An observer-study-based characterization","2022","12035","","120350D","","","","10.1117/12.2613134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131875022&doi=10.1117%2f12.2613134&partnerID=40&md5=57b91a9c703e156a1b05357df64a071e","Multiple objective assessment of image-quality (OAIQ)-based studies have reported that several deep-learning (DL)-based denoising methods show limited performance on signal-detection tasks. Our goal was to investigate the reasons for this limited performance. To achieve this goal, we conducted a task-based characterization of a DL-based denoising approach for individual signal properties. We conducted this study in the context of evaluating a DL-based approach for denoising single photon-emission computed tomography (SPECT) images. The training data consisted of signals of different sizes and shapes within a clustered-lumpy background, imaged with a 2D parallel-hole-collimator SPECT system. The projections were generated at normal and 20% low-count level, both of which were reconstructed using an ordered-subset-expectation-maximization (OSEM) algorithm. A convolutional neural network (CNN)-based denoiser was trained to process the low-count images. The performance of this CNN was characterized for five different signal sizes and four different signal-Tobackground ratio (SBRs) by designing each evaluation as a signal-known-exactly/background-known-statistically (SKE/BKS) signal-detection task. Performance on this task was evaluated using an anthropomorphic channelized Hotelling observer (CHO). As in previous studies, we observed that the DL-based denoising method did not improve performance on signal-detection tasks. Evaluation using the idea of observer-study-based characterization demonstrated that the DL-based denoising approach did not improve performance on the signal-detection task for any of the signal types. Overall, these results provide new insights on the performance of the DL-based denoising approach as a function of signal size and contrast. More generally, the observer study-based characterization provides a mechanism to evaluate the sensitivity of the method to specific object properties, and may be explored as analogous to characterizations such as modulation transfer function for linear systems. Finally, this work underscores the need for objective task-based evaluation of DL-based denoising approaches. © 2022 SPIE. All rights reserved.","Deep learning; Denoising; Model observer.; Objective task-based evaluation; SPECT","Biomedical signal processing; Convolutional neural networks; Deep learning; Function evaluation; Image denoising; Linear systems; Maximum principle; Particle beams; Signal detection; Signal to noise ratio; De-noising; Deep learning; Denoising approach; Detection tasks; Model observer; Model observer.; Objective task-based evaluation; Performance; Signal's detections; Task-based; Single photon emission computed tomography","","Mello-Thoms C.R.; Mello-Thoms C.R.; Taylor-Phillips S.","SPIE",""
"Zhang J.; Li K.","Zhang, Jiayang (58149371600); Li, Kang (36072845200)","58149371600; 36072845200","A Pruned Deep Learning Approach for Classification of Motor Imagery Electroencephalography Signals","2022","2022-July","","","4072","4075","3","10.1109/EMBC48229.2022.9871078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138126922&doi=10.1109%2fEMBC48229.2022.9871078&partnerID=40&md5=9381be5d59ba08128c1475fc40c9ac01","The Deep Learning (DL) approach has been gaining much popularity in recent years in the development of electroencephalogram (EEG) based Motor Imagery (MI) Brain-Computer Interface (BCI) systems, aiming to improve the performance of existing stroke rehabilitation strategies. A complex deep neural network structure has lots of neurons with thousands of parameters to optimize, and a great deal of data is often required to train the network and the training process can take an extremely long time. High training costs and high model complexity not only have negative impacts on the performance of the BCI system but also on its applicability to meet the real-time requirement to support the rehabilitation exercises of patients. To tackle the challenge, a contribution-based neuron selection method is proposed in this paper. A Convolutional Neural Network (CNN) based motor imagery classification framework is implemented, and a neuron pruning approach is developed and applied. The temporal and spatial features of EEG signals are captured by the CNN layers, and then the fast recursive algorithm (FRA) is applied to prune redundant parameters in the fully connected layers which reduces the computation cost of the CNN model without affecting its performance. The experimental results show that the proposed method can achieve up to 50% model size reduction and 67.09% computation savings. © 2022 IEEE.","","Algorithms; Deep Learning; Electroencephalography; Humans; Imagery, Psychotherapy; Neural Networks, Computer; Biomedical signal processing; Brain computer interface; Complex networks; Convolutional neural networks; Deep neural networks; Electrophysiology; Image classification; Image enhancement; Neurons; Patient rehabilitation; Convolutional neural network; Interface system; Learning approach; Motor imagery; Neural networks structure; Performance; Rehabilitation strategy; Stroke rehabilitation; Training costs; Training process; algorithm; electroencephalography; human; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.","36085842"
"Mur A.L.; Peyrin F.; Ducros N.","Mur, Antonio Lorente (57212479828); Peyrin, Francoise (57201753223); Ducros, Nicolas (24168226300)","57212479828; 57201753223; 24168226300","Deep Expectation-Maximization for Single-Pixel Image Reconstruction With Signal-Dependent Noise","2022","8","","","759","769","10","10.1109/TCI.2022.3200841","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137584226&doi=10.1109%2fTCI.2022.3200841&partnerID=40&md5=55e330d748b9c59d9ac9cae3a6d9d056","Image reconstruction from a sequence of a few linear measurements that are corrupted by signal-dependent normally distributed noise is an inverse problem with many biomedical imaging applications, such as computerized tomography and optical microscopy. In this study, we focus on single-pixel imaging, where the set-up acquires a down-sampled Hadamard transform of an image of the scene. Deep learning is a computationally efficient framework to solve inverse problems in imaging. Several neural-network architectures provide a link between deep and optimization-based image reconstruction methods. These deep-learning methods rely on a forward operator and lead to more interpretable networks. Here, we propose a novel network architecture obtained by unrolling an heuristic expectation-maximization algorithm. In particular, we compute the maximum a posteriori estimate of the unknown image given measurements corrupted by normally distributed signal-dependent noise. We show that the so-called expectation-maximization reconstruction network (EM-Net) applies to mixed Skellam-Gaussian noise models that are common in single-pixel imaging. We present reconstruction results from simulated and experimental single-pixel acquisitions. We show that EM-Net generalizes very well to noise levels not seen during training, despite having fewer learned parameters than alternative methods. The proposed EM-Net generally reconstructs images with fewer artifacts and higher signal-to-noise ratios, in particular in high-noise situations compared to other state of the art reconstruction algorithms that do not estimate the noise covariance.  © 2015 IEEE.","deep learning; expectation-maximization; Image reconstruction; iterative algorithm; single-pixel imaging; Skellam-Gaussian noise","Approximation algorithms; Computerized tomography; Deep learning; Gaussian noise (electronic); Image segmentation; Inverse problems; Iterative methods; Maximum principle; Medical imaging; Network architecture; Normal distribution; Pixels; Signal to noise ratio; Atmospheric measurement; Computational modelling; Deep learning; Expectation Maximization; Gaussians; Images reconstruction; Iterative algorithm; Noise measurements; Particle measurement; Single pixel; Single-pixel imaging; Skellam-gaussian noise; Image reconstruction","","","Institute of Electrical and Electronics Engineers Inc.",""
"Subasi A.; Kapadnis M.N.; Bulbul A.K.","Subasi, Abdulhamit (8327241200); Kapadnis, Manav Nitin (57323545600); Bulbul, Ayse Kosal (57709399500)","8327241200; 57323545600; 57709399500","Alzheimer’s disease detection using artificial intelligence","2022","","","","53","74","21","10.1016/B978-0-323-90037-9.00011-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130669432&doi=10.1016%2fB978-0-323-90037-9.00011-4&partnerID=40&md5=7730a86310b8d0a53bbba8083bffc6b5","Biomedical data relevant to several diseases are generally employed to diagnose precise physiological or pathological conditions. The objective of biomedical image analysis is exact modeling by using Artificial Intelligence (AI) algorithms to diagnose different diseases. Alzheimer’s disease (AD) is one of the most widespread dementia forms influencing the elderly people. On-time diagnosis of Alzheimer’s disease is crucial to discover innovative methods for AD treatment. AI is an efficient approach for AD detection since it can be utilized as a Computer-aided decision support systems approach in medical procedures and play a critical role to detect changes in the brain images to identify AD. This chapter presents the recent studies and advances in AI used for medical image analysis and image processing in AD detection. The main focus is to have a consistent but easy and quick model for automated AD detection relied on the application of AI methods. Hence, the focus will be on AI techniques for AD detection from brain images. Moreover, some of the AI techniques, which were utilized for AD detection is overviewed. Then a simple AD detection approach using deep learning models will be presented. The results show that CNN achieved a testing accuracy of 95.70% accuracy and a validation accuracy of 99.71% for the diagnosis of AD from brain MRI scans. The chapter will be completed with a review of the current state-of-the-art, a discussion of new trends and open challenges for potential investigation. © 2022 Elsevier Inc. All rights reserved.","Alzheimer’s disease detection; Artificial intelligence; Convolutional neural networks; Deep learning; Transfer learning","","","","Elsevier",""
"Ahmed H.; Shedeed H.A.; Hamad S.; Hussein A.S.","Ahmed, Hanan (59270834300); Shedeed, Howida A. (8275377800); Hamad, Safwat (25641172300); Hussein, Ashraf S. (22954146600)","59270834300; 8275377800; 25641172300; 22954146600","Convolutional Neural Network for Cancer Treatment Response Prediction","2022","","","","14","18","4","10.1109/ICENCO55801.2022.10032466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148649556&doi=10.1109%2fICENCO55801.2022.10032466&partnerID=40&md5=edc5b276a435b79d1960c1e7419ae326","Recently, efforts are exerted on cancer treatment prediction based on the biomarkers related to the tumor. Many biomarkers are used to discriminate cancer but there is no accurate evidence which is more accurate. To save resources and due to the enormous computational power, the analysis of huge sequences such as DNA (DesoxyriboNucleic Acid) becomes a valid process. Machine learning and deep learning algorithms have been used to predict drug response. The indicators show that the performance of deep learning models is better than the performance of machine learning based one. In this paper, we introduce the use of Convolutional Neural Network (CNN) to predict the response of 265 different drugs using the gene expression profile and mutation profile of 19702 genes. DeepInsight algorithm used to convert the input data to images to be more suitable as input to the CNN. We proposed eight CNNs with different architectures. At first, the whole data input passes through the DeepInsight model which converts the gene expression data and mutation data to images. Dimension reduction is then applied using the helper technique inside the DeepInsignt. The CNN are trained with different settings such as image size, no of nodes in layers...etc. Comparative analysis shows that the proposed architectures improve the prediction accuracy in a range between 16% and 24% as a reduction in mean squared error (MSE).  © 2022 IEEE.","Artificial Intelligence; Artificial neural networks; Biomedical; Convolutional neural networks; Drug Response Prediction; Personalized Medicine","Bioinformatics; Biomarkers; Convolution; Convolutional neural networks; Data handling; Deep learning; Diseases; DNA sequences; Forecasting; Gene expression; Learning algorithms; Learning systems; Network architecture; Biomedical; Convolutional neural network; Drug response; Drug response prediction; Machine-learning; Performance; Personalized medicines; Prediction-based; Response prediction; Treatment response; Mean square error","","","Institute of Electrical and Electronics Engineers Inc.",""
"Duhayyim M.A.; Malibari A.A.; Obayya M.; Nour M.K.; Salama A.S.; Eldesouki M.I.; Zamani A.S.; Rizwanullah M.","Duhayyim, Mesfer Al (57204360566); Malibari, Areej A. (6506143515); Obayya, Marwa (6505869929); Nour, Mohamed K. (56027613700); Salama, Ahmed S. (56480035100); Eldesouki, Mohamed I. (57581134200); Zamani, Abu Sarwar (57295189700); Rizwanullah, Mohammed (57263769000)","57204360566; 6506143515; 6505869929; 56027613700; 56480035100; 57581134200; 57295189700; 57263769000","Metaheuristic with Deep Learning Enabled Biomedical Bone Age Assessment and Classification Model","2022","73","3","","5473","5489","16","10.32604/cmc.2022.031976","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135077555&doi=10.32604%2fcmc.2022.031976&partnerID=40&md5=8f4b1016dcb8dd673d74cfec2064c5f6","The skeletal bone age assessment (BAA) was extremely implemented in development prediction and auxiliary analysis of medicinal issues. X-ray images of hands were detected from the estimation of bone age, whereas the ossification centers of epiphysis and carpal bones are important regions. The typical skeletal BAA approaches remove these regions for predicting the bone age, however, few of them attain suitable efficacy or accuracy. Automatic BAA techniques with deep learning (DL) methods are reached the leading efficiency on manual and typical approaches. Therefore, this study introduces an intellectual skeletal bone age assessment and classification with the use of metaheuristic with deep learning (ISBAAC-MDL) model. The presented ISBAAC-MDL technique majorly focuses on the identification of bone age prediction and classification process. To attain this, the presented ISBAAC-MDL model derives a mask Region-related Convolutional Neural Network (Mask-RCNN) with MobileNet as baseline model to extract features. Followed by, the whale optimization algorithm (WOA) is implemented for hyperparameter tuning of the MobileNet method. At last, Deep Feed-Forward Module (DFFM) based age prediction and Radial Basis Function Neural Network (RBFNN) based stage classification approach is utilized. The experimental evaluation of the ISBAAC-MDL model is tested using benchmark dataset and the outcomes are assessed over distinct factors. The experimental outcomes reported the better performances of the ISBAAC-MDL model over recent approaches with maximum accuracy of 0.9920. © 2022 Tech Science Press. All rights reserved.","age prediction; Biomedical images; bone age assessment; computer vision; deep learning; image classification","Computer vision; Convolutional neural networks; Deep learning; Forecasting; Learning systems; Musculoskeletal system; Radial basis function networks; Age predictions; Assessment models; Biomedical images; Bone age; Bone age assessment; Classification models; Deep learning; Images classification; Learning models; Metaheuristic; Image classification","Deanship of Scientific Research at Umm Al-Qura University, (22UQU4310373DSR17)","","Tech Science Press",""
"Zhang C.; Jiang H.; Liu W.; Li J.; Tang S.; Juhas M.; Zhang Y.","Zhang, Chi (57467085900); Jiang, Hao (57214820786); Liu, Weihuang (57214823733); Li, Junyi (57204470693); Tang, Shiming (57194712073); Juhas, Mario (55932041800); Zhang, Yang (57197788933)","57467085900; 57214820786; 57214823733; 57204470693; 57194712073; 55932041800; 57197788933","Correction of out-of-focus microscopic images by deep learning","2022","20","","","1957","1966","9","10.1016/j.csbj.2022.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129524857&doi=10.1016%2fj.csbj.2022.04.003&partnerID=40&md5=b27145c034e154b492ddf568c436c06a","Motivation: Microscopic images are widely used in basic biomedical research, disease diagnosis and medical discovery. Obtaining high-quality in-focus microscopy images has been a cornerstone of the microscopy. However, images obtained by microscopes are often out-of-focus, resulting in poor performance in research and diagnosis. Results: To solve the out-of-focus issue in microscopy, we developed a Cycle Generative Adversarial Network (CycleGAN) based model and a multi-component weighted loss function. We train and test our network in two self-collected datasets, namely Leishmania parasite dataset captured by a bright-field microscope, and bovine pulmonary artery endothelial cells (BPAEC) captured by a confocal fluorescence microscope. In comparison to other GAN-based deblurring methods, the proposed model reached state-of-the-art performance in correction. Another publicly available dataset, human cells dataset from the Broad Bioimage Benchmark Collection is used for evaluating the generalization abilities of the model. Our model showed excellent generalization capability, which could transfer to different types of microscopic image datasets. Availability and Implementation: Code and dataset are publicly available at: https://github.com/jiangdat/COMI. © 2022 The Author(s)","Bright-field microscope; Confocal fluorescence microscope; CycleGAN; Deep learning; Leishmania parasite; Mammalian cell; Microscopic image; Out-of-focus correction","Deep learning; Diagnosis; Endothelial cells; Fluorescence; Generative adversarial networks; Mammals; Medical imaging; Statistical tests; Bright-field microscope; Bright-fields; Confocal fluorescence microscope; Cycle generative adversarial network; Deep learning; Focus correction; Leishmania; Leishmania parasite; Mammalian cells; Microscopic image; Out-of-focus; Out-of-focus correction; Parasite-; actin filament; algorithm; animal cell; Article; benchmarking; BPAEC cell line; bright field microscopy; cell nucleus; confocal microscopy; cross validation; cycle generative adversarial network; deep learning; deep neural network; fluorescence microscopy; human; human cell; image quality; intermethod comparison; Leishmania; microscopy; mitochondrion; nonhuman; Microscopes","Guangdong Basic and Applied Basic Research Foundation, (2021A1515220115); Science, Technology and Innovation Commission of Shenzhen Municipality, (20200821222112001)","","Elsevier B.V.",""
"Joshi S.; Partibane B.; Hatamleh W.A.; Tarazi H.; Yadav C.S.; Krah D.","Joshi, Shubham (57212646143); Partibane, B. (6504284035); Hatamleh, Wesam Atef (57224119502); Tarazi, Hussam (57452680100); Yadav, Chandra Shekhar (59268309300); Krah, Daniel (57489428700)","57212646143; 6504284035; 57224119502; 57452680100; 59268309300; 57489428700","Glaucoma Detection Using Image Processing and Supervised Learning for Classification","2022","2022","","2988262","","","","10.1155/2022/2988262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126402824&doi=10.1155%2f2022%2f2988262&partnerID=40&md5=c672eb80eed08c50a03a630f5920cfd2","A difficult challenge in the realm of biomedical engineering is the detection of physiological changes occurring inside the human body, which is a difficult undertaking. At the moment, these irregularities are graded manually, which is very difficult, time-consuming, and tiresome due to the many complexities associated with the methods involved in their identification. In order to identify illnesses at an early stage, the use of computer-assisted diagnostics has acquired increased attention as a result of the requirement of a disease detection system. The major goal of this proposed work is to build a computer-aided design (CAD) system to help in the early identification of glaucoma as well as the screening and treatment of the disease. The fundus camera is the most affordable image analysis modality available, and it meets the financial needs of the general public. The extraction of structural characteristics from the segmented optic disc and the segmented optic cup may be used to characterize glaucoma and determine its severity. For this study, the primary goal is to estimate the potential of the image analysis model for the early identification and diagnosis of glaucoma, as well as for the evaluation of ocular disorders. The suggested CAD system would aid the ophthalmologist in the diagnosis of ocular illnesses by providing a second opinion as a judgment made by human specialists in a controlled environment. An ensemble-based deep learning model for the identification and diagnosis of glaucoma is in its early stages now. This method's initial module is an ensemble-based deep learning model for glaucoma diagnosis, which is the first of its kind ever developed. It was decided to use three pretrained convolutional neural networks for the categorization of glaucoma. These networks included the residual network (ResNet), the visual geometry group network (VGGNet), and the GoogLeNet. It was necessary to use five different data sets in order to determine how well the proposed algorithm performed. These data sets included the DRISHTI-GS, the Optic Nerve Segmentation Database (DRIONS-DB), and the High-Resolution Fundus (HRF). Accuracy of 91.11% for the PSGIMSR data set and the sensitivity of 85.55% and specificity of 95.20% for the suggested ensemble architecture on the PSGIMSR data set were achieved. Similarly, accuracy rates of 95.63%, 98.67%, 95.64%, and 88.96% were achieved using the DRIONS-DB, HRF, DRISHTI-GS, and combined data sets, respectively.  © 2022 Shubham Joshi et al.","","Diagnosis, Computer-Assisted; Fundus Oculi; Glaucoma; Humans; Optic Disk; Supervised Machine Learning; Biomedical engineering; Convolutional neural networks; Deep learning; Diagnosis; Diseases; Eye protection; Image analysis; Image classification; Optical data processing; Petroleum reservoir evaluation; Computer aided design systems; Data set; Glaucoma detection; High resolution; Image-analysis; Images processing; Learning models; Nerve segmentations; Optic nerve; Segmented optics; Article; artificial neural network; computer aided design; controlled study; convolutional neural network; data base; deep learning; diagnostic accuracy; diagnostic test accuracy study; disease classification; early diagnosis; eye disease; feed forward neural network; fuzzy system; geometry; glaucoma; googlenet architecture; human; image analysis; image processing; image segmentation; ophthalmologist; optic nerve; optic nerve segmentation database; residual neural network; retinal nerve fiber layer; sensitivity and specificity; supervised machine learning; transfer of learning; visual geometry group network; computer assisted diagnosis; diagnostic imaging; eye fundus; glaucoma; optic disk; procedures; supervised machine learning; Ophthalmology","","","Hindawi Limited","35273784"
"Pavone A.M.; Benfante V.; Stefano A.; Mamone G.; Milazzo M.; Di Pizza A.; Parenti R.; Maruzzelli L.; Miraglia R.; Comelli A.","Pavone, Anna Maria (57578504900); Benfante, Viviana (57211284401); Stefano, Alessandro (35794207900); Mamone, Giuseppe (17135015700); Milazzo, Mariapina (7005837543); Di Pizza, Ambra (57841731700); Parenti, Rosalba (57792357200); Maruzzelli, Luigi (23989257600); Miraglia, Roberto (23390480200); Comelli, Albert (57104982700)","57578504900; 57211284401; 35794207900; 17135015700; 7005837543; 57841731700; 57792357200; 23989257600; 23390480200; 57104982700","Automatic Liver Segmentation in Pre-TIPS Cirrhotic Patients: A Preliminary Step for Radiomics Studies","2022","13373 LNCS","","","408","418","10","10.1007/978-3-031-13321-3_36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135838559&doi=10.1007%2f978-3-031-13321-3_36&partnerID=40&md5=3e01e600c6ffbc8932fb8ce5fb41e578","The aim of this study is to present a deep learning (DL) algorithm for accurate liver delineation in high-resolution computed tomography (CT) images of pre-transjugular intrahepatic portosystemic shunt (TIPS) cirrhotic patients. In this way, we aim to improve the methodology performed by medical physicians in radiomics studies where the use of operator-independent segmentation methods is mandatory to correctly identify the target and to obtain accurate predictive models. Two DL models were investigated: UNet, the most widely used DL network for biomedical image segmentation, and the innovative customized efficient neural network (C-ENet). 111 patients with liver contrast-enhanced CT examinations before TIPS procedure were considered. The performance of the two DL networks was evaluated in terms of the similarity of their segmentations to the gold standard. The results show that C-ENet can be used to obtain accurate (dice similarity coefficient = 87.70%) segmentation of the liver region outperforming UNet (dice similarity coefficient = 85.33%). In conclusion, we demonstrated that DL can be efficiently applied to rapidly segment cirrhotic liver images, without any radiologist supervision, to produce user-independent results useful for subsequent radiomics studies. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","C-ENet; Cirrhosis; Deep learning; Liver; Segmentation; TIPS; UNet","Computerized tomography; Image segmentation; Medical imaging; Cirrhosis; Customized efficient neural network; Deep learning; Learning network; Liver segmentation; Neural-networks; Segmentation; Similarity coefficients; Transjugular intrahepatic portosystemic shunt; Unet; Deep learning","","Mazzeo P.L.; Distante C.; Frontoni E.; Sclaroff S.","Springer Science and Business Media Deutschland GmbH",""
"Bao J.; Bei C.; Zheng X.; Wang J.","Bao, Junxiao (58162231700); Bei, Cuilin (57836832700); Zheng, Xiang (58389825100); Wang, Jinli (57881859200)","58162231700; 57836832700; 58389825100; 57881859200","Deep Learning Algorithm in Biomedical Engineering in Intelligent Automatic Processing and Analysis of Sports Images","2022","2022","","3196491","","","","10.1155/2022/3196491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135701549&doi=10.1155%2f2022%2f3196491&partnerID=40&md5=c4ec4796065a52749a5dcd4c9b35516f","In order to improve the detection and identification ability of sports injury ultrasound medicine, a segmentation method of sports injury ultrasound medical image based on local features is proposed, and the research on the sports injury ultrasound medical detection and identification ability is carried out. Methods of the sports injury ultrasound medical image segmentation model are established; the sports injury ultrasound medical image information is enhanced by using the sports skeletal muscle block matching technology; the image features are extracted; and the characteristics of sports injury ultrasound medical images are analyzed by CT bright spot feature transmission. In detail, combined with the deep convolutional neural network training method, the extracted sports injury points are automatically detected for sports injury ultrasound medical images, and the sports injury ultrasound medical image segmentation is realized. The simulation results show that this method has high accuracy for sports injury ultrasound medical image segmentation, the error value can be controlled below 0.103, and finally, the effect of zero error is achieved. It is confirmed that the method proposed in this paper has high resolution and accuracy for sports injury point detection and has strong practical application ability. © 2022 Junxiao Bao et al.","","Bioinformatics; Computerized tomography; Convolution; Convolutional neural networks; Deep neural networks; Image analysis; Image segmentation; Medical imaging; Sports; Ultrasonic applications; Automatic analysis; Automatic processing; Detection and identifications; High-accuracy; Image-based; Local feature; Medical image segmentation; Segmentation methods; Sports injuries; Ultrasound medical images; Image enhancement","","","Hindawi Limited",""
"Malibari A.A.; Alzahrani J.S.; Obayya M.; Negm N.; Al-Hagery M.A.; Salama A.S.; Hilal A.M.","Malibari, Areej A. (6506143515); Alzahrani, Jaber S. (57221867248); Obayya, Marwa (6505869929); Negm, Noha (57224513486); Al-Hagery, Mohammed Abdullah (57203986293); Salama, Ahmed S. (56480035100); Hilal, Anwer Mustafa (57202837434)","6506143515; 57221867248; 6505869929; 57224513486; 57203986293; 56480035100; 57202837434","Biomedical Osteosarcoma Image Classification Using Elephant Herd Optimization and Deep Learning","2022","73","3","","6443","6459","16","10.32604/cmc.2022.031324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135064194&doi=10.32604%2fcmc.2022.031324&partnerID=40&md5=06624d2d75c400bbb5175c7ed0816ad9","Osteosarcoma is a type of malignant bone tumor that is reported across the globe. Recent advancements in Machine Learning (ML) and Deep Learning (DL) models enable the detection and classification of malignancies in biomedical images. In this regard, the current study introduces a new Biomedical Osteosarcoma Image Classification using Elephant Herd Optimization and Deep Transfer Learning (BOIC-EHODTL) model. The presented BOIC-EHODTL model examines the biomedical images to diagnose distinct kinds of osteosarcoma. At the initial stage, Gabor Filter (GF) is applied as a pre-processing technique to get rid of the noise from images. In addition, Adam optimizer with MixNet model is also employed as a feature extraction technique to generate feature vectors. Then, EHO algorithm is utilized along with Adaptive Neuro-Fuzzy Classifier (ANFC) model for recognition and categorization of osteosarcoma. EHO algorithm is utilized to fine-tune the parameters involved in ANFC model which in turn helps in accomplishing improved classification results. The design of EHO with ANFC model for classification of osteosarcoma is the novelty of current study. In order to demonstrate the improved performance of BOIC-EHODTL model, a comprehensive comparison was conducted between the proposed and existing models upon benchmark dataset and the results confirmed the better performance of BOIC-EHODTL model over recent methodologies. © 2022 Tech Science Press. All rights reserved.","Biomedical imaging; deep transfer learning parameter tuning; fuzzy logic; osteosarcoma classification","Benchmarking; Deep learning; Fuzzy inference; Fuzzy neural networks; Gabor filters; Learning systems; Medical imaging; Biomedical imaging; Deep transfer learning parameter tuning; Fuzzy-Logic; Images classification; Learning parameters; Optimisations; Osteosarcoma classification; Osteosarcomas; Parameters tuning; Transfer learning; Image classification","Deanship of Scientific Research at Umm Al-Qura University, (22UQU4340237DSR16); Deanship of Scientific Research, King Faisal University, DSR, KFU, (42/43); Deanship of Scientific Research, King Faisal University, DSR, KFU","","Tech Science Press",""
"Nimmagadda R.; Anandan P.","Nimmagadda, Ramya (57611414400); Anandan, P. (57203342586)","57611414400; 57203342586","Performance Analysis of Deep Learning Techniques on Automatic Brain Tumour Grading","2022","","","","","","","10.1109/ICCCI54379.2022.9741034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128729044&doi=10.1109%2fICCCI54379.2022.9741034&partnerID=40&md5=b1cd8f0f6c1c58551322e3969210f22f","In recent decades, there has been a lot of research in the subject of image processing. The detection of brain tumours in biomedical engineering, plays a critical role and has been a time-consuming effort in detecting the disease. The death rate increased as a result of the formation of a brain tumour, which leads to cancer. It is difficult to detect brain tumour at an early stage. Early detection of a brain tumour may save people's lives and keep them out of danger. In order to detect the brain tumour, several theories and procedures were researched and adopted. In this work, variety of information, collected from various sources, including journals, scholarly evidence. Different approaches and algorithms for diagnosing brain tumour are studied and their performance are analysed. The analysis shows that implementing a deep convolution neural network for diagnosing brain tumours gives improved results. © 2022 IEEE.","Brain tumour classification; Brain tumour detection; Deep convolution neural network; Medical image processing; MRI image segmentation","Biomedical engineering; Convolution; Convolutional neural networks; Deep neural networks; Diagnosis; Grading; Image classification; Image segmentation; Magnetic resonance imaging; Medical imaging; Tumors; Brain tumor classifications; Brain tumor detection; Brain tumors; Convolution neural network; Deep convolution neural network; Images segmentations; Medical images processing; MRI Image; MRI image segmentation; Tumour detection; Brain","","","Institute of Electrical and Electronics Engineers Inc.",""
"Isler I.; Lisle C.; Rineer J.; Kelly P.; Turgut D.; Ricci J.; Bagci U.","Isler, Ilkin (57453663000); Lisle, Curtis (6602758735); Rineer, Justin (6504459710); Kelly, Patrick (56365080700); Turgut, Damla (6603176290); Ricci, Jacob (57247420600); Bagci, Ulas (24176491700)","57453663000; 6602758735; 6504459710; 56365080700; 6603176290; 57247420600; 24176491700","Enhancing Organ at Risk Segmentation with Improved Deep Neural Networks","2022","12032","","1203233","","","","10.1117/12.2611498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131961819&doi=10.1117%2f12.2611498&partnerID=40&md5=86cf31b60bc4531c526d9e126d1a699e","Organ at risk (OAR) segmentation is a crucial step for treatment planning and outcome determination in radiotherapy treatments of cancer patients. Several deep learning based segmentation algorithms have been developed in recent years, however, U-Net remains the de facto algorithm designed specifically for biomedical image segmentation and has spawned many variants with known weaknesses. In this study, our goal is to present simple architectural changes in U-Net to improve its accuracy and generalization properties. Unlike many other available studies evaluating their algorithms on single center data, we thoroughly evaluate several variations of U-Net as well as our proposed enhanced architecture on multiple data sets for an extensive and reliable study of the OAR segmentation problem. Our enhanced segmentation model includes (a)architectural changes in the loss function, (b)optimization framework, and (c)convolution type. Testing on three publicly available multi-object segmentation data sets, we achieved an average of 80% dice score compared to the baseline U-Net performance of 63%. © 2022 SPIE.","Generalization; Multi-object segmentation; Organ at risk segmentation; Radiation Oncology; U-Net","Bioinformatics; Computer aided diagnosis; Image segmentation; Medical imaging; Oncology; Radiotherapy; Architectural changes; Generalisation; Multi-object segmentation; Organ at risk segmentation; Organs at risks; Radiation oncology; Radiotherapy treatment; Treatment outcomes; Treatment planning; U-net; Deep neural networks","National Institutes of Health, NIH, (R01-CA240639, R01-CA246704)","Colliot O.; Isgum I.; Landman B.A.; Loew M.H.","SPIE",""
"Lu P.; Fang F.; Zhang H.; Ling L.; Hua K.","Lu, Pengyue (57344157100); Fang, Faming (35753184800); Zhang, He (55685593900); Ling, Lei (57221232803); Hua, Keqin (57203187482)","57344157100; 35753184800; 55685593900; 57221232803; 57203187482","AugMS-Net:Augmented multiscale network for small cervical tumor segmentation from MRI volumes","2022","141","","104774","","","","10.1016/j.compbiomed.2021.104774","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119263879&doi=10.1016%2fj.compbiomed.2021.104774&partnerID=40&md5=a1b9308dae00ae26169ce5174ff7bb08","Cervical cancer is one of the leading causes of female-specific cancer death. Tumor region segmentation plays a pivotal role in both the clinical analysis and treatment planning of cervical cancer. Due to the heterogeneity and low contrast of biomedical images, current state-of-the-art tumor segmentation approaches are facing the challenge of the insensitive detection of small lesion regions. To tackle this problem, this paper proposes an augmented multiscale network (AugMS-Net) based on 3D U-Net to automatically segment cervical Magnetic Resonance Imaging (MRI) volumes. Since a multiscale strategy is considered one of the most promising algorithms to tackle small object recognition, we introduce a novel 3D module to explore more granular multiscale representations. Besides, we employ a deep multiscale supervision strategy to doubly supervise the side outputs hierarchically. To demonstrate the generalization of our model, we evaluated AugMS-Net on both a cervical dataset from MRI volumes and a liver dataset from Computerized Tomography (CT) volumes. Our proposed AugMS-Net shows superior performance over baseline models, yielding high accuracy while reducing the number of model parameters by nearly 20%. The source code and trained models are available at https://github.com/Cassieyy/AugMS-Net. © 2021 Elsevier Ltd","Augmented multiscale; Biomedical image; Deep learning; Semantic segmentation","Algorithms; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Uterine Cervical Neoplasms; Computerized tomography; Deep learning; Diseases; Object recognition; Semantic Segmentation; Semantics; Tumors; Augmented multiscale; Biomedical images; Cervical cancers; Clinical analysis; Clinical treatments; Deep learning; Imaging volume; Region segmentation; Semantic segmentation; Tumor segmentation; Article; controlled study; convolutional neural network; deep learning; female; human; image segmentation; liver; liver tumor; nuclear magnetic resonance imaging; quantitative analysis; receptive field; segmentation algorithm; uterine cervix cancer; x-ray computed tomography; algorithm; diagnostic imaging; image processing; nuclear magnetic resonance imaging; procedures; uterine cervix tumor; Magnetic resonance imaging","NSFC-RGC, (61961160734); Science Foundation of Shanghai, (20ZR1416200); National Natural Science Foundation of China, NSFC, (61731009); Shanghai Rising-Star Program, (21QA1402500, 61871185)","","Elsevier Ltd","34785076"
"Gastounioti A.; Rathore S.; Maghsoudi O.H.; Conant E.F.; Kontos D.; Bakas S.","Gastounioti, Aimilia (36604342100); Rathore, Saima (55000220500); Maghsoudi, Omid Haji (56132015900); Conant, Emily F. (7004184822); Kontos, Despina (6602886901); Bakas, Spyridon (55366125000)","36604342100; 55000220500; 56132015900; 7004184822; 6602886901; 55366125000","Computational imaging applications in brain and breast cancer","2022","","","","29","45","16","10.1016/B978-0-12-819872-8.00009-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150132641&doi=10.1016%2fB978-0-12-819872-8.00009-4&partnerID=40&md5=7855fa8ac75bd120048c710dba93439a","The rapid development of advanced computational algorithms from the domain of machine learning has shown promise for application in the clinical environment to (1) assist clinicians with tedious daily tasks and allow them to focus more on complex or urgent patient management, (2) offer second reads or opinions on tasks that require specialized training, as well as (3) assist in the training and education of new clinical experts. This chapter offers an overview of the state-of-the-art deep learning applications in the field of brain and breast cancer, as well as challenges and potential methods to improve the reproducibility of deep learning algorithms in biomedical image analysis of brain and breast cancer patients. The included references should not be considered as an exhaustive literature review but as studies serving as examples for the points made in this chapter. © 2023 Elsevier Inc. All rights reserved.","brain cancer; breast cancer; convolutional neural networks; Deep learning","","","","Elsevier",""
"Jing S.; Kun H.; Xin Y.; Juanli H.","Jing, Sun (57215333622); Kun, He (57610051800); Xin, Yao (57608455400); Juanli, Hu (57607389200)","57215333622; 57610051800; 57608455400; 57607389200","Optimization of Deep-Learning Network Using Resnet50 Based Model for Corona Virus Disease (COVID-19) Histopathological Image Classification","2022","","","","992","997","5","10.1109/EEBDA53927.2022.9744883","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128700284&doi=10.1109%2fEEBDA53927.2022.9744883&partnerID=40&md5=4c783e9293f9e8f6ea5204c678da0c2c","There is enormous attention surrounding COVID-19 these years. Artificial Intelligence are rising in the medical field. However, the next revolutionary steps lie in the upsurge of deep learning methodology. In this study, we propose a optimal Resnet50 based deep learning network for proper CT diagnosis of the COVID-19. The learning model was then adopted on the CT scan images with COVID-19 dataset (provided by Zhuhai HuiYu Medical Technology) and eventually achieves the autonomous diagnosis of new images by reading and analyzing more than 5000 CT pictures. The preliminary results of the core system show that the detecting sensitivity of the algorithm is 98.7, and the accuracy of the COVID-19 case detection is up to 97.4%. The CT detection for one COVID-19 case is expected to take 5.3 seconds, which greatly reduces the working intensity of doctors and the number of misdiagnoses significantly. In addition, the system can be extended to other more extensive medical image perception in the future. © 2022 IEEE.","accuracy; COVID-19; deep learning neural network; detection; optimal Resnet50 network","Biomedical engineering; Computerized tomography; Deep neural networks; Diagnosis; Medical imaging; Viruses; Accuracy; COVID-19; Deep learning neural network; Detection; Histopathological images; Learning network; Learning neural networks; Optimal resnet50 network; Optimisations; Virus disease; Image classification","Guangdong Educational Science Planning Project, (2021GXJK570); Zhuhai Huiyu Medical Technology Co., Ltd.","","Institute of Electrical and Electronics Engineers Inc.",""
"Pan Y.","Pan, Yangyi (57830222900)","57830222900","Influence of different image preprocessing methods on bone age prediction","2022","","","","632","636","4","10.1109/CVIDLICCEA56201.2022.9825218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135397871&doi=10.1109%2fCVIDLICCEA56201.2022.9825218&partnerID=40&md5=2e79d59ceaae582d689b0d5e84b4c727","In medical image recognition represented by bone age prediction, image samples need to be preprocessed to improve the quality of image samples and improve the learning efficiency of deep learning. This paper aims to compare the effects of different image preprocessing methods on the performance of the neural network. In this paper, the method of control experiment is used. Without pretreatment, the structure and framework of the neural network are controlled to remain unchanged, to make the conclusion more objective. This paper mainly discusses three pretreatment methods. 1 Conventional image filtering; 2. Use u-net network specially used for biomedical image segmentation to segment hand bones in X-ray; 3. The control group did not undergo image preprocessing. At the same time, this paper proposes to mark the gender of the owner of hand bone X-ray film in the form of a white background mark on the original image and control the gender weight by adjusting the size of the mark. U-net network preprocessing does not significantly improve the accuracy of the neural network, but this method makes the effect of deep neural network and shallow neural network almost the same, so it can be used as an effective method to prevent overfitting of neural networks. The main innovation of this paper is to explore the effectiveness of preprocessing algorithms in preventing the overfitting of medical image models by comparing the bone age prediction under various preprocessing methods. © 2022 IEEE.","bone age prediction; deep learning; grayscale histogram equalization; network lightweight; over-fitting; preprocessing; U-Net network","Equalizers; Forecasting; Image enhancement; Image recognition; Image segmentation; Medical imaging; X ray films; Age predictions; Bone age; Bone age prediction; Deep learning; Gray scale; Grayscale histogram equalization; Histogram equalizations; Net networks; Network lightweight; Overfitting; Preprocessing; U-net network; Deep neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","High-Speed Biomedical Imaging and Spectroscopy VII","2022","11971","","","","","66","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131659605&partnerID=40&md5=1628ce8d6e2c13850232d86bddef6f1a","The proceedings contain 9 papers. The topics discussed include: an adaptive excitation source for multiphoton deep and fast imaging; fast, cell-resolution, wide field-of-view two-photon microscopy to reveal functional network architectures across multi-modal cortical areas; high-speed broadband CARS in the fingerprint region through supercontinuum generation in bulk media; high speed focus-shift for light sheet microscope using continuous rotating planar mirrors; reconstruction-based spectroscopy using CMOS image sensors with random photon-trapping nanostructure per sensor; deep learning enables accelerated optical coherence tomography angiography; employing a neural network approach for reducing the convergence speed of diffuse optical image reconstruction algorithms; ultrahigh spatiotemporal resolution fluorescence molecular tomography with a sparsity constrained dimensional reduction reconstruction model; and showing differences in viscoelastic properties of cells growing on micropattern by using very long-time high speed microrheology as a new way to measure cell mechanics.","","","","Tsia K.K.; Goda K.","SPIE",""
"Tastan Y.; Baspinar U.; Okay B.B.","Tastan, Yahya (57983206700); Baspinar, Ulvi (55364736900); Okay, Burcu Bulut (59144564500)","57983206700; 55364736900; 59144564500","Classification of Motor Imagery EEG Signals for Using in Neuro-Rehabilitation Applications","2022","","","","","","","10.1109/ASYU56188.2022.9925366","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142740901&doi=10.1109%2fASYU56188.2022.9925366&partnerID=40&md5=039d68093b5efb1e4343e7413c3f32d0","Brain computer interfaces which are developed for the rehabilitation systems decode motor imagery EEG signals to control external devices. However, the extraction of the features from the EEG imagery signals and classification of it is an important problem. In this paper, common spatial pattern analysis, which is widely used in motor image applications, was preferred for getting features. As a classifier, the accuracy performances of Artificial neural network (%93), Convolutional Neural Network (%91), Support Vector Machine (%84) and K-Nearest Neighbour Algorithm (%90) were compared. As a result of the comparison, Artificial Neural Network method was the most successful classifier with %93.9 accuracy.  © 2022 IEEE.","classification; common spatial pattern; deep learning; machine learning; Motor Imagery EEG","Biomedical signal processing; Brain computer interface; Computer control systems; Convolutional neural networks; Deep learning; Image classification; Learning systems; Nearest neighbor search; Common spatial patterns; Deep learning; EEG signals; Image applications; Machine-learning; Motor imagery EEG; Neurorehabilitation []; Performance; Rehabilitation System; Spatial pattern analysis; Support vector machines","","","Institute of Electrical and Electronics Engineers Inc.",""
"Sadeghibakhi M.; Pourreza H.; Mahyar H.","Sadeghibakhi, Mehdi (57407146500); Pourreza, Hamidreza (23968187500); Mahyar, Hamidreza (55243538600)","57407146500; 23968187500; 55243538600","Multiple Sclerosis Lesions Segmentation Using Attention-Based CNNs in FLAIR Images","2022","10","","1800411","","","","10.1109/JTEHM.2022.3172025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129628774&doi=10.1109%2fJTEHM.2022.3172025&partnerID=40&md5=bb3e74450ad966b056a799ec52b7e4be","Objective: Multiple Sclerosis (MS) is an autoimmune and demyelinating disease that leads to lesions in the central nervous system. This disease can be tracked and diagnosed using Magnetic Resonance Imaging (MRI). A multitude of multimodality automatic biomedical approaches are used to segment lesions that are not beneficial for patients in terms of cost, time, and usability. The authors of the present paper propose a method employing just one modality (FLAIR image) to segment MS lesions accurately. Methods: A patch-based Convolutional Neural Network (CNN) is designed, inspired by 3D-ResNet and spatial-channel attention module, to segment MS lesions. The proposed method consists of three stages: (1) the Contrast-Limited Adaptive Histogram Equalization (CLAHE) is applied to the original images and concatenated to the extracted edges to create 4D images; (2) the patches of size 80 × 80 × 80 × 2 are randomly selected from the 4D images; and (3) the extracted patches are passed into an attention-based CNN which is used to segment the lesions. Finally, the proposed method was compared to previous studies of the same dataset. Results: The current study evaluates the model with a test set of ISIB challenge data. Experimental results illustrate that the proposed approach significantly surpasses existing methods of Dice similarity and Absolute Volume Difference while the proposed method uses just one modality (FLAIR) to segment the lesions. Conclusion: The authors have introduced an automated approach to segment the lesions, which is based on, at most, two modalities as an input. The proposed architecture comprises convolution, deconvolution, and an SCA-VoxRes module as an attention module. The results show, that the proposed method outperforms well compared to other methods.  © 2013 IEEE.","convolutional neural network; deep learning; lesion segmentation; Medical image processing; multiple sclerosis","Humans; Magnetic Resonance Imaging; Multiple Sclerosis; Neural Networks, Computer; Convolution; Deep neural networks; Image segmentation; Medical imaging; Three dimensional displays; Biomedical imaging; Convolutional neural network; Deep learning; Features extraction; Images segmentations; Lesion; Lesion segmentations; Medical images processing; Multiple sclerosis; Three-dimensional display; algorithm; Article; convolutional neural network; fluid-attenuated inversion recovery imaging; histogram; human; image processing; image segmentation; lesion volume; multiple sclerosis; residual neural network; screening; diagnostic imaging; nuclear magnetic resonance imaging; procedures; Magnetic resonance imaging","","","Institute of Electrical and Electronics Engineers Inc.","35711337"
"","","","21st International Conference on Intelligent Systems Design and Applications, ISDA 2021","2022","418 LNNS","","","","","1434","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127665433&partnerID=40&md5=15969d1c2bc8efa4a334912ac2b6e909","The proceedings contain 132 papers. The special focus in this conference is on Intelligent Systems Design and Applications. The topics include: Spare Parts Sales Forecasting for Mining Equipment: Methods Analysis and Evaluation; Deep Face Mask Detection: Prevention and Mitigation of COVID-19; Convolutional Neural Networks (CNN) Model for Mobile Brand Sentiment Analysis; improving Speech Emotion Recognition System Using Spectral and Prosodic Features; thoracic Disease Chest Radiographic Image Dataset: A Comprehensive Review; Recognition of Person Using ECG Signals Based on Single Heartbeat; twitter People’s Opinions Analysis During Covid-19 Quarantine Using Machine Learning and Deep Learning Models; intelligent Image Captioning Approach with Novel Ensembled Recurrent Neural Network Model; an Approach for Constructing a Simulation Model for Dynamic Analysis of Information Security System; Lower Limb Movement Recognition Using EMG Signals; gun Model Classification Based on Fired Cartridge Case Head Images with Siamese Networks; ensemble Learning for Data-Driven Diagnosis of Polycystic Ovary Syndrome; arabic Automatic Essay Scoring Systems: An Overview Study; Attitude Prediction of In-service Teachers Towards Blended Learning Using Machine Learning During COVID-19 Pandemic; investigating Drug Peddling in Nigeria Using a Machine Learning Approach; lifetime Optimization of Sensor Networks with Mobile Sink and Solar Energy Supply; genomic Variant Annotation: A Comprehensive Review of Tools and Techniques; improved Sentence Similarity Measurement in the Medical Field Based on Syntactico-Semantic Knowledge; using Machine Learning Approaches to Identify Exercise Activities from a Triple-Synchronous Biomedical Sensor; Modeling Travelers Behavior Using FSQCA; bearing Fault Classification of Induction Motor Using Statistical Features and Machine Learning Algorithms; Mobile Cloud Computing: Issues, Applications and Scope in COVID-19; Functionality and Architecture for a Platform for Independent Learners: KEPLAIR.","","","","Abraham A.; Gandhi N.; Hanne T.; Hong T.; Nogueira Rios T.; Ding W.","Springer Science and Business Media Deutschland GmbH",""
"Zhang Y.; Liu M.; Yu F.; Zeng T.; Wang Y.","Zhang, Yuqiang (57226780797); Liu, Min (55783125200); Yu, Fuhao (57221219160); Zeng, Tieyong (25423412800); Wang, Yaonan (55998880600)","57226780797; 55783125200; 57221219160; 25423412800; 55998880600","An O-Shape Neural Network with Attention Modules to Detect Junctions in Biomedical Images Without Segmentation","2022","26","2","","774","785","11","10.1109/JBHI.2021.3094187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112591760&doi=10.1109%2fJBHI.2021.3094187&partnerID=40&md5=63439a1285baa9d48b15aa31b0daaa7a","Junction plays an important role in biomedical research such as retinal biometric identification, retinal image registration, eye-related disease diagnosis and neuron reconstruction. However, junction detection in original biomedical images is extremely challenging. For example, retinal images contain many tiny blood vessels with complicated structures and low contrast, which makes it challenging to detect junctions. In this paper, we propose an O-shape Network architecture with Attention modules (Attention O-Net), which includes Junction Detection Branch (JDB) and Local Enhancement Branch (LEB) to detect junctions in biomedical images without segmentation. In JDB, the heatmap indicating the probabilities of junctions is estimated and followed by choosing the positions with the local highest value as the junctions, whereas it is challenging to detect junctions when the images contain weak filament signals. Therefore, LEB is constructed to enhance the thin branch foreground and make the network pay more attention to the regions with low contrast, which is helpful to alleviate the imbalance of the foreground between thin and thick branches and to detect the junctions of the thin branch. Furthermore, attention modules are utilized to introduce the feature maps of LEB to JDB, which can establish a complementary relationship and further integrate local features and contextual information between these two branches. The proposed method achieves the highest average F1-scores of 0.82, 0.73 and 0.94 in two retinal datasets and one neuron dataset, respectively. The experimental results confirm that Attention O-Net outperforms other state-of-the-art detection methods, and is helpful for retinal biometric identification.  © 2013 IEEE.","Biomedical images; deep learning; junction detection","Algorithms; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Retina; Anthropometry; Biometrics; Blood vessels; Diagnosis; Image segmentation; Network architecture; Neural networks; Ophthalmology; Biomedical research; Biometric identifications; Complementary relationship; Complicated structures; Contextual information; Junction detection; Neuron reconstruction; Retinal image registrations; accuracy; algorithm; Article; artificial neural network; attention; B scan; biometry; deep learning; entropy; feature extraction; human; image analysis; image enhancement; image reconstruction; image segmentation; learning algorithm; machine learning; mathematical model; nerve cell network; normal distribution; optical coherence tomography; retina blood vessel; retina disease; retina image; signal noise ratio; training; algorithm; diagnostic imaging; image processing; procedures; retina; Image enhancement","National Natural Science Foundation of China, NSFC, (61771189, 62073126); Natural Science Foundation of Hunan Province, (2020JJ2008)","","Institute of Electrical and Electronics Engineers Inc.","34197332"
"Vaiyapuri T.; Balaji P.; Shridevi S.; Alaskar H.; Sbai Z.","Vaiyapuri, Thavavel (57210643089); Balaji, Prasanalakshmi (57735278300); Shridevi, S. (57144528100); Alaskar, Haya (56028692500); Sbai, Zohra (36669382100)","57210643089; 57735278300; 57144528100; 56028692500; 36669382100","Computational Intelligence-Based Melanoma Detection and Classification Using Dermoscopic Images","2022","2022","","2370190","","","","10.1155/2022/2370190","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131707949&doi=10.1155%2f2022%2f2370190&partnerID=40&md5=00189b9f2dc18629e9b99945f418a335","Melanoma is a kind of skin cancer caused by the irregular development of pigment-producing cells. Since melanoma detection efficiency is limited to different factors such as poor contrast among lesions and nearby skin regions, and visual resemblance among melanoma and non-melanoma lesions, intelligent computer-aided diagnosis (CAD) models are essential. Recently, computational intelligence (CI) and deep learning (DL) techniques are utilized for effective decision-making in the biomedical field. In addition, the fast-growing advancements in computer-aided surgeries and recent progress in molecular, cellular, and tissue engineering research have made CI an inevitable part of biomedical applications. In this view, the research work here develops a novel computational intelligence-based melanoma detection and classification technique using dermoscopic images (CIMDC-DIs). The proposed CIMDC-DI model encompasses different subprocesses. Primarily, bilateral filtering with fuzzy k-means (FKM) clustering-based image segmentation is applied as a preprocessing step. Besides, NasNet-based feature extractor with stochastic gradient descent is applied for feature extraction. Finally, the manta ray foraging optimization (MRFO) algorithm with a cascaded neural network (CNN) is exploited for the classification process. To ensure the potential efficiency of the CIMDC-DI technique, we conducted a wide-ranging simulation analysis, and the results reported its effectiveness over the existing recent algorithms with the maximum accuracy of 97.50%.  © 2022 Thavavel Vaiyapuri et al.","","Algorithms; Artificial Intelligence; Dermoscopy; Humans; Melanoma; Neural Networks, Computer; Skin Neoplasms; Classification (of information); Computer aided diagnosis; Decision making; Deep learning; Efficiency; Gradient methods; Image classification; Image segmentation; K-means clustering; Medical applications; Oncology; Stochastic systems; Tissue; Tissue engineering; Classification technique; Decisions makings; Dermoscopic images; Detection efficiency; Diagnosis model; Learning techniques; Melanoma detection; Melanoma detection and classifications; Skin cancers; Visual resemblance; algorithm; artificial intelligence; diagnostic imaging; epiluminescence microscopy; human; melanoma; pathology; procedures; skin tumor; Dermatology","","","Hindawi Limited","35685142"
"Mulmule P.V.; Kanphade R.D.","Mulmule, Pallavi V. (56021679600); Kanphade, Rajendra D. (24174635600)","56021679600; 24174635600","Classification of Cervical Cytology Overlapping Cell Images with Transfer Learning Architectures","2022","15","1","","277","284","7","10.13005/bpj/2364","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129049697&doi=10.13005%2fbpj%2f2364&partnerID=40&md5=2bd47cf18a45a25acd64304181e0922c","Cervical cell classification is a clinical biomarker in cervical cancer screening at early stages. An accurate and early diagnosis plays a vital role in preventing the cervical cancer. Recently, transfer learning using deep convolutional neural networks; have been deployed in many biomedical applications. The proposed work aims at applying the cutting edge pretrained networks: AlexNet, ImageNet and Places365, to cervix images to detect the cancer. These pre-trained networks are fine-tuned and retrained for cervical cancer augmented data with benchmark CERVIX93 dataset available publically. The models were evaluated on performance measures viz; accuracy, precision, sensitivity, specificity, F-Score, MCC and kappa score. The results reflect that the AlexNet model is best for cervical cancer prediction with 99.03% accuracy and 0.98 of kappa coefficient showing a perfect agreement. Finally, the significant success rate makes the AlexNet model a useful assistive tool for radiologist and clinicians to detect the cervical cancer from pap-smear cytology images. © 2022 Oriental Scientific Publishing Company. All rights reserved.","Alexnet; Cervical cancer; Convolution Neural Network Models; Cytology Images; Deep learning architectures; ImageNet","accuracy; Article; artificial neural network; biocompatibility; cancer screening; controlled study; convolutional neural network; correlation coefficient; cytology; depth of field; diagnostic accuracy; diagnostic test accuracy study; female; human; image segmentation; kappa statistics; learning algorithm; Papanicolaou test; prediction; predictive value; scientific literature; sensitivity and specificity; support vector machine; uterine cervix cancer; uterine cervix cytology","","","Oriental Scientific Publishing Company",""
"Natarajan V.A.; Bhavishya G.; Siddardha B.; Reddy B.S.N.; Dathusai G.; Sree G.V.","Natarajan, V. Anantha (57215509255); Bhavishya, Gowni (58110163800); Siddardha, Byraboina (57988260000); Reddy, Bana Surendra Natha (58110182300); Dathusai, Gandla (58110172500); Sree, Golla Vidya (58110214100)","57215509255; 58110163800; 57988260000; 58110182300; 58110172500; 58110214100","Detection of Skin Malignancy Using Deep Convolutional Neural Networks with Transfer Learning Techniques","2022","","","","","","","10.1109/ICDSAAI55433.2022.10028965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148485183&doi=10.1109%2fICDSAAI55433.2022.10028965&partnerID=40&md5=7ee58f0bb59504b9b528441d36b21965","Fungal illness, germs, allergies, and microbes, among other things, can cause skin problems. Using medical technology to diagnose skin diseases much more quickly and accurately. This study is about using a Convolutional Neural Network (CNN), a commonly used deep neural architecture in many of the computer vision applications particularly for image classification tasks. CNN model is used in this study to diagnose skin abnormalities or diseases from images. Transfer learning techniques will be employed and using pre-trained models the complexity of the training process will be reduced. The trained model identifies the provided image as either skin illness or normal. CNN evaluates the raw picture element data from the dermoscopic image, after evaluation model training happens, and then pulls the features for better classification. The goal of this research is to address concerns with early diagnosis and enhance accuracy. Dermoscopic pictures are classified using deep learning models to identify the presence of skin lesions (Non-Melanoma).  © 2022 IEEE.","CNN (Convolutional Neural Networks); Dermoscopic images; non-melanoma; Skin lesion; VGG16","Bacteria; Biomedical engineering; Classification (of information); Convolution; Deep neural networks; Dermatology; Diagnosis; Diseases; Image classification; Learning algorithms; Learning systems; Neural network models; Oncology; Transfer learning; Convolutional neural network; Dermoscopic images; Learning techniques; Medical technologies; Non-melanoma; Skin disease; Skin lesion; Transfer learning; VGG16; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Li L.; Sun N.","Li, Li (56166587700); Sun, Nan (57686285500)","56166587700; 57686285500","Attention-Based DSC-ConvLSTM for Multiclass Motor Imagery Classification","2022","2022","","8187009","","","","10.1155/2022/8187009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130067158&doi=10.1155%2f2022%2f8187009&partnerID=40&md5=0961270c276f9c6b9001c294f4aa5605","With the rapid development of deep learning, researchers have gradually applied it to motor imagery brain computer interface (MI-BCI) and initially demonstrated its advantages over traditional machine learning. However, its application still faces many challenges, and the recognition rate of electroencephalogram (EEG) is still the bottleneck restricting the development of MI-BCI. In order to improve the accuracy of EEG classification, a DSC-ConvLSTM model based on the attention mechanism is proposed for the multi-classification of motor imagery EEG signals. To address the problem of the small sample size of well-labeled and accurate EEG data, the preprocessing uses sliding windows for data augmentation, and the average prediction loss of each sliding window is used as the final prediction loss for that trial. This not only increases the training sample size and is beneficial to train complex neural network models, but also the network no longer extracts the global features of the whole trial so as to avoid learning the difference features among trials, which can effectively eliminate the influence of individual specificity. In the aspect of feature extraction and classification, the overall network structure is designed according to the characteristics of the EEG signals in this paper. Firstly, depth separable convolution (DSC) is used to extract spatial features of EEG signals. On the one hand, this reduces the number of parameters and improves the response speed of the system. On the other hand, the network structure we designed is more conducive to extract directly the direct extraction of spatial features of EEG signals. Secondly, the internal structure of the Long Short-Term Memory (LSTM) unit is improved by using convolution and attention mechanism, and a novel bidirectional convolution LSTM (ConvLSTM) structure is proposed by comparing the effects of embedding convolution and attention mechanism in the input and different gates, respectively. In the ConvLSTM module, the convolutional structure is only introduced into the input-to-state transition, while the gates still remain the original fully connected mechanism, and the attention mechanism is introduced into the input to further improve the overall decoding performance of the model. This bidirectional ConvLSTM extracts the time-domain features of EEG signals and integrates the feature extraction capability of the CNN and the sequence processing capability of LSTM. The experimental results show that the average classification accuracy of the model reaches 73.7% and 92.6% on two datasets, BCI Competition IV Dataset 2a and High Gamma Dataset, respectively, which proves the robustness and effectiveness of the model we proposed. It can be seen that the model in this paper can deeply excavate significant EEG features from the original EEG signals, show good performance in different subjects and different datasets, and improve the influence of individual variability on the classification performance, which is of practical significance for promoting the development of brain-computer interface technology towards a practical and marketable direction.  © 2022 Li Li and Nan Sun.","","Algorithms; Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Neural Networks, Computer; Biomedical signal processing; Brain; Brain computer interface; Classification (of information); Decoding; Electroencephalography; Extraction; Feature extraction; Image classification; Image enhancement; Long short-term memory; Attention mechanisms; Electroencephalogram signals; ITS applications; Model-based OPC; Motor imagery; Motor imagery classification; Multi-classification; Network structures; Sliding Window; Spatial features; algorithm; brain computer interface; electroencephalography; human; imagination; procedures; Convolution","","","Hindawi Limited","35571721"
"Huang Q.-X.; Yap W.L.; Chiu M.-Y.; Sun H.-M.","Huang, Qi-Xian (57210599087); Yap, Wai Leong (57789716900); Chiu, Min-Yi (57226801575); Sun, Hung-Min (7404827640)","57210599087; 57789716900; 57226801575; 7404827640","Privacy-Preserving Deep Learning With Learnable Image Encryption on Medical Images","2022","10","","","66345","66355","10","10.1109/ACCESS.2022.3185206","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133685097&doi=10.1109%2fACCESS.2022.3185206&partnerID=40&md5=2a54a4852336c0f62921987351799fe7","The need for cloud servers for training deep neural network (DNN) models is increasing as more complex architecture designs of DNN models are developed. Nevertheless, cloud servers are considered semi-honest. With great attention to the privacy issues of medical diagnoses using a DNN, previous studies have proposed the idea of learnable image encryption. Though some methods have been presented to partially attack previous encryption schemes, there is still some space for improvement. We proposed a learnable image encryption scheme that is an enhanced version of previous methods and can be used to train a great DNN model and simultaneously keep the privacy of training images. We conducted an experiment on medical datasets from open sources and the result demonstrates the effectiveness of our proposed method in performance and privacy-preserving.  © 2013 IEEE.","Deep neural network; learnable image encryption; medical analysis; privacy-preserving","Bioinformatics; Cloud computing; Diagnosis; Image analysis; Image enhancement; Medical imaging; Privacy-preserving techniques; Biomedical imaging; Deep learning; Filtering algorithm; Image color analysis; Images encryptions; Learnable image encryption; Medical analysis; Medical diagnostic imaging; Neural network model; Privacy preserving; Deep neural networks","Senao Network Corporation; Ministry of Science and Technology, Taiwan, MOST, (MOST 110-2221-E-007-040-MY3)","","Institute of Electrical and Electronics Engineers Inc.",""
"Wen D.; Li R.; Tang H.; Liu Y.; Wan X.; Dong X.; Saripan M.I.; Lan X.; Song H.; Zhou Y.","Wen, Dong (26322164100); Li, Rou (57411821800); Tang, Hao (57609127800); Liu, Yijun (57210606021); Wan, Xianglong (56241529500); Dong, Xianling (57218361299); Saripan, M. Iqbal (14010419600); Lan, Xifa (57201469844); Song, Haiqing (36187456200); Zhou, Yanhong (55718596200)","26322164100; 57411821800; 57609127800; 57210606021; 56241529500; 57218361299; 14010419600; 57201469844; 36187456200; 55718596200","Task-State EEG Signal Classification for Spatial Cognitive Evaluation Based on Multiscale High-Density Convolutional Neural Network","2022","30","","","1041","1051","10","10.1109/TNSRE.2022.3166224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128616173&doi=10.1109%2fTNSRE.2022.3166224&partnerID=40&md5=5548343f35c0e87396966db4b69a5e3d","In this study, a multi-scale high-density convolutional neural network (MHCNN) classification method for spatial cognitive ability assessment was proposed, aiming at achieving the binary classification of task-state EEG signals before and after spatial cognitive training. Besides, the multi-dimensional conditional mutual information method was used to extract the frequency band features of the EEG data. And the coupling features under the combination of multi-frequency bands were transformed into multi-spectral images. At the same time, the idea of Densenet was introduced to improve the multi-scale convolutional neural network. Firstly, according to the discreteness of multispectral EEG image features, two-scale convolution kernels were used to calculate and learn useful channel and frequency band feature information in multispectral image data. Secondly, to enhance feature propagation and reduce the number of parameters, the dense network was connected after the multi-scale convolutional network, and the learning rate change function of the stochastic gradient descent algorithm was optimized to objectively evaluate the training effect. The experimental results showed that compared with the classical convolution neural network (CNN) and multi-scale convolution neural network, the proposed MHCNN had better classification performance in the six frequency band combinations with the highest accuracy of 98%: Theta-Alpha2-Gamma, Alpha2-Beta2-Gamma, Beta1-Beta2-Gamma, Theta-Beta2-Gamma, Theta- Alpha1-Gamma, and Alpha1-Alpha2-Gamma. By comparing the classification results of six frequency band combinations, it was found that the combination of the Theta-Beta2-Gamma band had the best classification effect. The MHCNN classification method proposed in this research could be used as an effective biological indicator of spatial cognitive training effect and could be extended to other brain function evaluations.  © 2001-2011 IEEE.","Multi-scale high-density convolutional neural network; spatial cognition evaluation; task-state EEG signals","Algorithms; Cognition; Electroencephalography; Humans; Neural Networks, Computer; Backpropagation; Biomedical signal processing; Electroencephalography; Electrophysiology; Function evaluation; Neural networks; Spectroscopy; Stochastic systems; Brain modeling; Convolutional neural network; EEG signals; Features extraction; License; Multi-scale high-density convolutional neural network; Multi-scales; Spatial cognition; Spatial cognition evaluation; Task state; Task-state EEG signal; accuracy; area under the curve; Article; artificial neural network; classification algorithm; cognitive development; controlled study; convolutional neural network; data analysis software; deep learning; diagnostic test accuracy study; electroencephalography; evaluation study; experimental study; human; human experiment; image analysis; learning algorithm; male; measurement accuracy; Morris water maze test; nerve cell network; normal human; spatial analysis; stochastic model; task performance; time series analysis; algorithm; cognition; procedures; Convolution","National Natural Science Foundation of China, NSFC, (61503326, 61876165); National Key Research and Development Program of China, NKRDPC, (2021YFF1200603)","","Institute of Electrical and Electronics Engineers Inc.","35404820"
"Ovi T.B.; Naba S.S.; Chanda D.; Onim M.S.H.","Ovi, Tareque Bashar (57456812100); Naba, Sauda Suara (57810556100); Chanda, Dibaloke (57456916800); Onim, Md. Saif Hassan (57221317313)","57456812100; 57810556100; 57456916800; 57221317313","A Transfer-Learning Based Ensemble Architecture for ECG Signal Classification","2022","","","","","","","10.1109/TENSYMP54529.2022.9864449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138492793&doi=10.1109%2fTENSYMP54529.2022.9864449&partnerID=40&md5=dca23b83d906cba2d0acbb828ae241f5","Manual interpretation and classification of ECG signals lack both accuracy and reliability. These continuous time-series signals are more effective when represented as an image for CNN-based classification. A continuous Wavelet transform filter is used here to get corresponding images. In achieving the best result generic CNN architectures lack sufficient accuracy and also have a higher run-time. To address this issue, we propose an ensemble method of transfer learning-based models to classify ECG signals. In our work, two modified VGG-16 models and one InceptionResNetV2 model with added feature extracting layers and ImageNet weights are working as the backbone. After ensemble, we report an increase of 6.36% accuracy than previous MLP based algorithms. After 5-fold cross-validation with the Physionet dataset, our model reaches an accuracy of 99.98 %.  © 2022 IEEE.","continuous wavelet transform; deep learning; ensemble learning; medical image processing; transfer learning","Biomedical signal processing; Convolutional neural networks; Deep learning; Electrocardiography; Image classification; Learning systems; Medical imaging; Wavelet transforms; Continous time; Continuous Wavelet Transform; Deep learning; ECG signals; Ensemble learning; Medical images processing; Runtimes; Signal classification; Time series signals; Transfer learning; Continuous time systems","","","Institute of Electrical and Electronics Engineers Inc.",""
"Mergin A.A.; Premi M.S.G.","Mergin, A. Ancy (57202237260); Premi, M. S. Godwin (36809617400)","57202237260; 36809617400","Convolutional Neural Networks (CNN) with Quantum-Behaved Particle Swarm Optimization (QPSO)-Based Medical Image Fusion","2022","","","2340005","","","","10.1142/S0219467823400053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136595001&doi=10.1142%2fS0219467823400053&partnerID=40&md5=cab94aca071858a08e6ef09a744c0f3f","Medical imaging fusion is the process of combining pictures from various imaging modalities to create a single image that may be used in clinical settings. Robust methods for merging image data from several modalities are being developed in the field of multimodal medical imaging. Deep learning (DL) has been widely researched in two areas: pattern recognition and image processing. We will demonstrate a multimodal image fusion with DL implementation that considers the characteristics of medical diagnostic imaging as well as the demands of clinical practice. For the past three years, pixel-level picture fusion has been a hot topic. This paper proposes a new multimodal medical picture fusion technique for a wide range of medical diagnostic challenges. Image fusion is crucial in biomedical research and clinical diagnostics for biomedical image processing and therapy planning. The most convincing argument for fusion is obtaining a significant amount of critical information from the input photographs. We show how a well-organized multimodal medical image fusion technique can be utilized to integrate computed tomography (CT) and magnetic resonance imaging (MRI) data in this study. Using convolutional neural networks (CNNs), the quantum-behaved particle swarm optimization (QPSO) algorithm was used to create a method for integrating multimodal medical pictures. In order to improve the overall quality and efficiency of QPSO, it was chosen to add the metrics of image entropy, standard deviation, average gradient (AG), spatial frequency (SF), and visual information fidelity (VIF). In experiments, multimodal medical images are utilized to evaluate a variety of parameters, including performance and algorithm stability. When compared to the other possibilities, the recommended technique outperformed them in the evaluations. On a range of quantitative metrics, this method outperforms the alternatives.  © 2023 World Scientific Publishing Company.","Convolutional neural networks (CNN); image entropy (EN); image fusion; MRI; QPSO; visual information fidelity (VIF)","","","","World Scientific",""
"Vidaurre-Gallart I.; Fernaud-Espinosa I.; Cosmin-Toader N.; Talavera-Martínez L.; Martin-Abadal M.; Benavides-Piccione R.; Gonzalez-Cid Y.; Pastor L.; DeFelipe J.; García-Lorenzo M.","Vidaurre-Gallart, Isabel (57375268000); Fernaud-Espinosa, Isabel (6507236506); Cosmin-Toader, Nicusor (57567818700); Talavera-Martínez, Lidia (57210860528); Martin-Abadal, Miguel (57204144129); Benavides-Piccione, Ruth (6507475009); Gonzalez-Cid, Yolanda (57221624136); Pastor, Luis (56186263400); DeFelipe, Javier (7004467085); García-Lorenzo, Marcos (57271014000)","57375268000; 6507236506; 57567818700; 57210860528; 57204144129; 6507475009; 57221624136; 56186263400; 7004467085; 57271014000","A Deep Learning-Based Workflow for Dendritic Spine Segmentation","2022","16","","817903","","","","10.3389/fnana.2022.817903","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127860017&doi=10.3389%2ffnana.2022.817903&partnerID=40&md5=c010576084aa9ecb5991a927338c2909","The morphological analysis of dendritic spines is an important challenge for the neuroscientific community. Most state-of-the-art techniques rely on user-supervised algorithms to segment the spine surface, especially those designed for light microscopy images. Therefore, processing large dendritic branches is costly and time-consuming. Although deep learning (DL) models have become one of the most commonly used tools in image segmentation, they have not yet been successfully applied to this problem. In this article, we study the feasibility of using DL models to automatize spine segmentation from confocal microscopy images. Supervised learning is the most frequently used method for training DL models. This approach requires large data sets of high-quality segmented images (ground truth). As mentioned above, the segmentation of microscopy images is time-consuming and, therefore, in most cases, neuroanatomists only reconstruct relevant branches of the stack. Additionally, some parts of the dendritic shaft and spines are not segmented due to dyeing problems. In the context of this research, we tested the most successful architectures in the DL biomedical segmentation field. To build the ground truth, we used a large and high-quality data set, according to standards in the field. Nevertheless, this data set is not sufficient to train convolutional neural networks for accurate reconstructions. Therefore, we implemented an automatic preprocessing step and several training strategies to deal with the problems mentioned above. As shown by our results, our system produces a high-quality segmentation in most cases. Finally, we integrated several postprocessing user-supervised algorithms in a graphical user interface application to correct any possible artifacts. Copyright © 2022 Vidaurre-Gallart, Fernaud-Espinosa, Cosmin-Toader, Talavera-Martínez, Martin-Abadal, Benavides-Piccione, Gonzalez-Cid, Pastor, DeFelipe and García-Lorenzo.","artificial neural network; automatic 3D image segmentation; confocal microscopy; pyramidal cells; reconstruction algorithms","Article; cingulate gyrus; confocal microscopy; convolutional neural network; deep learning; dendritic spine; feasibility study; image analysis; image segmentation; learning algorithm; machine learning; nerve cell network; nonhuman; pyramidal nerve cell; quantitative structure activity relation; reconstruction algorithm; support vector machine; training; workflow","CSIC-UV; Comunitat Valenciana; European Union ERDF; European Union's Horizon 2020 Framework; IFIC; Instituto de F?sica Corpuscular; Instituto de Física Corpuscular; Horizon 2020 Framework Programme, H2020, (945539); Horizon 2020 Framework Programme, H2020","","Frontiers Media S.A.",""
"Aydın M.; Kiraz B.; Eren F.; Uysalh Y.; Morova B.; Can Ozcan S.; Acilan C.; Kiraz A.","Aydın, Musa (56369220000); Kiraz, Berna (36959472600); Eren, Furkan (57226398182); Uysalh, Yiğit (57460004300); Morova, Berna (57195804504); Can Ozcan, Selahattin (57460004400); Acilan, Ceyda (16240700600); Kiraz, Alper (58903933900)","56369220000; 36959472600; 57226398182; 57460004300; 57195804504; 57460004400; 16240700600; 58903933900","A Deep Learning Model for Automated Segmentation of Fluorescence Cell images","2022","2191","1","012003","","","","10.1088/1742-6596/2191/1/012003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124988437&doi=10.1088%2f1742-6596%2f2191%2f1%2f012003&partnerID=40&md5=964ead13f966850d6125924ff08691aa","Deep learning techniques bring together key advantages in biomedical image segmentation. They speed up the process, increase the reproducibility, and reduce the workload in segmentation and classifcation. Deep learning techniques can be used for analysing cell concentration, cell viability, as well as the size and form of each cell. In this study, we develop a deep learning model for automated segmentation of fuorescence cell images, and apply it to fuorescence images recorded with a home-built epi-fuorescence microscope. A deep neural network model based on U-Net architecture was built using a publicly available dataset of cell nuclei images [1]. A model accuracy of 97.3% was reached at the end of model training. Fluorescence cell images acquired with our home-built microscope were then segmented using the developed model. 141 of 151 cells in 5 images were successfully segmented, revealing a segmentation success rate of 93.4%. This deep learning model can be extended to the analysis of diferent cell types and cell viability.  © 2021 Published under licence by IOP Publishing Ltd.","","Cells; Cytology; Deep neural networks; Fluorescence; Image segmentation; Automated segmentation; Biomedical image segmentation; Cell images; Cell viability; Fluorescence cell; Home-built; Learning models; Learning techniques; Reproducibilities; Speed up; Learning algorithms","KOSGEB; TÜBA; TÜBİTAK, (7190434); Türkiye Bilimler Akademisi","","IOP Publishing Ltd",""
"Alassaf A.; Sikkandar M.Y.","Alassaf, Ahmad (57191228351); Sikkandar, Mohamed Yacin (57202716139)","57191228351; 57202716139","Intelligent Deep Transfer Learning Based Malaria Parasite Detection and Classification Model Using Biomedical Image","2022","72","3","","5273","5285","12","10.32604/cmc.2022.025577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128662756&doi=10.32604%2fcmc.2022.025577&partnerID=40&md5=10a96545be2818f071bdb082445ac197","Malaria is a severe disease caused by Plasmodium parasites, which can be detected through blood smear images. The early identification of the disease can effectively reduce the severity rate. Deep learning (DL) models can be widely employed to analyze biomedical images, thereby minimizing the misclassification rate. With this objective, this study developed an intelligent deep-transfer-learning-based malaria parasite detection and classification (IDTL-MPDC) model on blood smear images. The proposed IDTL-MPDC technique aims to effectively determine the presence ofmalarial parasites in blood smear images. In addition, the IDTL-MPDC technique derives median filtering (MF) as a pre-processing step. In addition, a residual neural network (Res2Net) model was employed for the extraction of feature vectors, and its hyperparameters were optimally adjusted using the differential evolution (DE) algorithm. The k-nearest neighbor (KNN) classifier was used to assign appropriate classes to the blood smear images. The optimal selection of Res2Net hyperparameters by the DE model helps achieve enhanced classification outcomes. A wide range of simulation analyses of the IDTL-MPDC technique are carried out using a benchmark dataset, and its performance seems to be highly accurate (95.86%), highly sensitive (95.82%), highly specific (95.98%), with a high F1 score (95.69%), and high precision (95.86%), and it has been proven to be better than the other existing methods. © 2022 Tech Science Press. All rights reserved.","biomedical images; blood smear images; Computer-aided diagnosis; deep learning; malaria parasites","Benchmarking; Blood; Computer aided diagnosis; Computer aided instruction; Deep learning; Evolutionary algorithms; Image classification; Median filters; Nearest neighbor search; Biomedical images; Blood smear image; Blood smears; Classification models; Classification technique; Deep learning; Detection models; Hyper-parameter; Malaria parasite; Transfer learning; Diseases","Majmaah University, MU, (R-2022-76)","","Tech Science Press",""
"Sivanantham K.","Sivanantham, Kalimuthu (57646455400)","57646455400","Deep Learning-Based Convolutional Neural Network with Cuckoo Search Optimization for MRI Brain Tumour Segmentation","2022","","","","149","168","19","10.1007/978-3-030-96429-0_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128887024&doi=10.1007%2f978-3-030-96429-0_7&partnerID=40&md5=3d4ece0e209cc35511f64e888e46f5b5","In recent scenario there is a huge requirement of image processing in various applications, namely, pattern recognition, Image compression, multimedia computing, remote sensing, secured image data communication, biomedical imaging and content-based image restoration. The medical image processing is the process and technique where the human body images are created for the purpose of medical field to examine, reveal or diagnose the diseases. The internal anatomy of the human body is visualized by the medical imaging technique without opening the body. Proposed research consist of various steps preprocessing used to remove noise, lung MRI images that are diagnosed by a radiologist are segmented using basic thresholding and morphological operations to extract the lung parenchyma. Next the ROIs of pleural effusion are extracted followed by the extraction of the ROIs of pneumothorax. Ten shape and texture features area, convex area, equivalent diameter, mean, eccentricity, solidity, perimeter, entropy, smoothness and standard deviation are extracted from the ROIs. The CNN is trained to identify the feature vectors belonging to the four class’s pleural effusion, pneumothorax, normal lung and chest CT slices affected by other diseases. When the query MRI slice is applied, based on the training received, the classifies the query slice into the two classes for pneumonia or not. The classified result parameter optimized using Cuckoo search optimization algorithm (CSO). CSO algorithm a non-greedy local heuristic approach is used to solve optimization issues. The optimization results exhibit an accuracy of 94.18%. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Application of medical imaging; Computed tomography; Convolutional neural network; Cuckoo search optimization; Feature extraction; MRI image; Segmentation algorithm","Biological organs; Convolution; Deep learning; Extraction; Feature extraction; Image compression; Image reconstruction; Image segmentation; Magnetic resonance imaging; Mathematical morphology; Medical imaging; Optimization; Remote sensing; Textures; Application of medical imaging; Convolutional neural network; Cuckoo search optimization; Cuckoo searches; Features extraction; Human bodies; MRI Image; Pleural effusion; Search optimization; Segmentation algorithms; Computerized tomography","","","Springer Science and Business Media Deutschland GmbH",""
"","","","9th International Work-Conference on Bioinformatics and Biomedical Engineering, IWBBIO 2022","2022","13347 LNBI","","","","","922","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133165209&partnerID=40&md5=eb8db11cc84177d75b5e01c4371d7cd2","The proceedings contain 75 papers. The special focus in this conference is on Bioinformatics and Biomedical Engineering. The topics include: Automated TTC Image-Based Analysis of Mouse Brain Lesions; PET-Neuroimaging and Neuropsychological Study for Early Cognitive Impairment in Parkinson’s Disease; architecture and Calibration of a Multi-channel Electrical Impedance Myographer; advanced Incremental Attribute Learning Clustering Algorithm for Medical and Healthcare Applications; Assessment of Inflammation in Non-calcified Artery Plaques with Dynamic 18F-FDG-PET/CT: CT Alone, Does-It Detect the Vulnerable Plaque?; Comparative Analysis of the Spatial Structure Chloroplasts and Cyanobacteria Photosynthetic Systems I and II Genes; Unsupervised Classification of Some Bacteria with 16S RNA Genes; modern Approaches to Cancer Treatment; a Service for Flexible Management and Analysis of Heterogeneous Clinical Data; linear Predictive Modeling for Immune Metabolites Related to Other Metabolites; reconfigurable Arduino Shield for Biosignal Acquisition; smart Watch for Smart Health Monitoring: A Literature Review; Data Quality Enhancement for Machine Learning on Wearable ECGs; Measurable Difference Between Malignant and Benign Tumor of the Thyroid Gland Recognizable Using Echogenicity Index in Ultrasound B-MODE Imaging: An Experimental Blind Study; initial Prototype of Low-Cost Stool Monitoring System for Early Detection of Diseases; Cerebral Activation in Subjects with Developmental Coordination Disorder: A Pilot Study with PET Imaging; on the Use of Explainable Artificial Intelligence for the Differential Diagnosis of Pigmented Skin Lesions; estimating Frontal Body Landmarks from Thermal Sensors Using Residual Neural Networks; NMF for Quality Control of Multi-modal Retinal Images for Diagnosis of Diabetes Mellitus and Diabetic Retinopathy; radiomic-Based Lung Nodule Classification in Low-Dose Computed Tomography; modelling of Arbitrary Shaped Channels and Obstacles by Distance Function; Segmentation of Brain MR Images Using Quantum Inspired Firefly Algorithm with Mutation; a Deep Learning Framework for the Prediction of Conversion to Alzheimer Disease.","","","","Rojas I.; Valenzuela O.; Rojas F.; Herrera L.J.; Ortuño F.","Springer Science and Business Media Deutschland GmbH",""
"Hamza M.A.; Albraikan A.A.; Alzahrani J.S.; Dhahbi S.; Al-Turaiki I.; Al Duhayyim M.; Yaseen I.; Eldesouki M.I.","Hamza, Manar Ahmed (57223407265); Albraikan, Amani Abdulrahman (55938036300); Alzahrani, Jaber S. (57221867248); Dhahbi, Sami (22034298700); Al-Turaiki, Isra (35069063300); Al Duhayyim, Mesfer (57204360566); Yaseen, Ishfaq (57410292800); Eldesouki, Mohamed I. (57581134200)","57223407265; 55938036300; 57221867248; 22034298700; 35069063300; 57204360566; 57410292800; 57581134200","Optimal Deep Transfer Learning-Based Human-Centric Biomedical Diagnosis for Acute Lymphoblastic Leukemia Detection","2022","2022","","7954111","","","","10.1155/2022/7954111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131637824&doi=10.1155%2f2022%2f7954111&partnerID=40&md5=8c9ef508dc12856d21d892b2818bea1e","Human-centric biomedical diagnosis (HCBD) becomes a hot research topic in the healthcare sector, which assists physicians in the disease diagnosis and decision-making process. Leukemia is a pathology that affects younger people and adults, instigating early death and a number of other symptoms. Computer-aided detection models are found to be useful for reducing the probability of recommending unsuitable treatments and helping physicians in the disease detection process. Besides, the rapid development of deep learning (DL) models assists in the detection and classification of medical-imaging-related problems. Since the training of DL models necessitates massive datasets, transfer learning models can be employed for image feature extraction. In this view, this study develops an optimal deep transfer learning-based human-centric biomedical diagnosis model for acute lymphoblastic detection (ODLHBD-ALLD). The presented ODLHBD-ALLD model mainly intends to detect and classify acute lymphoblastic leukemia using blood smear images. To accomplish this, the ODLHBD-ALLD model involves the Gabor filtering (GF) technique as a noise removal step. In addition, it makes use of a modified fuzzy c-means (MFCM) based segmentation approach for segmenting the images. Besides, the competitive swarm optimization (CSO) algorithm with the EfficientNetB0 model is utilized as a feature extractor. Lastly, the attention-based long-short term memory (ABiLSTM) model is employed for the proper identification of class labels. For investigating the enhanced performance of the ODLHBD-ALLD approach, a wide range of simulations were executed on open access dataset. The comparative analysis reported the betterment of the ODLHBD-ALLD model over the other existing approaches.  © 2022 Manar Ahmed Hamza et al.","","Algorithms; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks, Computer; Precursor Cell Lymphoblastic Leukemia-Lymphoma; Behavioral research; Computer aided diagnosis; Decision making; Diseases; Gabor filters; Image segmentation; Medical imaging; Acute lymphoblastic leukaemias; Biomedical diagnosis; Detection models; Diagnosis model; Disease diagnosis; Healthcare sectors; Hot research topics; Human-centric; Learning models; Transfer learning; acute lymphoblastic leukemia; algorithm; human; image processing; machine learning; pathology; procedures; Deep learning","","","Hindawi Limited","35676951"
"Fang Z.; Dong E.; Tong J.; Sun Z.; Duan F.","Fang, Zhaoguo (57886283400); Dong, Enzeng (8982251000); Tong, Jigang (36495629700); Sun, Zhe (57209204655); Duan, Feng (24537140100)","57886283400; 8982251000; 36495629700; 57209204655; 24537140100","Classification of EEG Signals from Driving Fatigue by Image-Based Deep Recurrent Neural Networks","2022","","","","1773","1777","4","10.1109/ICMA54519.2022.9856167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137789265&doi=10.1109%2fICMA54519.2022.9856167&partnerID=40&md5=13fe7ea08ba2c48ce40ff8708b32976e","Evaluating fatigue driving detection systems has been a major interest of researchers. With the development of deep learning algorithms and multimodal technologies, more and more scholars have begun to look for new representation methods from multi-channel EEG time series data. Here, we propose to convert fatigue and normal state EEG data into a series of topology-preserving multispectral images with accompanying eyelid closure ratio (PERCLOS) labeling input into an image classification-inspired deep recurrent convolutional neural network we train, to find new data-robust representations from image sequences. We used the dataset SEED-VIG published by Shanghai Jiao Tong University in 2017 to help build a fatigue detection system. This dataset contains eye movement signals of 23 subjects and multimodal signals collected by 16 EEG electrodes. We use appropriate frequency bands to characterize fatigue to form color frequency bands, form a three-channel image based on azimuthal equidistant projection and Clough-Tocher interpolation algorithm, and form a two-dimensional image instead of signal as input to the model. The proposed method differs from the eigenvector representation in traditional EEG analysis and aims to preserve the spatial, spectral and temporal structure of the EEG and find the dimensional (frequency) range that best characterizes fatigue. Satisfactory classification results (96%) were obtained on fatigue detection.  © 2022 IEEE.","CNN; EEG; Fatigue Detection; LSTM","Biomedical signal processing; Computerized tomography; Convolution; Deep neural networks; Eye movements; Image classification; Image representation; Long short-term memory; Detection system; Driving fatigue; EEG signals; Fatigue detection; Image-based; LSTM; Multi channel; Multi-modal; Representation method; Time-series data; Convolutional neural networks","National Natural Science Foundation of China, NSFC, (11932013); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Tianjin City, (18JCYBJC87700); Natural Science Foundation of Tianjin City; National Key Research and Development Program of China, NKRDPC, (2017YFE0129700); National Key Research and Development Program of China, NKRDPC; Science Fund for Distinguished Young Scholars of Tianjin, (18JCJQJC46100); Science Fund for Distinguished Young Scholars of Tianjin","","Institute of Electrical and Electronics Engineers Inc.",""
"Nagro S.A.; Kutbi M.A.; Eid W.M.; Alyamani E.J.; Abutarboush M.H.; Altammami M.A.; Sendy B.K.","Nagro, Shimaa A. (57201773286); Kutbi, Mohammed A. (57192438121); Eid, Wafa M. (57881087900); Alyamani, Essam J. (16232219800); Abutarboush, Mohammed H. (57053348900); Altammami, Musaad A. (54973752200); Sendy, Bandar K. (57191334545)","57201773286; 57192438121; 57881087900; 16232219800; 57053348900; 54973752200; 57191334545","Automatic Identification of Single Bacterial Colonies Using Deep and Transfer Learning","2022","10","","","120181","120190","9","10.1109/ACCESS.2022.3221958","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142820337&doi=10.1109%2fACCESS.2022.3221958&partnerID=40&md5=71f1ba80489a13f63dbbe0a621683bd4","Bacterial classification is a vital step in medical diagnosis. This procedure normally has several stages. An early stage involves inspecting the morphology of the bacterial colonies. Traditionally, a bacterial colony expert inspects the sample to determine the type of bacteria through visual inspection or molecular biology techniques. With advances in image processing, specifically, the use of deep and transfer learning techniques, and the wide availability of cameras, we applied deep and transfer learning techniques to address this task without requiring expert knowledge or sample shipping. We used a convolutional neural network (CNN) to identify different bacterial colonies based on their appearance in images captured by cell phone cameras. In this paper, we collected a dataset that contains images of different bacteria taken by cell phone cameras with various settings. Thus, images of two classes of bacterial colonies were obtained in King Abdulaziz City for Science and Technology. The dataset contains 8,043 images. The experimental results show that our application has high accuracy without requiring expert inspections.  © 2013 IEEE.","AlexNet; bacterial classification; bacterial colonies; bacteriology; dataset; deep convolutional neural network; Deep learning; DenseNet; ResNet; SqueezeNet; VGG-16","Automation; Bacteria; Cellular telephones; Computer aided diagnosis; Deep neural networks; Learning algorithms; Medical imaging; Molecular biology; Alexnet; Bacterial classifications; Bacterial colonies; Biomedical imaging; Convolutional neural network; Dataset; Deep convolutional neural network; Deep learning; Densenet; Resnet; Squeezenet; Transfer learning; VGG-16; X-ray imaging; COVID-19","Ministry of Education, Saudi Arabia, (7956)","","Institute of Electrical and Electronics Engineers Inc.",""
"Liu J.; Li Z.; Jin Y.; Liu Y.; Liu C.; Zhao L.; Chen X.","Liu, Jinlei (57217225940); Li, Zhiyuan (57219471508); Jin, Yanrui (57211265874); Liu, Yunqing (57222581061); Liu, Chengliang (7409795747); Zhao, Liqun (57211959543); Chen, Xiaojun (55739098400)","57217225940; 57219471508; 57211265874; 57222581061; 7409795747; 57211959543; 55739098400","A review of arrhythmia detection based on electrocardiogram with artificial intelligence","2022","19","7","","549","560","11","10.1080/17434440.2022.2115887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137042856&doi=10.1080%2f17434440.2022.2115887&partnerID=40&md5=b7c0bfb0e15a032782e61c43507c9ae2","Introduction: With the widespread availability of portable electrocardiogram (ECG) devices, there will be a surge in ECG diagnoses. Traditional computer-aided diagnosis of arrhythmia mainly relies on the rules of medical knowledge, which are insufficient due to the limitations of data quality and human expert knowledge. The research of arrhythmia detection methods based on artificial intelligence (AI) techniques can assist physicians in high-precision arrhythmia diagnosis. AI algorithms can also be embedded in smart ECG devices to help more people perform early screening for arrhythmia. Areas covered: The primary objective of this paper is to describe the application of AI methods in the process of arrhythmia detection. Meanwhile, the advantages and limitations of various approaches in different applications are summarized to provide guidance and reference for future research work. Expert opinion: Machine learning (ML) and deep learning (DL) algorithms can be more effectively employed to handle ECG signal denoising and quality assessment, wave detection and delineation, and arrhythmia classification problems. The DL approach can automatically learn deep representation features and temporal features of the ECG signal for heartbeat or rhythm classification. The application of AI methods for arrhythmia detection systems will significantly relieve the pressure on physicians to analyze ECGs. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Arrhythmia; deep learning; electrocardiogram; heartbeat classification; machine learning; signal quality assessment; wave delineation","Algorithms; Arrhythmias, Cardiac; Artificial Intelligence; Electrocardiography; Heart Rate; Humans; Biomedical signal processing; Computer aided diagnosis; Deep learning; Diseases; Learning systems; Signal denoising; Arrhythmia; Arrhythmia detection; Artificial intelligence methods; Deep learning; Electrocardiogram signal; Heartbeat classifications; Machine-learning; Signal quality assessment; Traditional computers; Wave delineation; algorithm; artificial intelligence; automation; classification algorithm; clinical assessment; clinical effectiveness; convolutional neural network; deep learning; electrocardiography; feature extraction; feature learning (machine learning); heart arrhythmia; human; image processing; machine learning; QRS complex; quality control; Review; sequence learning; heart arrhythmia; heart rate; Electrocardiograms","Science and Technology Commission of Shanghai Municipality, STCSM, (2021SHZDZX0102); Science and Technology Commission of Shanghai Municipality, STCSM; National Key Research and Development Program of China, NKRDPC, (2018YFB1307005); National Key Research and Development Program of China, NKRDPC","","Taylor and Francis Ltd.","35993248"
"Ragab M.; Nahhas A.F.","Ragab, Mahmoud (55932216500); Nahhas, Alaa F. (57202251728)","55932216500; 57202251728","Optimal Deep Transfer Learning Model for Histopathological Breast Cancer Classification","2022","73","2","","2849","2864","15","10.32604/cmc.2022.028855","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132314819&doi=10.32604%2fcmc.2022.028855&partnerID=40&md5=536a88bbd831e1cfea5c1017a004cdb8","Earlier recognition of breast cancer is crucial to decrease the severity and optimize the survival rate. One of the commonly utilized imaging modalities for breast cancer is histopathological images. Since manual inspection of histopathological images is a challenging task, automated tools using deep learning (DL) and artificial intelligence (AI) approaches need to be designed. The latest advances of DL models help in accomplishing maximum image classification performance in several application areas. In this view, this study develops a Deep Transfer Learning with Rider Optimization Algorithm for Histopathological Classification of Breast Cancer (DTLRO-HCBC) technique. The proposed DTLRO-HCBC technique aims to categorize the existence of breast cancer using histopathological images. To accomplish this, the DTLRO-HCBC technique undergoes pre-processing and data augmentation to increase quantitative analysis. Then, optimal SqueezeNet model is employed for feature extractor and the hyperparameter tuning process is carried out using the Adadelta optimizer. Finally, rider optimization with deep feed forward neural network (RO-DFFNN) technique was utilized employed for breast cancer classification. The RO algorithm is applied for optimally adjusting the weight and bias values of the DFFNN technique. For demonstrating the greater performance of the DTLRO-HCBC approach, a sequence of simulations were carried out and the outcomes reported its promising performance over the current state of art approaches. © 2022 Tech Science Press. All rights reserved.","biomedical analysis; Breast cancer; computer vision; deep learning; histopathological images; machine learning","Computer vision; Convolutional neural networks; Data handling; Deep learning; Diseases; Feedforward neural networks; Learning systems; Medical imaging; Biomedical analysis; Breast Cancer; Breast cancer classifications; Deep learning; Histopathological images; Learning models; Machine-learning; Optimization algorithms; Performance; Transfer learning; Image classification","King Abdulaziz University, KAU, (D-773-130-1443); Deanship of Scientific Research, King Saud University","","Tech Science Press",""
"","","","1st International Symposium on Bioinformatics and Biomedicine, BioInfoMed 2020","2022","374 LNNS","","","","","454","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127033336&partnerID=40&md5=63bea6ac8d683f8b47c81de6c5a5a38f","The proceedings contain 46 papers. The special focus in this conference is on Bioinformatics and Biomedicine. The topics include: A Generalized Net Model with Intuitionistic Fuzzy Assessments of the Process of Cardiopulmonary Resuscitation; A Generalized Net Model of the Pattern of Behavior in Patients with eGFR &lt; 20 mL/min (CKD Stage IV-V); generalized Net Model of Biometric Authentication System Based on Palm Geometry and Palm Vein Matching; A Generalized Net Model of the Process of Obtaining and Diagnosing Convalescent Plasma from Patients with COVID-19; Possible Application of Generalized Nets in Telemedicine Screening of Corona Virus Disease 2019 (COVID-19); generalized Net Model of the Upper Limb Arterial Supply System; generalized Net Model of Ant Lion Optimizer; Implementation of Expanding Hierarchical Operators in GN IDE; fuzzy U-Net Neural Network Design for Image Segmentation; a Comparative Machine Learning Modelling Approach for Patients’ Mortality Prediction in Hospital Intensive Care Unit; effects of Variable Impulsive Perturbations on the Stability of Fractional-Order Cohen–Grossberg Neural Networks with Respect to Functions; visualization on Stability of Impulsive Cohen-Grossberg Neural Networks with Time-Varying Delays; performance Prediction of a Microbial Fuel Cell Based on Artificial Neural Networks; functional Outcome Prediction of Operated Proximal Humerus Fractures by Means of Artificial Neural Networks; application of Virtual Reality as a Tool for Structural Analysis of Molecules – Steroids, Pharmaceuticals and Pesticides; in-silico Investigation of Human Visual System; Sequence-Based Prediction of Food-Originated ACE Inhibitory Peptides Using Deep Learning Algorithm; Cascading Approach for Automatic ICD-10 Codes Association To Diseases in Bulgarian; interval-Valued Intuitionistic Fuzzy Estimations of an Ultrasonic Image for Recognition Purposes; intuitionistic Fuzzy Representation of Uncertainty in Biomedical Operations; resveratrol Stiffens 1-palmitoyl-2-oleoyl-sn-glycero-3-phosphocholine Bilayers.","","","","Sotirov S.S.; Pencheva T.; Kacprzyk J.; Atanassov K.T.; Sotirova E.; Staneva G.","Springer Science and Business Media Deutschland GmbH",""
"Liu W.; Lu B.","Liu, Wansu (57315844700); Lu, Biao (57469530700)","57315844700; 57469530700","Multi-Stream Convolutional Neural Network-Based Wearable, Flexible Bionic Gesture Surface Muscle Feature Extraction and Recognition","2022","10","","833793","","","","10.3389/fbioe.2022.833793","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127125352&doi=10.3389%2ffbioe.2022.833793&partnerID=40&md5=794b12aa32a61eb2a1e4d4bf1de73065","Surface electromyographic (sEMG) signals are weak physiological electrical signals, which are highly susceptible to coupling external noise and cause major difficulties in signal acquisition and processing. The study of using sEMG signals to analyze human motion intention mainly involves data preprocessing, feature extraction, and model classification. Feature extraction is an extremely critical part; however, this often involves many manually designed features with specialized domain knowledge, so the experimenter will spend time and effort on feature extraction. To address this problem, deep learning methods that can automatically extract features are applied to the sEMG-based gesture recognition problem, drawing on the success of deep learning for image classification. In this paper, sEMG is captured using a wearable, flexible bionic device, which is simple to operate and highly secure. A multi-stream convolutional neural network algorithm is proposed to enhance the ability of sEMG to characterize hand actions in gesture recognition. The algorithm virtually augments the signal channels by reconstructing the sample structure of the sEMG to provide richer input information for gesture recognition. The methods for noise processing, active segment detection, and feature extraction are investigated, and a basic method for gesture recognition based on the combination of multichannel sEMG signals and inertial signals is proposed. Suitable filters are designed for the common noise in the signal. An improved moving average method based on the valve domain is used to reduce the segmentation error rate caused by the short resting signal time in continuous gesture signals. In this paper, three machine learning algorithms, K-nearest neighbor, linear discriminant method, and multi-stream convolutional neural network, are used for hand action classification experiments, and the effectiveness of the multi-stream convolutional neural network algorithm is demonstrated by comparison of the results. To improve the accuracy of hand action recognition, a final 10 gesture classification accuracy of up to 93.69% was obtained. The separability analysis showed significant differences in the signals of the two cognitive-behavioral tasks when the optimal electrode combination was used. A cross-subject analysis of the test set subjects illustrated that the average correct classification rate using the pervasive electrode combination could reach 93.18%. Copyright © 2022 Liu and Lu.","bionic gestures; feature extraction recognition; multistream convolutional neural networks; surface muscles; wearable flexibility","Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Domain Knowledge; Electrodes; Extraction; Feature extraction; Gesture recognition; Learning algorithms; Nearest neighbor search; Wearable technology; Bionic gesture; Convolutional neural network; Electromyographic; Feature extraction recognition; Features extraction; Gestures recognition; Multi-stream; Multistream convolutional neural network; Surface muscle; Wearable flexibility; Muscle","Collaborative Innovation Center?Cloud Computing Industry; Excellent Academic and Technical Backbone University, (2020XJGG01); Key Disciplines of Computer Science and Technology, (2018jyxm0960, 2019xjzdxk1, 4199106); Key Scientific Research Project of Suzhou University in 2020, (2020yzd01)","","Frontiers Media S.A.",""
"Abdelminaam D.S.; Fahmy A.G.; Ali Y.M.; El-Din O.A.D.; Aly A.R.; Heidar M.","Abdelminaam, Diaa Salama (55630276000); Fahmy, Andrew Gamal (57754606000); Ali, Youssef Mohamed (57755267300); El-Din, Omar Ahmed Diaa (57755934600); Aly, Ahmed Raouf (57753609800); Heidar, Mahmoud (57754606100)","55630276000; 57754606000; 57755267300; 57755934600; 57753609800; 57754606100","DeepECG :Building an Efficient Framework for Automatic Arrhythmia classification model","2022","","","","203","209","6","10.1109/MIUCC55081.2022.9781646","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132440473&doi=10.1109%2fMIUCC55081.2022.9781646&partnerID=40&md5=7aad39c27479ad08184c7d99905ac015","ECG analysis is useful for determining heart health. As a result, cardiovascular disorders require the identification and classification of ECG signals. Not only is early prevention crucial, but so is rapid discovery and treatment. The classification of related ECG signals is extremely important in modern medicine, the electrocardiogram (ECG) is one of the four major components of a routine medical evaluation. The electrocardiogram (ECG) is the safest and most effective method of identifying cardiovascular disorders. ECG measurement has become more convenient and faster as a result of advances in electronic information technology, which offers numerous benefits. ECG automated classification requires a large amount of data. Machine learning and deep learning networks have made significant progress in the recent years, not only in image processing, voice recognition, and a variety of other domains. It has also been widely used to assist in the diagnosis of cardiac illness using ECG signals. Also deep learning has been applied successfully for the classification of the arrhythmia from ECG signals. The main objective of this paper is to recognize and classify ECG signals. The methods used will help in effectively evaluating heart health easily. The proposed framework will focus on mainly classification of ECG signals for detecting arrhythmia, we propose machine learning algorithm for auto classifying and detection arrhythmia diseases using four machine learning techniques and one deep lerning algorithm. Experimental results outperform a wide variety of state-of-the-art approaches. The proposed algorithms accuracies are 98%(KNN), 99%(DT), 92%(SVM), 95%(RF), 77%(LR) and 98%(CNN) respectively. © 2022 IEEE.","Arrhythmia classification; CNN; Convolutional Neural Networks; ECG; Optimized Framework","Biomedical signal processing; Convolutional neural networks; Deep learning; Diseases; Image processing; Learning algorithms; Learning systems; Support vector machines; Arrhythmia classification; Automated classification; Classification models; Convolutional neural network; Electrocardiogram analysis; Electrocardiogram signal; Electronic information; Large amounts of data; Modern medicine; Optimized framework; Electrocardiograms","","Bahaa-Eldin A.; AbdelRaouf A.; Shorim N.; Refaat S.; Elbohy S.E.","Institute of Electrical and Electronics Engineers Inc.",""
"Luo Y.; Ma Y.; O’ Brien H.; Jiang K.; Kohli V.; Maidelin S.; Saeed M.; Deng E.; Pushparajah K.; Rhode K.S.","Luo, Yimin (57199124543); Ma, Yingliang (55570539600); O’ Brien, Hugh (57411898000); Jiang, Kui (57203871718); Kohli, Vikram (57209682598); Maidelin, Sesilia (57411898100); Saeed, Mahrukh (57412303800); Deng, Emily (57411624300); Pushparajah, Kuberan (6505850994); Rhode, Kawal S. (9245867600)","57199124543; 55570539600; 57411898000; 57203871718; 57209682598; 57411898100; 57412303800; 57411624300; 6505850994; 9245867600","Edge-enhancement densenet for X-ray fluoroscopy image denoising in cardiac electrophysiology procedures","2022","49","2","","1262","1275","13","10.1002/mp.15426","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122836336&doi=10.1002%2fmp.15426&partnerID=40&md5=65c7deba4a2a81f0f818fa86e3cd05bd","Purpose: Reducing X-ray dose increases safety in cardiac electrophysiology procedures but also increases image noise and artifacts which may affect the discernibility of devices and anatomical cues. Previous denoising methods based on convolutional neural networks (CNNs) have shown improvements in the quality of low-dose X-ray fluoroscopy images but may compromise clinically important details required by cardiologists. Methods: In order to obtain denoised X-ray fluoroscopy images whilst preserving details, we propose a novel deep-learning-based denoising framework, namely edge-enhancement densenet (EEDN), in which an attention-awareness edge-enhancement module is designed to increase edge sharpness. In this framework, a CNN-based denoiser is first used to generate an initial denoising result. Contours representing edge information are then extracted using an attention block and a group of interacted ultra-dense blocks for edge feature representation. Finally, the initial denoising result and enhanced edges are combined to generate the final X-ray image. The proposed denoising framework was tested on a total of 3262 clinical images taken from 100 low-dose X-ray sequences acquired from 20 patients. The performance was assessed by pairwise voting from five cardiologists as well as quantitative indicators. Furthermore, we evaluated our technique's effect on catheter detection using 416 images containing coronary sinus catheters in order to examine its influence as a pre-processing tool. Results: The average signal-to-noise ratio of X-ray images denoised with EEDN was 24.5, which was 2.2 times higher than that of the original images. The accuracy of catheter detection from EEDN denoised sequences showed no significant difference compared with their original counterparts. Moreover, EEDN received the highest average votes in our clinician assessment when compared to our existing technique and the original images. Conclusion: The proposed deep learning-based framework shows promising capability for denoising interventional X-ray fluoroscopy images. The results from the catheter detection show that the network does not affect the results of such an algorithm when used as a pre-processing step. The extensive qualitative and quantitative evaluations suggest that the network may be of benefit to reduce radiation dose when applied in real time in the catheter laboratory. © 2021 The Authors. Medical Physics published by Wiley Periodicals LLC on behalf of American Association of Physicists in Medicine.","cardiac electrophysiology procedures; convolutional neural network; denoising; edge enhancement; X-ray fluoroscopy","Electrophysiologic Techniques, Cardiac; Fluoroscopy; Humans; Neural Networks, Computer; Signal-To-Noise Ratio; X-Rays; Biomedical signal processing; Catheters; Convolution; Deep learning; Electrophysiology; Heart; Image denoising; Image enhancement; Neurology; Signal to noise ratio; Cardiac electrophysiology; Cardiac electrophysiology procedure; Catheter detections; Convolutional neural network; De-noising; Edge enhancements; Electrophysiology procedure; Fluoroscopy images; Low dose; X-ray fluoroscopy; Article; artifact reduction; cardiologist; cardiovascular procedure; clinical assessment; clinical evaluation; computer vision; convolutional neural network; deconvolution; deep learning; digitization; feature extraction; fluoroscopy; heart catheterization; heart electrophysiology; heart pacing; human; image denoising; image processing; mean squared error; noise reduction; quantitative analysis; radiation dose; radiofrequency ablation; signal noise ratio; thorax radiography; vision; fluoroscopy; heart function test; X ray; Convolutional neural networks","Centre for Medical Engineering; King's College London‐China; NIHR Biomedical Research Centre, Royal Marsden NHS Foundation Trust/Institute of Cancer Research, BRC; National Institute for Health and Care Research, NIHR; King's College London, KCL; Guy's and St Thomas' NHS Foundation Trust; National Institute for Health Research Biomedical Research Centre at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology; Centre For Medical Engineering, King’s College London, CME, (WT 203148/Z/16/Z)","","John Wiley and Sons Ltd","34954836"
"Liu H.; Liu Y.; Wang Y.; Liu B.; Bao X.","Liu, Haofeng (58171529200); Liu, Yuefeng (56002608700); Wang, Yue (56301578700); Liu, Bo (57207810645); Bao, Xiang (58591687000)","58171529200; 56002608700; 56301578700; 57207810645; 58591687000","EEG classification algorithm of motor imagery based on CNN-Transformer fusion network","2022","","","","1302","1309","7","10.1109/TrustCom56396.2022.00182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151750344&doi=10.1109%2fTrustCom56396.2022.00182&partnerID=40&md5=300c58dba743162dd5e600a565b4c3c8","In recent years, with the development of social economy and technology, the brain-computer interface based on motor imagery(MI-BCI) has gradually become the focus content of many re-searchers. However, the motor imagery EEG signal (MI-EEG) itself has the characteristics of non-linearity and low signal-to-noise ratio, and because the characteristics of different domains of MI-EEG cannot be effectively combined, the recognition rate of MI-EEG is unsatisfactory. To overcome the above problems, this paper proposes a Transformer-based one-dimensional convolutional neural network model(CNN-Transformer) for the classification and recognition of four types of motor imagery EEG signals. Firstly, the artifacts of the original EEG are removed and new time-space-frequency features are constructed by preprocessing such as bandpass filtering and PCA dimensionality; then, the local features in the temporal dimension are extracted through the convolution and pooling operations of 1D-CNN, while reducing the dimension of the time feature; next, the Transformer based on the attention mechanism is used to extract more abstract and high-level temporal features from multiple perspectives; finally, the classification results are integrated and output through the fully connected layer. The performance of the CNN-Transformer model is evaluated using the competition dataset 2008 BCI-Competition 2A. The results show that the average accuracy and kappa value of the CNN-Transformer model are as high as 99.29%(±0.07%) and 98.43%(±0.21), respectively, which are 3.72% and 7.68% higher than the classical architecture (CNN-LSTM). This model provides a design idea for improving the accuracy of MI-EEG classification and recognition, and also lays a foundation for the wide application of MI-BCI. © 2022 IEEE.","brain-computer interface; classification and recognition; convolutional neural network; deep learning; motor imagery; transformer","Biomedical signal processing; Brain computer interface; Convolution; Economic and social effects; Image classification; Long short-term memory; Signal to noise ratio; Classification algorithm; Classification and recognition; Convolutional neural network; Deep learning; EEG classification; EEG signals; Motor imagery; Motor imagery EEG; Transformer; Transformer modeling; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Salami A.; Andreu-Perez J.; Gillmeister H.","Salami, Abbas (57218767719); Andreu-Perez, Javier (55653526300); Gillmeister, Helge (6504344958)","57218767719; 55653526300; 6504344958","EEG-ITNet: An Explainable Inception Temporal Convolutional Network for Motor Imagery Classification","2022","10","","","36672","36685","13","10.1109/ACCESS.2022.3161489","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127075047&doi=10.1109%2fACCESS.2022.3161489&partnerID=40&md5=c8045420028af71c1cded7772ef22864","In recent years, neural networks and especially deep architectures have received substantial attention for EEG signal analysis in the field of brain-computer interfaces (BCIs). In this ongoing research area, the end-to-end models are more favoured than traditional approaches requiring signal transformation pre-classification. They can eliminate the need for prior information from experts and the extraction of handcrafted features. However, although several deep learning algorithms have been already proposed in the literature, achieving high accuracies for classifying motor movements or mental tasks, they often face a lack of interpretability and therefore are not quite favoured by the neuroscience community. The reasons behind this issue can be the high number of parameters and the sensitivity of deep neural networks to capture tiny yet unrelated discriminative features. We propose an end-to-end deep learning architecture called EEG-ITNet and a more comprehensible method to visualise the network learned patterns. Using inception modules and causal convolutions with dilation, our model can extract rich spectral, spatial, and temporal information from multi-channel EEG signals with less complexity (in terms of the number of trainable parameters) than other existing end-to-end architectures, such as EEG-Inception and EEG-TCNet. By an exhaustive evaluation on dataset 2a from BCI competition IV and OpenBMI motor imagery dataset, EEG-ITNet shows up to 5.9% improvement in the classification accuracy in different scenarios with statistical significance compared to its competitors. We also comprehensively explain and support the validity of network illustration from a neuroscientific perspective. We have also made our code freely accessible at https://github.com/AbbasSalami/EEG-ITNet.  © 2013 IEEE.","Brain-computer interface; deep learning; deep neural network visualisation; inception module; motor imagery; temporal convolutional network","Biomedical signal processing; Classification (of information); Computer architecture; Convolution; Deep neural networks; Electroencephalography; Electrophysiology; Extraction; Feature extraction; Image enhancement; Interfaces (computer); Learning algorithms; Network architecture; Visualization; Convolutional networks; Convolutional neural network; Deep learning; Deep neural network visualization; Features extraction; Inception module; Kernel; Motor imagery; Network visualization; Temporal convolutional network; Brain computer interface","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","International Conference on Recent Progresses in Science, Engineering and Technology, ICRPSET 2022","2022","","","","","","263","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167619205&partnerID=40&md5=11ac0b546adaf16b1fc1c7618e8210b9","The proceedings contain 53 papers. The topics discussed include: transfer learning in deep neural network model of ECG signal classification; deep neural network based algorithm for stroke prediction; design and performance evaluation of a gigabit passive optical network (GPON) through fiber-to-the-home (FTTH) technology; transformation of urban growth and shrinkage of Khulna City in Bangladesh: a remote sensing based approach; a feature engineering approach for detecting cyberbullying in Bangla text using machine learning; an image restoration technique using patch-based reference frame for through-the-air imaging; design and analysis of robust two stage op-amp using 90 nm CMOS technology for biomedical applications; tentative design and feasibility assessment of grid connected hydro-power based hybrid renewable energy - a case study; automatic Bangla signboard and region of text interests detection from natural scene; spatiotemporal changes in aerosol loadings across Bangladesh from 2010-2021; design and implementation of a low-cost Arduino based line follower gardener robot; and pattern analysis of aerosol optical depth and its relationship with meteorological parameters over Bangladesh during the Covid-19 pandemic lockdown.","","","","","Institute of Electrical and Electronics Engineers Inc.",""
"Sobhanan Warrier G.; Amirthalakshmi T.M.; Nimala K.; Thaj Mary Delsy T.; Stella Rose Malar P.; Ramkumar G.; Raju R.","Sobhanan Warrier, Gayathry (57209854734); Amirthalakshmi, T.M. (57189231482); Nimala, K. (56168268800); Thaj Mary Delsy, T. (56584594600); Stella Rose Malar, P. (57859229300); Ramkumar, G. (56654228700); Raju, Raja (59158128700)","57209854734; 57189231482; 56168268800; 56584594600; 57859229300; 56654228700; 59158128700","Automated Recognition of Cancer Tissues through Deep Learning Framework from the Photoacoustic Specimen","2022","2022","","4356744","","","","10.1155/2022/4356744","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136595096&doi=10.1155%2f2022%2f4356744&partnerID=40&md5=cc8644eee0a4ef1695e606915a9ffb52","The fast advancement of biomedical research technology has expanded and enhanced the spectrum of diagnostic instruments. Various research groups have found optical imaging, ultrasonic imaging, and magnetic resonance imaging to create multifunctional devices that are critical for biomedical activities. Multispectral photoacoustic imaging that integrates the ideas of optical and ultrasonic technologies is one of the most essential instruments. At the same time, early cancer identification is becoming increasingly important in order to minimize fatality. Deep learning (DL) techniques have recently advanced to the point where they can be used to diagnose and classify cancer using biological images. This paper describes a hybrid optimization method that combines in-depth transfer learning-based cancer detection with multispectral photoacoustic imaging. The goal of the PS-ACO-RNN approach is to use ultrasound images to detect and classify the presence of cancer. Bilateral filtration (BF) is often used as a noise removal approach in image processing. In addition, lightweight LEDNet models are used to separate the biological images. A feature extractor with particle swarm with ant colony optimization (PS-ACO) paradigm can also be used. Finally, biological images assign appropriate class labels using a recurrent neural network (RNN) model. The effectiveness of the PS-ACO-RNN technique is verified using a benchmark database, and test results show that the PS-ACO-RNN approach works better than current approaches.  © 2022 Gayathry Sobhanan Warrier et al.","","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Neoplasms; Neural Networks, Computer; ant colony optimization; Article; cancer classification; cancer diagnosis; data base; deep learning; diagnostic accuracy; diagnostic test accuracy study; echography; human; image processing; intermethod comparison; multispectral imaging; noise reduction; particle swarm optimization; photoacoustics; recurrent neural network; algorithm; diagnostic imaging; neoplasm; procedures","","","Hindawi Limited","36017020"
"Shultzman A.; Eldar Y.C.","Shultzman, Avner (57218510812); Eldar, Yonina C. (35562426100)","57218510812; 35562426100","Nonlinear Waveform Inversion for Quantitative Ultrasound","2022","8","","","893","904","11","10.1109/TCI.2022.3208515","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139443729&doi=10.1109%2fTCI.2022.3208515&partnerID=40&md5=35300e4c6946c274b8834ba3abe14f68","Due to its non-invasive and non-radiating nature, along with its low cost, ultrasound (US) imaging is widely used in medical applications. Typical B-mode US images have limited resolution and contrast and weak physical interpretation. Inverse US methods were developed to reconstruct the media's speed-of-sound (SoS) based on a linear acoustic model. However, the wave propagation in medical US is governed by nonlinear acoustics, which introduces more complex behaviors neglected in the linear model. In this work we propose a nonlinear waveform inversion (NWI) approach for quantitative US, that considers a nonlinear acoustics model to simultaneously reconstruct multiple material properties, including the medium's SoS, density, attenuation, and nonlinearity parameter. We thus broaden current inverse US approaches, such as the full waveform inversion (FWI) algorithm, by considering nonlinear media, and additional physical parameters. We represent the nonlinear acoustic model by means of a recurrent neural network, which enables us to apply advanced optimization algorithms borrowed from the deep learning toolbox and achieve more efficient reconstructions compared to the FWI method. We evaluate the performance of our approach on in-silico data and show that neglecting nonlinear effects may result in substantial degradation in the reconstruction, paving the way of NWI into clinical applications.  © 2015 IEEE.","Biomedical imaging; inverse problems; nonlinear acoustics; recurrent neural networks; ultrasonic variables measurement","Acoustic wave propagation; Image reconstruction; Medical imaging; Recurrent neural networks; Systems engineering; Tomography; Ultrasonics; Waveform analysis; Acoustic pulse; Acoustics waves; Biomedical imaging; Computational modelling; Images reconstruction; Medium; Non-linear acoustics; Nonlinear waveform; Propagation; Ultrasonic variable measurement; Inverse problems","Manya Igel Centre for Biomedical Engineering and Signal Processing; European Research Council, ERC; Horizon 2020, (101000967)","","Institute of Electrical and Electronics Engineers Inc.",""
"Babikir A.K.O.; Thron C.","Babikir, Aml Kamal Osman (57567575600); Thron, Christopher (7003625301)","57567575600; 7003625301","Malaria Detection Using Machine Learning","2022","1006","","","139","153","14","10.1007/978-3-030-92245-0_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127852770&doi=10.1007%2f978-3-030-92245-0_7&partnerID=40&md5=a8b785ab99415d917f0b9c3b8cf0b4f5","In spite of great improvements in healthcare around the globe, malaria remains a huge burden, with millions of infections occurring yearly. The first step in fighting malaria is to have an accurate, fast, and trusted diagnosing method, which is a problem facing lab technicians worldwide. In Sudan, the burden of malaria is especially heavy because the healthcare system is weakly structured, the number of qualified personnel to conduct an accurate diagnosis is low, and the number of samples that can be tested per day is limited. Machine learning and deep learning algorithms have the potential for addressing these problems by partially automating the process. This chapter describes the design, implementation, and testing of a machine learning model that detects one of the most widespread malaria parasites (Plasmodium falciparum) using samples of thin blood smears on standard microscope slides that were taken by local laboratories in Khartoum, Sudan. A watershed segmentation technique is used to acquire the erythrocytes from microscopic blood sample images, followed by a deep learning classifier. The classifier is based on a convolutional neural network (CNN) obtained using transfer learning: first, a base CNN is trained using a large publicly available dataset of stained infected and uninfected cells; then, several layers are appended to the CNN, which is retrained using locally obtained cell images, with image augmentation. Results showed that although good performance is obtained on the public dataset with the base CNN, the retrained CNN performs poorly on local images. Two reasons for this are the small number of local images available for training, as well as the poor quality of local images. We conclude that these factors pose significant obstacles for the use of machine learning in biomedical applications in developing countries. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Blood; Cell images; Clinical diagnosis; Convolutional neural network; Dataset; Detection; Healthcare; Infections; Labs; Machine learning; Malaria; Microscopy; PCR; Plasmodium; Procedure; Regression; Techniques; Threshold; Transfer learning; Tropical","","","","Springer Science and Business Media Deutschland GmbH",""
"Chen H.; Gao J.; Zhao D.; Wang H.; Song H.; Su Q.","Chen, Hongyang (57935194000); Gao, Jingyang (55995325700); Zhao, Di (56701350400); Wang, Hongzhi (57193402519); Song, Hong (7404037613); Su, Qinghua (50362000500)","57935194000; 55995325700; 56701350400; 57193402519; 7404037613; 50362000500","Review of the research progress in deep learning and biomedical image analysis till 2020; [深度学习与生物医学图像分析2020年综述]","2021","26","3","","475","486","11","10.11834/jig.200351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104664544&doi=10.11834%2fjig.200351&partnerID=40&md5=c4631c28d4b66b831314279da402a26f","Medical big data mainly include electronic health record data, such as medical imaging data and genetic information data, among which medical imaging data takes up the most of medical data currently. One of the problems that researchers in computer science are greatly concerned about is how to apply medical big data in clinical practice.Artificial intelligence (AI) provides a good way to address this problem. AI algorithms, particularly deep learning, have demonstrated remarkable progress in image-recognition tasks. Historically, in radiology practice, trained physicians visually assess medical images for the detection, characterization, and monitoring of diseases. AI methods excel at automatically recognizing complex patterns in imaging data and providing quantitative, rather than qualitative, assessments of radiographic characteristics. Methods ranging from convolutional neural networks to variational autoencoders have found myriad applications in the medical image analysis field, propelling it forward at a rapid pace. In this review, by combining recent work and the latest research progress of big data analysis of medical images until 2020, we have summarized the theory, main process, and evaluation results of multiple deep learning algorithms in some fields of medical image analysis, including magnetic resonance imaging (MRI), pathology imaging, ultrasound imaging, electrical signals, digital radiography, molybdenum target, and diabetic eye imaging, using deep learning. MRI is one of the main research areas of medical image analysis. The existing research literature includes Alzheimer's disease MRI, Parkinson's disease MRI, brain tumor MRI, prostate cancer MRI, and cardiac MRI. MRI is also divided into two-dimensional and three-dimensional image analysis, especially for three-dimensional data, where insufficient data volume leads to problems such as overfitting, large calculations, and slow training. Medical ultrasound (also known as diagnostic sonography or ultrasonography) is a diagnostic imaging technique or therapeutic application of ultrasound. It is used to create an image of internal body structures such as tendons, muscles, joints, blood vessels, and internal organs. It aims to find the source of a disease or to exclude pathology. The practice of examining pregnant women using ultrasound is called obstetric ultrasonography and was an early development and application of clinical ultrasonography. Ultrasonography uses sound waves with higher frequencies than those audible to humans (>20 000 Hz). Ultrasonic images, also known as sonograms, are made by sending ultrasound pulses into the tissue using a probe. The ultrasound pulses echo off tissues with different reflection properties and are recorded and displayed as an image. Many different types of images can be formed. The most common is a B-mode image (brightness), which displays the acoustic impedance of a two-dimensional cross-section of a tissue. Other types can display blood flow, tissue motion over time, the location of blood, the presence of specific molecules, the stiffness of a tissue, or the anatomy of a three-dimensional region. Pathology is the gold standard for diagnosing some diseases, especially digital image of pathology.We specifically discuss AI combined with digital pathology images for diagnosis. Electroencephalography (EEG) is an electrophysiological monitoring method to record the electrical activity of the brain. It is typically noninvasive, with the electrodes placed along the scalp. However, invasive electrodes are sometimes used, for example in electrocorticography, sometimes called intracranial EEG. EEG is most often used to diagnose epilepsy, which causes abnormalities in EEG readings. It is also used to diagnose sleep disorders, depth of anesthesia, coma, encephalopathies, and brain death. EEG used to be a first-line method of diagnosis for tumors, stroke, and other focal brain disorders, but its use has decreased with the advent of high-resolution anatomical imaging techniques such as MRI and computed tomography (CT). Despite limited spatial resolution, EEG continues to be a valuable tool for research and diagnosis. It is one of the few mobile techniques available and offers millisecond-range temporal resolution, which is not possible with CT, positron emission tomography (PET), or MRI. Electrocardiography(ECG or EKG) is the process of producing an electrocardiogram. It is a graph of voltage versus time of the electrical activity of the heart using electrodes placed on the skin. These electrodes detect small electrical changes that are a consequence of cardiac muscle depolarization followed by repolarization during each cardiac cycle (heartbeat). Changes in the normal ECG pattern occur in numerous cardiac abnormalities, including cardiac rhythm disturbances (e.g., atrial fibrillation and ventricular tachycardia), inadequate coronary artery blood flow (e.g., myocardial ischemia and myocardial infarction), and electrolyte disturbances (e.g., hypokalemia and hyperkalemia).We analyzed the advantages and disadvantages of existing algorithms and the important and difficult points in the field of medical imaging, and introduced the application of intelligent imaging and deep learning in the field of big data analysis and early disease diagnosis. The current algorithms in the field of medical imaging have made considerable progress, but there is still a lot of room for development. We also focus on the optimization and improvement of different algorithms in different sub-fields under a variety of segmentation and classification indicators (e.g., Dice, IoU, accuracy and recall rate), and we look forward to the future development hotspots in this field. Deep learning has developed rapidly in the field of medical imaging and has broad prospects for development. It plays an important role in the early diagnosis of diseases. It can effectively improve the work efficiency of doctors and reduce their burden. Moreover, it has important theoretical research and practical application value. © 2021, Editorial Office of Journal of Image and Graphics. All right reserved.","Deep learning; Magnetic resonance imaging(MRI); Pathology; Review; Target segmentation; Ultrasound","","","","Editorial and Publishing Board of JIG",""
"Heena A.; Biradar N.; Maroof N.M.","Heena, Ayesha (57215537131); Biradar, Nagashettappa (56267698900); Maroof, Najmuddin M. (57215192261)","57215537131; 56267698900; 57215192261","Machine Learning Based Detection and Classification of Heart Abnormalities","2022","300 LNNS","","","15","22","7","10.1007/978-3-030-84760-9_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115630582&doi=10.1007%2f978-3-030-84760-9_2&partnerID=40&md5=777633047b8d07d3bf869a22a39ab80a","Various types of heart abnormalities require various parameters of consideration for effective detection, analysis, processing and classification of heart abnormalities. Like any other disease, prevention is the key to avoid heart diseases. Heart abnormalities are very common not only in India but all over the world, but with better understanding of different symptoms of heart problems, proper diagnosis and prognosis is possible, so that early and optimal treatment is initiated. Particularly in these Pandemic situations of COVID 19 which led to more stress and as a consequence many heart related issues. Deep learning is also vastly employed technique in recent researches for classification of heart images and biomedical images in general. Neural network and support vector machine (SVM) algorithms are also frequently used in classification because of higher accuracy in results. The use of machine learning resulted in improved accuracy and reduced variability in comparison to manual quantification of echocardiographic parameters. A hybrid algorithm (Image enhancement and denoising both carried out in preprocessing task) is developed in this article which can efficiently and effectively classify the heart abnormalities by detecting whether the image is normal or abnormal, if abnormal whether mild stage or critical stage. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Classification; Detection; Gradient modulation; Intensity preservation dynamic histogram equalization; Luminance modulation; Neural network; Support vector machine algorithm","","BKIT Bhalki; KBN College of Engineering; VTU Belagavi and family","Chen J.I.; Tavares J.M.; Iliyasu A.M.; Du K.","Springer Science and Business Media Deutschland GmbH",""
"Liu X.; Lv L.; Shen Y.; Xiong P.; Yang J.; Liu J.","Liu, Xiuling (35115326500); Lv, Linyang (57222148568); Shen, Yonglong (57221081272); Xiong, Peng (36449520300); Yang, Jianli (50562422100); Liu, Jing (56283372200)","35115326500; 57222148568; 57221081272; 36449520300; 50562422100; 56283372200","Multiscale space-time-frequency feature-guided multitask learning CNN for motor imagery EEG classification","2021","18","2","026003","","","","10.1088/1741-2552/abd82b","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101673787&doi=10.1088%2f1741-2552%2fabd82b&partnerID=40&md5=5f46a892825ab3a97c687d2f32f59007","Objective. Motor imagery (MI) electroencephalography (EEG) classification is regarded as a promising technology for brain-computer interface (BCI) systems, which help people to communicate with the outside world using neural activities. However, decoding human intent accurately is a challenging task because of its small signal-to-noise ratio and non-stationary characteristics. Methods that directly extract features from raw EEG signals ignores key frequency domain information. One of the challenges in MI classification tasks is finding a way to supplement the frequency domain information ignored by the raw EEG signal. Approach. In this study, we fuse different models using their complementary characteristics to develop a multiscale space-time-frequency feature-guided multitask learning convolutional neural network (CNN) architecture. The proposed method consists of four modules: the space-time feature-based representation module, time-frequency feature-based representation module, multimodal fused feature-guided generation module, and classification module. The proposed framework is based on multitask learning. The four modules are trained using three tasks simultaneously and jointly optimized. Results. The proposed method is evaluated using three public challenge datasets. Through quantitative analysis, we demonstrate that our proposed method outperforms most state-of-the-art machine learning and deep learning techniques for EEG classification, thereby demonstrating the robustness and effectiveness of our method. Moreover, the proposed method is employed to realize control of robot based on EEG signal, verifying its feasibility in real-time applications. Significance. To the best of our knowledge, a deep CNN architecture that fuses different input cases, which have complementary characteristics, has not been applied to BCI tasks. Because of the interaction of the three tasks in the multitask learning architecture, our method can improve the generalization and accuracy of subject-dependent and subject-independent methods with limited annotated data. © 2021 IOP Publishing Ltd.","deep learning; EEG; motor imagery; multiscale feature; multitask learning","Algorithms; Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Neural Networks, Computer; Biomedical signal processing; Brain; Brain computer interface; Classification (of information); Convolutional neural networks; Deep learning; Electroencephalography; Electrophysiology; Frequency domain analysis; Image classification; Multi-task learning; Network architecture; Signal to noise ratio; Classification tasks; Complementary characteristics; Learning architectures; Learning techniques; Non stationary characteristics; Real-time application; Space-time features; Time frequency features; Article; controlled study; convolutional neural network; cross validation; data processing; deep learning; electroencephalography; feature extraction; human; imagery; machine learning; priority journal; qualitative analysis; quantitative analysis; signal noise ratio; signal processing; algorithm; brain computer interface; electroencephalography; imagination; procedures; Learning systems","","","IOP Publishing Ltd","33395676"
"Yi F.; Park S.; Moon I.","Yi, Faliu (36560720900); Park, Seonghwan (57222426113); Moon, Inkyu (55388941800)","36560720900; 57222426113; 55388941800","High-throughput label-free cell detection and counting from diffraction patterns with deep fully convolutional neural networks","2021","26","3","","","","","10.1117/1.JBO.26.3.036001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102710347&doi=10.1117%2f1.JBO.26.3.036001&partnerID=40&md5=cde0d3a0b06953e5a6a86af21803741a","SIGNIFICANCE: Digital holographic microscopy (DHM) is a promising technique for the study of semitransparent biological specimen such as red blood cells (RBCs). It is important and meaningful to detect and count biological cells at the single cell level in biomedical images for biomarker discovery and disease diagnostics. However, the biological cell analysis based on phase information of images is inefficient due to the complexity of numerical phase reconstruction algorithm applied to raw hologram images. New cell study methods based on diffraction pattern directly are desirable. AIM: Deep fully convolutional networks (FCNs) were developed on raw hologram images directly for high-throughput label-free cell detection and counting to assist the biological cell analysis in the future. APPROACH: The raw diffraction patterns of RBCs were recorded by use of DHM. Ground-truth mask images were labeled based on phase images reconstructed from RBC holograms using numerical reconstruction algorithm. A deep FCN, which is UNet, was trained on the diffraction pattern images to achieve the label-free cell detection and counting. RESULTS: The implemented deep FCNs provide a promising way to high-throughput and label-free counting of RBCs with a counting accuracy of 99% at a throughput rate of greater than 288 cells per second and 200  μm  ×  200  μm field of view at the single cell level. Compared to convolutional neural networks, the FCNs can get much better results in terms of accuracy and throughput rate. CONCLUSIONS: High-throughput label-free cell detection and counting were successfully achieved from diffraction patterns with deep FCNs. It is a promising approach for biological specimen analysis based on raw hologram directly.","cell counting; deep learning; digital holographic microscopy; holography application; optical information processing; red blood cell analysis","Algorithms; Erythrocytes; Holography; Neural Networks, Computer; algorithm; erythrocyte; holography","","","NLM (Medline)","33686845"
"Altameem A.; Sachdev J.S.; Singh V.; Poonia R.C.; Kumar S.; Saudagar A.K.J.","Altameem, Ayman (55331466600); Sachdev, Jaideep Singh (57222403513); Singh, Vijander (57191532025); Poonia, Ramesh Chandra (56638603100); Kumar, Sandeep (57197068167); Saudagar, Abdul Khader Jilani (56166431300)","55331466600; 57222403513; 57191532025; 56638603100; 57197068167; 56166431300","Performance Analysis of Machine Learning Algorithms for Classifying Hand Motion-Based EEG Brain Signals","2022","42","3","","1095","1107","12","10.32604/csse.2022.023256","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124945126&doi=10.32604%2fcsse.2022.023256&partnerID=40&md5=3e9a4ac7e2155cc4705f1e8f9b8b6b63","Brain-computer interfaces (BCIs) records brain activity using electroencephalogram (EEG) headsets in the form of EEG signals; these signals can be recorded, processed and classified into different hand movements, which can be used to control other IoT devices. Classification of hand movements will be one step closer to applying these algorithms in real-life situations using EEG headsets. This paper uses different feature extraction techniques and sophisticated machine learning algorithms to classify hand movements from EEG brain signals to control prosthetic hands for amputated persons. To achieve good classification accuracy, denoising and feature extraction of EEG signals is a significant step. We saw a considerable increase in all the machine learning models when the moving average filter was applied to the raw EEG data. Feature extraction techniques like a fast fourier transform (FFT) and continuous wave transform (CWT) were used in this study; three types of features were extracted, i.e., FFT Features, CWT Coefficients and CWT scalogram images. We trained and compared different machine learning (ML) models like logistic regression, random forest, k-nearest neighbors (KNN), light gradient boosting machine (GBM) and XG boost on FFT and CWT features and deep learning (DL) models like VGG-16, Dense-Net201 and ResNet50 trained on CWT scalogram images. XG Boost with FFT features gave the maximum accuracy of 88%. © 2022 CRL Publishing. All rights reserved.","Brain signal; Brain-computer interface; Convolutional neural networks; Hand motion recognition; Machine learning","Adaptive boosting; Artificial limbs; Biomedical signal processing; Brain; Convolutional neural networks; Decision trees; Deep learning; Electroencephalography; Extraction; Fast Fourier transforms; Feature extraction; Motion estimation; Nearest neighbor search; Brain signals; Continuous Wave; Convolutional neural network; Electroencephalogram signals; Feature extraction techniques; Hand motion; Hand motion recognition; Hands movement; Machine learning algorithms; Motion recognition; Brain computer interface","Deanship of Scientific Research, King Saud University","","Tech Science Press",""
"Liu J.; Ye F.; Xiong H.","Liu, Jinzhen (55804702100); Ye, Fangfang (57223026202); Xiong, Hui (57204024123)","55804702100; 57223026202; 57204024123","Multi-class motor imagery EEG classification method with high accuracy and low individual differences based on hybrid neural network","2021","18","4","0460F1","","","","10.1088/1741-2552/ac1ed0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115157103&doi=10.1088%2f1741-2552%2fac1ed0&partnerID=40&md5=4ed13d9c8f1871b9b68bc47bfbcae55b","Objective. Most current methods of classifying different patterns for motor imagery EEG signals require complex pre-processing and feature extraction steps, which consume time and lack adaptability, ignoring individual differences in EEG signals. It is essential to improve algorithm performance with the increased classes and diversity of subjects. Approach. This study introduces deep learning method for end-to-end learning to complete the classification of four-class MI tasks, aiming to improve the recognition rate and balance the classification accuracy among different subjects. A new one-dimensional input data representation method is proposed. This representation method can increase the number of samples and ignore the influence of channel correlation. In addition, a cascade network of convolutional neural network and gated recurrent unit is designed to learn time-frequency information from EEG data without extracting features manually, this model can capture the hidden representations related to different MI mode of each people. Main results. Experiments on BCI Competition 2a dataset and actual collected dataset achieve high accuracy near 99.40% and 92.56%, and the standard deviation is 0.34 and 1.35 respectively. Results demonstrate that the proposed method outperforms the advanced methods and baseline models. Significance. Experimental results show that the proposed method improves the accuracy of multi-classification and overcomes the impact of individual differences on classification by training neural network subject-dependent, which promotes the development of actual brain-computer interface systems. © 2021 IOP Publishing Ltd.","brain-computer interface; convolutional neural network; gated recurrent unit; individual differences; motor imagery","Algorithms; Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Individuality; Neural Networks, Computer; Biomedical signal processing; Convolution; Convolutional neural networks; Electroencephalography; Image classification; Learning systems; Recurrent neural networks; Classification methods; Convolutional neural network; EEG classification; EEG signals; Gated recurrent unit; High-accuracy; Individual Differences; Motor imagery; Motor imagery EEG; Representation method; Article; comparative study; computer vision; controlled study; convolutional neural network; data processing; deep learning; electroencephalogram; entropy; feature extraction; feed forward neural network; gated recurrent unit network; human; human experiment; imagery; measurement accuracy; memory; normal human; probability; reference electrode; time series analysis; algorithm; brain computer interface; electroencephalography; imagination; individuality; Brain computer interface","Natural Science Foundation Applying System of Tianjin, (18JCQNJC84000, 18JCYBJC90400); National Natural Science Foundation of China, NSFC, (61871288)","","Institute of Physics","34407527"
"Rishika P.S.; Rohith V.","Rishika, P.S. (57289712200); Rohith, V. (57202901951)","57289712200; 57202901951","Identification of Colorectal Cancer in pathological images Using CNN Algorithm","2021","","","","1358","1363","5","10.1109/ICESC51422.2021.9532919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116663591&doi=10.1109%2fICESC51422.2021.9532919&partnerID=40&md5=9e1f70e4879c1efae3ddbf1f8be5eeba","With the advent of machine learning-based approaches, computer-aided diagnosis (CAD) relying on histopathological imaging has advanced fast in several recent years. Traditionally, features derived from images, such as textures or morphological characteristic properties, are used to train a classifier. As of late, profound deep - learning-based techniques have been applied straightforwardly to the crude (natural) information. In any case, their convenience is affected by the scarcity of explained information in the biomedical area. To use the learning abilities of profound deep Convolutional Neural Networks (CNNs) inside the bounds of restricted named information, the proposed approach examines the exchange learning approaches that intend to apply the information acquired from addressing a source (e.g., non-clinical) issue, to learn better prescient models for the objective (e.g., biomedical) task. As another option, another versatile and minimal CNN-based engineering architecture that can be prepared without any preparation even on scant and low-goal information is proposed. In addition, quantitative relative assessments are led among the conventional strategies, move learning-based techniques, and the proposed versatile methodology for the specific errand of disease recognition and recognizable proof from scant and low-goal histology pictures. The major difference between deep CNN and other conventional CNN is stratified patch convolution techniques are used which reduces the overall cost all well can obtain features even from the abstract segment also. Preposterous benchmark dataset framed, for this reason, the proposed versatile methodology accomplished a higher disease recognition exactness with a critical hole, though the deep profound CNNs with move learning accomplished a prevalent malignancy(cancer) recognizable proof. © 2021 IEEE.","Big Data Analysis; Colorectal Cancer (CRC); Convolutional Neural Networks; Deep Learning; Gray Level Co-Occurrence matrix (GLCM); MultisSVM; Region of Interest","Big data; Computer aided diagnosis; Computer aided instruction; Convolution; Convolutional neural networks; Deep neural networks; Image segmentation; Textures; Big data analyse; Colorectal cancer; Convolutional neural network; Deep learning; Gray level co-occurrence matrix; Gray-level co-occurrence matrix; Grey-level co-occurrence matrixes; Multissvm; Region-of-interest; Regions of interest; Diseases","","","Institute of Electrical and Electronics Engineers Inc.",""
"Gu J.; Yang T.S.; Ye J.C.; Yang D.H.","Gu, Jawook (57198346092); Yang, Tae Seong (57227290400); Ye, Jong Chul (7403237499); Yang, Dong Hyun (16177049100)","57198346092; 57227290400; 7403237499; 16177049100","CycleGAN denoising of extreme low-dose cardiac CT using wavelet-assisted noise disentanglement","2021","74","","102209","","","","10.1016/j.media.2021.102209","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113314449&doi=10.1016%2fj.media.2021.102209&partnerID=40&md5=6503e3cf38c20938e05f4dd39b39cdef","In electrocardiography (ECG) gated cardiac CT angiography (CCTA), multiple images covering the entire cardiac cycle are taken continuously, so reduction of the accumulated radiation dose could be an important issue for patient safety. Although ECG-gated dose modulation (so-called ECG pulsing) is used to acquire many phases of CT images at a low dose, the reduction of the radiation dose introduces noise into the image reconstruction. To address this, we developed a high performance unsupervised deep learning method using noise disentanglement that can effectively learn the noise patterns even from extreme low dose CT images. For noise disentanglement, we use a wavelet transform to extract the high-frequency signals that contain the most noise. Since matched low-dose and high-dose cardiac CT data are impossible to obtain in practice, our neural network was trained in an unsupervised manner using cycleGAN for the extracted high frequency signals from the low-dose and unpaired high-dose CT images. Once the network is trained, denoised images are obtained by subtracting the estimated noise components from the input images. Image quality evaluation of the denoised images from only 4% dose CT images was performed by experienced radiologists for several anatomical structures. Visual grading analysis was conducted according to the sharpness level, noise level, and structural visibility. Also, the signal-to-noise ratio was calculated. The evaluation results showed that the quality of the images produced by the proposed method is much improved compared to low-dose CT images and to the baseline cycleGAN results. The proposed noise-disentangled cycleGAN with wavelet transform effectively removed noise from extreme low-dose CT images compared to the existing baseline algorithms. It can be an important denoising platform for low-dose CT. © 2021 Elsevier B.V.","Adversarial training; Coronary CT angiography; Cycle consistency; Low-dose CT; Unsupervised learning; Wavelet transform","Algorithms; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Signal-To-Noise Ratio; Tomography, X-Ray Computed; Biomedical signal processing; Deep learning; Electrocardiography; Grading; Heart; Image compression; Image denoising; Image enhancement; Image quality; Image reconstruction; Learning systems; Quality control; Signal to noise ratio; Wavelet transforms; A-wavelet transform; Anatomical structures; Evaluation results; High frequency signals; Image quality evaluation; Learning methods; Noise components; Visual grading analysis; algorithm; article; computed tomographic angiography; controlled study; deep learning; drug megadose; heart; human; image quality; low drug dose; low-dose computed tomography; radiologist; signal noise ratio; visibility; wavelet transform; algorithm; image processing; signal noise ratio; x-ray computed tomography; Computerized tomography","Development of Novel Artificial Intelligence Technologies To Assist Imaging Diagnosis of Pulmonary; Ministry of Trade, Industry and Energy, MOTIE; Ministry of Health and Welfare, MOHW, (HI18C0022); Korea Health Industry Development Institute, KHIDI","","Elsevier B.V.","34450466"
"Al Hammadi A.Y.; Yeun C.Y.; Damiani E.; Yoo P.D.; Hu J.; Yeun H.K.; Yim M.-S.","Al Hammadi, Ahmed Y. (57223054645); Yeun, Chan Yeob (6508380997); Damiani, Ernesto (57195375517); Yoo, Paul D. (23979079900); Hu, Jiankun (55499371900); Yeun, Hyun Ku (57200176321); Yim, Man-Sung (7005922956)","57223054645; 6508380997; 57195375517; 23979079900; 55499371900; 57200176321; 7005922956","Explainable artificial intelligence to evaluate industrial internal security using EEG signals in IoT framework","2021","123","","102641","","","","10.1016/j.adhoc.2021.102641","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112393109&doi=10.1016%2fj.adhoc.2021.102641&partnerID=40&md5=90318a27f158437923fe7cd53615e3f9","Industrial insider threat detection has consistently been a popular field of research. To help detect potential insider threats, the emotional states of humans are identified through a wide range of physiological signals including the galvanic skin response, electrocardiogram, and electroencephalogram (EEG). This paper presents an insider risk assessment system as a fitness for duty security evaluation using EEG brainwave signals with explainable deep learning and machine learning algorithms to classify abnormal EEG signals indicating a potential insider threat and evaluating fitness for duty. The system is designed to be cost-effective by using an Emotiv Insight EEG device with five electrodes. In this study, the data from 17 people in different emotional states were collected. The different levels of emotions were mapped and classified into four risk levels, namely low, normal, medium, and high. The data were collected while the subjects were presented with different images from the scientific international affective picture system. The collected EEG signals were preprocessed to eliminate noise from physical movements and blinking. The data were then used to train self-feature learning of two- and one-dimensional convolutional neural networks, Adaptive Boosting, random forest, and K-nearest neighbors models; the proposed method yielded classification accuracies of 96, 75, 97, 94 and 81%, respectively. © 2021 Elsevier B.V.","Deep learning; EEG sensor; Explainable artificial intelligence (XAI); Fitness for duty; Industrial insider; Insider threat; Internet of things (IoT); Security evaluation; Two-dimensional CNN","Convolutional neural networks; Cost effectiveness; Decision trees; Deep learning; Electroencephalography; Electrophysiology; Industrial research; Internet of things; Learning algorithms; Learning systems; Nearest neighbor search; Physiological models; Risk assessment; Classification accuracy; Electro-encephalogram (EEG); Fitness for duties; Galvanic skin response; Insider threat detections; K-nearest neighbors; Physiological signals; Security evaluation; Biomedical signal processing","Khalifa University of Science, Technology and Research, KU, (8474000137-RC1-C2PS-T3)","","Elsevier B.V.",""
"Perdios D.; Vonlanthen M.; Martinez F.; Arditi M.; Thiran J.-P.","Perdios, Dimitris (57192071270); Vonlanthen, Manuel (57205571000); Martinez, Florian (57196352448); Arditi, Marcel (7006031772); Thiran, Jean-Philippe (35554798200)","57192071270; 57205571000; 57196352448; 7006031772; 35554798200","CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement Tracking","2021","40","3","9302667","1078","1089","11","10.1109/TMI.2020.3046700","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098783135&doi=10.1109%2fTMI.2020.3046700&partnerID=40&md5=c0abee9bbece47d07c6417da2a9a4465","Thanks to its capability of acquiring full-view frames at multiple kilohertz, ultrafast ultrasound imaging unlocked the analysis of rapidly changing physical phenomena in the human body, with pioneering applications such as ultrasensitive flow imaging in the cardiovascular system or shear-wave elastography. The accuracy achievable with these motion estimation techniques is strongly contingent upon two contradictory requirements: a high quality of consecutive frames and a high frame rate. Indeed, the image quality can usually be improved by increasing the number of steered ultrafast acquisitions, but at the expense of a reduced frame rate and possible motion artifacts. To achieve accurate motion estimation at uncompromised frame rates and immune to motion artifacts, the proposed approach relies on single ultrafast acquisitions to reconstruct high-quality frames and on only two consecutive frames to obtain 2-D displacement estimates. To this end, we deployed a convolutional neural network-based image reconstruction method combined with a speckle tracking algorithm based on cross-correlation. Numerical and in vivo experiments, conducted in the context of plane-wave imaging, demonstrate that the proposed approach is capable of estimating displacements in regions where the presence of side lobe and grating lobe artifacts prevents any displacement estimation with a state-of-the-art technique that relies on conventional delay-and-sum beamforming. The proposed approach may therefore unlock the full potential of ultrafast ultrasound, in applications such as ultrasensitive cardiovascular motion and flow analysis or shear-wave elastography. © 1982-2012 IEEE.","Biomedical imaging; deep learning; diffraction artifacts; displacement estimation; image reconstruction; speckle tracking; ultrafast ultrasound imaging","Algorithms; Elasticity Imaging Techniques; Humans; Image Processing, Computer-Assisted; Motion; Phantoms, Imaging; Ultrasonography; Cardiovascular system; Convolutional neural networks; Image enhancement; Medical imaging; Motion estimation; Shear flow; Shear waves; Ultrasonic imaging; Delay and sum beamforming; Displacement estimation; Displacement tracking; Estimation techniques; Image reconstruction methods; In-vivo experiments; Shear wave elastography; State-of-the-art techniques; accuracy; algorithm; Article; artifact reduction; convolutional neural network; cross correlation; diffraction; human; image quality; image reconstruction; in vivo study; echography; elastography; image processing; imaging phantom; motion; Image reconstruction","","","Institute of Electrical and Electronics Engineers Inc.","33351759"
"Park I.; Lee U.","Park, Ingyu (57195070543); Lee, Unjoo (55598165900)","57195070543; 55598165900","Automatic, qualitative scoring of the clock drawing test (Cdt) based on u‐net, cnn and mobile sensor data","2021","21","15","5239","","","","10.3390/s21155239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111697363&doi=10.3390%2fs21155239&partnerID=40&md5=3af1a334615e426a559482b7b8b15a5c","The Clock Drawing Test (CDT) is a rapid, inexpensive, and popular screening tool for cognitive functions. In spite of its qualitative capabilities in diagnosis of neurological diseases, the assessment of the CDT has depended on quantitative methods as well as manual paper based methods. Furthermore, due to the impact of the advancement of mobile smart devices imbedding several sensors and deep learning algorithms, the necessity of a standardized, qualitative, and automatic scoring system for CDT has been increased. This study presents a mobile phone application, mCDT, for the CDT and suggests a novel, automatic and qualitative scoring method using mobile sensor data and deep learning algorithms: CNN, a convolutional network, U‐Net, a convolutional network for biomedical image segmentation, and the MNIST (Modified National Institute of Standards and Technology) database. To obtain DeepC, a trained model for segmenting a contour image from a hand drawn clock image, U‐Net was trained with 159 CDT hand‐drawn images at 128 × 128 resolu-tion, obtained via mCDT. To construct DeepH, a trained model for segmenting the hands in a clock image, U‐Net was trained with the same 159 CDT 128 × 128 resolution images. For obtaining DeepN, a trained model for classifying the digit images from a hand drawn clock image, CNN was trained with the MNIST database. Using DeepC, DeepH and DeepN with the sensor data, parameters of contour (0–3 points), numbers (0–4 points), hands (0–5 points), and the center (0–1 points) were scored for a total of 13 points. From 219 subjects, performance testing was completed with images and sensor data obtained via mCDT. For an objective performance analysis, all the images were scored and crosschecked by two clinical experts in CDT scaling. Performance test analysis derived a sensitivity, specificity, accuracy and precision for the contour parameter of 89.33, 92.68, 89.95 and 98.15%, for the hands parameter of 80.21, 95.93, 89.04 and 93.90%, for the numbers parameter of 83.87, 95.31, 87.21 and 97.74%, and for the center parameter of 98.42, 86.21, 96.80 and 97.91%, respec-tively. From these results, the mCDT application and its scoring system provide utility in differentiating dementia disease subtypes, being valuable in clinical practice and for studies in the field. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Automatic scoring; Clock drawing test; CNN; Deep learning; MNIST; U‐Net; Wearable sensor","Algorithms; Cognition; Humans; Mass Screening; Neuropsychological Tests; Research Design; Bioinformatics; Classification (of information); Clocks; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Learning algorithms; Learning systems; Accuracy and precision; Biomedical image segmentation; Convolutional networks; Mobile phone applications; Mobile smart devices; National Institute of Standards and Technology; Neurological disease; Performance analysis; algorithm; cognition; human; mass screening; methodology; neuropsychological test; Image segmentation","Basic Science Research, (2020R1F1A1048281); Hallym University, Hallym, (HRF‐202003‐021)","","MDPI AG","34372476"
"Hari K.N.; Karthikeyan B.; Rajasekhar Reddy M.; Seethalakshmi R.","Hari, Karthik N. (57271069000); Karthikeyan, B. (57200009318); Rajasekhar Reddy, M. (56168651800); Seethalakshmi, R. (56036664600)","57271069000; 57200009318; 56168651800; 56036664600","Diabetic Retinopathy Detection with Feature Enhancement and Deep Learning","2021","","","","","","","10.1109/ICSCAN53069.2021.9526438","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115684927&doi=10.1109%2fICSCAN53069.2021.9526438&partnerID=40&md5=4bb4fae22b69ace4fa6ad1dc805f4abc","Diabetic Retinopathy is a medical condition which occurs in people having diabetes. Both type 1 and type 2 diabetes patients are affected by this disease. The major problem is there are no significant symptoms of this disease at its early stages for it to be identified and treated, only when it gets worse it starts to show symptoms. Primarily, there are two major types of diabetic retinopathy which are non-proliferative diabetic retinopathy and proliferative diabetic retinopathy. Non-proliferative diabetic retinopathy is the early stages of the disease which when identified can be treated. Proliferative diabetic retinopathy is the later stage of the disease which when identified is difficult to treat. This disease is both time taking and prone to errors when manually examined by doctors. Deep learning has been in existence for a while and has been efficient in analysing medical images. Convolutional Neural Networks (CNNs) are used for feature extraction from the image and difference of gaussians algorithm is used in improving feature extraction. The dataset used is from Kaggle containing around 35126 images. There are some deep learning models for this problem statement but they don't predict the disease flawlessly. Three convolutional neural networks are trained, validated and tested on the dataset. These models perform better than the existing models in predicting diabetic retinopathy on the Kaggle dataset.  © 2021 IEEE.","Convolutional Neural Networks; Deep Learning; Difference of Gaussians; Fundus Images; Medical Image Computing","Biomedical signal processing; Convolution; Convolutional neural networks; Extraction; Eye protection; Feature extraction; Image enhancement; Medical imaging; Diabetic retinopathy; Difference of Gaussians; Feature enhancement; Learning models; Medical conditions; Problem statement; Type-2 diabetes; Deep learning","SASTRA Deemed University","","Institute of Electrical and Electronics Engineers Inc.",""
"Goswami M.","Goswami, Mayank (55636509800)","55636509800","Deep learning models for benign and malign ocular tumor growth estimation","2021","93","","101986","","","","10.1016/j.compmedimag.2021.101986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115792448&doi=10.1016%2fj.compmedimag.2021.101986&partnerID=40&md5=fc369388af10c8443dda0db183aa6ab7","Relatively abundant availability of medical imaging data has provided significant support in the development and testing of Neural Network based image processing methods. Clinicians often face issues in selecting suitable image processing algorithm for medical imaging data. A strategy for the selection of a proper model is presented here. The training data set comprises optical coherence tomography (OCT) and angiography (OCT-A) images of 50 mice eyes with more than 100 days follow-up. The data contains images from treated and untreated mouse eyes. Four deep learning variants are tested for automatic (a) differentiation of tumor region with healthy retinal layer and (b) segmentation of 3D ocular tumor volumes. Exhaustive sensitivity analysis of deep learning models is performed with respect to the number of training and testing images using eight performance indices to study accuracy, reliability/reproducibility, and speed. U-net with UVgg16 is best for malign tumor data set with treatment (having considerable variation) and U-net with Inception backbone for benign tumor data (with minor variation). Loss value and root mean square error (R.M.S.E.) are found most and least sensitive performance indices, respectively. The performance (via indices) is found to be exponentially improving regarding a number of training images. The segmented OCT-Angiography data shows that neovascularization drives the tumor volume. Image analysis shows that photodynamic imaging-assisted tumor treatment protocol is transforming an aggressively growing tumor into a cyst. An empirical expression is obtained to help medical professionals choose a particular model given the number of images and types of characteristics. We recommend that the presented exercise should be taken as standard practice before employing a particular deep learning model for biomedical image analysis. © 2021 Elsevier Ltd","Cancer growth; Deep CNN; Image segmentation; OCT angiography; OCT imaging","Animals; Deep Learning; Image Processing, Computer-Assisted; Mice; Neoplasms; Neural Networks, Computer; Reproducibility of Results; Tomography, Optical Coherence; Angiography; Bayesian networks; Deep learning; Digital storage; Image analysis; Image enhancement; Image quality; Mammals; Mean square error; Ophthalmology; Optical tomography; Reliability analysis; Sensitivity analysis; Statistical tests; Tumors; Cancer growth; Deep CNN; Images segmentations; Imaging data; Learning models; Ocular tumor; Optical coherence tomography angiography; Optical coherence tomography imaging; Tomography imaging; Tumor volumes; A scan; animal experiment; animal model; antineoplastic protocol; Article; B scan; benign neoplasm; cancer growth; cancer size; classifier; convolutional neural network; deep learning; depth perception; diagnostic accuracy; eye cancer; eye tumor; follow up; image analysis; image segmentation; mouse; neovascularization (pathology); nonhuman; ocular blood vessel; optical coherence tomography; optical coherence tomography angiography; photodynamic therapy; reliability; reproducibility; three-dimensional imaging; tumor differentiation; tumor growth; tumor volume; tumor xenograft; animal; image processing; neoplasm; Image segmentation","BT/IITR; IMPRINT-II; UCDavis","","Elsevier Ltd","34509705"
"Liu Z.; Jin L.; Chen J.; Fang Q.; Ablameyko S.; Yin Z.; Xu Y.","Liu, Zhichao (57224220369); Jin, Luhong (57188997813); Chen, Jincheng (57224226390); Fang, Qiuyu (57224215835); Ablameyko, Sergey (6603926017); Yin, Zhaozheng (36351279000); Xu, Yingke (25936994900)","57224220369; 57188997813; 57224226390; 57224215835; 6603926017; 36351279000; 25936994900","A survey on applications of deep learning in microscopy image analysis","2021","134","","104523","","","","10.1016/j.compbiomed.2021.104523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107265175&doi=10.1016%2fj.compbiomed.2021.104523&partnerID=40&md5=258a4648cf02a90e0cdc1ad27dfa703f","Advanced microscopy enables us to acquire quantities of time-lapse images to visualize the dynamic characteristics of tissues, cells or molecules. Microscopy images typically vary in signal-to-noise ratios and include a wealth of information which require multiple parameters and time-consuming iterative algorithms for processing. Precise analysis and statistical quantification are often needed for the understanding of the biological mechanisms underlying these dynamic image sequences, which has become a big challenge in the field. As deep learning technologies develop quickly, they have been applied in bioimage processing more and more frequently. Novel deep learning models based on convolution neural networks have been developed and illustrated to achieve inspiring outcomes. This review article introduces the applications of deep learning algorithms in microscopy image analysis, which include image classification, region segmentation, object tracking and super-resolution reconstruction. We also discuss the drawbacks of existing deep learning-based methods, especially on the challenges of training datasets acquisition and evaluation, and propose the potential solutions. Furthermore, the latest development of augmented intelligent microscopy that based on deep learning technology may lead to revolution in biomedical research. © 2021 Elsevier Ltd","Deep learning; Image processing; Neural network; Super-resolution microscopy","Algorithms; Deep Learning; Image Processing, Computer-Assisted; Microscopy; Neural Networks, Computer; Deep neural networks; Image analysis; Image segmentation; Iterative methods; Learning algorithms; Signal to noise ratio; Deep learning; Dynamics characteristic; Images processing; Learning technology; Microscopy image analysis; Microscopy images; Neural-networks; Super-resolution microscopy; Time lapse images; Tissue cells; convolutional neural network; deep learning; human tissue; image analysis; image processing; medical research; microscopy; review; signal noise ratio; algorithm; image processing; Optical resolving power","Natural Science Foundation of Zhejiang Province, ZJNSF, (LR18H180001); Natural Science Foundation of Zhejiang Province, ZJNSF; National Key Research and Development Program of China, NKRDPC, (2018YFE0119000); National Key Research and Development Program of China, NKRDPC; Fundamental Research Funds for the Central Universities, (2021XZZX022); Fundamental Research Funds for the Central Universities","","Elsevier Ltd","34091383"
"Matek C.; Krappe S.; Münzenmayer C.; Haferlach T.; Marr C.","Matek, Christian (55368586300); Krappe, Sebastian (36711850400); Münzenmayer, Christian (8639210900); Haferlach, Torsten (57150421100); Marr, Carsten (10539477500)","55368586300; 36711850400; 8639210900; 57150421100; 10539477500","Highly accurate differentiation of bone marrow cell morphologies using deep neural networks on a large image data set","2021","138","20","","1917","1927","10","10.1182/blood.2020010568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119064133&doi=10.1182%2fblood.2020010568&partnerID=40&md5=2acfa4fd314e20e29827625cd993bc7a","Biomedical applications of deep learning algorithms rely on large expert annotated data sets. The classification of bone marrow (BM) cell cytomorphology, an important cornerstone of hematological diagnosis, is still done manually thousands of times every day because of a lack of data sets and trained models. We applied convolutional neural networks (CNNs) to a large data set of 171 374 microscopic cytological images taken from BM smears from 945 patients diagnosed with a variety of hematological diseases. The data set is the largest expert-annotated pool of BM cytology images available in the literature. It allows us to train high-quality classifiers of leukocyte cytomorphology that identify a wide range of diagnostically relevant cell species with high precision and recall. Our CNNs outcompete previous feature-based approaches and provide a proof-of-concept for the classification problem of single BM cells. This study is a step toward automated evaluation of BM cell morphology using state-of-the-art image-classification algorithms. The underlying data set represents an educational resource, as well as a reference for future artificial intelligence–based approaches to BM cytomorphology. © 2021 American Society of Hematology","","Bone Marrow Cells; Cell Differentiation; Hematologic Diseases; Humans; Image Processing, Computer-Assisted; Microscopy; Neural Networks, Computer; accuracy; adult; algorithm; Article; artifact; basophil; bone marrow cell; cell differentiation; cell structure; cells by body anatomy; classification; continuous process; controlled study; convolutional neural network; deep neural network; eosinophil; female; hematologic disease; human; human cell; human tissue; leukocyte; major clinical study; male; metamyelocyte; monocyte; myelocyte; neutrophil; plasma cell; support vector machine; bone marrow cell; cell differentiation; cytology; hematologic disease; image processing; microscopy; pathology; procedures","German National Research foundation, (SFB 1243); Horizon 2020 Framework Programme, H2020; European Research Council, ERC; Horizon 2020, (866411); Horizon 2020","","Elsevier B.V.","34792573"
"Sharifrazi D.; Alizadehsani R.; Joloudari J.H.; Band S.S.; Hussain S.; Sani Z.A.; Hasanzadeh F.; Shoeibi A.; Dehzangi A.; Sookhak M.; Alinejad-Rokny H.","Sharifrazi, Danial (57222259351); Alizadehsani, Roohallah (55328861400); Joloudari, Javad Hassannataj (57208314874); Band, Shahab S. (57221738247); Hussain, Sadiq (57223086827); Sani, Zahra Alizadeh (36060136500); Hasanzadeh, Fereshteh (57220785949); Shoeibi, Afshin (57193554372); Dehzangi, Abdollah (23396537700); Sookhak, Mehdi (55520828400); Alinejad-Rokny, Hamid (53871090400)","57222259351; 55328861400; 57208314874; 57221738247; 57223086827; 36060136500; 57220785949; 57193554372; 23396537700; 55520828400; 53871090400","CNN-KCL: Automatic myocarditis diagnosis using convolutional neural network combined with k-means clustering","2022","19","3","","2381","2402","21","10.3934/MBE.2022110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123456949&doi=10.3934%2fMBE.2022110&partnerID=40&md5=66fd6a1c9305796aa7cde458980ab024","Myocarditis is the form of an inflammation of the middle layer of the heart wall which is caused by a viral infection and can affect the heart muscle and its electrical system. It has remained one of the most challenging diagnoses in cardiology. Myocardial is the prime cause of unexpected death in approximately 20% of adults less than 40 years of age. Cardiac MRI (CMR) has been considered a noninvasive and golden standard diagnostic tool for suspected myocarditis and plays an indispensable role in diagnosing various cardiac diseases. However, the performance of CMR depends heavily on the clinical presentation and features such as chest pain, arrhythmia, and heart failure. Besides, other imaging factors like artifacts, technical errors, pulse sequence, acquisition parameters, contrast agent dose, and more importantly qualitatively visual interpretation can affect the result of the diagnosis. This paper introduces a new deep learning-based model called Convolutional Neural Network-Clustering (CNN-KCL) to diagnose Myocarditis. In this study, we used 47 subjects with a total number of 98,898 images to diagnose myocarditis disease. Our results demonstrate that the proposed method achieves an accuracy of 97.41% based on 10 fold-cross validation technique with 4 clusters for diagnosis of Myocarditis. To the best of our knowledge, this research is the first to use deep learning algorithms for the diagnosis of myocarditis. © 2022 the Author(s), licensee AIMS Press.","Biomedical machine learning; Cardiac MRI; Convolutional neural network; Diagnosis; Myocarditis; Prediction","Adult; Algorithms; Cluster Analysis; Humans; Magnetic Resonance Imaging; Myocarditis; Neural Networks, Computer; Cardiology; Convolution; Deep learning; Diagnosis; Heart; K-means clustering; Learning algorithms; Biomedical machine learning; Cardiac MRI; Convolutional neural network; Heart muscles; Heart wall; K-means++ clustering; Middle layer; Myocarditi; Neural network clustering; Viral infections; adult; algorithm; cluster analysis; diagnostic imaging; human; myocarditis; nuclear magnetic resonance imaging; Convolutional neural networks","","","American Institute of Mathematical Sciences","35240789"
"Banerjee S.; Singh S.K.; Chakraborty A.; Basu S.; Das A.; Bag R.","Banerjee, Shubhendu (57193737728); Singh, Sumit Kumar (57211858675); Chakraborty, Avishek (57209847244); Basu, Sharmistha (57360173500); Das, Atanu (56506075800); Bag, Rajib (14824524500)","57193737728; 57211858675; 57209847244; 57360173500; 56506075800; 14824524500","Diagnosis of melanoma lesion using neutrosophic and deep learning","2021","38","5","","1327","1338","11","10.18280/ts.380507","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120486486&doi=10.18280%2fts.380507&partnerID=40&md5=2c87bf3ecfdf1439bb08c839b35ba23f","Melanoma is a kind of skin cancer which occurs due to too much exposure of melanocyte cells to the dangerous UV radiations, that gets damaged and multiplies uncontrollably. This is popularly known as malignant melanoma and is comparatively less heard of than certain other types of skin cancers; however it can be more detrimental as it swiftly spreads if not detected and attended at a primary stage. The differentiation between benign and melanocytic lesions sometimes may be confusing, but the symptoms of the disease can reasonably be discriminated by a profound investigation of its histopathological and clinical characteristics. In the recent past, Deep Convolutional Neural Networks (DCNNs) have advanced in accomplishing far better results. The necessity of the present day is to have faster and computationally efficient mechanisms for diagnosis of the deadly disease. This paper makes an effort to showcase a deep learning-based 'Keras' algorithm, which is established on the implementation of DCNNs to investigate melanoma from dermoscopic and digital pictures and provide swifter and more accurate result as contrasted to standard CNNs. The main highlight of this paper, basically stands in its incorporation of certain ambitious notions like the segmentation performed by a culmination of a moving straight line with a sequence of points and the application of the concept of triangular neutrosophic number based on uncertain parameters. The experiment was done on a total of 40,676 images obtained from four commonly available datasets- International Symposium on Biomedical Imaging (ISBI) 2017, International Skin Imaging Collaboration (ISIC) 2018, ISIC 2019 and ISIC 2020 and the end result received was indeed motivating. It attained a Jac score of 86.81% on ISIC 2020 dataset and 95.98%, 95.66% and 94.42% on ISBI 2017, ISIC 2018 and ISIC 2019 datasets, respectively. The present research yielded phenomenal output in most instances in comparison to the pre-defined parameters with the similar types of works in this field. © 2021 Lavoisier. All rights reserved.","Deep learning; Keras; Melanoma; Neutrosophic; Skin cancer; Skin lesion segmentation","Convolutional neural networks; Deep neural networks; Dermatology; Diagnosis; Diseases; Medical imaging; Uncertainty analysis; Biomedical imaging; Deep learning; Keras; Lesion segmentations; Malignant melanoma; Neutrosophic; Skin cancers; Skin imaging; Skin lesion; Skin lesion segmentation; Oncology","","","International Information and Engineering Technology Association",""
"Dhar S.; Shamir L.","Dhar, Sanchari (57408095800); Shamir, Lior (8906230500)","57408095800; 8906230500","Evaluation of the benchmark datasets for testing the efficacy of deep convolutional neural networks","2021","5","3","","92","101","9","10.1016/j.visinf.2021.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122645738&doi=10.1016%2fj.visinf.2021.10.001&partnerID=40&md5=b91cbee058e7ab1be4e83952a91a98ac","In the past decade, deep neural networks, and specifically convolutional neural networks (CNNs), have been becoming a primary tool in the field of biomedical image analysis, and are used intensively in other fields such as object or face recognition. CNNs have a clear advantage in their ability to provide superior performance, yet without the requirement to fully understand the image elements that reflect the biomedical problem at hand, and without designing specific algorithms for that task. The availability of easy-to-use libraries and their non-parametric nature make CNN the most common solution to problems that require automatic biomedical image analysis. But while CNNs have many advantages, they also have certain downsides. The features determined by CNNs are complex and unintuitive, and therefore CNNs often work as a “Black Box”. Additionally, CNNs learn from any piece of information in the pixel data that can provide a discriminative signal, making it more difficult to control what the CNN actually learns. Here we follow common practices to test whether CNNs can classify biomedical image datasets, but instead of using the entire image we use merely parts of the images that do not have biomedical content. The experiments show that CNNs can provide high classification accuracy even when they are trained with datasets that do not contain any biomedical information, or can be systematically biased by irrelevant information in the image data. The presence of such consistent irrelevant data is difficult to identify, and can therefore lead to biased experimental results. Possible solutions to this downside of CNNs can be control experiments, as well as other protective practices to validate the results and avoid biased conclusions based on CNN-generated annotations. © 2021 The Author(s)","Convolutional neural networks; Data acquisition bias; Deep learning; Experimental design","Bioinformatics; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Face recognition; Image analysis; Benchmark datasets; Biomedical image analysis; Biomedical problems; Convolutional neural network; Data acquisition bias; Deep learning; Image elements; Learn+; Nonparametrics; Performance; Data acquisition","Zhejiang University Press; National Science Foundation, NSF, (AST-1903823)","","Elsevier B.V.",""
"Lee H.; Shin M.","Lee, Hyeonjeong (57207747683); Shin, Miyoung (7401536642)","57207747683; 7401536642","Learning explainable time-morphology patterns for automatic arrhythmia classification from short single-lead ecgs","2021","21","13","4331","","","","10.3390/s21134331","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108405138&doi=10.3390%2fs21134331&partnerID=40&md5=2928419fc5f73099bb3937b9e08f482e","Automatic detection of abnormal heart rhythms, including atrial fibrillation (AF), using signals obtained from a single-lead wearable electrocardiogram (ECG) device, is useful for daily cardiac health monitoring. In this study, we propose a novel image-based deep learning framework to classify single-lead ECG recordings of short variable length into several different rhythms associated with arrhythmias. By transforming variable-length 1D ECG signals into fixed-size 2D time-morphology representations and feeding them to the beat–interval–texture convolutional neural network (BIT-CNN) model, we aimed to learn the comprehensible characteristics of beat shape and inter-beat patterns over time for arrhythmia classification. The proposed approach allows feature embedding vectors to provide interpretable time-morphology patterns focused at each step of the learning process. In addition, this method reduces the number of model parameters needed to be trained and aids visual interpretation, while maintaining similar performance to other CNN-based approaches to arrhythmia classification. For experiments, we used the PhysioNet/CinC Challenge 2017 dataset and achieved an overall F1_NAO of 81.75% and F1_NAOP of 76.87%, which are comparable to those of the state-of-the-art methods for variable-length ECGs. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Arrhythmia classification; Atrial fibrillation (AF); Convolutional neural network (CNN); Deep learning; Electrocardiogram (ECG)","Algorithms; Atrial Fibrillation; Electrocardiography; Humans; Neural Networks, Computer; Chemical detection; Convolutional neural networks; Deep learning; Diseases; Electrocardiography; Morphology; Textures; Arrhythmia classification; Atrial fibrillation; Automatic Detection; Feature embedding; Learning frameworks; Learning process; State-of-the-art methods; Visual interpretation; algorithm; atrial fibrillation; electrocardiography; human; Biomedical signal processing","Ministry of Education, Kenya, MOE, (4199990113966)","","MDPI AG","34202805"
"Zheng Z.; Yan H.; Setzer F.C.; Shi K.J.; Mupparapu M.; Li J.","Zheng, Zhiyang (57219469626); Yan, Hao (56276514800); Setzer, Frank C. (19934334800); Shi, Katherine J. (57216731760); Mupparapu, Mel (7003536251); Li, Jing (37081011600)","57219469626; 56276514800; 19934334800; 57216731760; 7003536251; 37081011600","Anatomically Constrained Deep Learning for Automating Dental CBCT Segmentation and Lesion Detection","2021","18","2","9219218","603","614","11","10.1109/TASE.2020.3025871","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092913468&doi=10.1109%2fTASE.2020.3025871&partnerID=40&md5=b9e40c8229bff18c5891786f55f21b96","Compared with the rapidly growing artificial intelligence (AI) research in other branches of healthcare, the pace of developing AI capacities in dental care is relatively slow. Dental care automation, especially the automated capability for dental cone beam computed tomography (CBCT) segmentation and lesion detection, is highly needed. CBCT is an important imaging modality that is experiencing ever-growing utilization in various dental specialties. However, little research has been done for segmenting different structures, restorative materials, and lesions using deep learning. This is due to multifold challenges such as content-rich oral cavity and significant within-label variation on each CBCT image as well as the inherent difficulty of obtaining many high-quality labeled images for training. On the other hand, oral-Anatomical knowledge exists in dentistry, which shall be leveraged and integrated into the deep learning design. In this article, we propose a novel anatomically constrained Dense U-Net for integrating oral-Anatomical knowledge with data-driven Dense U-Net. The proposed algorithm is formulated as a regularized or constrained optimization and solved using mean-field variational approximation to achieve computational efficiency. Mathematical encoding for transforming descriptive knowledge into a quantitative form is also proposed. Our experiment demonstrates that the proposed algorithm outperforms the standard Dense U-Net in both lesion detection accuracy and dice coefficient (DICE) indices in multilabel segmentation. Benefited from the integration with anatomical domain knowledge, our algorithm performs well with data from a small number of patients included in the training. Note to Practitioners-This article proposes a novel deep learning algorithm to enable the automated capability for cone beam computed tomography (CBCT) segmentation and lesion detection. Despite the growing adoption of CBCT in various dental specialties, such capability is currently lacking. The proposed work will provide tools to help reduce subjectivity and human errors, as well as streamline and expedite the clinical workflow. This will greatly facilitate dental care automation. Furthermore, due to the capacity of integrating oral-Anatomical knowledge into the deep learning design, the proposed algorithm does not require many high-quality labeled images to train. The algorithm can provide good accuracy under limited training samples. This ability is highly desirable for practitioners by saving labor-intensive, costly labeling efforts, and enjoying the benefits provided by AI.  © 2004-2012 IEEE.","Biomedical image segmentation; healthcare automation; machine learning; neural networks","Approximation algorithms; Computational efficiency; Computerized tomography; Constrained optimization; Data integration; Dentistry; Knowledge management; Cone-beam computed tomography; Dice coefficient; Different structure; Domain knowledge; Imaging modality; Lesion detection; Restorative materials; Variational approximation; Deep learning","NSF DMS, (1830363, 1903135)","","Institute of Electrical and Electronics Engineers Inc.",""
"Sun B.; Zhao X.; Zhang H.; Bai R.; Li T.","Sun, Biao (54417994100); Zhao, Xing (57222507025); Zhang, Han (55511716000); Bai, Ruifeng (55876612700); Li, Ting (55728945000)","54417994100; 57222507025; 55511716000; 55876612700; 55728945000","EEG Motor Imagery Classification with Sparse Spectrotemporal Decomposition and Deep Learning","2021","18","2","9199413","541","551","10","10.1109/TASE.2020.3021456","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104075628&doi=10.1109%2fTASE.2020.3021456&partnerID=40&md5=558be50bf312e4cece6f6c5d5d798ab2","Classification of electroencephalogram-based motor imagery (MI-EEG) tasks raises a big challenge in the design and development of brain-computer interfaces (BCIs). In view of the characteristics of nonstationarity, time-variability, and individual diversity of EEG signals, a deep learning framework termed SSD-SE-convolutional neural network (CNN) is proposed for MI-EEG classification. The framework consists of three parts: 1) the sparse spectrotemporal decomposition (SSD) algorithm is proposed for feature extraction, overcoming the drawbacks of conventional time-frequency analysis methods and enhancing the robustness to noise; 2) a CNN is constructed to fully exploit the time-frequency features, thus outperforming traditional classification methods both in terms of accuracy and kappa value; and 3) the squeeze-And-excitation (SE) blocks are adopted to adaptively recalibrate channelwise feature responses, which further improves the overall performance and offers a compelling classification solution for MI-EEG applications. Experimental results on two datasets reveal that the proposed framework outperforms state-of-The-Art methods in terms of both classification quality and robustness. The advantages of SSD-SE-CNN include high accuracy, high efficiency, and robustness to cross-Trial and cross-session variations, making it an ideal candidate for long-Term MI-EEG applications. Note to Practitioners-Motor imagery-based brain-computer interfaces (MI-BCIs) are widely used to allow a user to control a device using only his or her neural activity. This article proposed a new framework to classify two-class MI tasks based on electroencephalography (EEG) signals. In this framework, a new sparse spectrotemporal decomposition method is used to extract time-frequency features from EEG signals. A convolutional neural network with squeeze-And-excitation blocks is then constructed to classify the MI tasks. We show the superiority of our method on two datasets and prove its feasibility for long-Term MI-BCI applications.  © 2004-2012 IEEE.","Brain-computer interfaces (BCIs); convolutional neural network (CNN); motor imagery (MI); sparse representation; spectral decomposition","Brain; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Electroencephalography; Electrophysiology; Image classification; Neurons; Brain computer interfaces (BCIs); Classification methods; Classification quality; Individual diversities; Motor imagery classification; State-of-the-art methods; Time frequency features; Time-frequency analysis methods; Biomedical signal processing","Tianjin Special Branch Plan High Level Innovation Team Grant and Tianjin Key Projects of Natural Science Foundation, (18JCZDJC32700); Nvidia; National Natural Science Foundation of China, NSFC, (61675039, 61971303, 81971660); Chinese Academy of Meteorological Sciences, CAMS, (2016-I2M-3-023); National Key Research and Development Program of China, NKRDPC, (2017YFB1300301); Beijing Science and Technology Planning Project, (Z191100010618004)","","Institute of Electrical and Electronics Engineers Inc.",""
"Greenfield D.A.; González G.; Evans C.L.","Greenfield, Daniel A. (57215875827); González, Germán (57158550000); Evans, Conor L. (7403479580)","57215875827; 57158550000; 7403479580","Convolutional neural networks in advanced biomedical imaging applications","2021","","","","197","236","39","10.1007/978-3-030-71676-9_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141115981&doi=10.1007%2f978-3-030-71676-9_9&partnerID=40&md5=d1ddac3a30338aed3da6c5b7c479c899","Deep learning (DL), in particular Convolutional Neural Networks (CNNs), can be used to build powerful quantitative image analysis tools. To take advantage of these capabilities and establish tractable goals and problem solving approaches, it is crucial to understand how both imaging and computational tools have been developed and used together. Different advanced optical imaging methods, whether invasive or non-invasive, are applicable to a wide variety of biomedical research, and CNN algorithms can be tailored to assist with extracting meaningful results from imaging data. © Springer Nature Switzerland AG 2021.","Biomedical optics; Coherent Raman imaging; Convolutional neural networks; Edge computing; Model interpretability; Multiphoton fluorescence microscopy; Optical coherence tomography; Second harmonic generation","","","","Springer International Publishing",""
"Spilger R.; Lee J.-Y.; Chagin V.O.; Schermelleh L.; Cardoso M.C.; Bartenschlager R.; Rohr K.","Spilger, Roman (57204810164); Lee, Ji-Young (56384662100); Chagin, Vadim O. (6602934814); Schermelleh, Lothar (6506159683); Cardoso, M. Cristina (7103171689); Bartenschlager, Ralf (57203048756); Rohr, Karl (55332030200)","57204810164; 56384662100; 6602934814; 6506159683; 7103171689; 57203048756; 55332030200","Deep probabilistic tracking of particles in fluorescence microscopy images","2021","72","","102128","","","","10.1016/j.media.2021.102128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109031660&doi=10.1016%2fj.media.2021.102128&partnerID=40&md5=6ae42b515cf065f62a8c82a609aeb7ba","Tracking of particles in temporal fluorescence microscopy image sequences is of fundamental importance to quantify dynamic processes of intracellular structures as well as virus structures. We introduce a probabilistic deep learning approach for fluorescent particle tracking, which is based on a recurrent neural network that mimics classical Bayesian filtering. Compared to previous deep learning methods for particle tracking, our approach takes into account uncertainty, both aleatoric and epistemic uncertainty. Thus, information about the reliability of the computed trajectories is determined. Manual tuning of tracking parameters is not necessary and prior knowledge about the noise statistics is not required. Short and long-term temporal dependencies of individual object dynamics are exploited for state prediction, and assigned detections are used to update the predicted states. For correspondence finding, we introduce a neural network which computes assignment probabilities jointly across multiple detections as well as determines the probabilities of missing detections. Training requires only simulated data and therefore tedious manual annotation of ground truth is not needed. We performed a quantitative performance evaluation based on synthetic and real 2D as well as 3D fluorescence microscopy images. We used image data of the Particle Tracking Challenge as well as real time-lapse fluorescence microscopy images displaying virus structures and chromatin structures. It turned out that our approach yields state-of-the-art results or improves the tracking results compared to previous methods. © 2021 Elsevier B.V.","Biomedical imaging; Deep learning; Microscopy images; Tracking","Algorithms; Bayes Theorem; Humans; Microscopy, Fluorescence; Neural Networks, Computer; Reproducibility of Results; Fluorescence; Fluorescence microscopy; Learning systems; Petroleum reservoir evaluation; Uncertainty analysis; Viruses; 3d fluorescence microscopies; Chromatin structure; Epistemic uncertainties; Fluorescence microscopy images; Fluorescent particle; Individual objects; Intracellular structures; Probabilistic tracking; article; chromatin structure; deep learning; fluorescence microscopy; noise; prediction; probability; quantitative analysis; reliability; simulation; virus morphology; writing; algorithm; Bayes theorem; fluorescence microscopy; human; reproducibility; Recurrent neural networks","Wellcome Trust, WT, (107457/Z/15/Z); Wellcome Trust, WT; Deutsche Forschungsgemeinschaft, DFG, (240245660, CA 198/15-1, P11, RO 2471/10-1, SFB 1129); Deutsche Forschungsgemeinschaft, DFG","","Elsevier B.V.","34229189"
"Guo N.; Bai Z.","Guo, Ning (58966932800); Bai, Zhengyao (23388661700)","58966932800; 23388661700","The integration of attention mechanism and dense atrous convolution for lung image segmentation; [注意力机制下密集空洞卷积的肺部图像分割]","2021","26","9","","2146","2155","9","10.11834/jig.200429","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115214474&doi=10.11834%2fjig.200429&partnerID=40&md5=448243ac44323510cf898d7e1dfe3628","Objective: As an important criterion for the diagnosis of early-stage lung cancer, chest computed tomography (CT) images-based pulmonary nodules detection have been implemented via location observation, scope and shape of the lesions. The CT image has been analyzed lung organizational structures like the lung parenchyma and the contextual part, such as hydrops, trachea, bronchus, and ribs. CT images-based lung parenchyma has been hard to interpret automatically and precisely. The precise extraction of lung parenchyma has played a vital role in lung-based diseases analyses. Most of lung segmentation have been conducted based on regular image processing algorithms like threshold or morphological operation. The convolutional neural networks (CNNs) have been used in computerized pulmonary disease analysis. CNN-driven lung segmentation algorithms have been adopted in computer-aided diagnosis (CAD). The U-shape structure has been designed for medical image segmentation based on end-to-end fully convolutional network (FCN) structure. The credibility for biomedical image segmentations have been realized based on the encoding and decoding symmetric network structure. A novel convolutional neural network based on U-Net architecture has been illustrated via integrating attention mechanism and dense atrous convolution (DAC). Method: The network has contained an encoder and a decoder. The encoder has consisted of convolution and down sampling. The deductible spatial dimension of feature maps have been used to learn more semantic information. And the attention mechanism decoder has been implemented for de-convolution and up-sampling to re-configure the spatial dimension of the feature maps. The decoding mode using attention mechanism has been manipulated to make the target area output more effectively. Meanwhile, the algorithm of lung image segmentation has been used to identify the target-oriented neural network's attention using transmitted skip-connection to improve the weight of the salient feature. The feature resolution capability has been enhanced to the requirements for intensive spatial prediction via pooling consecutive operations and convolution striding. The DAC block has been deployed between the encoder and the decoder to extract multi-scale information of the context sufficiently. The advantages of Inception, ResNet and atrous convolution for the block have been inherited to capture multi-sized features consequently. The max-pooling and up-sampling operators have been utilized to reduce and increase the resolution of feature maps intensively based on the classic U-Net framework, which could lead to feature loss and accuracy reduced problems during training. The original max-pooling and up-sampling operators have been replaced via down-sample and up-sample block with inception structure to widen the multi-filters network and avoid feature loss. The Dice coefficient loss function has been used instead of the cross entropy loss to identify the gap between prediction and ground-truth. The deep learning framework Pytorch have been used on a server with two NVIDIA GeForce RTX 2080Ti graphics cards and each GPU has 11 Gigabyte memory. At the experimental stage, the original images have been resized to 256×256 pixels and 80% of these for training besides the test remaining. The proposed model has been trained for 120 epochs. Based on an initial learning rate of 0.000 1, the Adam has been opted as the optimization algorithm. Result: In order to verify the efficiency of the proposed method, we conduct multi-compatible verifications called FCN-8 s, U-Net, UNet++, ResU-Net and CE-Net (context encoder network) have been conducted. Four segmentation metrics have been adopted to assess the segmentation. These metrics has evolved the Dice similarity coefficient (DSC), the intersection over union (IoU), sensitivity (SE) and accuracy (ACC). The experimental results on the LUNA16 dataset have demonstrated the priorities in terms of all metrics results. The average Dice similarity coefficient has reached 0.985 9, which has 0.443% higher than the segmentation results of the second-performing CE-Net. The model consequence has achieved 0.972 2, 0.993 8, and 0.982 2 each in terms of IoU, ACC and SE. This second qualified segmentation performance has reached: 0.272%, 0.512% and 0.374% each (more better). Compared with other algorithms, the predictable results of modeling has closer to the label made. The adhesive difficulties on the left and right lung cohesion issue have been resolved well. Conclusion: An encoded/decoded structure in novel convolutional neural network has been integrated via attention mechanism and dense atrous convolution for lungs segmentation. The experiment results have illustrated that the qualified and effective framework for segmenting the lung parenchyma area have its own priority. © 2021, Editorial Office of Journal of Image and Graphics. All right reserved.","Attention mechanism; Computer-aided diagnosis(CAD); Convolutional neural networks(CNN); Dense atrous convolution(DAC); Lung segmentation","","","","Editorial and Publishing Board of JIG",""
"Nayak D.K.; Mishra P.; Das P.; Jamader A.R.; Acharya B.","Nayak, Deepak Kumar (57536098700); Mishra, Pragatika (57292344600); Das, Puja (57209750061); Jamader, Asik Rahaman (57216616414); Acharya, Biswaranjan (57654575800)","57536098700; 57292344600; 57209750061; 57216616414; 57654575800","Application of Deep Learning in Biomedical Informatics and Healthcare","2022","213","","","113","132","19","10.1007/978-981-16-5304-9_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116884597&doi=10.1007%2f978-981-16-5304-9_9&partnerID=40&md5=e77a403a1701efad6bb465c1f5ad5c6c","With the technological advancement in both biological as well as medical fields, it has provided us with explosive volumes of data: health metaphors, EEG, protein sequences and genomic data. Such information can be used to study human health and associated diseases. A combination of both increased automation technologies and a huge size of data introduce machine learning. Furthermore, recognized process such the same as SVM, NN, as well as RF utilized in a development while the QSAR model leads to the use of deep learning. The flexibility of different NN architecture in deep learning is the major thing where there is no similarity between machine learning mechanism along with deep learning methods. Deep learning is the advanced ground in the current era concerning process development and applications. DL uses multiple processing layers to build different computational models. Additionally, DL is capable of capturing a large volume of data by using different hardware designs that are currently being available. The deep learning-based algorithm developed using artificial neural networks (ANN) shows potential fetching features and more complex datasets. The objective of this research work is to discuss the different deep learning techniques like medical image processing and its division, genomic sequences, gene pattern exploration, extrapolation in protein bonding and its applications in the biomedical field. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Biomedical informatics; Deep learning; e-Health records; Genomics; Translational bioinformatics","","","","Springer Science and Business Media Deutschland GmbH",""
"Gao H.; Li Y.; Zhang Z.; Zhao W.","Gao, Honghao (36442463200); Li, Ying (57216709143); Zhang, Zijian (24337088400); Zhao, Wenbing (8201703800)","36442463200; 57216709143; 24337088400; 8201703800","Editorial: Machine Learning Used in Biomedical Computing and Intelligence Healthcare, Volume I","2021","12","","678140","","","","10.3389/fgene.2021.678140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106019668&doi=10.3389%2ffgene.2021.678140&partnerID=40&md5=2b594ec4fd1ed95e86dce73ba381cf29","[No abstract available]","biomedical computing; healthcare; intelligence; machine learning; precision medicine","acute lymphoblastic leukemia; algorithm; Alzheimer disease; artificial intelligence; artificial neural network; atrial fibrillation; biomedicine; computer analysis; convolutional neural network; deep learning; dyslipidemia; Editorial; electrocardiography; electroencephalogram; health care; human; image processing; machine learning; pancreas cancer; systolic blood pressure","Frontiers in Genetics, Frontiers in Public Health, and Frontiers in Computer Science","","Frontiers Media S.A.",""
"Premaladha J.; Surendra Reddy M.; Hemanth Kumar Reddy T.; Sri Sai Charan Y.; Nirmala V.","Premaladha, J. (56181566900); Surendra Reddy, M. (57425296800); Hemanth Kumar Reddy, T. (57425732600); Sri Sai Charan, Y. (57425154800); Nirmala, V. (57425012300)","56181566900; 57425296800; 57425732600; 57425154800; 57425012300","Recognition of Facial Expression Using Haar Cascade Classifier and Deep Learning","2022","311","","","335","351","16","10.1007/978-981-16-5529-6_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123405086&doi=10.1007%2f978-981-16-5529-6_27&partnerID=40&md5=affd75cf9bf1f306ac8071a611e7b36d","Every human has emotions in life at all phases of life’s moment or instance. These emotions keep changing ever so often and person to person because of the biological reflexes of human brain produced by the nervous system due to the neurophysiological changes which are closely associated with behavior, mood swings; thoughts, etc. are tending to be reflected as an expression on the human face. The application of study of these emotions of humans using facial expressions became very prominent in the fields of biomedical engineering, neuroscience, product screening, marketing, and advertisement, etc. In early works of emotion recognition is for the most part useful for analyzing product reviews or some methodologies by monitoring videos and images in real time. Imparting artificial intelligence to the future of the world where every industry thrives well. In recent years, progressive growth in artificial intelligence is seen especially in the field of machine learning with the predominant subset called deep learning. Mainly, deep learning algorithms made an overriding burgeon in image classification thereby avoiding the complex process in facial recognition. The framework proposed in this paper describes conceptual and theoretical knowledge for human facial emotion recognition with a labeled model and applying a Haar cascade classifier using CNN classification—a class in deep neural networks used in its implementation. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Adaboost Training; CNN—Convolutional Neural Network; Data Augmentation; Deep Learning; Facial Emotion Recognition; Haar Cascade Classifier; Image Preprocessing; Prediction","","","Ranganathan G.; Fernando X.; Shi F.","Springer Science and Business Media Deutschland GmbH",""
"Ampavathi A.; Vijaya Saradhi T.","Ampavathi, Anusha (57221535639); Vijaya Saradhi, T. (56974426500)","57221535639; 56974426500","Research challenges and future directions towards medical data processing","2022","10","6","","633","652","19","10.1080/21681163.2021.2018665","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122232285&doi=10.1080%2f21681163.2021.2018665&partnerID=40&md5=1dccbfcd3465b0162f0c1c39310740f4","Data in the healthcare industry and machine learning techniques is useful to analyse a huge amount of data to identify the hidden patterns in the disease, to give personalised treatment for the patient and also used to predict the disease. The main intent of this paper is to plan for a systematic review on medical storage systems, noise removal techniques for medical images and multi-disease prediction using artificial intelligence. This paper conducts a algorithmic contributions used for medical storage systems, noise removal in medical images and multi-disease prediction that are analysed. Moreover, the performance metrics measured in various contributions adopted tools, and different datasets utilised for solving those problems are surveyed. Finally, a strong research gaps and challenges that will pave the way for creating a room for future research perspective are explored. The suitable research gap is focused with the existing limitations in traditional medical storage systems, noise removal methods and multi-disease prediction models that could motivate the researchers to focus on developing new models. Thus, with a strong integration of biomedical and healthcare data, modern healthcare organisations can possibly revolutionise the medical therapies and personalised medicine. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","artificial intelligence; deep learning; Health care domain; machine learning; medical storage systems; multi-disease prediction; noise removal techniques for medical images","Data handling; Deep learning; Digital storage; Diseases; Learning systems; Medical imaging; Patient treatment; Deep learning; Health care domain; Machine-learning; Medical storage system; Multi-disease prediction; Noise removal technique for medical image; Noises removal; Research challenges; Storage systems; System noise; accuracy; algorithm; analysis; Article; artificial intelligence; artificial neural network; block chain technology; cancer staging; clinical audit; clinical decision support system; cognition; comparative study; computer aided design; computer assisted tomography; contrast enhancement; data mining; data storage system; deep learning; diagnostic accuracy; disease severity; electroencephalography; entropy; extraction; futurology; gene expression; glucose blood level; health care industry; health care organization; health promotion; homomorphic cryptography; image enhancement; image quality; image segmentation; immunization; information storage; learning algorithm; machine learning; mammography; medical informatics; nerve cell network; neuropsychological test; noise; noise reduction; nonhuman; nuclear magnetic resonance imaging; performance analysis; performance indicator; personalized medicine; physical activity; positron emission tomography; predictive value; prostatectomy; research; sensitivity and specificity; signal noise ratio; simulation; single photon emission computed tomography; social network; systematic review; technology; total quality management; training; visual field; Forecasting","","","Taylor and Francis Ltd.",""
"Luo X.; Li J.; Chen M.; Yang X.; Li X.","Luo, Xiong (13408498900); Li, Jianyuan (57212538711); Chen, Maojian (57202950796); Yang, Xi (57191642094); Li, Xiangjun (57224205961)","13408498900; 57212538711; 57202950796; 57191642094; 57224205961","Ophthalmic Disease Detection via Deep Learning with a Novel Mixture Loss Function","2021","25","9","9440825","3332","3339","7","10.1109/JBHI.2021.3083605","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107223940&doi=10.1109%2fJBHI.2021.3083605&partnerID=40&md5=de7c59bd9c8f8b23f728d4acc87548aa","With the popularization of computer-aided diagnosis (CAD) technologies, more and more deep learning methods are developed to facilitate the detection of ophthalmic diseases. In this article, the deep learning-based detections for some common eye diseases, including cataract, glaucoma, and age-related macular degeneration (AMD), are analyzed. Generally speaking, morphological change in retina reveals the presence of eye disease. Then, while using some existing deep learning methods to achieve this analysis task, the satisfactory performance may not be given, since fundus images usually suffer from the impact of data imbalance and outliers. It is, therefore, expected that with the exploration of effective and robust deep learning algorithms, the detection performance could be further improved. Here, we propose a deep learning model combined with a novel mixture loss function to automatically detect eye diseases, through the analysis of retinal fundus color images. Specifically, given the good generalization and robustness of focal loss and correntropy-induced loss functions in addressing complex dataset with class imbalance and outliers, we present a mixture of those two losses in deep neural network model to improve the recognition performance of classifier for biomedical data. The proposed model is evaluated on a real-life ophthalmic dataset. Meanwhile, the performance of deep learning model with our proposed loss function is compared with the baseline models, while adopting accuracy, sensitivity, specificity, Kappa, and area under the receiver operating characteristic curve (AUC) as the evaluation metrics. The experimental results verify the effectiveness and robustness of the proposed algorithm. © 2013 IEEE.","Convolutional neural network (CNN); Deep learning; Loss function; Ophthalmic disease detection","Algorithms; Deep Learning; Fundus Oculi; Glaucoma; Humans; Neural Networks, Computer; ROC Curve; Classification (of information); Computer aided diagnosis; Computer aided instruction; Deep neural networks; Image analysis; Learning algorithms; Learning systems; Mixtures; Ophthalmology; Statistics; Age-related macular degeneration; Computer Aided Diagnosis(CAD); Detection performance; Evaluation metrics; Morphological changes; Neural network model; Performance of classifier; Receiver operating characteristic curves; age related macular degeneration; area under the curve; Article; blindness; cataract; computer assisted tomography; computer model; convolutional neural network; coronavirus disease 2019; deep learning; entropy; excitation; eye disease; eye fundus; histogram; human; image analysis; image processing; learning; loss of function mutation; receiver operating characteristic; sensitivity and specificity; algorithm; diagnostic imaging; glaucoma; Deep learning","Fundamental Research Funds for the University of Science, and Technology Beijing, (FRF-BD-19-012 A.); Scientific and Technological Innovation Foundation of Shunde Graduate School; National Natural Science Foundation of China, NSFC, (81961138010, U1836106); Natural Science Foundation of Beijing Municipality, (19L2029, M21032); University of Science and Technology Beijing, USTB, (BK20BF010); Beijing Intelligent Logistics System Collaborative Innovation Center, BILSCIC, (BILSCIC-2019KF-08)","","Institute of Electrical and Electronics Engineers Inc.","34033552"
"Alsaade F.W.; Alzahrani M.S.","Alsaade, Fawaz Waselallah (22937047900); Alzahrani, Mohammed Saeed (57483011800)","22937047900; 57483011800","Classification and Detection of Autism Spectrum Disorder Based on Deep Learning Algorithms","2022","2022","","8709145","","","","10.1155/2022/8709145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126076335&doi=10.1155%2f2022%2f8709145&partnerID=40&md5=8c4de86b15f3a2ce9a831dd6f8e79852","Autism spectrum disorder (ASD) is a type of mental illness that can be detected by using social media data and biomedical images. Autism spectrum disorder (ASD) is a neurological disease correlated with brain growth that later impacts the physical impression of the face. Children with ASD have dissimilar facial landmarks, which set them noticeably apart from typically developed (TD) children. Novelty of the proposed research is to design a system that is based on autism spectrum disorder detection on social media and face recognition. To identify such landmarks, deep learning techniques may be used, but they require a precise technology for extracting and producing the proper patterns of the face features. This study assists communities and psychiatrists in experimentally detecting autism based on facial features, by using an uncomplicated web application based on a deep learning system, that is, a convolutional neural network with transfer learning and the flask framework. Xception, Visual Geometry Group Network (VGG19), and NASNETMobile are the pretrained models that were used for the classification task. The dataset that was used to test these models was collected from the Kaggle platform and consisted of 2,940 face images. Standard evaluation metrics such as accuracy, specificity, and sensitivity were used to evaluate the results of the three deep learning models. The Xception model achieved the highest accuracy result of 91%, followed by VGG19 (80%) and NASNETMobile (78%). © 2022 Fawaz Waselallah Alsaade and Mohammed Saeed Alzahrani.","","Algorithms; Autism Spectrum Disorder; Brain; Child; Deep Learning; Humans; Neural Networks, Computer; Convolutional neural networks; Deep learning; Face recognition; Learning algorithms; Social networking (online); Statistical tests; Autism spectrum disorders; Biomedical images; Children with autisms; Data images; Facial landmark; Learning techniques; Mental illness; Neurological disease; Social media; Social media datum; algorithm; autism; brain; child; human; Diseases","","","Hindawi Limited","35265118"
"Chen Z.; Wang Y.; Song Z.","Chen, Zhongye (57225080029); Wang, Yijun (56586253700); Song, Zhongyan (57225071102)","57225080029; 56586253700; 57225071102","Classification of motor imagery electroencephalography signals based on image processing method","2021","21","14","4646","","","","10.3390/s21144646","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109093903&doi=10.3390%2fs21144646&partnerID=40&md5=ffec91b4f021223886972b5ef5976db6","In recent years, more and more frameworks have been applied to brain-computer interface technology, and electroencephalogram-based motor imagery (MI-EEG) is developing rapidly. However, it is still a challenge to improve the accuracy of MI-EEG classification. A deep learning framework termed IS-CBAM-convolutional neural network (CNN) is proposed to address the non-stationary nature, the temporal localization of excitation occurrence, and the frequency band distribution characteristics of the MI-EEG signal in this paper. First, according to the logically symmetrical relationship between the C3 and C4 channels, the result of the time-frequency image subtraction (IS) for the MI-EEG signal is used as the input of the classifier. It both reduces the redundancy and increases the feature differences of the input data. Second, the attention module is added to the classifier. A convolutional neural network is built as the base classifier, and information on the temporal location and frequency distribution of MI-EEG signal occurrences are adaptively extracted by introducing the Convolutional Block Attention Module (CBAM). This approach reduces irrelevant noise interference while increasing the robustness of the pattern. The performance of the framework was evaluated on BCI competition IV dataset 2b, where the mean accuracy reached 79.6%, and the average kappa value reached 0.592. The experimental results validate the feasibility of the framework and show the performance improvement of MI-EEG signal classification. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Attention module; Brain-computer interface; Convolutional neural network (CNN); Feature enhancement; Motor imagery (MI)","Algorithms; Brain-Computer Interfaces; Electroencephalography; Imagination; Neural Networks, Computer; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Electroencephalography; Electrophysiology; Image classification; Distribution characteristics; EEG signal classification; Feature differences; Frequency distributions; Image processing - methods; Learning frameworks; Temporal localization; Time-frequency images; algorithm; brain computer interface; electroencephalography; imagination; Biomedical signal processing","National Natural Science Foundation of China, NSFC, (61540022)","","MDPI AG","34300386"
"Yang B.; Chen W.; Luo H.; Tan Y.; Liu M.; Wang Y.","Yang, Bo (57226054865); Chen, Weixun (57193341285); Luo, Huiqiong (57207453212); Tan, Yinghui (57207452321); Liu, Min (55783125200); Wang, Yaonan (55998880600)","57226054865; 57193341285; 57207453212; 57207452321; 55783125200; 55998880600","Neuron Image Segmentation via Learning Deep Features and Enhancing Weak Neuronal Structures","2021","25","5","9170749","1634","1645","11","10.1109/JBHI.2020.3017540","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105843609&doi=10.1109%2fJBHI.2020.3017540&partnerID=40&md5=a6049820927f9a1231c99ed3f4389a70","Neuron morphology reconstruction (tracing) in 3D volumetric images is critical for neuronal research. However, most existing neuron tracing methods are not applicable in challenging datasets where the neuron images are contaminated by noises or containing weak filament signals. In this paper, we present a two-stage 3D neuron segmentation approach via learning deep features and enhancing weak neuronal structures, to reduce the impact of image noise in the data and enhance the weak-signal neuronal structures. In the first stage, we train a voxel-wise multi-level fully convolutional network (FCN), which specializes in learning deep features, to obtain the 3D neuron image segmentation maps in an end-to-end manner. In the second stage, a ray-shooting model is employed to detect the discontinued segments in segmentation results of the first-stage, and the local neuron diameter of the broken point is estimated and direction of the filamentary fragment is detected by rayburst sampling algorithm. Then, a Hessian-repair model is built to repair the broken structures, by enhancing weak neuronal structures in a fibrous structure determined by the estimated local neuron diameter and the filamentary fragment direction. Experimental results demonstrate that our proposed segmentation approach achieves better segmentation performance than other state-of-the-art methods for 3D neuron segmentation. Compared with the neuron reconstruction results on the segmented images produced by other segmentation methods, the proposed approach gains 47.83% and 34.83% improvement in the average distance scores. The average Precision and Recall rates of the branch point detection with our proposed method are 38.74% and 22.53% higher than the detection results without segmentation. © 2013 IEEE.","3D fully convolutional networks; hessian matrix; image segmentation; Neuron tracing","Algorithms; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Neurons; Biomedical signal processing; Convolutional neural networks; Deep learning; Image enhancement; Image reconstruction; Neurons; Convolutional networks; Neuron morphologies; Neuron reconstruction; Precision and recall; Segmentation methods; Segmentation performance; Segmentation results; State-of-the-art methods; algorithm; article; image segmentation; learning; nerve cell; noise; recall; image processing; nerve cell; three-dimensional imaging; Image segmentation","National Natural Science Foundation of China, NSFC, (61771189); Natural Science Foundation of Hunan Province, (2020JJ2008)","","Institute of Electrical and Electronics Engineers Inc.","32809948"
"Bule M.; Jalalimanesh N.; Bayrami Z.; Baeeri M.; Abdollahi M.","Bule, Mohammed (56789924300); Jalalimanesh, Nafiseh (12798817800); Bayrami, Zahra (15020404700); Baeeri, Maryam (24175573900); Abdollahi, Mohammad (57940559800)","56789924300; 12798817800; 15020404700; 24175573900; 57940559800","The rise of deep learning and transformations in bioactivity prediction power of molecular modeling tools","2021","98","5","","954","967","13","10.1111/cbdd.13750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115050412&doi=10.1111%2fcbdd.13750&partnerID=40&md5=0ebb53031e8da0fa9950273edcfd7882","The search and design for the better use of bioactive compounds are used in many experiments to best mimic compounds' functions in the human body. However, finding a cost-effective and timesaving approach is a top priority in different disciplines. Nowadays, artificial intelligence (AI) and particularly deep learning (DL) methods are widely applied to improve the precision and accuracy of models used in the drug discovery process. DL approaches have been used to provide more opportunities for a faster, efficient, cost-effective, and reliable computer-aided drug discovery. Moreover, the increasing biomedical data volume in areas, like genome sequences, medical images, protein structures, etc., has made data mining algorithms very important in finding novel compounds that could be drugs, uncovering or repurposing drugs and improving the area of genetic markers-based personalized medicine. Furthermore, deep neural networks (DNNs) have been demonstrated to outperform other techniques such as random forests and SVMs for QSAR studies and ligand-based virtual screening. Despite this, in QSAR studies, the quality of different data sources and potential experimental errors has greatly affected the accuracy of QSAR predictions. Therefore, further researches are still needed to improve the accuracy, selectivity, and sensitivity of the DL approach in building the best models of drug discovery. © 2021 John Wiley & Sons A/S","artificial intelligence; deep learning; machine learning; neural networks; QSAR","Algorithms; Data Mining; Deep Learning; Drug Design; Humans; Ligands; Models, Molecular; Proteins; Quantitative Structure-Activity Relationship; ligand; protein; Article; artificial intelligence; cost effectiveness analysis; data accuracy; data mining; deep learning; deep neural network; human; molecular model; nonhuman; personalized medicine; pharmacophore; prediction; protein protein interaction; protein structure; quantitative structure activity relation; three dimensional quantitative structure activity relationship; algorithm; chemistry; drug design","Iran National Science Foundation, INSF","","John Wiley and Sons Inc","34532977"
"Radhakrishnan T.; Karhade J.; Ghosh S.K.; Muduli P.R.; Tripathy R.K.; Acharya U.R.","Radhakrishnan, Tejas (57221687165); Karhade, Jay (57218875780); Ghosh, S.K. (57197818632); Muduli, P.R. (57522976200); Tripathy, R.K. (56035676800); Acharya, U. Rajendra (7004510847)","57221687165; 57218875780; 57197818632; 57522976200; 56035676800; 7004510847","AFCNNet: Automated detection of AF using chirplet transform and deep convolutional bidirectional long short term memory network with ECG signals","2021","137","","104783","","","","10.1016/j.compbiomed.2021.104783","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113926187&doi=10.1016%2fj.compbiomed.2021.104783&partnerID=40&md5=65b09d8aee9b2e998119826083ea9908","Atrial fibrillation (AF) is the most common type of cardiac arrhythmia and is characterized by the heart's beating in an uncoordinated manner. In clinical studies, patients often do not have visible symptoms during AF, and hence it is harder to detect this cardiac ailment. Therefore, automated detection of AF using the electrocardiogram (ECG) signals can reduce the risk of stroke, coronary artery disease, and other cardiovascular complications. In this paper, a novel time-frequency domain deep learning-based approach is proposed to detect AF and classify terminating and non-terminating AF episodes using ECG signals. This approach involves evaluating the time-frequency representation (TFR) of ECG signals using the chirplet transform. The two-dimensional (2D) deep convolutional bidirectional long short-term memory (BLSTM) neural network model is used to detect and classify AF episodes using the time-frequency images of ECG signals. The proposed TFR based 2D deep learning approach is evaluated using the ECG signals from three public databases. Our developed approach has obtained an accuracy, sensitivity, and specificity of 99.18% (Confidence interval (CI) as [98.86, 99.49]), 99.17% (CI as [98.85 99.49]), and 99.18% (CI as [98.86 99.49]), respectively, with 10-fold cross-validation (CV) technique to detect AF automatically. The proposed approach also classified terminating and non-terminating AF episodes with an average accuracy of 75.86%. The average accuracy value obtained using the proposed approach is higher than the short-time Fourier transform (STFT), discrete-time continuous wavelet transform (DT-CWT), and Stockwell transform (ST) based time-frequency analysis methods with deep convolutional BLSTM models to detect AF. The proposed approach has better AF detection performance than the existing deep learning-based techniques using ECG signals from the MIT-BIH database. © 2021 Elsevier Ltd","Atrial fibrillation; Chirplet transform; Classification; Deep CNN-BLSTM; ECG signal; Smart healthcare","Algorithms; Atrial Fibrillation; Electrocardiography; Humans; Memory, Short-Term; Neural Networks, Computer; Wavelet Analysis; Biomedical signal processing; Brain; Convolution; Diseases; Electrocardiography; Frequency domain analysis; Heart; Long short-term memory; Atrial fibrillation; Automated detection; Chirplet transforms; Confidence interval; Deep CNN-bidirectional long short-term memory; Electrocardiogram signal; Memory network; Short term memory; Smart healthcare; Time-frequency representations; Article; artificial neural network; atrial fibrillation; cardiovascular disease; cerebrovascular accident; continuous wavelet transform; controlled study; convolutional neural network; coronary artery disease; correlation coefficient; cross validation; deep learning; deep neural network; electrocardiogram; Fourier transform; heart arrhythmia; human; long short term memory network; P wave; QRS complex; recurrent neural network; RR interval; sensitivity and specificity; short term memory; short time Fourier transform; Stockwell transform; time; algorithm; atrial fibrillation; electrocardiography; short term memory; wavelet analysis; Classification (of information)","HBD, (BITS/GAU/RIG/2019/H0632)","","Elsevier Ltd","34481184"
"Jia X.; Song Y.; Yang L.; Xie L.","Jia, Xueyu (57222238948); Song, Yonghao (57216459682); Yang, Lie (57216461783); Xie, Longhan (8218534100)","57222238948; 57216459682; 57216461783; 8218534100","Joint spatial and temporal features extraction for multi-classification of motor imagery EEG","2022","71","","103247","","","","10.1016/j.bspc.2021.103247","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117401887&doi=10.1016%2fj.bspc.2021.103247&partnerID=40&md5=0f2170e6384f4db3df0c269bedc075cb","The application of brain-computer interface (BCI) has always been limited by low decoding accuracy due to excessive noise in electroencephalogram (EEG) signals. The traditional methods employ some representative features while losing too much information. Deep learning methods have achieved good results, but subject to the insufficient ability of extracting discriminative features from EEG. In this paper, we propose a novel decoding framework that effectively uses spatial and temporal information by time-contained spatial filtering and spatial–temporal analysis network (TSF-STAN) for EEG multi-classification tasks. Firstly, the TSF with the joint one-versus-rest (Joint-OVR) strategy is given to map the signal to a new space, where each category can be more easily distinguished, while preserving the time-domain characteristics. Next, the STAN is designed to extract discriminative spatial and temporal features further with convolutional layers, and then perform classification. Detailed experiments have been carried out to verify the effectiveness of our framework on BCI competition IV-2a and IV-2b datasets of motor imagery (MI) EEG. The results show that our method has outperformed recent outstanding algorithms, with the average accuracy of 83.0% on IV-2a and 88.0% on IV-2b. Spatial and temporal information is well used to obtain better performance, which has a good potential of EEG decoding for application of BCI. © 2021","Brain-computer interface (BCI); Convolutional neural network (CNN); Electroencephalogram (EEG); Motor imagery (MI); Spatial filtering","Beamforming; Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Decoding; Deep learning; Electroencephalography; Image classification; Information filtering; Time domain analysis; Brain-computer interface; Convolutional neural network; Electroencephalogram; Motor imagery; Multi-classification; Spatial features; Spatial filterings; Temporal features; Article; binary classification; classification; controlled study; convolutional neural network; decomposition; deep learning; electroencephalogram; feature extraction; filtration; human; human experiment; imagery; spatiotemporal analysis; Brain computer interface","Guangzhou Research Foundation, (201903010028, 202002030324); Ministry of Education for Equipment Pre-Research, (6141A02033124); Shenzhen Institute of Artificial Intelligence and Robotics for Society, (AC01202005011); Zhongshan Research Foundation, (2020B2020); National Natural Science Foundation of China, NSFC, (52075177); Guangdong Medical Research Foundation, (2018KZDXM002, 2019A050505001)","","Elsevier Ltd",""
"Armanious K.; Abdulatif S.; Shi W.; Salian S.; Küstner T.; Weiskopf D.; Hepp T.; Gatidis S.; Yang B.","Armanious, Karim (57208782510); Abdulatif, Sherif (57194649144); Shi, Wenbin (57221148113); Salian, Shashank (57221141405); Küstner, Thomas (56549927000); Weiskopf, Daniel (6603960393); Hepp, Tobias (58593220800); Gatidis, Sergios (26658018800); Yang, Bin (55584795030)","57208782510; 57194649144; 57221148113; 57221141405; 56549927000; 6603960393; 58593220800; 26658018800; 55584795030","Age-Net: An MRI-Based Iterative Framework for Brain Biological Age Estimation","2021","40","7","","1778","1791","13","10.1109/TMI.2021.3066857","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103203641&doi=10.1109%2fTMI.2021.3066857&partnerID=40&md5=0a8f160e4f9e56befb45d1b52f81bcb7","The concept of biological age (BA) - although important in clinical practice - is hard to grasp mainly due to the lack of a clearly defined reference standard. For specific applications, especially in pediatrics, medical image data are used for BA estimation in a routine clinical context. Beyond this young age group, BA estimation is mostly restricted to whole-body assessment using non-imaging indicators such as blood biomarkers, genetic and cellular data. However, various organ systems may exhibit different aging characteristics due to lifestyle and genetic factors. Thus, a whole-body assessment of the BA does not reflect the deviations of aging behavior between organs. To this end, we propose a new imaging-based framework for organ-specific BA estimation. In this initial study we focus mainly on brain MRI. As a first step, we introduce a chronological age (CA) estimation framework using deep convolutional neural networks (Age-Net). We quantitatively assess the performance of this framework in comparison to existing state-of-the-art CA estimation approaches. Furthermore, we expand upon Age-Net with a novel iterative data-cleaning algorithm to segregate atypical-aging patients (BA /≈ CA) from the given population. We hypothesize that the remaining population should approximate the true BA behavior. We apply the proposed methodology on a brain magnetic resonance image (MRI) dataset containing healthy individuals as well as Alzheimer’s patients with different dementia ratings. We demonstrate the correlation between the predicted BAs and the expected cognitive deterioration in Alzheimer’s patients. A statistical and visualization-based analysis has provided evidence regarding the potential and current challenges of the proposed methodology. © 2021 IEEE.","Biological age estimation; chronological age; deep learning; magnetic resonance imaging","Aging; Algorithms; Brain; Child; Humans; Magnetic Resonance Imaging; Neural Networks, Computer; Deep neural networks; Deterioration; Iterative methods; Magnetism; Medical imaging; Population statistics; Resonance; Three dimensional displays; Age estimation; Alzheimer; Biological age estimation; Biomedical imaging; Brain magnetic resonance images; Chronological age; Deep learning; Genetic; Three-dimensional display; Whole-body; aging; algorithm; brain; child; diagnostic imaging; human; nuclear magnetic resonance imaging; Magnetic resonance imaging","Deutsche Forschungsgemeinschaft, DFG, (42821930/SPP 2177)","","Institute of Electrical and Electronics Engineers Inc.","33729932"
"Abdolghader P.; Ridsdale A.; Grammatikopoulos T.; Resch G.; Légaré F.; Stolow A.; Pegoraro A.F.; Tamblyn I.","Abdolghader, Pedram (56943376400); Ridsdale, Andrew (6602601333); Grammatikopoulos, Tassos (6602896058); Resch, Gavin (57287303200); Légaré, François (7004424965); Stolow, Albert (7003515475); Pegoraro, Adrian F. (24559536300); Tamblyn, Isaac (12790735100)","56943376400; 6602601333; 6602896058; 57287303200; 7004424965; 7003515475; 24559536300; 12790735100","Unsupervised hyperspectral stimulated Raman microscopy image enhancement: Denoising and segmentation via one-shot deep learning","2021","29","21","","34205","34219","14","10.1364/OE.439662","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116593199&doi=10.1364%2fOE.439662&partnerID=40&md5=f38e520196f9659bb73d0660cd639c9e","Hyperspectral stimulated Raman scattering (SRS) microscopy is a label-free technique for biomedical and mineralogical imaging which can suffer from low signal-to-noise ratios. Here we demonstrate the use of an unsupervised deep learning neural network for rapid and automatic denoising of SRS images: UHRED (Unsupervised Hyperspectral Resolution Enhancement and Denoising). UHRED is capable of “one-shot” learning; only one hyperspectral image is needed, with no requirements for training on previously labelled datasets or images. Furthermore, by applying a k-means clustering algorithm to the processed data, we demonstrate automatic, unsupervised image segmentation, yielding, without prior knowledge of the sample, intuitive chemical species maps, as shown here for a lithium ore sample. © 2021 Optical Society of America under the terms of the OSA Open Access Publishing Agreement.","","Deep learning; Hyperspectral imaging; Image denoising; Image segmentation; K-means clustering; Mineralogy; Ores; Signal to noise ratio; Spectroscopy; Stimulated Raman scattering; De-noising; HyperSpectral; Label-free techniques; Learning neural networks; Low signal-to-noise ratio; Microscopy images; Raman microscopy; Raman scattering microscopy; Resolution enhancement; Stimulated Raman; article; deep learning; image enhancement; image segmentation; k means clustering; microscopy; Image enhancement","","","The Optical Society","34809216"
"Waibel D.J.E.; Shetab Boushehri S.; Marr C.","Waibel, Dominik Jens Elias (57211167650); Shetab Boushehri, Sayedali (57222222574); Marr, Carsten (10539477500)","57211167650; 57222222574; 10539477500","InstantDL: an easy-to-use deep learning pipeline for image segmentation and classification","2021","22","1","103","","","","10.1186/s12859-021-04037-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101903803&doi=10.1186%2fs12859-021-04037-3&partnerID=40&md5=d8747df3bf77a4c5896fe7635b68024a","Background: Deep learning contributes to uncovering molecular and cellular processes with highly performant algorithms. Convolutional neural networks have become the state-of-the-art tool to provide accurate and fast image data processing. However, published algorithms mostly solve only one specific problem and they typically require a considerable coding effort and machine learning background for their application. Results: We have thus developed InstantDL, a deep learning pipeline for four common image processing tasks: semantic segmentation, instance segmentation, pixel-wise regression and classification. InstantDL enables researchers with a basic computational background to apply debugged and benchmarked state-of-the-art deep learning algorithms to their own data with minimal effort. To make the pipeline robust, we have automated and standardized workflows and extensively tested it in different scenarios. Moreover, it allows assessing the uncertainty of predictions. We have benchmarked InstantDL on seven publicly available datasets achieving competitive performance without any parameter tuning. For customization of the pipeline to specific tasks, all code is easily accessible and well documented. Conclusions: With InstantDL, we hope to empower biomedical researchers to conduct reproducible image processing with a convenient and easy-to-use pipeline. © 2021, The Author(s).","","Algorithms; Deep Learning; Image Processing, Computer-Assisted; Machine Learning; Neural Networks, Computer; Convolutional neural networks; Data handling; Image classification; Image segmentation; Learning algorithms; Pipeline processing systems; Pipelines; Semantics; Uncertainty analysis; Cellular process; Competitive performance; Parameter-tuning; Semantic segmentation; Specific problems; Specific tasks; State of the art; Work-flows; algorithm; article; deep learning; image processing; image segmentation; pipeline; prediction; uncertainty; workflow; algorithm; image processing; machine learning; Deep learning","Benedikt Mairhörmann; Niklas Köhler and Nikos Chlis; Horizon 2020 Framework Programme, H2020, (862811, 866411); European Research Council, ERC; Bundesministerium für Bildung und Forschung, BMBF, (01ZX1710A-F)","","BioMed Central Ltd","33653266"
"Chen Z.; Lin Z.; Wang P.; Ding M.","Chen, Zijiao (57221283719); Lin, Zihuai (8649563900); Wang, Peng (57213430563); Ding, Ming (7202280996)","57221283719; 8649563900; 57213430563; 7202280996","Negative-ResNet: noisy ambulatory electrocardiogram signal classification scheme","2021","33","14","","8857","8869","12","10.1007/s00521-020-05635-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098718635&doi=10.1007%2fs00521-020-05635-7&partnerID=40&md5=c7a06859546dde004467db7a374abd9c","With recently successful applications of deep learning in computer vision and general signal processing, deep learning has shown many unique advantages in medical signal processing. However, data labelling quality has become one of the most significant issues for AI applications, especially when it requires domain knowledge (e.g. medical image labelling). Besides, there might be noisy labels in practical datasets, which impairs the training process of neural networks. In this paper, we propose a semi-supervised algorithm for training data samples with noisy labels by performing selected positive learning and negative learning. To verify the effectiveness of the proposed scheme, we designed a portable ECG patch-RealCare and applied the algorithm on a real-life dataset. Our experimental results show that we can achieve an accuracy of 91.0%, which is 6.2% higher than a normal training process with ResNet. There are 65 patients in our dataset, and we randomly picked 2 patients to perform validation. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd. part of Springer Nature.","Arrhythmia detection; Deep learning application; Negative learning; Noisy label classification","Biomedical signal processing; Computer aided instruction; Deep learning; Domain Knowledge; Electrocardiograms; Medical imaging; Arrhythmia detection; Classification scheme; Data labelling; Deep learning application; Electrocardiogram signal classifications; Negative learning; Noisy label classification; Noisy labels; Signal-processing; Training process; Classification (of information)","","","Springer Science and Business Media Deutschland GmbH",""
"Siam A.I.; Sedik A.; El-Shafai W.; Elazm A.A.; El-Bahnasawy N.A.; El Banby G.M.; Khalaf A.A.M.; Abd El-Samie F.E.","Siam, Ali I. (57209332606); Sedik, Ahmed (57210323159); El-Shafai, Walid (55819860600); Elazm, Atef Abou (35148021700); El-Bahnasawy, Nirmeen A. (57193137667); El Banby, Ghada M. (36711548200); Khalaf, Ashraf A.M. (57208694591); Abd El-Samie, Fathi E. (12785222000)","57209332606; 57210323159; 55819860600; 35148021700; 57193137667; 36711548200; 57208694591; 12785222000","Biosignal classification for human identification based on convolutional neural networks","2021","34","7","e4685","","","","10.1002/dac.4685","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101203434&doi=10.1002%2fdac.4685&partnerID=40&md5=4a573270a3e7f897058b9b22d491b4bd","Human identification is considered as a serious challenge for several applications such as cybersecurity and access control. Recently, the trend of human identification has been directed to human biometrics, which can be used to recognize persons based on some physiological or behavioral characteristics that they own, such as fingerprint, iris, and biosignals. There are several types of human biosignals including electroencephalography (EEG), electrocardiography (ECG), and photoplethysmography (PPG) signals. This paper presents a human identification system based on PPG signals. The proposed system consists of three main phases: signal acquisition, signal pre-processing, and feature extraction/classification. The pre-processing phase involves denoising of the acquired signal, transformation of the 1D signal sequence into a 2D image, and computation of the spectrogram. Feature extraction is carried out on the images obtained from the pre-processing phase. Features are extracted from the images based on convolutional neural networks (CNNs). The proposed CNN model consists of a sequence of convolutional (CNV) and pooling layers. Finally, the obtained feature maps are fed to the classifier to discriminate human identities. The proposed identification algorithm is applied on signals with and without an additive white Gaussian noise (AWGN). The simulation results reveal that the proposed algorithm achieves an accuracy of 99.5% with the spectrogram representation and 89.8% with the 2D image representation, in the absence of noise. In addition, the paper gives a discussion of the efficiency of denoising techniques such as wavelet denoising, Savitzky–Golay and Kalman filtering, when involved with the proposed algorithm. The simulation results prove that the wavelet dencoising technique has a best performance among the discussed noise reduction techniques. © 2021 John Wiley & Sons Ltd.","Biometrics; deep learning; human identification; photoplethysmography (PPG); signal denoising","Access control; Convolution; Convolutional neural networks; Electrocardiography; Electroencephalography; Electrophysiology; Extraction; Feature extraction; Gaussian noise (electronic); Image processing; Photoplethysmography; Spectrographs; White noise; Additive White Gaussian noise; Behavioral characteristics; De-noising techniques; Human identification; Identification algorithms; Noise reduction technique; Photoplethysmography (PPG); Signal acquisitions; Biomedical signal processing","","","John Wiley and Sons Ltd",""
"Manssor S.A.F.; Sun S.; Zhao G.; Qu B.","Manssor, Samah A F (57189094874); Sun, Shaoyuan (8409764900); Zhao, Guoshun (57377519500); Qu, Binjie (57377831000)","57189094874; 8409764900; 57377519500; 57377831000","Gait Recognition System in Thermal Infrared Night Imaging by Using Deep Convolutional Neural Networks","2021","38","6","","527","538","11","10.19884/j.1672-5220.202107007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121443132&doi=10.19884%2fj.1672-5220.202107007&partnerID=40&md5=09c644a65dae48bc050da9166d1f18ff","Gait is an essential biomedical feature that distinguishes individuals through walking. This feature automatically stimulates the need for remote human recognition in security-sensitive visual monitoring applications. However, there is still a lack of sufficient accuracy of gait recognition at night, in addition to taking some critical factors that affect the performances of the recognition algorithm. Therefore, a novel approach is proposed to automatically identify individuals from thermal infrared (TIR) images according to their gaits captured at night. This approach uses a new night gait network (NGaitNet) based on similarity deep convolutional neural networks (CNNs) method to enhance gait recognition at night. First, the TIR image is represented via personal movements and enhanced body skeleton segments. Then, the state-space method with a Hough transform is used to extract gait features to obtain skeletal joints' angles. These features are trained to identify the most discriminating gait patterns that indicate a change in human identity. To verify the proposed method, the experimental results are performed by using learning and validation curves via being connected by the Visdom website. The proposed thermal infrared imaging night gait recognition (TIRNGaitNet) approach has achieved the highest gait recognition accuracy rates (99.5%, 97.0%), especially under normal walking conditions on the Chinese Academy of Sciences Institute of Automation infrared night gait dataset (CASIA C) and Donghua University thermal infrared night gait database (DHU night gait dataset). On the same dataset, the results of the TIRNGaitNet approach provide the record scores of (98.0%, 87.0%) under the slow walking condition and (94.0%, 86.0%) for the quick walking condition. Copyright © 2021 Journal Center of Donghua University. All right reserved.","Convolutional neural network (CNN); Feature extraction; Gait recognition; Silhouette; Thermal infrared (TIR) image","","","","Dong Hua University",""
"Ge Y.; Liu P.; Ni Y.; Chen J.; Yang J.; Su T.; Zhang H.; Guo J.; Zheng H.; Li Z.; Liang D.","Ge, Yongshuai (55761551500); Liu, Peizhen (57217201903); Ni, Yifan (57217194303); Chen, Jianwei (59063292500); Yang, Jiecheng (57219749451); Su, Ting (57217197414); Zhang, Huitao (36467487100); Guo, Jinchuan (7404489290); Zheng, Hairong (7403440733); Li, Zhicheng (55707186500); Liang, Dong (57195152723)","55761551500; 57217201903; 57217194303; 59063292500; 57219749451; 57217197414; 36467487100; 7404489290; 7403440733; 55707186500; 57195152723","Enhancing the X-Ray Differential Phase Contrast Image Quality with Deep Learning Technique","2021","68","6","9146355","1751","1758","7","10.1109/TBME.2020.3011119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096223246&doi=10.1109%2fTBME.2020.3011119&partnerID=40&md5=65d5637e7bd9c80f101ad6dbcb92688a","Objective: The purpose of this work is to investigate the feasibility of using deep convolutional neural network (CNN) to improve the image quality of a grating-based X-ray differential phase contrast imaging (XPCI) system. Methods: In this work, a novel deep CNN based phase signal extraction and image noise suppression algorithm (named as XP-NET) is developed. The numerical phase phantom, the ex vivo biological specimen and the ACR breast phantom are evaluated via the numerical simulations and experimental studies, separately. Moreover, images are also evaluated under different low radiation levels to verify its dose reduction capability. Results: Compared with the conventional analytical method, the novel XP-NET algorithm is able to reduce the bias of large DPC signals and hence increasing the DPC signal accuracy by more than 15%. Additionally, the XP-NET is able to reduce DPC image noise by about 50% for low dose DPC imaging tasks. Conclusion: This proposed novel end-to-end supervised XP-NET has a great potential to improve the DPC signal accuracy, reduce image noise, and preserve object details. Significance: We demonstrate that the deep CNN technique provides a promising approach to improve the grating-based XPCI performance and its dose efficiency in future biomedical applications.  © 1964-2012 IEEE.","convolutional neural network (CNN); image noise; signal estimation; X-ray phase contrast imaging","Algorithms; Deep Learning; Image Processing, Computer-Assisted; Radiography; Signal-To-Noise Ratio; X-Rays; Bioinformatics; Biomedical signal processing; Convolutional neural networks; Deep neural networks; Image denoising; Image enhancement; Image quality; Medical applications; Phantoms; X rays; Analytical method; Biological specimens; Biomedical applications; Breast phantom; Dose efficiency; Dose reduction; Learning techniques; Ray differentials; algorithm; Article; breast; breast calcification; contrast radiography; controlled study; convolutional neural network; diagnostic accuracy; digital mammography; ex vivo study; feasibility study; image quality; noise reduction; quantitative analysis; signal detection; X rray differential phase contrast imaging; image processing; radiography; signal noise ratio; X ray; Deep learning","Guangdong Basic and Applied Basic Research Foundation, (2019A1515011262); Shenzhen Basic Research Program, (JCYJ20170413162354654); National Natural Science Foundation of China, NSFC, (11674232, 11804356); National Natural Science Foundation of China, NSFC","","IEEE Computer Society","32746069"
"","","","Proceedings of the 5th International Conference on Biological Information and Biomedical Engineering, BIBE 2021","2021","","","","","","239","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120556775&partnerID=40&md5=000c574ab81ce18d691a8acd8095c438","The proceedings contain 40 papers. The topics discussed include: effect of electrode size and maximum current limitation on multichannel transcranial electrical stimulation optimization; research on technical standards of prevention and control of low vision among adolescents; Covid-19 classification with deep neural network and belief functions; overview of machine learning methods for genome-wide association analysis; computational design of potential binder protein for SARS-CoV-2 spike RBD through a novel deep neural network based-protein outpainting algorithm; facile fabrication of cell delivery microrobot using self-rolled-up method; information-based similarity of binary symbol sequence as a new index for sleep apnea research; and thermal dose images enhance the prediction of local tumor progression after multimode ablation.","","","","Chen B.","Association for Computing Machinery",""
"Ma T.; Wang S.; Xia Y.; Zhu X.; Evans J.; Sun Y.; He S.","Ma, Tengfei (58386668100); Wang, Shasha (57222966765); Xia, Yuting (57221389484); Zhu, Xinhua (57222966374); Evans, Julian (42161310500); Sun, Yaoran (57191647400); He, Sailing (36048024500)","58386668100; 57222966765; 57221389484; 57222966374; 42161310500; 57191647400; 36048024500","CNN-based classification of fNIRS signals in motor imagery BCI system","2021","18","5","056019","","","","10.1088/1741-2552/abf187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104275427&doi=10.1088%2f1741-2552%2fabf187&partnerID=40&md5=e2bfd1a7f48e917678257fb2d83f4b5e","Objective. Development of a brain-computer interface (BCI) requires classification of brain neural activities to different states. Functional near-infrared spectroscopy (fNIRS) can measure the brain activities and has great potential for BCI. In recent years, a large number of classification algorithms have been proposed, in which deep learning methods, especially convolutional neural network (CNN) methods are successful. fNIRS signal has typical time series properties, we combined fNIRS data and kinds of CNN-based time series classification (TSC) methods to classify BCI task. Approach. In this study, participants were recruited for a left and right hand motor imagery experiment and the cerebral neural activities were recorded by fNIRS equipment (FOIRE-3000). TSC methods are used to distinguish the brain activities when imagining the left or right hand. We have tested the overall person, single person and overall person with single-channel classification results, and these methods achieved excellent classification results. We also compared the CNN-based TSC methods with traditional classification methods such as support vector machine. Main results. Experiments showed that the CNN-based methods have significant advantages in classification accuracy: the CNN-based methods have achieved remarkable results in the classification of left-handed and right-handed imagination tasks, reaching 98.6% accuracy on overall person, 100% accuracy on single person, and in the single-channel classification an accuracy of 80.1% has been achieved with the best-performing channel. Significance. These results suggest that using the CNN-based TSC methods can significantly improve the BCI performance and also lay the foundation for the miniaturization and portability of training rehabilitation equipment. © 2021 IOP Publishing Ltd.","BCI; CNN; fNIRS; motor imagery; time series classification","Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Neural Networks, Computer; Spectroscopy, Near-Infrared; Biomedical signal processing; Brain; Brain computer interface; Convolutional neural networks; Deep learning; Image classification; Infrared devices; Interface states; Learning systems; Near infrared spectroscopy; Neurophysiology; Support vector machines; Time series; hemoglobin; Classification accuracy; Classification algorithm; Classification methods; Classification results; Functional near-infrared spectroscopy (fnirs); Hand motor imageries; Learning methods; Time series classifications; adult; Article; classification algorithm; comparative study; convolutional neural network; data classification; female; fully convolutional neural network; functional near-infrared spectroscopy; hemodynamic parameters; human; imagery; inception network; left hand motor imagery; long short term memory network; long short term memory network inception network; male; measurement accuracy; multilayer perceptron; nerve cell network; normal human; optical density; oscillation; priority journal; residual network; right hand motor imagery; single channel classification; single person classification; time series classification; brain computer interface; electroencephalography; imagination; near infrared spectroscopy; Functional neuroimaging","","","IOP Publishing Ltd","33761480"
"Arif M.; Ajesh F.; Shamsudheen S.; Geman O.; Izdrui D.; Vicoveanu D.","Arif, Muhammad (56452459100); Ajesh, F. (57217016287); Shamsudheen, Shermin (57223927301); Geman, Oana (53863372800); Izdrui, Diana (57223106792); Vicoveanu, Dragos (25522574300)","56452459100; 57217016287; 57223927301; 53863372800; 57223106792; 25522574300","Brain Tumor Detection and Classification by MRI Using Biologically Inspired Orthogonal Wavelet Transform and Deep Learning Techniques","2022","2022","","2693621","","","","10.1155/2022/2693621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123674522&doi=10.1155%2f2022%2f2693621&partnerID=40&md5=13187cc309127b2c3f702af6de30b723","Radiology is a broad subject that needs more knowledge and understanding of medical science to identify tumors accurately. The need for a tumor detection program, thus, overcomes the lack of qualified radiologists. Using magnetic resonance imaging, biomedical image processing makes it easier to detect and locate brain tumors. In this study, a segmentation and detection method for brain tumors was developed using images from the MRI sequence as an input image to identify the tumor area. This process is difficult due to the wide variety of tumor tissues in the presence of different patients, and, in most cases, the similarity within normal tissues makes the task difficult. The main goal is to classify the brain in the presence of a brain tumor or a healthy brain. The proposed system has been researched based on Berkeley's wavelet transformation (BWT) and deep learning classifier to improve performance and simplify the process of medical image segmentation. Significant features are extracted from each segmented tissue using the gray-level-co-occurrence matrix (GLCM) method, followed by a feature optimization using a genetic algorithm. The innovative final result of the approach implemented was assessed based on accuracy, sensitivity, specificity, coefficient of dice, Jaccard's coefficient, spatial overlap, AVME, and FoM.  © 2022 Muhammad Arif et al.","","Algorithms; Brain; Brain Neoplasms; Deep Learning; Humans; Magnetic Resonance Imaging; Wavelet Analysis; Biomimetics; Brain; Deep learning; Genetic algorithms; Histology; Image enhancement; Image segmentation; Learning systems; Medical imaging; Tumors; Wavelet transforms; Biologically-inspired; Brain tumors; Detection methods; Learning techniques; Medical science; MRI sequences; Orthogonal wavelet transforms; Segmentation methods; Tumor classification; Tumour detection; adult; Article; brain tumor; classification; classifier; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; feature extraction; genetic algorithm; human; image processing; image segmentation; major clinical study; nuclear magnetic resonance imaging; sensitivity and specificity; support vector machine; tumor diagnosis; wavelet transform; algorithm; brain; brain tumor; diagnostic imaging; nuclear magnetic resonance imaging; procedures; wavelet analysis; Magnetic resonance imaging","","","Hindawi Limited","35047149"
"Waly M.I.; Sikkandar M.Y.; Aboamer M.A.; Kadry S.; Thinnukool O.","Waly, Mohamed Ibrahim (57196075534); Sikkandar, Mohamed Yacin (57202716139); Aboamer, Mohamed Abdelkader (56073053400); Kadry, Seifedine (55906598300); Thinnukool, Orawit (56146494600)","57196075534; 57202716139; 56073053400; 55906598300; 56146494600","Optimal deep convolution neural network for cervical cancer diagnosis model","2022","70","2","","3297","3309","12","10.32604/cmc.2022.020713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115993107&doi=10.32604%2fcmc.2022.020713&partnerID=40&md5=1dafd35e4d4d7422b32fcedd812b6d64","Biomedical imaging is an effective way of examining the internal organ of the human body and its diseases. An important kind of biomedical image is Pap smear image that is widely employed for cervical cancer diagnosis. Cervical cancer is a vital reason for increased women's mortality rate. Proper screening of pap smear images is essential to assist the earlier identification and diagnostic process of cervical cancer. Computer-aided systems for cancerous cell detection need to be developed using deep learning (DL) approaches. This study introduces an intelligent deep convolutional neural network for cervical cancer detection and classification (IDCNN-CDC) model using biomedical pap smear images. The proposed IDCNN-CDC model involves four major processes such as preprocessing, segmentation, feature extraction, and classification. Initially, the Gaussian filter (GF) technique is applied to enhance data through noise removal process in the Pap smear image. The Tsallis entropy technique with the dragonfly optimization (TE-DFO) algorithm determines the segmentation of an image to identify the diseased portions properly. The cell images are fed into the DL based SqueezeNet model to extract deep-learned features. Finally, the extracted features from SqueezeNet are applied to the weighted extreme learning machine (ELM) classification model to detect and classify the cervix cells. For experimental validation, the Herlev database is employed. The database was developed at Herlev University Hospital (Denmark). The experimental outcomes make sure that higher performance of the proposed technique interms of sensitivity, specificity, accuracy, and F-Score. © 2022 Tech Science Press. All rights reserved.","Biomedical images; Cervical cancer; Computer aided diagnosis; Deep learning; Herlev database; Pap smear images","Computer aided diagnosis; Computer aided instruction; Convolution; Convolutional neural networks; Database systems; Diseases; Feature extraction; Image enhancement; Image segmentation; Medical imaging; Biomedical images; Cancer classification; Cancer detection; Cancer diagnosis; Cervical cancers; Classification models; Deep learning; Detection models; Herlev database; Pap smear images; Deep neural networks","Majmaah University, MU, (R-2021-164)","","Tech Science Press",""
"Neeraj; Singhal V.; Mathew J.; Behera R.K.","Neeraj (57221702962); Singhal, Vatsal (57296301000); Mathew, Jimson (21834193800); Behera, Ranjan Kumar (57210095386)","57221702962; 57296301000; 21834193800; 57210095386","Detection of alcoholism using EEG signals and a CNN-LSTM-ATTN network","2021","138","","104940","","","","10.1016/j.compbiomed.2021.104940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117074939&doi=10.1016%2fj.compbiomed.2021.104940&partnerID=40&md5=181f14f5eb0809a7b49942c5367f6228","Alcoholism is a serious disorder that poses a problem for modern society, but the detection of alcoholism has no widely accepted standard tests or procedures. If alcoholism goes undetected at its early stages, it can create havoc in the patient's life. An electroencephalography (EEG) is a method used to measure the brain's electrical activity and can detect alcoholism. EEG signals are complex and multi-channel and thus can be difficult to interpret manually. Several previous works have tried to classify a subject as alcoholic or control (non-alcoholic) based on EEG signals. Such works have mainly used machine learning or statistical techniques along with handcrafted features such as entropy, correlation dimension, Hurst exponent. With the growth in computational power and data volume worldwide, deep learning models have recently been gaining momentum in various fields. However, only a few studies are available on the application of deep learning models for the classification of alcoholism using EEG signals. This paper proposes a deep learning architecture that uses a combination of fast Fourier transform (FFT), a convolution neural network (CNN), long short-term memory (LSTM), and a recently proposed attention mechanism for extracting Spatio-temporal features from multi-channel EEG signals. The proposed architecture can classify a subject as an alcoholic or control with a high degree of accuracy by analyzing EEG signals of that subject and can be used for automating alcoholism detection. The analytical results using the proposed architecture show a 98.83% accuracy, making it better than most state-of-the-art algorithms. © 2021","Alcoholism; Deep learning; EEG; FFT; Time series","Alcoholism; Algorithms; Electroencephalography; Humans; Machine Learning; Neural Networks, Computer; Biomedical signal processing; Brain; Electroencephalography; Electrophysiology; Long short-term memory; Network architecture; Signal detection; Alcoholism; Brain electrical activity; Convolution neural network; Deep learning; Learning models; Multi channel; Proposed architectures; Standard procedures; Standard tests; Times series; alcoholism; Article; clinical feature; comparative study; controlled study; convolutional neural network; deep learning; diagnostic accuracy; electric activity; electroencephalography; entropy; feature extraction; Fourier transform; human; image segmentation; long short term memory network; recurrent neural network; algorithm; electroencephalography; machine learning; Fast Fourier transforms","","","Elsevier Ltd","34656864"
"Giriprasad P.; Sanjeeva reddy G.A.; Sreehari R.V.","Giriprasad, P. (57382423700); Sanjeeva reddy, Gaddam A. (57381718800); Sreehari, R.V. (57381894600)","57382423700; 57381718800; 57381894600","Automatic Classification of Cardiac Arrhythmias based on ECG Signals Using Transferred Deep Learning Convolution Neural Network","2021","2089","1","012058","","","","10.1088/1742-6596/2089/1/012058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121526464&doi=10.1088%2f1742-6596%2f2089%2f1%2f012058&partnerID=40&md5=5191c72fbdc604dc19d6a9ddac0d2082","In the current article, an automatic classification of cardiac arrhythmias is presented using a transfer deep learning approach with the help of electrocardiography (ECG) signal analysis. Now a days, an ECG waveform serves as a powerful tool used for the analysis of cardiac arrhythmias (irregularities). The goal of the present work is to implement an algorithm based on deep learning for classification of different cardiac arrhythmias. Initially, the one dimensional (1-D) ECG signals are transformed to two dimensional (2-D) scalogram images with the help of Continuous Wavelet(CWT) .Four different categories of ECG waveform were selected from four PhysioNet MIT-BIH databases, namely arrhythmia database, Normal Sinus Rhythm database, Malignant Ventricular Ectopy database and BIDMC Congestive heart failure database to examine the proposed technique. The major interest of the present study is to develop a transferred deep learning algorithm for automatic categorization of the mentioned four different heart diseases. Final results proved that the 2-D scalogram images trained with a deep convolutional neural network CNN with transfer learning technique (AlexNet) pepped up with a prominent accuracy of 95.67%. Hence,it is worthwhile to say the above stated algorithm demonstrates as an effective automated heart disease detection tool © 2021 Institute of Physics Publishing. All rights reserved.","AlexNet; Deep learning algorithms; ECG classification; Transfer learning","Biomedical signal processing; Cardiology; Convolution; Database systems; Deep neural networks; Diseases; Heart; Learning algorithms; 'current; Alexnet; Automatic classification; Cardiac arrhythmia; Convolution neural network; Deep learning algorithm; Electrocardiography classification; Heart disease; Transfer learning; Waveforms; Electrocardiography","","","IOP Publishing Ltd",""
"Pietka E.; Gertych A.","Pietka, Ewa (6603704848); Gertych, Arkadiusz (7801318586)","6603704848; 7801318586","Advances in biomedical image processing","2021","89","","101891","","","","10.1016/j.compmedimag.2021.101891","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102633947&doi=10.1016%2fj.compmedimag.2021.101891&partnerID=40&md5=dc14c6ea9665445cdac379ec846b0ccc","[No abstract available]","","Image Processing, Computer-Assisted; abdominal viscera; Alzheimer disease; anatomical concepts; atopic dermatitis; biomedical engineering; classification; computer assisted tomography; convolutional neural network; data analysis; deep learning; diagnostic imaging; digital imaging; echography; Editorial; feature extraction; functional link artificial neural network; high frequency ultrasound; human; image processing; image segmentation; imaging algorithm; machine learning; mild cognitive impairment; multimodal imaging; nuclear magnetic resonance imaging; particle swarm optimization; priority journal; wound healing","","","Elsevier Ltd","33744791"
"Kar M.K.; Nath M.K.; Neog D.R.","Kar, Mithun Kumar (37087476200); Nath, Malaya Kumar (26423133700); Neog, Debanga Raj (37087579900)","37087476200; 26423133700; 37087579900","A Review on Progress in Semantic Image Segmentation and Its Application to Medical Images","2021","2","5","397","","","","10.1007/s42979-021-00784-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128319580&doi=10.1007%2fs42979-021-00784-5&partnerID=40&md5=98d28f4b102eba15a7f2b1f6ce0ee806","Semantic image segmentation is a popular image segmentation technique where each pixel in an image is labeled with an object class. This technique has become a vital part of image analysis nowadays as it facilitates the description, categorization, and visualization of the regions of interest in an image. The recent developments in computer vision algorithms and the increasing availability of large datasets have made semantic image segmentation very popular in the field of computer vision. Motivated by the human visual system which can identify objects in a complex scene very efficiently, researchers are interested in building a model that can semantically segment an image into meaningful object classes. This paper reviews deep learning-based semantic segmentation techniques that use deep neural network architectures for image segmentation of biomedical images. We have provided a discussion on the fundamental concepts related to deep learning methods used in semantic segmentation for the benefit of readers. The standard datasets and existing deep network architectures used in both medical and non-medical fields are discussed with their significance. Finally, this paper concludes by discussing the challenges and future research directions in the field of deep learning-based semantic segmentation for applications in the medical field. © 2021, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.","Automated medical image analysis; Convolution neural network; Deep learning; Deep neural network; Recurrent neural network; Semantic segmentation","","National Institute of Technology Srinagar, NITSRI","","Springer",""
"The N.H.; Nhung N.T.H.; Binh N.T.","The, Nguyen Huu (57209367224); Nhung, Nguyen Thi Hong (57188569272); Binh, Nguyen Thanh (36052211500)","57209367224; 57188569272; 36052211500","Adaptive Lung Diseases Images Classification Technique Based on Deep Learning","2022","85","","","803","814","11","10.1007/978-3-030-75506-5_65","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115081403&doi=10.1007%2f978-3-030-75506-5_65&partnerID=40&md5=62f80e893f27698eccac78516256b684","Medical images have made an important contribution to improving the accuracy and effectiveness of disease diagnosis, such as diseases related to lung, heart, liver, kidney, etc. Pneumonia has increased rapidly in the world in recent years. Chest X-ray image analysis is a common method for detecting lung diseases. An advanced artificial intelligence system will help doctors have accurate conclusions, timely treatment for patients and reducing mortality. Using machine learning on X-ray images is of great interest, but research results are still limited in accuracy. This paper proposed an adaptive technique for lung diseases image classification based on the deep learning method. We improved the convolutional neural network for lung diseases image classification, created a training model with a suitable number of hidden network layers and optimal algorithms to detect pneumonia images. As a result, the rate of correct detection of pneumonia image was 98.72%. We used chest X-ray images dataset that published by Kaggle, including 5863 chest X-ray images. The results of the proposed method are better than the other methods. © 2022, Springer Nature Switzerland AG.","Chest X-ray pneumonia; Convolutional neural network; Lung diseases; Pneumonia","Biological organs; Biomedical engineering; Convolutional neural networks; Deep learning; Diagnosis; Image classification; Learning systems; Medical imaging; Multilayer neural networks; Network layers; Patient treatment; Adaptive technique; Artificial intelligence systems; Chest X-ray image; Disease diagnosis; Images classification; Learning methods; Optimal algorithm; Research results; Image enhancement","University of Cuu Long","Van Toi V.; Nguyen T.-H.; Long V.B.; Huong H.T.T.","Springer Science and Business Media Deutschland GmbH",""
"Xiao D.; Zang Z.; Sapermsap N.; Wang Q.; Xie W.; Chen Y.; Li D.D.U.","Xiao, Dong (57202353382); Zang, Zhenya (57221473959); Sapermsap, Natakorn (57216453659); Wang, Quan (57223692229); Xie, Wujun (57221150116); Chen, Yu (55874544500); Li, David Day Uei (56381706200)","57202353382; 57221473959; 57216453659; 57223692229; 57221150116; 55874544500; 56381706200","Dynamic fluorescence lifetime sensing with CMOS single-photon avalanche diode arrays and deep learning processors","2021","12","6","","3450","3462","12","10.1364/BOE.425663","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105995220&doi=10.1364%2fBOE.425663&partnerID=40&md5=67d14fedf13250e628c14af85be94e5f","Measuring fluorescence lifetimes of fast-moving cells or particles have broad applications in biomedical sciences. This paper presents a dynamic fluorescence lifetime sensing (DFLS) system based on the time-correlated single-photon counting (TCSPC) principle. It integrates a CMOS 192 × 128 single-photon avalanche diode (SPAD) array, offering an enormous photon-counting throughput without pile-up effects. We also proposed a quantized convolutional neural network (QCNN) algorithm and designed a field-programmable gate array embedded processor for fluorescence lifetime determinations. The processor uses a simple architecture, showing unparallel advantages in accuracy, analysis speed, and power consumption. It can resolve fluorescence lifetimes against disturbing noise. We evaluated the DFLS system using fluorescence dyes and fluorophore-tagged microspheres. The system can effectively measure fluorescence lifetimes within a single exposure period of the SPAD sensor, paving the way for portable time-resolved devices and shows potential in various applications. © 2021 OSA - The Optical Society. All rights reserved.","","Avalanche diodes; CMOS integrated circuits; Convolutional neural networks; Field programmable gate arrays (FPGA); Fluorescence; Fluorophores; Particle beams; Photons; Piles; f8836; fluorescein; fluorescent dye; microsphere; Biomedical science; Broad application; Embedded processors; Fluorescence lifetime sensing; Fluorescence lifetimes; Single photon avalanche diode; Single-photon avalanche diode arrays; Time-correlated single-photon counting; Article; block random access memory; controlled study; convolutional neural network; deep learning; diagnostic accuracy; dynamic fluorescence lifetime sensing; flow cytometry; fluorescence imaging; high throughput analysis; image quality; nonhuman; normal distribution; Poisson distribution; remote sensing; spectral sensitivity; validation process; Deep learning","","","The Optical Society",""
"Riyad M.; Khalil M.; Adib A.","Riyad, Mouad (57209615613); Khalil, Mohammed (55628523934); Adib, Abdellah (57222401572)","57209615613; 55628523934; 57222401572","A novel multi-scale convolutional neural network for motor imagery classification","2021","68","","102747","","","","10.1016/j.bspc.2021.102747","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106858928&doi=10.1016%2fj.bspc.2021.102747&partnerID=40&md5=e5df5d66ff63248297071549a4a0e835","Brain-Computer Interfaces (BCI) allows us to use brain activity as a pathway to interact with machines for varied purposes that may enhance humans life. Most of those systems rely on motor imagery that generates different patterns of the electroencephalography signals. However, those phenomenon produce signals with low quality which makes their recognition a troublesome job. Thus, we come up with a novel Convolutional Neural Network (CNN) that is constructed specially for this application. A multi-branch system is used to preserve and deal with each band separably, which will grant a better classification. By using the dataset BCI IV-2a, we demonstrate that our method achieves better training time compared with the existing CNNs, and better classification compared with the state-of-the-art baselines. We conduct an ablation study to evaluate the impact of the parallel pipelines on the performances by adding them gradually, and we show that adding features extracted from different scales has indeed a positive influence on diverse metrics. Further, we compared the training time of the network with and without Separable and Depthwise convolutional layers, we conclude that they permit the reduction of the training time thanks to their low computational requirement along with the positive impact on the accuracy. We note that there is some benefit in the tasks that provides the weakest patterns. To further clarify the results, we carry out an extensive analysis of the network based on the relevance of the input feature, which explained the failed classification. © 2021 Elsevier Ltd","Brain–computer interfaces; Convolutional neural network; Deep learning; Electroencephalography; Motor imagery","Biomedical signal processing; Brain; Brain computer interface; Classification (of information); Convolution; Deep learning; Electrophysiology; Image classification; Neural networks; Brain activity; Branch system; Convolutional neural network; Deep learning; Human lives; Low qualities; Motor imagery; Motor imagery classification; Multi-scales; Training time; algorithm; Article; auxiliary multiscale input; classification; controlled study; convolutional neural network; data accuracy; deep learning; deep learning important feature; deep neural network; electroencephalogram; electroencephalography; electrooculography; feature extraction; filter banks common spatial pattern; human; human experiment; imagery; intermethod comparison; motor imager; Riemannian geometry; ShallowConvNet; task performance; Electroencephalography","","","Elsevier Ltd",""
"Kant P.; Laskar S.H.; Hazarika J.","Kant, Piyush (57218253680); Laskar, S.H. (55075744100); Hazarika, Jupitara (57202357937)","57218253680; 55075744100; 57202357937","Classification Techniques for Binary Motor Imagery Signal for Brain-Computer Interfaces","2022","777","","","1261","1273","12","10.1007/978-981-16-2761-3_109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121753289&doi=10.1007%2f978-981-16-2761-3_109&partnerID=40&md5=ae47c41e39017fe535a5a406cdf778fa","Brain-computer interface (BCI) is a tool to decode human brain signals in order to enable communication with the outer world just by using electroencephalogram (EEG) signals. Motor imagery (MI) signals recorded from the scalp during the imagination of movements are used as inputs for the BCI applications. Authors did review various classification methods, used to classify MI data. Machine learning (ML) has proven to be a very effective tool in classifying MI signals. Several machine learning techniques are available to train ML models. Conventional machine learning methods can provide good classification results. However, deep learning (DL) methods are also found to provide better performance for such problems. The study compares conventional ML and deep neural networks based transfer learning as two classification approaches. Conventional machine learning was evaluated using SVM, KNN, and LDA classifiers, whereas transfer learning is implemented using alexnet, vgg16, and vgg19 networks. The study has shown the dominance of deep learning techniques over conventional classification techniques in our experiments. Transfer learning using the VGG net has resulted in a classification accuracy of 94.29%. The finding of the study suggests that although deep neural networks are computationally complex, and these networks can be very vital in the implementation of BCI technology. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Continuous wavelet transform (CWT); Convolutional neural network (CNN); Deep learning; Electroencephalogram (EEG); Feature selection; Motor imagery (MI); Wavelet packet transform (WPT)","Biomedical signal processing; Brain computer interface; Convolutional neural networks; Deep neural networks; Image classification; Learning algorithms; Support vector machines; Wavelet analysis; Wavelet transforms; Continuous wavelet transform; Convolutional neural network; Deep learning; Electroencephalogram; Features selection; Motor imagery; Wavelet packet transform; Wavelet packet transforms; Electroencephalography","","Dhawan A.; Tripathi V.S.; Arya K.V.; Naik K.","Springer Science and Business Media Deutschland GmbH",""
"Wang W.; Leonhardt S.; Tarassenko L.; Shan C.; McDuff D.","Wang, Wenjin (57192554264); Leonhardt, Steffen (7004971042); Tarassenko, Lionel (56213223400); Shan, Caifeng (13605743800); McDuff, Daniel (36106217600)","57192554264; 7004971042; 56213223400; 13605743800; 36106217600","Guest Editorial: Camera-Based Monitoring for Pervasive Healthcare Informatics","2021","25","5","9428048","1358","1360","2","10.1109/JBHI.2021.3072439","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105807033&doi=10.1109%2fJBHI.2021.3072439&partnerID=40&md5=a52642fa29294959c59cbeaaf90f30d0","This special issue of the IEEE Journal of Biomedical and Health Informatics journal presents and highlight some of the latest developments on applying camera-based techniques for pervasive healthcare informatics. It has attracted a great number of submissions from researchers both from academia and from industry. Five articles presented in this special issue focus on camera-based physiological measurement, applying novel signal- and image-processing techniques to improve the robustness of vital-sign measurement and having the systems validated in real-world use cases such as automotive and clinical practice. A general video-processing framework for camera-based pulse-rate measurement includes two common parts, such as frontends that pre-process images or post-process measured signals, and the core algorithm that extracts the photoplethysmography (PPG) signal from the optical signals.","","Cameras; Health care; Image enhancement; Optical data processing; Video signal processing; Clinical practices; Latest development; Measured signals; Pervasive healthcare; Photoplethysmography (PPG); Physiological measurement; Signal and image processing; Video processing; accuracy; actimetry; algorithm; apnea; artificial intelligence; artificial neural network; atrial fibrillation; behavior; breathing rate; deep learning; delirium; dementia; depression; echography; fever; gastroesophageal reflux; heart arrhythmia; heart rate; hemoglobin blood level; histopathology; hypertension; intensive care unit; medical informatics; melanoma; monitoring; oxygen saturation; patient monitoring; photoelectric plethysmography; polysomnography; pulse rate; quality of life; Review; skin temperature; sleep disorder; sleep quality; telemedicine; Medical informatics","","","Institute of Electrical and Electronics Engineers Inc.",""
"Ghosh L.; Dewan D.; Chowdhury A.; Konar A.","Ghosh, Lidia (8586972800); Dewan, Dipayan (57212339915); Chowdhury, Abir (57212340496); Konar, Amit (7004422312)","8586972800; 57212339915; 57212340496; 7004422312","Exploration of face-perceptual ability by EEG induced deep learning algorithm","2021","66","","102368","","","","10.1016/j.bspc.2020.102368","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099498909&doi=10.1016%2fj.bspc.2020.102368&partnerID=40&md5=041460b965136d4b8b51137ac80b4a17","Face perception essentially refers to an individual's ability to understand and interpret a familiar face. This paper attempts to quantify the face perceptual ability of human subjects using their memory responses, acquired by an electroencephalographic (EEG) device, during engagement of the human subjects in a face recognition task. The entire experimental protocol is designed in the settings of pattern recognition, comprising five main steps, namely artifact removal, feature extraction, classifier training and testing, and face-perception ability measurement. The primary objective of the paper is to design a deep neural network model that utilizes both the temporal and spatial EEG features to categorize the familiar face (FF) and unfamiliar face (UF) responses of human subjects from their brain signals. To extract the spatial information, the acquired raw EEG data is transformed into multi-spectral 2-dimensional images by a deep learning approach. The spatial information, along with the EEG time-frequency domain (temporal) features are then utilized to train the proposed deep neural network, which can preserve the spatial as well as temporal EEG features that are more robust and less sensitive to the variations along each dimension. The proposed deep neural network paradigm demonstrates promising results in classifying the EEG responses for FF and UF recognition with high classification accuracy. Biological underpinning of the cortical mechanism using sLORETA and event related potential (ERP) analysis in perceiving FFs and UFs by both the healthy controls and prosopagnosic patients is also a significant inclusion in the paper. The first and foremost advantage of the proposed work is that it provides a technological means to assess the variations in face perceptual ability of individuals. It can also be used as a biomarker for early prosopagnosia diagnosis. © 2021 Elsevier Ltd","Deep learning; Electroencephalography; Face perception-ability; Prosopagnosia","Ability testing; Biomedical signal processing; Deep neural networks; Electroencephalography; Face recognition; Frequency domain analysis; Learning algorithms; Neural networks; Biological underpinnings; Classification accuracy; Electroencephalographic (EEG); Event-related potentials; Experimental protocols; Neural network model; Spatial informations; Time frequency domain; adult; Article; artifact reduction; classification; classifier; clinical article; cognitive defect; controlled study; deep learning; deep neural network; electroencephalography; event related potential; facial recognition; feature extraction; female; fusiform face area; Hilbert Huang transform; human; long short term memory network; low resolution brain electromagnetic tomography; male; pattern recognition; priority journal; prosopagnosia; right hemisphere; short time Fourier transform; Deep learning","Ministry of Human Resource Development, MHRD","","Elsevier Ltd",""
"Baygin M.; Dogan S.; Tuncer T.; Datta Barua P.; Faust O.; Arunkumar N.; Abdulhay E.W.; Emma Palmer E.; Rajendra Acharya U.","Baygin, Mehmet (55293658600); Dogan, Sengul (25653093400); Tuncer, Turker (37062172100); Datta Barua, Prabal (36993665100); Faust, Oliver (14830975900); Arunkumar, N. (24330633400); Abdulhay, Enas W. (23388143900); Emma Palmer, Elizabeth (57224476270); Rajendra Acharya, U. (7004510847)","55293658600; 25653093400; 37062172100; 36993665100; 14830975900; 24330633400; 23388143900; 57224476270; 7004510847","Automated ASD detection using hybrid deep lightweight features extracted from EEG signals","2021","134","","104548","","","","10.1016/j.compbiomed.2021.104548","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107676445&doi=10.1016%2fj.compbiomed.2021.104548&partnerID=40&md5=9580b6b80bacf0bdbeec8c94f63d4f9d","Background: Autism spectrum disorder is a common group of conditions affecting about one in 54 children. Electroencephalogram (EEG) signals from children with autism have a common morphological pattern which makes them distinguishable from normal EEG. We have used this type of signal to design and implement an automated autism detection model. Materials and method: We propose a hybrid lightweight deep feature extractor to obtain high classification performance. The system was designed and tested with a big EEG dataset that contained signals from autism patients and normal controls. (i) A new signal to image conversion model is presented in this paper. In this work, features are extracted from EEG signal using one-dimensional local binary pattern (1D_LBP) and the generated features are utilized as input of the short time Fourier transform (STFT) to generate spectrogram images. (ii) The deep features of the generated spectrogram images are extracted using a combination of pre-trained MobileNetV2, ShuffleNet, and SqueezeNet models. This method is named hybrid deep lightweight feature generator. (iii) A two-layered ReliefF algorithm is used for feature ranking and feature selection. (iv) The most discriminative features are fed to various shallow classifiers, developed using a 10-fold cross-validation strategy for automated autism detection. Results: A support vector machine (SVM) classifier reached 96.44% accuracy based on features from the proposed model. Conclusions: The results strongly indicate that the proposed hybrid deep lightweight feature extractor is suitable for autism detection using EEG signals. The model is ready to serve as part of an adjunct tool that aids neurologists during autism diagnosis in medical centers. © 2021 Elsevier Ltd","1D_LBP-STFT; Autism classification; Hybrid lightweight deep feature generator; ReliefF<sup>2</sup>; Transfer learning","Algorithms; Autism Spectrum Disorder; Child; Electroencephalography; Humans; Support Vector Machine; Automation; Biomedical signal processing; Diseases; Electroencephalography; Feature extraction; Image processing; Spectrographs; Support vector machines; Transfer learning; 1d_LBP-short time fourier transform; Autism classification; Autism spectrum disorders; Condition; Electroencephalogram signals; Feature extractor; Hybrid lightweight deep feature generator; Relieff2; Spectrograms; Transfer learning; Article; autism; decision tree; deep neural network; discriminant analysis; electroencephalogram; feature extraction; feature ranking; feature selection; female; human; k nearest neighbor; logistic regression analysis; major clinical study; male; short time Fourier transform; support vector machine; transfer of learning; algorithm; child; electroencephalography; Classification (of information)","","","Elsevier Ltd","34119923"
"Sharpless N.E.; Kerlavage A.R.","Sharpless, Norman E. (7007007543); Kerlavage, Anthony R. (57512653300)","7007007543; 57512653300","The potential of AI in cancer care and research","2021","1876","1","188573","","","","10.1016/j.bbcan.2021.188573","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109023973&doi=10.1016%2fj.bbcan.2021.188573&partnerID=40&md5=5ca9ee6aebbaeb0ad245a8dfc01b5565","Current applications of artificial intelligence (AI), machine learning, and deep learning in cancer research and clinical care are highly diverse—from aiding radiologists in reading medical images to predicting oncoprotein folding and dynamics. The list of available AI-based tools is growing rapidly and will only continue to expand. With the immense potential for AI to advance cancer research and clinical care, the National Cancer Institute (NCI) has a responsibility to consider and support the development and evaluation of such technologies. NCI's current involvement in AI research spans the spectrum of development, implementation, and assessment. That includes generating large, publicly available, curated datasets; shifting the culture of data sharing; training the next generation of scientists in both AI and cancer sciences; fostering interdisciplinary collaborations; investing in research to improve AI methods and models that are designed specifically for cancer; widening access to computing power; procuring computer architecture for future developments; and assuring AI research and technologies follow ethical principles. In addition to a broad overview of AI applications in cancer research and care, and NCI's ongoing AI-based activities, this Perspective outlines NCI's four priority areas for future investment of cancer-focused AI development. © 2021","Artificial intelligence; Machine learning","Animals; Artificial Intelligence; Biomedical Research; Diffusion of Innovation; Humans; Machine Learning; Medical Oncology; National Cancer Institute (U.S.); Neoplasms; United States; microRNA; oncoprotein; algorithm; amino acid sequence; Article; artificial intelligence; artificial neural network; bladder cancer; breast cancer; cancer model; carcinogenesis; deep learning; electronic health record; genotype; health care cost; human; image quality; lymph node metastasis; machine learning; medical student; metastasis; national health organization; nuclear magnetic resonance imaging; personalized medicine; quality of life; risk factor; training; animal; diagnostic imaging; genetics; mass communication; medical research; metabolism; national health organization; neoplasm; oncology; United States","","","Elsevier B.V.","34052390"
"Lo J.; Cardinell J.; Costanzo A.; Sussman D.","Lo, Justin (57224993439); Cardinell, Jillian (57207689301); Costanzo, Alejo (57300830500); Sussman, Dafna (36638418300)","57224993439; 57207689301; 57300830500; 36638418300","Medical augmentation (Med‐aug) for optimal data augmentation in medical deep learning networks","2021","21","21","7018","","","","10.3390/s21217018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117419879&doi=10.3390%2fs21217018&partnerID=40&md5=157f10b57d24d1801e61631808c130fd","Deep learning (DL) algorithms have become an increasingly popular choice for image classification and segmentation tasks; however, their range of applications can be limited. Their limitation stems from them requiring ample data to achieve high performance and adequate gen-eralizability. In the case of clinical imaging data, images are not always available in large quanti-ties. This issue can be alleviated by using data augmentation (DA) techniques. The choice of DA is important because poor selection can possibly hinder the performance of a DL algorithm. We propose a DA policy search algorithm that offers an extended set of transformations that accom-modate the variations in biomedical imaging datasets. The algorithm makes use of the efficient and high‐dimensional optimizer Bi‐Population Covariance Matrix Adaptation Evolution Strategy (BIPOP‐CMA‐ES) and returns an optimal DA policy based on any input imaging dataset and a DL algorithm. Our proposed algorithm, Medical Augmentation (Med‐Aug), can be implemented by other researchers in related medical DL applications to improve their model’s performance. Fur-thermore, we present our found optimal DA policies for a variety of medical datasets and popular segmentation networks for other researchers to use in related tasks. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural networks; Data augmentation; Deep learning; Fetal MRI; Segmentation","Algorithms; Deep Learning; Diagnostic Imaging; Education, Medical; Neural Networks, Computer; Bioinformatics; Convolutional neural networks; Covariance matrix; Deep learning; Evolutionary algorithms; Image segmentation; Optimization; Convolutional neural network; Data augmentation; Deep learning; Fetal MRI; Images classification; Images segmentations; Learning network; Optimal data; Performance; Segmentation; algorithm; diagnostic imaging; medical education; Medical imaging","Ryerson University","","MDPI","34770324"
"Escorcia-Gutierrez J.; Mansour R.F.; Beleño K.; Jiménez-Cabas J.; Pérez M.; Madera N.; Velasquez K.","Escorcia-Gutierrez, José (57191268293); Mansour, Romany F. (36960713000); Beleño, Kelvin (57410276900); Jiménez-Cabas, Javier (57202833550); Pérez, Meglys (59159121200); Madera, Natasha (57278705000); Velasquez, Kevin (57410862700)","57191268293; 36960713000; 57410276900; 57202833550; 59159121200; 57278705000; 57410862700","Automated Deep Learning Empowered Breast Cancer Diagnosis Using Biomedical Mammogram Images","2022","71","2","","4221","4235","14","10.32604/cmc.2022.022322","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122769222&doi=10.32604%2fcmc.2022.022322&partnerID=40&md5=3ae0821a195d4ca5af59d02370f64fa6","Biomedical image processing is a hot research topic which helps to majorly assist the disease diagnostic process. At the same time, breast cancer becomes the deadliest disease among women and can be detected by the use of different imaging techniques. Digital mammograms can be used for the earlier identification and diagnostic of breast cancer to minimize the death rate. But the proper identification of breast cancer has mainly relied on the mammography findings and results to increased false positives. For resolving the issues of false positives of breast cancer diagnosis, this paper presents an automated deep learning based breast cancer diagnosis (ADL-BCD) model using digital mammograms. The goal of the ADL-BCD technique is to properly detect the existence of breast lesions using digital mammograms. The proposed model involves Gaussian filter based pre-processing and Tsallis entropy based image segmentation. In addition, Deep Convolutional Neural Network based Residual Network (ResNet 34) is applied for feature extraction purposes. Specifically, a hyper parameter tuning process using chimp optimization algorithm (COA) is applied to tune the parameters involved in ResNet 34 model. The wavelet neural network (WNN) is used for the classification of digital mammograms for the detection of breast cancer. The ADL-BCD method is evaluated using a benchmark dataset and the results are analyzed under several performance measures. The simulation outcome indicated that the ADL-BCD model outperforms the state of art methods in terms of different measures. © 2022 Tech Science Press. All rights reserved.","Breast cancer; Deep learning; Digital mammograms; Disease diagnosis; Resnet 34; Wavelet neural network","Benchmarking; Computer aided diagnosis; Convolutional neural networks; Deep neural networks; Diseases; E-learning; Image segmentation; X ray screens; Breast Cancer; Breast cancer diagnosis; Deep learning; Diagnosis model; Digital mammograms; Disease diagnosis; False positive; Neural-networks; Resnet 34; Wavelet neural network; Mammography","","","Tech Science Press",""
"Quan H.T.; Huy D.D.; Hoan N.T.; Duc N.T.","Quan, Huynh Thanh (57261962400); Huy, Dong Duc (57261962500); Hoan, Ngo Thanh (36476226300); Duc, Nguyen Thanh (57207762079)","57261962400; 57261962500; 36476226300; 57207762079","Deep Learning-Based Automatic Detection of Defective Tablets in Pharmaceutical Manufacturing","2022","85","","","789","801","12","10.1007/978-3-030-75506-5_64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115104610&doi=10.1007%2f978-3-030-75506-5_64&partnerID=40&md5=c4453fec65d819a29af3f3398e822f0a","With many tablets produced everyday in manufacturing plants, the pharmaceutical industry needs automatic, highly accurate methods for inspection of tablet quality. Detecting defective tablets is of importance to reduce unqualified products to consumers. In this paper, we propose a deep learning method combining image processing and deep convolutional neural networks (DCNN) for detection of defective tablets using images captured by a multiple-camera inspection system. A dataset of 6000 images of tablets labelled either GOOD or NOT-GOOD were collected at a pharmaceutical factory using commercial camera inspection systems. After collecting and labelling, the images were preprocessed to normalize intensity values. The entire dataset was split into a training set (50%, 3000 images), a validation set (16.6%, 1000 images) and a testing set (33.3%, 2000 images). We trained DCNN ResNets (ResNet50, ResNet101) and DenseNets (DenseNet169, DenseNet201) models on the training set and validated them on the validation set. We applied transfer learning techniques by using pre-trained models that had been trained on the ImageNet dataset in combination with data augmentation and training strategies such as learning rate rescheduling overtime. We compared our deep learning methods with various machine-learning ones such as Support Vector Machine (SVM), K-Nearest-Neighbors (KNN), AdaBoost that used intensity histograms as features. Tuning hyperparameters were performed to seek the best hyper-parameters and algorithms. We achieved best performances using the deep learning models as the ResNet50, and DenseNet169 obtained 96.60% ± 4.9% and 94.13% ± 4.2% accuracies (ACC), respectively. In contrast, SVM achieved 87.75% ACC, KNN achieved 76.09% ± 7.7% ACC while AdaBoost achieved 81.25% ACC, respectively. © 2022, Springer Nature Switzerland AG.","AI; CNN network; Pharmaceutical industry; ResNet; Tablet visual inspection","Adaptive boosting; Biomedical engineering; Cameras; Convolutional neural networks; Deep neural networks; Defects; Engineering education; Image processing; Inspection; Inspection equipment; Learning systems; mHealth; Nearest neighbor search; Statistical tests; Support vector machines; Transfer learning; Automatic Detection; Camera inspection system; Intensity histograms; K nearest neighbor (KNN); Learning techniques; Manufacturing plant; Pharmaceutical industry; Pharmaceutical manufacturing; Deep learning","","Van Toi V.; Nguyen T.-H.; Long V.B.; Huong H.T.T.","Springer Science and Business Media Deutschland GmbH",""
"Zhang X.-M.; Liang L.; Liu L.; Tang M.-J.","Zhang, Xiao-Meng (58612847100); Liang, Li (57684147000); Liu, Lin (57204698555); Tang, Ming-Jing (57205244111)","58612847100; 57684147000; 57204698555; 57205244111","Graph Neural Networks and Their Current Applications in Bioinformatics","2021","12","","690049","","","","10.3389/fgene.2021.690049","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112708351&doi=10.3389%2ffgene.2021.690049&partnerID=40&md5=a84c4b5dc40f597573970d69469ac484","Graph neural networks (GNNs), as a branch of deep learning in non-Euclidean space, perform particularly well in various tasks that process graph structure data. With the rapid accumulation of biological network data, GNNs have also become an important tool in bioinformatics. In this research, a systematic survey of GNNs and their advances in bioinformatics is presented from multiple perspectives. We first introduce some commonly used GNN models and their basic principles. Then, three representative tasks are proposed based on the three levels of structural information that can be learned by GNNs: node classification, link prediction, and graph generation. Meanwhile, according to the specific applications for various omics data, we categorize and discuss the related studies in three aspects: disease prediction, drug discovery, and biomedical imaging. Based on the analysis, we provide an outlook on the shortcomings of current studies and point out their developing prospect. Although GNNs have achieved excellent results in many biological tasks at present, they still face challenges in terms of low-quality data processing, methodology, and interpretability and have a long road ahead. We believe that GNNs are potentially an excellent method that solves various biological problems in bioinformatics research. © Copyright © 2021 Zhang, Liang, Liu and Tang.","bioinformatics; deep learning; graph neural networks; network biology; omics data","circular ribonucleic acid; ligand; long untranslated RNA; microRNA; algorithm; amino acid sequence; Article; artificial neural network; bioinformatics; Caenorhabditis elegans; cell differentiation; computer model; data processing; deep learning; diagnostic imaging; disease association; drug design; drug development; drug information; drug interaction; drug metabolism; drug response; drug stability; Escherichia coli; functional connectivity; functional magnetic resonance imaging; gene expression; gene sequence; image enhancement; image quality; image segmentation; information dissemination; interferometry; kernel method; learning algorithm; machine learning; methodology; microbiome; molecular model; nerve cell network; nuclear magnetic resonance imaging; omics; personalized medicine; protein function; protein protein interaction; protein structure; proteomics; quantum mechanics; receptive field; RNA sequence; signal processing; single cell RNA seq; training","Doctor Science Foundation of Yunnan Normal University, (01000205020503090); National Natural Science Foundation of China, NSFC, (61862067)","","Frontiers Media S.A.",""
"Nazir M.; Shakil S.; Khurshid K.","Nazir, Maria (57226116963); Shakil, Sadia (56184336000); Khurshid, Khurram (57119490500)","57226116963; 56184336000; 57119490500","Role of deep learning in brain tumor detection and classification (2015 to 2020): A review","2021","91","","101940","","","","10.1016/j.compmedimag.2021.101940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108679245&doi=10.1016%2fj.compmedimag.2021.101940&partnerID=40&md5=7a61fde7303ab5d6e02aff1d527b9e9b","During the last decade, computer vision and machine learning have revolutionized the world in every way possible. Deep Learning is a sub field of machine learning that has shown remarkable results in every field especially biomedical field due to its ability of handling huge amount of data. Its potential and ability have also been applied and tested in the detection of brain tumor using MRI images for effective prognosis and has shown remarkable performance. The main objective of this research work is to present a detailed critical analysis of the research and findings already done to detect and classify brain tumor through MRI images in the recent past. This analysis is specifically beneficial for the researchers who are experts of deep learning and are interested to apply their expertise for brain tumor detection and classification. As a first step, a brief review of the past research papers using Deep Learning for brain tumor classification and detection is carried out. Afterwards, a critical analysis of Deep Learning techniques proposed in these research papers (2015–2020) is being carried out in the form of a Table. Finally, the conclusion highlights the merits and demerits of deep neural networks. The results formulated in this paper will provide a thorough comparison of recent studies to the future researchers, along with the idea of the effectiveness of various deep learning approaches. We are confident that this study would greatly assist in advancement of brain tumor research. © 2021 Elsevier Ltd","Brain tumor; Deep learning; Machine learning; Neural networks","Brain; Brain Neoplasms; Deep Learning; Humans; Machine Learning; Neural Networks, Computer; Brain; Computer vision; Deep neural networks; Diagnosis; Learning systems; Magnetic resonance imaging; Tumors; Biomedical fields; Brain tumor classifications; Brain tumors; Critical analysis; Learning approach; Learning techniques; Research papers; Sub fields; Article; brain tumor; deep learning; deep neural network; detection algorithm; diagnostic imaging; feature selection; human; image analysis; multiclass classification; nuclear magnetic resonance imaging; quantitative analysis; transfer of learning; tumor classification; tumor diagnosis; brain; brain tumor; machine learning; Deep learning","","","Elsevier Ltd","34293621"
"Al-Saegh A.; Dawwd S.A.; Abdul-Jabbar J.M.","Al-Saegh, Ali (57219307602); Dawwd, Shefa A. (35775894900); Abdul-Jabbar, Jassim M. (6507674157)","57219307602; 35775894900; 6507674157","CutCat: An augmentation method for EEG classification","2021","141","","","433","443","10","10.1016/j.neunet.2021.05.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108114097&doi=10.1016%2fj.neunet.2021.05.032&partnerID=40&md5=3fc1e494f1e2b62cc687c3637b20f30c","The non-invasive electroencephalogram (EEG) signals enable humans to communicate with devices and have control over them, this process requires precise classification and identification of those signals. The recent revolution of deep learning has empowered both feature extraction and classification in a joint manner of different data types. However, deep learning is a data learning approach that demands a large number of training samples. Whilst, the EEG research field lacks a large amount of data which restricts the use of deep learning within this field. This paper proposes a novel augmentation method for enlarging EEG datasets. Our CutCat augmentation method generates trials from inter- and intra-subjects and trials. The method relies on cutting a specific period from an EEG trial and concatenating it with a period from another trial from the same subject or different subjects. The method has been tested on shallow and deep convolutional neural networks (CNN) for the classification of motor imagery (MI) EEG data. Two input formulation types images and time-series have been used as input to the neural networks. Short-time Fourier transform (STFT) is used for generating training images from the time-series signals. The experimental results demonstrate that the proposed augmentation method is a promising strategy for handling the classification of small-scale datasets. Classification results on two EEG datasets show advancement in comparison with the results of state-of-the-art researches. © 2021 Elsevier Ltd","Augmentation; BCI; CNN; Deep learning; EEG; Motor imagery","Algorithms; Brain-Computer Interfaces; Electroencephalography; Fourier Analysis; Humans; Neural Networks, Computer; Biomedical signal processing; Brain computer interface; Classification (of information); Deep neural networks; Fourier series; Time series; Augmentation; Augmentation methods; BCI; Classification and identifications; Convolutional neural network; Datatypes; Deep learning; Electroencephalogram signals; Feature extraction and classification; Motor imagery; adult; article; controlled study; convolutional neural network; deep learning; electroencephalogram; female; human; human experiment; imagery; male; short time Fourier transform; time series analysis; algorithm; brain computer interface; electroencephalography; Fourier analysis; Electroencephalography","","","Elsevier Ltd","34147756"
"Hu H.; Liu A.; Zhou Q.; Guan Q.; Li X.; Chen Q.","Hu, Haigen (30267591900); Liu, Aizhu (57220183654); Zhou, Qianwei (55330189900); Guan, Qiu (55671678500); Li, Xiaoxin (55157215200); Chen, Qi (56937307500)","30267591900; 57220183654; 55330189900; 55671678500; 55157215200; 56937307500","An adaptive learning method of anchor shape priors for biological cells detection and segmentation","2021","208","","106260","","","","10.1016/j.cmpb.2021.106260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109861265&doi=10.1016%2fj.cmpb.2021.106260&partnerID=40&md5=b76e6469f3d6f94bdd22834668e2953b","Background and objective: Owing to the variable shapes, large size difference, uneven grayscale and dense distribution among biological cells in an image, it is still a challenging task for the standard Mask R-CNN to accurately detect and segment cells. Especially, the state-of-the-art anchor-based methods fail to generate the anchors of sufficient scales effectively according to the various sizes and shapes of cells, thereby hardly covering all scales of cells. Methods: We propose an adaptive approach to learn the anchor shape priors from data samples, and the aspect ratios and the number of anchor boxes can be dynamically adjusted by using ISODATA clustering algorithm instead of human prior knowledge in this work. To solve the identification difficulties for small objects owing to the multiple down-samplings in a deep learning-based method, a densification strategy of candidate anchors is presented to enhance the effects of identifying tinny size cells. Finally, a series of comparative experiments are conducted on various datasets to select appropriate a network structure and verify the effectiveness of the proposed methods. Results: The results show that the ResNet-50-FPN combining the ISODATA method and densification strategy can obtain better performance than other methods in multiple metrics (including AP, Precision, Recall, Dice and PQ) for various biological cell datasets, such as U373, GoTW1, SIM+ and T24. Conclusions: Our adaptive algorithm could effectively learn the anchor shape priors from the various sizes and shapes of cells. It is promising and encouraging for a real-world anchor-based detection and segmentation application of biomedical engineering in the future. © 2021 Elsevier B.V.","Anchor densification; Anchor shape; Cell detection and segmentation; ISODATA; Mask R-CNN","Algorithms; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Aspect ratio; Biomedical engineering; Cells; Clustering algorithms; Cytology; Deep learning; Densification; Image segmentation; Phantoms; Anchor densification; Anchor shape; Biological cells; Cell detection; Cell segmentation; Densifications; ISODATA; Learn+; Shape priors; Size and shape; Article; cell shape; clustering algorithm; comparative study; data analysis; deep learning; feature extraction; human; image segmentation; k means clustering; machine learning; residual neural network; algorithm; image processing; Anchors","Microsystems Technology Key Laboratory Foundation of China; National Natural Science Foundation of China, NSFC, (61801428, 61802347, 61972354); Natural Science Foundation of Zhejiang Province, ZJNSF, (LGF20H180002, LGG18F030002, LY18F020031, LY18F020034); National Key Research and Development Program of China, NKRDPC, (2018YFB1305202)","","Elsevier Ireland Ltd","34273675"
"Zarei A.; Beheshti H.; Asl B.M.","Zarei, Asghar (57211463914); Beheshti, Hossein (57520921400); Asl, Babak Mohammadzadeh (24398491400)","57211463914; 57520921400; 24398491400","Detection of sleep apnea using deep neural networks and single-lead ECG signals","2022","71","","103125","","","","10.1016/j.bspc.2021.103125","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114496975&doi=10.1016%2fj.bspc.2021.103125&partnerID=40&md5=156e50ac3a2b28065e38ac678ff23e14","Sleep apnea causes frequent cessation of breathing during sleep. Feature extraction approaches play a key role in the performance of apnea detection algorithms that use single-lead electrocardiogram signals. Handcrafted features have high computational complexity due to their large dimensions and are usually not robust. To cope with the mentioned problems, in the current paper, an automatic feature extraction method is developed by combining the Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) recurrent network. Also, the fully connected layers are utilized to distinguish apnea events from the normal segments. Then, the apnea-hypopnea index (AHI) is applied to discriminate apnea subjects from healthy ones. Finally, in order to assess the usefulness of the proposed method, some experiments are conducted on the publicly accessible Apnea-ECG and UCDDB datasets. The results based on the sensitivity (94.41%), specificity (98.94%), and accuracy (97.21%), indicate that our proposed method provides significant improvements compared to the other sleep apnea detection methods. Our model also achieves an accuracy of 93.70%, sensitivity of 90.69%, and specificity of 95.82% for UCDDB dataset. It can be inferred that using the deep-learning based algorithm for detecting apnea patients would help physicians in making a decision more accurately. © 2021 Elsevier Ltd","CNN; Deep learning; ECG signal; LSTM; Sleep apnea","Biomedical signal processing; Chemical detection; Convolutional neural networks; Deep neural networks; Electrocardiography; Extraction; Feature extraction; Learning algorithms; Sleep research; Apnea detection; Convolutional neural network; Deep learning; Detection algorithm; ECG signals; Electrocardiogram signal; Features extraction; Large dimensions; Performance; Sleep apnea; adult; apnea hypopnea index; Article; autocorrelation; comparative study; controlled study; convolutional neural network; detection algorithm; diagnostic accuracy; diagnostic test accuracy study; electrocardiogram; feature extraction; human; image processing; long short term memory network; major clinical study; physician; recurrent neural network; sensitivity and specificity; sleep disordered breathing; Long short-term memory","","","Elsevier Ltd",""
"Durkee M.S.; Abraham R.; Clark M.R.; Giger M.L.","Durkee, Madeleine S. (56677655800); Abraham, Rebecca (57215870962); Clark, Marcus R. (56664601700); Giger, Maryellen L. (7103040897)","56677655800; 57215870962; 56664601700; 7103040897","Artificial Intelligence and Cellular Segmentation in Tissue Microscopy Images","2021","191","10","","1693","1701","8","10.1016/j.ajpath.2021.05.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115163423&doi=10.1016%2fj.ajpath.2021.05.022&partnerID=40&md5=133006568dbba9637ee8804579e5d488","With applications in object detection, image feature extraction, image classification, and image segmentation, artificial intelligence is facilitating high-throughput analysis of image data in a variety of biomedical imaging disciplines, ranging from radiology and pathology to cancer biology and immunology. Specifically, a growth in research on deep learning has led to the widespread application of computer-visualization techniques for analyzing and mining data from biomedical images. The availability of open-source software packages and the development of novel, trainable deep neural network architectures has led to increased accuracy in cell detection and segmentation algorithms. By automating cell segmentation, it is now possible to mine quantifiable cellular and spatio-cellular features from microscopy images, providing insight into the organization of cells in various pathologies. This mini-review provides an overview of the current state of the art in deep learning– and artificial intelligence–based methods of segmentation and data mining of cells in microscopy images of tissue. © 2021 American Society for Investigative Pathology","","Animals; Artificial Intelligence; Cells; Deep Learning; Humans; Image Processing, Computer-Assisted; Microscopy; Organ Specificity; artificial intelligence; artificial neural network; data mining; deep learning; deep neural network; generative adversarial network; high throughput analysis; human; image analysis; image processing; image quality; image segmentation; immunofluorescence; immunohistochemistry; microscopy; Review; selection bias; signal noise ratio; animal; antibody specificity; cells; cytology","Median Technologies; Mitsubishi; Riverain Technologies LLC; National Institutes of Health, NIH, (U19 AI082724); U.S. Department of Defense, DOD, (LR180083); National Institute of Allergy and Infectious Diseases, NIAID; National Institute of Arthritis and Musculoskeletal and Skin Diseases, NIAMS, (R01AR055646); University of Chicago; Medical Research Council, MRC, (R01 AI148705, R01 AR055646, U01 CA195564)","","Elsevier Inc.","34129842"
"Han J.; Wang D.; Li Z.; Shi F.","Han, Jianlin (57226689033); Wang, Dan (57191485105); Li, Zairan (56608398500); Shi, Fuqian (23398821000)","57226689033; 57191485105; 56608398500; 23398821000","Deep self-organizing map neural networks for plantar pressure image segmentation employing marr-hildreth features","2021","12","4","","1","21","20","10.4018/IJACI.2021100101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116296286&doi=10.4018%2fIJACI.2021100101&partnerID=40&md5=ad7224b4def195e70ce3acfa0164ec8e","Using the plantar pressure imaging analysis method to realize the optimization design of shoe last is still relatively preliminary. The analysis and utilization of imaging data still have problems such as single processing, incomplete information acquisition, and poor processing model robustness. A deep self-organizing map neural network based on Marr-Hildreth filter (dSOM-wh) is developed in this research. The structure and learning algorithms were optimized by learning vector quantization (LVQ) and count propagation (CP). As a kind of Marr-Hildreth filter, Laplacian of Gaussian (LoG) was developed for the preprocessing. The proposed method performed high effectiveness in accuracy (AC) (92.88%), sensitive (SE) (0.8941), and f-measurement (F1) (0.8720) by comparing with ANN, CNN, SegNet, ResNet, and pre-trained inception-v neural networks. The classification-based plantar pressure biomedical functional zoning technologies have potential applications in the comfort shoe production industry. Copyright © 2021, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.","Deep neural network; Foot biomedical functional zoning; Marr-hildreth filter; Plantar pressure; Self-organizing map","Backpropagation; Conformal mapping; Image segmentation; Self organizing maps; Zoning; Analysis method; Foot biomedical functional zoning; Functional zoning; Images segmentations; Imaging analysis; Marr-hildreth filter; Neural-networks; Optimization design; Plantar pressures; Shoe last; Deep neural networks","Huidong County Footwear Technology Innovation Center Construction Project of Guangdong Provincial Department of Science and Technology, (2017B090922003)","","IGI Global",""
"Schouten J.P.E.; Matek C.; Jacobs L.F.P.; Buck M.C.; Bošnački D.; Marr C.","Schouten, Jens P. E. (57222963224); Matek, Christian (55368586300); Jacobs, Luuk F. P. (57222959002); Buck, Michèle C. (57222016114); Bošnački, Dragan (6602212448); Marr, Carsten (10539477500)","57222963224; 55368586300; 57222959002; 57222016114; 6602212448; 10539477500","Tens of images can suffice to train neural networks for malignant leukocyte detection","2021","11","1","7995","","","","10.1038/s41598-021-86995-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104271125&doi=10.1038%2fs41598-021-86995-5&partnerID=40&md5=1e4d8774280e1317394d6c05afd480c8","Convolutional neural networks (CNNs) excel as powerful tools for biomedical image classification. It is commonly assumed that training CNNs requires large amounts of annotated data. This is a bottleneck in many medical applications where annotation relies on expert knowledge. Here, we analyze the binary classification performance of a CNN on two independent cytomorphology datasets as a function of training set size. Specifically, we train a sequential model to discriminate non-malignant leukocytes from blast cells, whose appearance in the peripheral blood is a hallmark of leukemia. We systematically vary training set size, finding that tens of training images suffice for a binary classification with an ROC-AUC over 90%. Saliency maps and layer-wise relevance propagation visualizations suggest that the network learns to increasingly focus on nuclear structures of leukocytes as the number of training images is increased. A low dimensional tSNE representation reveals that while the two classes are separated already for a few training images, the distinction between the classes becomes clearer when more training images are used. To evaluate the performance in a multi-class problem, we annotated single-cell images from a acute lymphoblastic leukemia dataset into six different hematopoietic classes. Multi-class prediction suggests that also here few single-cell images suffice if differences between morphological classes are large enough. The incorporation of deep learning algorithms into clinical practice has the potential to reduce variability and cost, democratize usage of expertise, and allow for early detection of disease onset and relapse. Our approach evaluates the performance of a deep learning based cytology classifier with respect to size and complexity of the training data and the classification task. © 2021, The Author(s).","","Databases as Topic; Humans; Image Processing, Computer-Assisted; Leukocytes; Lymphocytes; Neural Networks, Computer; data base; human; image processing; leukocyte; lymphocyte; pathology","Deutsche Jose Carreras-Leukämie Stiftung; German Science Foundation DFG, (SFB 1243); Horizon 2020 Framework Programme, H2020, (866411); European Research Council, ERC; Deutsche Forschungsgemeinschaft, DFG","","Nature Research","33846442"
"Mathe M.; Padmaja M.; Tirumala Krishna B.","Mathe, Mariyadasu (57226287907); Padmaja, M. (23985728500); Tirumala Krishna, Battula (57202987492)","57226287907; 23985728500; 57202987492","Intelligent approach for artifacts removal from EEG signal using heuristic-based convolutional neural network","2021","70","","102935","","","","10.1016/j.bspc.2021.102935","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111019110&doi=10.1016%2fj.bspc.2021.102935&partnerID=40&md5=406f67f280e9290fcc4a4cab32f3b366","In general, the electrical activity of the brain is recorded using Electroencephalography (EEG), which is contaminated with some signal artifacts. By using automatic removal of artifacts from EEG signals, different Brain-Computer Interface (BCI) and clinical diagnostics applications are in practice. However, they are not efficient to remove the artifact from the EEG signal. Thus, we plan for the intelligent model for artifacts removal of EEG signal. The two main phases of the proposed model are training and testing. The deep learning model in the training phase is used as the filter to automatically remove noise from the contaminated EEG signal. The proposed model adopts improved One-Dimensional Convolution Neural Networks (1D-CNN) for artifacts removal from EEG signals. Here, a new hybrid algorithm named Spider Monkey-based Electric Fish Optimization (SM-EFO) is proposed by integrating the Spider Monkey Optimization (SMO) and Electric Fish Optimization (EFO) algorithm. The model parameters of the One-Dimensional Convolutional Neural Networks (1D-CNN) are tuned by using SM-EFO. The experimentation is performed on the standard benchmark dataset, and the experimental results establish that the proposed model can achieve significant improvement and get cleaner waveforms in terms of several performance measures when compared to the conventional models. © 2021","Electrocardiogram; Electroencephalography Artifacts Removal; Electromyogram; Electrooculogram; One-Dimensional Convolutional Neural Network; Spider Monkey-based Electric Fish Optimization","Benchmarking; Biomedical signal processing; Brain; Brain computer interface; Convolution; Deep learning; Electrocardiography; Electroencephalography; Electrophysiology; Neural networks; Optimization; Artifact removal; Convolutional neural network; Electric fish; Electro-oculogram; Electroencephalography artifact removal; Electromyo grams; One-dimensional; One-dimensional convolutional neural network; Optimisations; Spider monkey-based electric fish optimization; algorithm; Article; convolutional neural network; deep learning; electrocardiogram; electroencephalogram; electroencephalography; electromyogram; electrooculogram; heuristics; image artifact; signal noise ratio; waveform; Fish","","","Elsevier Ltd",""
"Chintamani R.D.; Kumar P.; Karan R.","Chintamani, Rameshwar D. (57223138404); Kumar, Parmalik (57206834851); Karan, Rajneesh (57218366828)","57223138404; 57206834851; 57218366828","Motor Imagery Classification Based on Hybrid Feature Extraction and Deep Neural Network","2021","","","9395753","885","893","8","10.1109/ICAIS50930.2021.9395753","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104946127&doi=10.1109%2fICAIS50930.2021.9395753&partnerID=40&md5=3a25ef1cd494424b3618427733b8377a","The brain-computer interface increases the capacity of critical diseases diagnosis in neurological science. The increased capacity of diagnosis uses motor imagery electroencephalogram signals. This paper prosed hybrid feature extraction methods based on wavelet packet decomposition and common spatial pattern. The hybrid techniques are very efficient instead of discrete wavelet transform and common spatial pattern. For the process of classification proposed deep neural network-based model. The proposed model enhances the classification ratio despite the machine learning algorithm. The method of classification ratio varies 8-12% instead of the machine learning algorithm. The multi-kernel approach of the deep neural network increases the sample size and boosts data mapping and performance of the classification algorithm. The proposed algorithm is tested on BCI competition-IV dataset (2a and 2b). The simulation process has used the MATLAB R2014a software; this software is a well-known algorithm analysis software. For the evaluation process of result, four parameters such as accuracy, sensitivity, specificity and error are measured. These parameters compare with existing methods of motor imagery EEG classification. The performance of parameters indicates the efficiency of proposed algorithm when compared with the existing methods.  © 2021 IEEE.","BCI; classification; CSP; DNN; EEG; feature extraction; MATLAB; MI; WPD","Biomedical signal processing; Brain computer interface; Classification (of information); Deep learning; Deep neural networks; Discrete wavelet transforms; Electroencephalography; Extraction; Feature extraction; Image classification; Learning systems; MATLAB; Neural networks; Parameter estimation; Wavelet decomposition; Algorithm analysis; Classification algorithm; Common spatial patterns; Electroencephalogram signals; Hybrid-feature extraction; Motor imagery classification; Simulation process; Wavelet Packet Decomposition; Learning algorithms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Han Y.; Wang B.; Luo J.; Li L.; Li X.","Han, Yuexing (35200598400); Wang, Bing (57216234600); Luo, Jie (57192110544); Li, Long (57188975448); Li, Xiaolong (57203151188)","35200598400; 57216234600; 57192110544; 57188975448; 57203151188","A classification method for EEG motor imagery signals based on parallel convolutional neural network","2022","71","","103190","","","","10.1016/j.bspc.2021.103190","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116429615&doi=10.1016%2fj.bspc.2021.103190&partnerID=40&md5=c05c3e0b76ac8e0e99a5e691c7363324","Deep learning has been used popularly and successfully in state of art researches to classify different types of images. However, so far, the applications of deep learning methods for the electroencephalography (EEG) motor imagery classification is very limited. In this study, a pre-processing algorithm is proposed for the EEG signals representation. Then, a parallel convolutional neural network (PCNN) architecture is proposed to classify motor imagery signals. For the raw EEG signals representation, a new form of the images is created to combine spatial filtering and frequency bands extracting together. By feeding the represented images into the PCNN, it stacks three unique sub-models together aiming to optimize the performance of classification. The average accuracy of the proposed method achieves 83.0 ± 3.4% on BCI Competition IV dataset 2b, which outperforms the compared methods at least 5.2%. The average Kappa value of the proposed method achieves 0.659 ± 0.067 on dataset 2b, providing at least 20.5% improvement with respect to the compared algorithms. The results show that the proposed method performs better in EEG motor imagery signals classification. © 2021 Elsevier Ltd","Brain computer interface (BCI); Deep learning; Motor imagery (MI); Parallel convolutional neural network (PCNN); Regularized common spatial pattern (RCSP); Short time fourier transform (STFT)","Arts computing; Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Electroencephalography; Image classification; Brain computer interface; Common spatial patterns; Convolutional neural network; Deep learning; Motor imagery; Parallel convolutional neural network; Regularized common spatial pattern; Short time fourier transform; Short time Fourier transforms; Article; convolutional neural network; cross validation; deep learning; electroencephalography; feature extraction; imagery; imaging algorithm; motor imagery; parallel convolutional neural network; short term memory; short time Fourier transform; signal noise ratio; signal processing; twin support vector machine; Electrophysiology","Natural Science Foundation of Shanghai, (20ZR1419000)","","Elsevier Ltd",""
"Xie Y.; Cai Y.; Yu Y.; Wang S.; Wang W.; Song S.","Xie, Yufei (57222569104); Cai, Yu (57201093943); Yu, Yang (57422626700); Wang, Sen (38863494200); Wang, Wenlin (56942563700); Song, Shasha (57192926026)","57222569104; 57201093943; 57422626700; 38863494200; 56942563700; 57192926026","Endoscopic Ultrasound Image Recognition Based on Data Mining and Deep Learning","2022","10","","","10273","10282","9","10.1109/ACCESS.2022.3143580","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123293477&doi=10.1109%2fACCESS.2022.3143580&partnerID=40&md5=c7378a68210cab5d485ca22b4c594f9d","The recognition of medical images, especially endoscopic ultrasound images, has the characteristics of changing images and insignificant gray-scale changes, which requires repeated observation and comparison by medical staff. In view of the above-mentioned characteristics of ultrasound imaging, a system scheme suitable for image processing is proposed, which can analyze the biliary tract, gallbladder, abdominal lymph nodes, liver, descending duodenum, duodenal bulb, stomach, pancreas, pancreatic lymph nodes, there are a total of 10 ultrasonic organs, including 21 kinds of sub-categories and 3510 images. The images are preprocessed using binarization, histogram equalization, median filtering and edge enhancement algorithms. The improved YoloV4 convolutional neural network algorithm is used to train the data set and perform high accuracy is detected in real time. Finally, the average accuracy of this algorithm has reached 91.59%. The algorithm proposed in this paper can make up for the shortcomings of manual detection in the original image detection system, improve the efficiency of detection, and at the same time as an auxiliary system can reduce detection misjudgments, and promote the development of automated and intelligent detection in the medical field. This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/","Biomedical imaging; Gray-scale; Histograms; Interference; Medical diagnostic imaging; Stomach; Ultrasonic imaging","Convolution; Deep learning; Edge detection; Endoscopy; Image enhancement; Image recognition; Median filters; Medical imaging; Neural networks; Ultrasonic imaging; Abdominal lymph nodes; Convolutional neural network; Endoscopic ultrasonographies; Endoscopic ultrasounds; Gray scale; Images processing; Pancreatic lymph nodes; System scheme; Ultrasound images; Ultrasound imaging; Data mining","National Natural Science Foundation of China, (10.13039/501100001809); National Natural Science Foundation of China","","Institute of Electrical and Electronics Engineers Inc.",""
"Kim S.; Shin D.Y.; Kim T.; Lee S.; Hyun J.K.; Park S.-M.","Kim, Sehyeon (57210279104); Shin, Dae Youp (57221385649); Kim, Taekyung (59099055800); Lee, Sangsook (57413293600); Hyun, Jung Keun (7202748992); Park, Sung-Min (57191161899)","57210279104; 57221385649; 59099055800; 57413293600; 7202748992; 57191161899","Enhanced Recognition of Amputated Wrist and Hand Movements by Deep Learning Method Using Multimodal Fusion of Electromyography and Electroencephalography","2022","22","2","680","","","","10.3390/s22020680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122886087&doi=10.3390%2fs22020680&partnerID=40&md5=581bd3fa5fef337665b9e7ebf989f153","Motion classification can be performed using biometric signals recorded by electroen-cephalography (EEG) or electromyography (EMG) with noninvasive surface electrodes for the control of prosthetic arms. However, current single-modal EEG and EMG based motion classification techniques are limited owing to the complexity and noise of EEG signals, and the electrode placement bias, and low-resolution of EMG signals. We herein propose a novel system of two-dimensional (2D) input image feature multimodal fusion based on an EEG/EMG-signal transfer learning (TL) paradigm for detection of hand movements in transforearm amputees. A feature extraction method in the frequency domain of the EEG and EMG signals was adopted to establish a 2D image. The input images were used for training on a model based on the convolutional neural network algorithm and TL, which requires 2D images as input data. For the purpose of data acquisition, five transforearm amputees and nine healthy controls were recruited. Compared with the conventional single-modal EEG signal trained models, the proposed multimodal fusion method significantly improved classification accuracy in both the control and patient groups. When the two signals were combined and used in the pretrained model for EEG TL, the classification accuracy increased by 4.18–4.35% in the control group, and by 2.51–3.00% in the patient group. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Brain–computer interface (BCI); Convolutional neural network (CNN); Electroencephalography (EEG); Electromyography (EMG); Transfer learning (TL); Transforearm amputees","Algorithms; Amputees; Brain-Computer Interfaces; Deep Learning; Electroencephalography; Electromyography; Humans; Wrist; Artificial limbs; Biomedical signal processing; Brain computer interface; Convolutional neural networks; Data acquisition; Deep learning; Electrodes; Electroencephalography; Electrophysiology; Feature extraction; Motion analysis; Brain–computer interface; Convolutional neural network; Electroencephalography; Electromyography; Electromyography signals; Multi-modal fusion; Transfer learning; Transforearm amputee; algorithm; amputee; brain computer interface; electroencephalography; electromyography; human; wrist; Convolution","Korea Medical Device Development Fund, KMDF, (202017D01); Korea Medical Device Development Fund, KMDF; Ministry of Education, MOE, (2020R1A6A1A03047902); Ministry of Education, MOE; Ministry of Trade, Industry and Energy, MOTIE; Ministry of Food and Drug Safety, MFDS; Ministry of Science, ICT and Future Planning, MSIP, (2020R1A2C2004764, 2020R1A2C2005385); Ministry of Science, ICT and Future Planning, MSIP; Ministry of Health and Welfare, MOHW; National Research Foundation of Korea, NRF","","MDPI","35062641"
"Zhao J.; Hu X.; Gausmann S.; Antonio-Lopez J.E.; Correa R.A.; Schülzgen A.","Zhao, Jian (57205716662); Hu, Xiaowen (57216365106); Gausmann, Stefan (56110046900); Antonio-Lopez, Jose Enrique (24824110200); Correa, Rodrigo Amezcua (14123120000); Schülzgen, Axel (7004054043)","57205716662; 57216365106; 56110046900; 24824110200; 14123120000; 7004054043","Learning-Based Image Transport Through Disordered Optical Fibers With Transverse Anderson Localization","2021","9","","710351","","","","10.3389/fphy.2021.710351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119456970&doi=10.3389%2ffphy.2021.710351&partnerID=40&md5=54d22ee08f80faf030dd3049fb2acafc","Fiber-optic imaging systems play a unique role in biomedical imaging and clinical practice due to their flexibilities of performing imaging deep into tissues and organs with minimized penetration damage. Their imaging performance is often limited by the waveguide mode properties of conventional optical fibers and the image reconstruction method, which restrains the enhancement of imaging quality, transport robustness, system size, and illumination compatibility. The emerging disordered Anderson localizing optical fibers circumvent these difficulties by their intriguing properties of the transverse Anderson localization of light, such as single-mode-like behavior, wavelength independence, and high mode density. To go beyond the performance limit of conventional system, there is a growing interest in integrating the disordered Anderson localizing optical fiber with deep learning algorithms. Novel imaging platforms based on this concept have been explored recently to make the best of Anderson localization fibers. Here, we review recent developments of Anderson localizing optical fibers and focus on the latest progress in deep-learning-based imaging applications using these fibers. © Copyright © 2021 Zhao, Hu, Gausmann, Antonio-Lopez, Correa and Schülzgen.","convolutional neural network; deep learning; imaging; optical fiber; transverse Anderson localization","Convolutional neural networks; Deep learning; Image enhancement; Image reconstruction; Learning algorithms; Medical imaging; Anderson localization; Andersons; Biomedical imaging; Clinical practices; Convolutional neural network; Deep learning; Fiber optics imaging; Imaging performance; Property; Transverse anderson localization; Optical fibers","","","Frontiers Media SA",""
"Davamani K.A.; Robin C.R.R.; Amudha S.; Anbarasi L.J.","Davamani, K. Anita (57210209037); Robin, C.R. Rene (57189274646); Amudha, S. (57217088432); Anbarasi, L. Jani (57222292455)","57210209037; 57189274646; 57217088432; 57222292455","Biomedical image segmentation by deep learning methods","2021","","","","131","154","23","10.1002/9781119785750.ch6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124250605&doi=10.1002%2f9781119785750.ch6&partnerID=40&md5=cc0abfe09b19cd3507ae7f3acb36ecff","Deep learning methods have been employed to predict and analyse various application in medical imaging. Deep Learning technology is a computational algorithm that learns by itself to demonstrate a desired behaviours. Neural network processes the input neurons according to the corresponding types of networks based on algorithm provided and passes it to the hidden layer. Finally, it outputs the result through output layer. Deep learning algorithms tend to be more useful in different applications. It plays important role in biomedical image segmentations such as identifying skin cancer, lung cancer, brain tumour, skin psoriasis, etc. Deep learning includes algorithms like Convolutional Neural Network (CNN), Restricted Boltzmann Machine (RBM), Generative Adversarial Network (GAN), Recurrent Neural Network (RNN), U-Net, V-net, Fully Convolutional Attention Network (FCANET), Docker- powered based deep learning, ResNet18, ResNet50, SqueezeNet and DenseNet-121 which processes on medical images and helps in identifying the defect in earlier stage by helping the physician to start the treatment process. This paper is about the review of deep learning algorithms using medical image segmentation. Future implementations can be performed through additional feature for the existing algorithm with better performance. © 2021 Scrivener Publishing LLC. All rights reserved.","Convolution neural network; Deep learning; Image processing; Image segmentation","","","","wiley",""
"Verma R.; Kumar N.; Patil A.; Kurian N.C.; Rane S.; Graham S.; Vu Q.D.; Zwager M.; Raza S.E.A.; Rajpoot N.; Wu X.; Chen H.; Huang Y.; Wang L.; Jung H.; Thomas Brown G.; Liu Y.; Liu S.; Jahromi S.A.F.; Khani A.A.; Montahaei E.; Baghshah M.S.; Behroozi H.; Semkin P.; Rassadin A.; Dutande P.; Lodaya R.; Baid U.; Baheti B.; Talbar S.; Mahbod A.; Ecker R.; Ellinger I.; Luo Z.; Dong B.; Xu Z.; Yao Y.; Lv S.; Feng M.; Xu K.; Zunair H.; Hamza A.B.; Smiley S.; Yin T.-K.; Fang Q.-R.; Srivastava S.; Mahapatra D.; Trnavska L.; Zhang H.; Narayanan P.L.; Law J.; Yuan Y.; Tejomay A.; Mitkari A.; Koka D.; Ramachandra V.; Kini L.; Sethi A.","Verma, Ruchika (57217427976); Kumar, Neeraj (58071541900); Patil, Abhijeet (57215861536); Kurian, Nikhil Cherian (57192096727); Rane, Swapnil (57211019383); Graham, Simon (56927520600); Vu, Quoc Dang (57207860516); Zwager, Mieke (57203876404); Raza, Shan E. Ahmed (54960699400); Rajpoot, Nasir (8042017200); Wu, Xiyi (57212064548); Chen, Huai (57201315366); Huang, Yijie (57198358598); Wang, Lisheng (7409186133); Jung, Hyun (57224844489); Thomas Brown, G. (58708956500); Liu, Yanling (57203373310); Liu, Shuolin (57212010550); Jahromi, Seyed Alireza Fatemi (57222162976); Khani, Ali Asghar (57216616539); Montahaei, Ehsan (57219506753); Baghshah, Mahdieh Soleymani (15845103800); Behroozi, Hamid (15043648400); Semkin, Pavel (57224321573); Rassadin, Alexandr (57195612821); Dutande, Prasad (57208108410); Lodaya, Romil (57222871479); Baid, Ujjwal (56642771000); Baheti, Bhakti (56642743500); Talbar, Sanjay (12800615100); Mahbod, Amirreza (57198352337); Ecker, Rupert (7005592222); Ellinger, Isabella (6602308489); Luo, Zhipeng (59047881900); Dong, Bin (57222170708); Xu, Zhengyu (57224320677); Yao, Yuehan (57215430277); Lv, Shuai (57224322605); Feng, Ming (57208437642); Xu, Kele (56413567000); Zunair, Hasib (57203385885); Hamza, Abdessamad Ben (57222519365); Smiley, Steven (57224306869); Yin, Tang-Kai (7103080004); Fang, Qi-Rui (57224308123); Srivastava, Shikhar (57225774991); Mahapatra, Dwarikanath (25422481200); Trnavska, Lubomira (57224312649); Zhang, Hanyun (57224318516); Narayanan, Priya Lakshmi (57196660440); Law, Justin (57224318594); Yuan, Yinyin (7402706941); Tejomay, Abhiroop (57224319086); Mitkari, Aditya (57224322029); Koka, Dinesh (57224310282); Ramachandra, Vikas (26039418900); Kini, Lata (57194344167); Sethi, Amit (12775689700)","57217427976; 58071541900; 57215861536; 57192096727; 57211019383; 56927520600; 57207860516; 57203876404; 54960699400; 8042017200; 57212064548; 57201315366; 57198358598; 7409186133; 57224844489; 58708956500; 57203373310; 57212010550; 57222162976; 57216616539; 57219506753; 15845103800; 15043648400; 57224321573; 57195612821; 57208108410; 57222871479; 56642771000; 56642743500; 12800615100; 57198352337; 7005592222; 6602308489; 59047881900; 57222170708; 57224320677; 57215430277; 57224322605; 57208437642; 56413567000; 57203385885; 57222519365; 57224306869; 7103080004; 57224308123; 57225774991; 25422481200; 57224312649; 57224318516; 57196660440; 57224318594; 7402706941; 57224319086; 57224322029; 57224310282; 26039418900; 57194344167; 12775689700","MoNuSAC2020: A Multi-Organ Nuclei Segmentation and Classification Challenge","2021","40","12","","3413","3423","10","10.1109/TMI.2021.3085712","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107351463&doi=10.1109%2fTMI.2021.3085712&partnerID=40&md5=f2a497c9c140b75817307c387dca259f","Detecting various types of cells in and around the tumor matrix holds a special significance in characterizing the tumor micro-environment for cancer prognostication and research. Automating the tasks of detecting, segmenting, and classifying nuclei can free up the pathologists' time for higher value tasks and reduce errors due to fatigue and subjectivity. To encourage the computer vision research community to develop and test algorithms for these tasks, we prepared a large and diverse dataset of nucleus boundary annotations and class labels. The dataset has over 46,000 nuclei from 37 hospitals, 71 patients, four organs, and four nucleus types. We also organized a challenge around this dataset as a satellite event at the International Symposium on Biomedical Imaging (ISBI) in April 2020. The challenge saw a wide participation from across the world, and the top methods were able to match inter-human concordance for the challenge metric. In this paper, we summarize the dataset and the key findings of the challenge, including the commonalities and differences between the methods developed by various participants. We have released the MoNuSAC2020 dataset to the public. © 1982-2012 IEEE.","computational pathology; instance segmentation; Multi-organ dataset; nucleus classification; panoptic quality","Algorithms; Cell Nucleus; Humans; Image Processing, Computer-Assisted; Medical imaging; Statistical tests; Tumors; Biomedical imaging; Class labels; Microenvironments; Nuclei segmentation; Nucleus boundaries; Test algorithms; Vision research; adult; Article; cancer tissue; classification; cohort analysis; computer vision; controlled study; convolutional neural network; deep learning; human; image segmentation; information processing; major clinical study; monusac2020 dataset; multicenter study; segmentation algorithm; semantics; algorithm; cell nucleus; image processing; Large dataset","UK Research and Innovation, UKRI; Österreichische Forschungsförderungsgesellschaft, FFG, (872636); Österreichische Forschungsförderungsgesellschaft, FFG","","Institute of Electrical and Electronics Engineers Inc.","34086562"
"Abunadi I.; Senan E.M.","Abunadi, Ibrahim (57189636917); Senan, Ebrahim Mohammed (57222957501)","57189636917; 57222957501","Deep learning and machine learning techniques of diagnosis dermoscopy images for early detection of skin diseases","2021","10","24","3158","","","","10.3390/electronics10243158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121285366&doi=10.3390%2felectronics10243158&partnerID=40&md5=936d2ea8f1d49477b6cd71aec8feb454","With the increasing incidence of severe skin diseases, such as skin cancer, endoscopic medical imaging has become urgent for revealing the internal and hidden tissues under the skin. Diagnostic information to help doctors make an accurate diagnosis is provided by endoscopy devices. Nonetheless, most skin diseases have similar features, which make it challenging for dermatologists to diagnose patients accurately. Therefore, machine and deep learning techniques can have a critical role in diagnosing dermatoscopy images and in the accurate early detection of skin diseases. In this study, systems for the early detection of skin lesions were developed. The performance of the machine learning and deep learning was evaluated on two datasets (e.g., the International Skin Imaging Collaboration (ISIC 2018) and Pedro Hispano (PH2)). First, the proposed system was based on hybrid features that were extracted by three algorithms: local binary pattern (LBP), gray level co-occurrence matrix (GLCM), and wavelet transform (DWT). Such features were then integrated into a feature vector and classified using artificial neural network (ANN) and feedforward neural network (FFNN) classifiers. The FFNN and ANN classifiers achieved superior results compared to the other methods. Accuracy rates of 95.24% for diagnosing the ISIC 2018 dataset and 97.91% for diagnosing the PH2 dataset were achieved using the FFNN algorithm. Second, convolutional neural networks (CNNs) (e.g., ResNet-50 and AlexNet models) were applied to diagnose skin diseases using the transfer learning method. It was found that the ResNet-50 model fared better than AlexNet. Accuracy rates of 90% for diagnosing the ISIC 2018 dataset and 95.8% for the PH2 dataset were reached using the ResNet-50 model. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Biomedical image processing; Deep learning; Dermoscopy images; Machine learning; Melanoma; Skin diseases","","Prince Sultan University, PSU","","MDPI",""
"Singh K.; Malhotra J.","Singh, Kuldeep (57216243325); Malhotra, Jyoteesh (25628189800)","57216243325; 25628189800","Deep learning based smart health monitoring for automated prediction of epileptic seizures using spectral analysis of scalp EEG","2021","44","4","","1161","1173","12","10.1007/s13246-021-01052-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114028271&doi=10.1007%2fs13246-021-01052-9&partnerID=40&md5=258c7bbd4ecc011bd004dca96805a5b1","Being one of the most prevalent neurological disorders, epilepsy affects the lives of patients through the infrequent occurrence of spontaneous seizures. These seizures can result in serious injuries or unexpected deaths in individuals due to accidents. So, there exists a crucial need for an automatic prediction of epileptic seizures to alert the patients well before the onset of seizures, enabling them to have a healthier quality of life. In this era, the Internet of Things (IoT) technologies are being used in a cloud-fog integrated environment to address such healthcare challenges using deep learning approaches. The present paper also proposes a smart health monitoring approach for automated prediction of epileptic seizures using deep learning-based spectral analysis of EEG signals. This approach processes EEG signals using filtering, segmentation into short duration segments and spectral-domain transformation. These signals are then analysed spectrally by separating them into several spectral bands, such as delta, theta, alpha, beta, and sub-bands of gamma. Furthermore, the mean spectral amplitude and spectral power features are retrieved from each spectral band to characterize various seizure states, which are fed to the proposed LSTM and CNN models. The results of the proposed CNN model show a maximum accuracy of 98.3% and 97.4% to obtain a binary classification of preictal and interictal seizure states for two different spectral band combinations respectively. Thus, the proposed CNN architecture accompanied by spectral analysis of EEG signals provides a viable method for reliable and real-time prediction of epileptic seizures. © 2021, Australasian College of Physical Scientists and Engineers in Medicine.","Deep learning; Epilepsy; Healthcare; Internet of Things; Scalp EEG; Spectral analysis","Algorithms; Deep Learning; Electroencephalography; Epilepsy; Humans; Quality of Life; Scalp; Seizures; Biomedical signal processing; Forecasting; Internet of things; Long short-term memory; Neurophysiology; Signal analysis; Spectrum analysis; Automatic prediction; Binary classification; Integrated environment; Internet of thing (IOT); Maximum accuracies; Neurological disorders; Real-time prediction; Spectral amplitude; alpha rhythm; Article; automation; beta rhythm; binary classification; convolutional neural network; deep learning; delta rhythm; digital filtering; electroencephalography; gamma rhythm; image segmentation; internet of things; long term memory; patient monitoring; prediction; reliability; seizure; short term memory; signal processing; simulation; spectroscopy; technology; theta rhythm; algorithm; electroencephalography; epilepsy; human; quality of life; scalp; seizure; Deep learning","","","Springer Science and Business Media Deutschland GmbH","34468965"
"Sharma A.; Lysenko A.; Boroevich K.A.; Vans E.; Tsunoda T.","Sharma, Alok (55482800200); Lysenko, Artem (35105526200); Boroevich, Keith A (8505888200); Vans, Edwin (56349077600); Tsunoda, Tatsuhiko (7203020452)","55482800200; 35105526200; 8505888200; 56349077600; 7203020452","DeepFeature: feature selection in nonimage data using convolutional neural network","2021","22","6","bbab297","","","","10.1093/bib/bbab297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121950828&doi=10.1093%2fbib%2fbbab297&partnerID=40&md5=6f05a8d8bdd37176ac35e341b65cf7e8","Artificial intelligence methods offer exciting new capabilities for the discovery of biological mechanisms from raw data because they are able to detect vastly more complex patterns of association that cannot be captured by classical statistical tests. Among these methods, deep neural networks are currently among the most advanced approaches and, in particular, convolutional neural networks (CNNs) have been shown to perform excellently for a variety of difficult tasks. Despite that applications of this type of networks to high-dimensional omics data and, most importantly, meaningful interpretation of the results returned from such models in a biomedical context remains an open problem. Here we present, an approach applying a CNN to nonimage data for feature selection. Our pipeline, DeepFeature, can both successfully transform omics data into a form that is optimal for fitting a CNN model and can also return sets of the most important genes used internally for computing predictions. Within the framework, the Snowfall compression algorithm is introduced to enable more elements in the fixed pixel framework, and region accumulation and element decoder is developed to find elements or genes from the class activation maps. In comparative tests for cancer type prediction task, DeepFeature simultaneously achieved superior predictive performance and better ability to discover key pathways and biological processes meaningful for this context. Capabilities offered by the proposed framework can enable the effective use of powerful deep learning methods to facilitate the discovery of causal mechanisms in high-dimensional biomedical data. © 2021 The Author(s). Published by Oxford University Press.","Convolutional neural network; DeepInsight; Feature selection; Non-image data; Omics data","Algorithms; Deep Learning; Humans; Neural Networks, Computer; algorithm; human","Japan Society for the Promotion of Science, JSPS, (20H03240); Japan Society for the Promotion of Science, JSPS","","Oxford University Press","34368836"
"Rajkumar S.; Karthick K.; Selvanathan N.; Saravanan U.K.B.; Murali M.; Dhiyanesh B.","Rajkumar, S. (58023527800); Karthick, K. (57260995000); Selvanathan, N. (57237060500); Saravanan, U.K. Balaji (57235929100); Murali, M. (58085893900); Dhiyanesh, B. (55489175600)","58023527800; 57260995000; 57237060500; 57235929100; 58085893900; 55489175600","Brain Tumor Detection Using Deep Learning Neural Network for Medical Internet of Things Applications","2021","","","9489187","","","","10.1109/ICCES51350.2021.9489187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113800141&doi=10.1109%2fICCES51350.2021.9489187&partnerID=40&md5=96f6846a45363504fa1702c2951124e0","The Internet of Things technology in medical applications ensures that the medical industry can improve the quality and optimization of medical care. In a medical image, the parameters of the imaging device can be identified and then the medical image is analyzed, and corrective actions can be taken in real time. Digitization has reached many areas of medical technology. Magnetic Resonance Imaging (MRI) is technology development in the medical field that MRI Images can be brain tumor classified as a disease of a patient's internal organs, and then generate high-resolution images for detection. A condition can be identified as a brain tumor by reading the MRI image. MRI technology is useful for detecting brain tumor diseases with drugs. The weakness of detecting brain tumor diseases performed by doctors on MRI images is still manual. The proposed Deep Leamer's Neural Network algorithms are important methods in medical imaging using MRI images for predicting the early symptoms of a disease medical imaging MRI methods. Medical image in human brain tumor position, different functions based on the tumor image are obtained, including contrast, energy, dissimilarity, uniformity, entropy and correlation. The simulation results show that the proposed Deep Learning Neural Network (DLNN) algorithm achieves better detection of abnormal. It is in low grayscale exfoliation and normal tissues in the human brain. The proposed DLNN algorithm also detects human brain tumors within seconds in a short time compared to other algorithms. © 2021 IEEE.","Brain Tumor; Classification; Deep Learning Technology; Imaging Applications; Internet of Things; Magnetic Resonance Imaging; Medical Image","Biomedical engineering; Brain; Deep learning; Deep neural networks; Internet of things; Magnetic resonance imaging; Medical applications; Neural networks; Tumors; Corrective actions; High resolution image; Human brain tumors; Internet of things technologies; Learning neural networks; Medical industries; Medical technologies; Neural network algorithm; Medical imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"Montiel H.; Jacinto E.; Martínez F.","Montiel, Holman (56624316100); Jacinto, Edwar (55657557700); Martínez, Fredy (36451984500)","56624316100; 55657557700; 36451984500","A Double-Loop Hybrid Approach For The Recognition Of Fissures In Bone Structures","2021","16","11","","1151","1156","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112674150&partnerID=40&md5=eeff6870a9a0131dacbee6b4dda7c5fe","This paper shows the structure of a double loop hybrid system developed as a software tool to support the identification of fissures and fractures in bone structures from radiological images. The proposed scheme uses two recognition loops with completely different design paradigms (hence its classification as a hybrid system), but whose independent results complement each other to offer a high-performance tool. The first loop is developed from digital image processing, here is used an algorithm for labeling and identification of the region of interest (ROI), and morphological operations on it for damage detection. The second loop uses deep learning to build a neural model capable of categorizing images with bone damage. The result of the two loops is combined by an inference machine that allows identifying images with damage with an overall accuracy above 80%. © 2006-2021 Asian Research Publishing Network (ARPN). All rights reserved.","biomedical computing; bone structures; deep neural network; fissures recognition; image processing; radiological images","","Universidad Distrital","","Asian Research Publishing Network",""
"Makrogiannis S.; Zheng K.; Harris C.","Makrogiannis, Sokratis (6602210816); Zheng, Keni (57192919716); Harris, Chelsea (57217154275)","6602210816; 57192919716; 57217154275","Discriminative Localized Sparse Approximations for Mass Characterization in Mammograms","2021","11","","725320","","","","10.3389/fonc.2021.725320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122896665&doi=10.3389%2ffonc.2021.725320&partnerID=40&md5=3af8e7f7c099bdc1512738cf0afaae4a","The most common form of cancer among women in both developed and developing countries is breast cancer. The early detection and diagnosis of this disease is significant because it may reduce the number of deaths caused by breast cancer and improve the quality of life of those effected. Computer-aided detection (CADe) and computer-aided diagnosis (CADx) methods have shown promise in recent years for aiding in the human expert reading analysis and improving the accuracy and reproducibility of pathology results. One significant application of CADe and CADx is for breast cancer screening using mammograms. In image processing and machine learning research, relevant results have been produced by sparse analysis methods to represent and recognize imaging patterns. However, application of sparse analysis techniques to the biomedical field is challenging, as the objects of interest may be obscured because of contrast limitations or background tissues, and their appearance may change because of anatomical variability. We introduce methods for label-specific and label-consistent dictionary learning to improve the separation of benign breast masses from malignant breast masses in mammograms. We integrated these approaches into our Spatially Localized Ensemble Sparse Analysis (SLESA) methodology. We performed 10- and 30-fold cross validation (CV) experiments on multiple mammography datasets to measure the classification performance of our methodology and compared it to deep learning models and conventional sparse representation. Results from these experiments show the potential of this methodology for separation of malignant from benign masses as a part of a breast cancer screening workflow. Copyright © 2021 Makrogiannis, Zheng and Harris.","breast cancer screening; computer-aided diagnosis (CADx); mammographic imaging; mass classification; sparse approximation","algorithm; area under the curve; Article; breast cancer; computer aided design; controlled study; convolutional neural network; cross validation; diagnostic test accuracy study; human; image analysis; image reconstruction; mammography; mathematical model; measurement repeatability; nerve cell network; neuroimaging; performance; receiver operating characteristic; screening test; sparse analysis; spatial analysis; statistical analysis; training; validation process","National Institutes of Health, NIH, (SC3GM113754); National Institute of General Medical Sciences, NIGMS; Army Research Office, ARO, (U54GM104941, W911NF2010095)","","Frontiers Media S.A.",""
"Azran A.; Schclar A.; Saabni R.","Azran, Adi (57234967700); Schclar, Alon (8319691800); Saabni, Raid (35198993400)","57234967700; 8319691800; 35198993400","Text line extraction using deep learning and minimal sub seams","2021","","","3474941","","","","10.1145/3469096.3474941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113610367&doi=10.1145%2f3469096.3474941&partnerID=40&md5=c41fc70ea9926e11e979de88c2cd9cdf","Accurate text line extraction is a vital prerequisite for efficient and successful text recognition systems ranging from keywords/phrases searching to complete conversion to text. In many cases, the proposed algorithms target binary pre-processed versions of the image, which may cause insufficient results due to poor quality document images. Recently, more papers present solutions that work directly on gray-level images [1,2,7,12,15]. In this paper, we present a novel robust, and efficient algorithm to extract text-lines directly from gray-level document images. The proposed approach uses a combination of two variants of Convolutional Neural Network (CNNs), followed by minimal energy seam extraction. The first ConvNet is a modified version of the autoencoder used for biomedical image segmentation [8]. The second is a deep convolutional Neural Network, working on overlapping vertical slices of the original image. The two variants are combined to one neural net after re-attaching the resulting slices of the second net. The merged results of the two nets are used as a preprocessed image to obtain an energy map for a second phase. In the second step, we use the algorithm presented in [2], to track minimal energy sub-seams accumulated to perform a full local minimal/maximal separating and medial seam defining the text baselines and the text line regions. We have tested our approach on multi-lingual various datasets written at a range of image quality based on the ICDAR datasets.  © 2021 ACM.","convolutional neural networks; historical document image analysis; image processing; line extraction; local projection profile; minimal seams; seam carving; text line extraction","Character recognition; Convolution; Convolutional neural networks; Deep neural networks; Digital image storage; Extraction; Image segmentation; Biomedical image segmentation; Document images; Gray level image; Minimal energy; Original images; Text recognition; Text-line extractions; Vertical slices; Deep learning","","","Association for Computing Machinery, Inc",""
"Ju L.; Wang X.; Zhao X.; Lu H.; Mahapatra D.; Bonnington P.; Ge Z.","Ju, Lie (57217724734); Wang, Xin (57211222232); Zhao, Xin (57211998742); Lu, Huimin (57209823396); Mahapatra, Dwarikanath (25422481200); Bonnington, Paul (6602671732); Ge, Zongyuan (56287884800)","57217724734; 57211222232; 57211998742; 57209823396; 25422481200; 6602671732; 56287884800","Synergic Adversarial Label Learning for Grading Retinal Diseases via Knowledge Distillation and Multi-Task Learning","2021","25","10","","3709","3720","11","10.1109/JBHI.2021.3052916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099732775&doi=10.1109%2fJBHI.2021.3052916&partnerID=40&md5=2e8540763794d41b6d0e027afca15d43","The need for comprehensive and automated screening methods for retinal image classification has long been recognized. Well-qualified doctors annotated images are very expensive and only a limited amount of data is available for various retinal diseases such as diabetic retinopathy (DR) and age-related macular degeneration (AMD). Some studies show that some retinal diseases such as DR and AMD share some common features like haemorrhages and exudation but most classification algorithms only train those disease models independently when the only single label for one image is available. Inspired by multi-task learning where additional monitoring signals from various sources is beneficial to train a robust model. We propose a method called synergic adversarial label learning (SALL) which leverages relevant retinal disease labels in both semantic and feature space as additional signals and train the model in a collaborative manner using knowledge distillation. Our experiments on DR and AMD fundus image classification task demonstrate that the proposed method can significantly improve the accuracy of the model for grading diseases by 5.91% and 3.69% respectively. In addition, we conduct additional experiments to show the effectiveness of SALL from the aspects of reliability and interpretability in the context of medical imaging application. © 2013 IEEE.","Deep convolutional neural networks; knowledge distillation; medical imaging classification; multi-task learning","Algorithms; Diabetic Retinopathy; Distillation; Fundus Oculi; Humans; Reproducibility of Results; Retinal Diseases; Automation; Biomedical signal processing; Diagnosis; Distillation; Distilleries; Eye protection; Grading; Image classification; Image enhancement; Medical imaging; Multi-task learning; Ophthalmology; Semantics; Additional experiments; Age-related macular degeneration; Automated screening; Classification algorithm; Diabetic retinopathy; Imaging applications; Interpretability; Monitoring signals; accuracy; Article; artificial neural network; computer model; controlled study; convolutional neural network; diabetic retinopathy; diagnostic imaging; diagnostic test accuracy study; distillation; entropy; eye fundus; human; kernel method; learning algorithm; machine learning; multiclass classification; optical coherence tomography; proliferative diabetic retinopathy; refraction error; reliability; retina blood vessel; retina disease; retina image; retinal pigment epithelium; support vector machine; time series analysis; training; algorithm; diabetic retinopathy; reproducibility; Learning systems","","","Institute of Electrical and Electronics Engineers Inc.","33465032"
"Guo K.; Wu J.; Wan W.; Li L.; Wang T.; Zhu X.; Qu L.","Guo, Kaixuan (57215183906); Wu, Jun (57266847900); Wan, Wan (57285346200); Li, Longfei (57223305256); Wang, Tao (58736748500); Zhu, Xingliang (57215524940); Qu, Lei (36175185400)","57215183906; 57266847900; 57285346200; 57223305256; 58736748500; 57215524940; 36175185400","Biomedical image segmentation based on classification supervision","2021","","","","22","27","5","10.1145/3473258.3473262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121702646&doi=10.1145%2f3473258.3473262&partnerID=40&md5=bc8916f30d4067e7b93d1ddfecd0f51f","Convolutional neural networks (CNN) has been widely used in the biomedical image segmentation (BIS) for their remarkable feature representation capability. However, there are often segmentation errors and missing segmentation problems in biomedical image segmentation based on deep learning. In this paper, we propose a full convolutional neural network, which is assisted by classification supervision based on segmentation network. The algorithm first obtains a segmentation result through a basic segmentation network. Then a Classification Supervision Module (CSM) is designed to enable the network to judge whether each slicer contains lesions from the perspective of classification. In this way we allow the network to take advantage of more global information. Experimental results on several available databases demonstrate the effectiveness and advancement of the proposed method.  © 2021 ACM.","Biomedical image; Classification supervision; Convolutional neural network; Image segmentation","Convolution; Convolutional neural networks; Deep learning; Image classification; Biomedical image segmentation; Biomedical images; Classification supervision; Convolutional neural network; Feature representation; Global informations; Images segmentations; Segmentation error; Segmentation results; Image segmentation","University Synergy Innovation Program of Anhui Province, (GXXT-2019-008); National Natural Science Foundation of China, NSFC, (61871411, 61901003); Natural Science Foundation of Anhui Province, (1908085QF255)","","Association for Computing Machinery",""
"Wang Y.; Tian L.; Li M.; Liu Z.; Liu J.; Sun Y.","Wang, Yuesong (57226822414); Tian, Liguo (34973432000); Li, Meng (57188867418); Liu, Zilu (57219133071); Liu, Jinqi (57226817403); Sun, Yu (57219132808)","57226822414; 34973432000; 57188867418; 57219133071; 57226817403; 57219132808","Research on Recognition of Plant Physiological Electrical Signals under Different Light Intensities Based on Image Convolutional Neural Network: The relationship between light factors and plant physiological electrical signals","2021","","","3478247","","","","10.1145/3474198.3478247","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122609970&doi=10.1145%2f3474198.3478247&partnerID=40&md5=2315c1e0fcbd55073487ce0f14648495","A technical idea of using image convolutional neural network to solve the recognition problem of plant physiological electrical signals under different light intensities is proposed. First, the plant physiological electrical signal under different light intensities is converted into a two-dimensional picture, and the plant physiological electrical signal recognition problem is transformed into a target detection problem in the field of image recognition. Furthermore, the recognition ability of plant physiological electrical signals under different light intensities is improved, and different light intensities of plants are judged by plant physiological electrical signals to reflect the growth state of plants themselves. Based on this idea, a plant physiological electrical signal recognition under different light intensities based on image convolutional neural network PlantImageDet algorithm is proposed. Aloe is selected as the experimental object in this experiment, the experimental results show that the proposed algorithm can effectively identify the type of light intensity of plant physiological electrical signals. In a data set of 3 types and 4740 samples collected in the experiment, the recognition accuracy rate reaches 92.04%. The validity of the proposed hypothesis and the feasibility of the proposed algorithm are verified, so the plant physiological electrical signal can be used as an effective evaluation index for the detection of light intensity environmental factors.  © 2021 ACM.","Convolutional Neural Network; Deep learning; Environmental factors of light intensity; Plant physiological electrical signal","Biomedical signal processing; Convolution; Deep learning; Image recognition; Physiological models; Physiology; Convolutional neural network; Deep learning; Different lights; Electrical signal; Environmental factor of light intensity; Environmental factors; Light intensity; Plant physiological electrical signal; Signal recognition; Technical ideas; Convolutional neural networks","","","Association for Computing Machinery",""
"","","","International Conference on Biomedical Engineering, ICoBE 2021","2021","2071","1","","","","475","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122013028&partnerID=40&md5=73bdc49eecc912b8262bcc4e013b201c","The proceedings contain 56 papers. The topics discussed include: identifying drug-resistant tuberculosis from chest x-ray images using a simple convolutional neural network; computer-aided detection of lung tumors in chest x-ray images using a bone suppression algorithm and a deep learning framework; synthesis and characterization of electrospun polyvinylidene fluoride-based (PVDF) scaffolds for renal bioengineering; study on optical properties of milk based on light propagation theory; the influences of sintering process on the characteristics of Corbiculacea (Etok) shells based hydroxyapatite powder; synthesis methods of doped hydroxyapatite: a brief review; synthesis and characterization of Nanoporous biphasic calcium phosphate; and antibacterial activity of biodegradable plastic from Chromolaena odorata (Pokok Kapal Terbang) leaves.","","","","Yazid H.B.; Fook C.Y.; Abdul Rahim S.B.; Mustafa N.B.; Sakeran H.; Bin Norali A.N.; Mamat N.B.; Noor A.B.M.; Bin Mahmud M.F.","IOP Publishing Ltd",""
"Safdarian N.; Nezhad S.Y.D.; Dabanloo N.J.","Safdarian, Naser (55309051800); Nezhad, Shadi Yoosefan Dezfuli (57225033512); Dabanloo, Nader Jafarnia (8507301300)","55309051800; 57225033512; 8507301300","Detection and classification of myocardial infarction with support vector machine classifier using grasshopper optimization algorithm","2021","11","3","","185","193","8","10.4103/jmss.JMSS_24_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111814793&doi=10.4103%2fjmss.JMSS_24_20&partnerID=40&md5=65b4faf820a6465d4b46f62258d260ff","Background: Providing a noninvasive, rapid, and cost-effective approach to diagnose of myocardial infarction (MI) is essential in the early stages of electrocardiogram (ECG) signaling. In this article, we proposed the new optimization method for support vector machine (SVM) classifier to MI classification. Methods: After preprocessing ECG signal and noise removal, three features such as Q-wave integral, T-wave integral, and QRS-complex integral have been extracted in this study. After that, different statistical tests have evaluated the matrix of these features. To more accurately detect and classify the MI disease, optimizing the SVM classification parameters using the grasshopper optimization algorithm (GOA) was first used in this study (that called SVM-GOA). Results: After applying the GOA on the SVM classifier for all three kernels, the final results of MI detection for sensitivity, specificity, and accuracy were 100% ± 0%, 100% ± 0%, and 100% ± 0%, respectively. The final results of different MI types' classification after applying the GOA on SVM for polynomial kernel were obtained 100% ± 0%, 97.37% ± 0%, and 94.2% ± 0.2% for sensitivity and specificity and accuracy, respectively. However, the results of both linear and RBF kernels that were used for the SVM classifier method have also shown a significant increase after using GOA. Conclusion: This article's results show the highly desirable effect of applying a GOA to optimize different kernel parameters used in the SVM classifier for accurate detection and classification of MI. The proposed algorithm's final results show that the proposed system has a relatively higher performance than other previous studies. © 2021 Journal of Medical Signals and Sensors Published by Wolters Kluwer-Medknow.","Biomedical signal processing; electrocardiogram; grasshopper optimization algorithm; myocardial infarction; support vector machine classifier","adolescent; adult; aged; Article; Bayesian learning; classification algorithm; comparative study; computer assisted diagnosis; convolutional neural network; deep neural network; diagnostic accuracy; electrocardiogram; feature extraction; female; gaussian mixture model; grasshopper optimization algorithm; heart infarction; hidden Markov model; Hilbert transform; human; image processing; k nearest neighbor; kernel method; major clinical study; male; metaheuristics; multilayer perceptron; noise reduction; probabilistic neural network; Q wave; QRS complex; R wave; radial basis function; recursive neural network; sensitivity and specificity; signal processing; support vector machine; T wave; wavelet transform","","","Isfahan University of Medical Sciences(IUMS)",""
"Aswathi C.D.; Mathew N.A.; Riyas K.S.; Jose R.","Aswathi, C.D. (57189048177); Mathew, Nimmy Ann (57204980237); Riyas, K.S. (56047352600); Jose, Renu (55212773400)","57189048177; 57204980237; 56047352600; 55212773400","Comparison of Machine Learning Algorithms for Heart Rate Variability Based Driver Drowsiness Detection","2021","","","","","","","10.1109/GCAT52182.2021.9587733","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119487838&doi=10.1109%2fGCAT52182.2021.9587733&partnerID=40&md5=245988ee3fb32d93a13ca4dfcdb255f2","Drowsy driving due to insufficient sleep has led to many serious traffic accidents. Measuring the drowsiness of the driver and taking timely actions can avoid such accidents. Earlier, conventional methods such as eye states and facial expressions were used to detect drowsiness. Nowadays new techniques have been developed for the same purpose, which uses bio-electric signals like an Electro Cardio Gram(ECG). Heart Rate Variability (HRV) can be used to assess drivers' drowsiness, fatigue, and stress levels. HRV is determined by the interval of RR measured by an Electro Cardiogram. Twelve features are monitored, including both time and frequency domains, in order to determine the HRV changes. HRV monitoring is used to actually predict epileptic seizures. The proposed work uses Heart Rate Variability (HRV) analysis with a Machine Learning and Deep Learning to detect drowsiness. A comparison is also made between the performance of four different Machine Learning(ML) algorithms while using one-dimensional convolutional neural networks (1D CNNs). Convolutional neural networks (CNN) are used increasingly in Computer Vision and Machine Learning operations. 2D CNNs consist of millions of parameters and many hidden layers, and it has Interpreting complex patterns and objects. Two-dimensional signals, such as images and video frames, are used as inputs for 2D CNNs. However, this may not be the ideal choice in many applications, especially those involving One-Dimensional signals such as biomedical signals. To solve the problem, 1D CNNs were introduced with the highest level of performance. Specifically, the 1D CNN has four layers: a Convolutional Layer, Batch Normalization Layer, Maxpooling Layer, and Fully Connected Layer. The proposed strategy has the potential to help avoid accidents caused by drowsy driving. © 2021 IEEE.","Electro Cardio Gram(ECG); Heart Rate Variability(HRV); Machine Learning(ML); One Dimensional Convolutional Neural Network(1D CNNs)","Accidents; Bioelectric phenomena; Bioinformatics; Biomedical signal processing; Cardiology; Convolution; Convolutional neural networks; Deep learning; Electroencephalography; Electrophysiology; Heart; Learning algorithms; Multilayer neural networks; Convolutional neural network; Driver drowsiness; Drowsy driving; Electro cardio gram; Heart rate variability; Machine learning algorithms; Machine-learning; One dimensional convolutional neural network(1d CNN); One-dimensional; Performance; Electrocardiography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Verma P.; Dumka A.; Bhardwaj A.; Kestwal M.C.","Verma, Parag (57204720597); Dumka, Ankur (56159612000); Bhardwaj, Anuj (35145251700); Kestwal, Mukesh Chandra (56241719900)","57204720597; 56159612000; 35145251700; 56241719900","Classifying Breast Density in Mammographic Images Using Wavelet-Based and Fine-Tuned Sensory Neural Networks","2021","21","5","2140004","","","","10.1142/S0219467821400040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100030778&doi=10.1142%2fS0219467821400040&partnerID=40&md5=d0a21378d841b7e1e699c94e1739794b","In this modern world of biomedical medicine, the classification of breast density has been considered a very important part of the process of breast diagnosis. Furthering the same research, this research aims to determine the patient’s breast density by mammogram image with the help of modern techniques such as computerized devices and machine learning algorithms, which will greatly help the radiologist. To carry out this process, this research paper introduces a Convolutional Neural Network (CNN) model of deep learning that will work as a basis for waveform conversion and fine-tune. This deep learning model will prove effective in automatically classifying a patient’s breast density. With the help of this method, the last two layers which are fully connected are removed and joined with two newly formed layers. This would have helped in addressing a pre-trained AlexNet model that further improved the classification process. In this model, the original or preprocessed images are used at level 1 of the input (which is in sharp contrast to the usual methods based on the CNN model), which also makes the model compatible with the use of redundant wavelet coefficients. Because in the field of radiologists it is very important to underline the difference between scattered density and heterogeneous density, so the main objective of this research is focused on this end. As the proposed method has an accuracy of 82.2%, it shows a better performance. This research paper further compares the effectiveness and performance of the proposed method to traditional fine-tuning CNN models, with satisfactory results. The comparative results of the proposed method suggest that the proposed method is in the field of radiologists representing a helpful tool. This method may be intended to act as a second eye for doctors in the medical field with the intention of classifying the categories of breast density in the patient during breast cancer screening. © 2021 World Scientific Publishing Company","Breast cancer; breast density classification; CNN model; convolutional neural network; deep learning model; fine-tuned sensory network; mammography images; wavelet-based technique","Computer aided diagnosis; Convolution; Convolutional neural networks; Deep learning; Diseases; Image classification; Learning algorithms; X ray screens; Breast Cancer; Breast density classifications; Convolutional neural network; Convolutional neural network model; Deep learning model; Fine-tuned sensory network; Learning models; Mammography images; Neural network model; Sensory networks; Wavelet-based technique; Mammography","","","World Scientific",""
"Ahn J.C.; Connell A.; Simonetto D.A.; Hughes C.; Shah V.H.","Ahn, Joseph C. (57221635443); Connell, Alistair (56982662900); Simonetto, Douglas A. (6602313881); Hughes, Cian (56351939700); Shah, Vijay H. (56052061300)","57221635443; 56982662900; 6602313881; 56351939700; 56052061300","Application of Artificial Intelligence for the Diagnosis and Treatment of Liver Diseases","2021","73","6","","2546","2563","17","10.1002/hep.31603","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107948969&doi=10.1002%2fhep.31603&partnerID=40&md5=f08eeaff9ecba29ebbfb62d6670f78d3","Modern medical care produces large volumes of multimodal patient data, which many clinicians struggle to process and synthesize into actionable knowledge. In recent years, artificial intelligence (AI) has emerged as an effective tool in this regard. The field of hepatology is no exception, with a growing number of studies published that apply AI techniques to the diagnosis and treatment of liver diseases. These have included machine-learning algorithms (such as regression models, Bayesian networks, and support vector machines) to predict disease progression, the presence of complications, and mortality; deep-learning algorithms to enable rapid, automated interpretation of radiologic and pathologic images; and natural-language processing to extract clinically meaningful concepts from vast quantities of unstructured data in electronic health records. This review article will provide a comprehensive overview of hepatology-focused AI research, discuss some of the barriers to clinical implementation and adoption, and suggest future directions for the field. © 2020 by the American Association for the Study of Liver Diseases.","","Artificial Intelligence; Gastroenterology; Humans; Liver Diseases; Medical Records Systems, Computerized; Translational Research, Biomedical; acute liver failure; acute on chronic liver failure; artificial intelligence; artificial neural network; computer assisted tomography; deep learning; echography; health data; histopathology; human; liver cirrhosis; liver disease; liver transplantation; machine learning; model; natural language processing; nonalcoholic fatty liver; nonalcoholic steatohepatitis; nuclear magnetic resonance imaging; omics; prediction; Review; virus hepatitis; electronic medical record system; gastroenterology; liver disease; procedures","","","John Wiley and Sons Inc","33098140"
"Kassim Y.M.; Palaniappan K.; Yang F.; Poostchi M.; Palaniappan N.; Maude R.J.; Antani S.; Jaeger S.","Kassim, Yasmin M. (57192917205); Palaniappan, Kannappan (6701784534); Yang, Feng (56408792200); Poostchi, Mahdieh (26421326000); Palaniappan, Nila (59023926200); Maude, Richard J (25625222500); Antani, Sameer (6701355570); Jaeger, Stefan (55516608100)","57192917205; 6701784534; 56408792200; 26421326000; 59023926200; 25625222500; 6701355570; 55516608100","Clustering-Based Dual Deep Learning Architecture for Detecting Red Blood Cells in Malaria Diagnostic Smears","2021","25","5","9244549","1735","1746","11","10.1109/JBHI.2020.3034863","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105779054&doi=10.1109%2fJBHI.2020.3034863&partnerID=40&md5=ce124a8081c83f1e2f806d3525fd77f9","Computer-assisted algorithms have become a mainstay of biomedical applications to improve accuracy and reproducibility of repetitive tasks like manual segmentation and annotation. We propose a novel pipeline for red blood cell detection and counting in thin blood smear microscopy images, named RBCNet, using a dual deep learning architecture. RBCNet consists of a U-Net first stage for cell-cluster or superpixel segmentation, followed by a second refinement stage Faster R-CNN for detecting small cell objects within the connected component clusters. RBCNet uses cell clustering instead of region proposals, which is robust to cell fragmentation, is highly scalable for detecting small objects or fine scale morphological structures in very large images, can be trained using non-overlapping tiles, and during inference is adaptive to the scale of cell-clusters with a low memory footprint. We tested our method on an archived collection of human malaria smears with nearly 200,000 labeled cells across 965 images from 193 patients, acquired in Bangladesh, with each patient contributing five images. Cell detection accuracy using RBCNet was higher than 97\%. The novel dual cascade RBCNet architecture provides more accurate cell detections because the foreground cell-cluster masks from U-Net adaptively guide the detection stage, resulting in a notably higher true positive and lower false alarm rates, compared to traditional and other deep learning methods. The RBCNet pipeline implements a crucial step towards automated malaria diagnosis. © 2013 IEEE.","connected components; deep learning; faster R-CNN; Red blood cells (RBCs); semantic segmentation; superpixel; U-Net; white blood cells (WBCs)","Cluster Analysis; Deep Learning; Erythrocytes; Humans; Image Processing, Computer-Assisted; Malaria; Reproducibility of Results; Bioinformatics; Blood; Cells; Cluster computing; Cytology; Diagnosis; Diseases; Learning systems; Medical applications; Object detection; Pipelines; Biomedical applications; Connected component; Learning architectures; Malaria diagnosis; Manual segmentation; Morphological structures; Reproducibilities; Superpixel segmentations; accuracy; anemia; Article; artificial neural network; blood smear; cancer diagnosis; cell separation; cerebral malaria; deep learning; entropy; erythrocyte; fever; headache; histogram; human; information processing; learning algorithm; leukocyte; machine learning; malaria; memory; microscopy; nerve cell network; Plasmodium falciparum; reproducibility; seizure; training; visual acuity; cluster analysis; erythrocyte; image processing; malaria; Deep learning","National Science Foundation, NSF, (1950873); National Science Foundation, NSF; National Institutes of Health, NIH; National Institute of Neurological Disorders and Stroke, NINDS, (R01NS110915); National Institute of Neurological Disorders and Stroke, NINDS; U.S. National Library of Medicine, NLM; Army Research Laboratory, ARL, (W911NF-1820285); Army Research Laboratory, ARL; Wellcome Trust, WT; Lister Hill National Center for Biomedical Communications, LHNCBC","","Institute of Electrical and Electronics Engineers Inc.","33119516"
"Pontoriero A.D.; Nordio G.; Easmin R.; Giacomel A.; Santangelo B.; Jahuar S.; Bonoldi I.; Rogdaki M.; Turkheimer F.; Howes O.; Veronese M.","Pontoriero, Antonella D. (57226107576); Nordio, Giovanna (56974260900); Easmin, Rubaida (56296742100); Giacomel, Alessio (57226114142); Santangelo, Barbara (57211426130); Jahuar, Sameer (57226129335); Bonoldi, Ilaria (26040450300); Rogdaki, Maria (23019760300); Turkheimer, Federico (7004599949); Howes, Oliver (6602176923); Veronese, Mattia (36487315800)","57226107576; 56974260900; 56296742100; 57226114142; 57211426130; 57226129335; 26040450300; 23019760300; 7004599949; 6602176923; 36487315800","Automated Data Quality Control in FDOPA brain PET Imaging using Deep Learning","2021","208","","106239","","","","10.1016/j.cmpb.2021.106239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110441377&doi=10.1016%2fj.cmpb.2021.106239&partnerID=40&md5=9561bc41c166cac5ac16c441a4c8ae16","Introduction. With biomedical imaging research increasingly using large datasets, it becomes critical to find operator-free methods to quality control the data collected and the associated analysis. Attempts to use artificial intelligence (AI) to perform automated quality control (QC) for both single-site and multi-site datasets have been explored in some neuroimaging techniques (e.g. EEG or MRI), although these methods struggle to find replication in other domains. The aim of this study is to test the feasibility of an automated QC pipeline for brain [18F]-FDOPA PET imaging as a biomarker for the dopamine system. Methods. Two different Convolutional Neural Networks (CNNs) were used and combined to assess spatial misalignment to a standard template and the signal-to-noise ratio (SNR) relative to 200 static [18F]-FDOPA PET images that had been manually quality controlled from three different PET/CT scanners. The scans were combined with an additional 400 scans, in which misalignment (200 scans) and low SNR (200 scans) were simulated. A cross-validation was performed, where 80% of the data were used for training and 20% for validation. Two additional datasets of [18F]-FDOPA PET images (50 and 100 scans respectively with at least 80% of good quality images) were used for out-of-sample validation. Results. The CNN performance was excellent in the training dataset (accuracy for motion: 0.86 ± 0.01, accuracy for SNR: 0.69 ± 0.01), leading to 100% accurate QC classification when applied to the two out-of-sample datasets. Data dimensionality reduction affected the generalizability of the CNNs, especially when the classifiers were applied to the out-of-sample data from 3D to 1D datasets. Conclusions. This feasibility study shows that it is possible to perform automatic QC of [18F]-FDOPA PET imaging with CNNs. The approach has the potential to be extended to other PET tracers in both brain and non-brain applications, but it is dependent on the availability of large datasets necessary for the algorithm training. © 2021","convolutional neural networks; FDOPA; PET; QC; quality control","Artificial Intelligence; Brain; Deep Learning; Humans; Positron Emission Tomography Computed Tomography; Positron-Emission Tomography; Quality Control; Alignment; Amines; Automation; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Large dataset; Neuroimaging; Polyethylene terephthalates; Quality assurance; Quality control; 6 fluorodopa f 18; biological marker; Automated data; Convolutional neural network; FDOPA; Large datasets; Noise ratio; PET images; PET imaging; Quality control; Signal to noise; accuracy; Article; automation; brain mapping; classifier; convolutional neural network; cross validation; data quality; deep learning; densenet convolutional neural network; dimensionality reduction; dopaminergic system; false negative result; feasibility study; image analysis; image artifact; image quality; image segmentation; neuroimaging; nuclear magnetic resonance imaging; pattern recognition; positron emission tomography; quality control; signal noise ratio; standardized uptake value ratio; stochastic model; validation study; artificial intelligence; brain; diagnostic imaging; human; positron emission tomography; positron emission tomography-computed tomography; quality control; Signal to noise ratio","JMAS; Maudsley National Health Service Foundation Trust; National Institute for Health Research Biomedical Research Centre at South London; National Institute for Health Research Biomedical Research Centre at South London and Maudsley National Health Service Foundation Trust; Brain and Behavior Research Foundation, BBRF; South London and Maudsley NHS Foundation Trust; Wellcome Trust, WT, (094849/Z/10/Z, 215747/Z/19); Maudsley Charity, (666); Medical Research Council, MRC, (MC- A656-5QD30, MC_U120097115); National Institute for Health Research, NIHR; Royal College of Physicians, RCP; King's College London","","Elsevier Ireland Ltd","34289438"
"Rasheed S.; Mumtaz W.","Rasheed, Suleman (57223425196); Mumtaz, Wajid (55359401300)","57223425196; 55359401300","Classification of Hand-Grasp Movements of Stroke Patients using EEG Data","2021","","","9445231","86","90","4","10.1109/ICAI52203.2021.9445231","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108068781&doi=10.1109%2fICAI52203.2021.9445231&partnerID=40&md5=c19bb4fd16539d26f41a56574c1d7cfb","Electroencephalography (EEG) based Brain Controlled Prosthetics can potentially improve the lives of people with movement disorders, however, the successful classification of the brain thoughts into correct intended movement is still a challenge. In recent years, machine learning based methods, especially deep neural networks, have improved the pattern recognition and classification performance of computer vision systems. However, there is a need to evaluate the classical EEG signal processing algorithms against advanced machine learning based variants, specifically in the domain of Brain Computer Interfaces (BCI). This study aims to be a benchmark where we evaluate the performance of 5 popular motor imagery BCI pipelines and compare classical signal processing techniques (wavelet transform and power spectral density) with motor imagery specific algorithms (Common Spatial Patterns and Filter Bank Common Spatial Patterns (FBCSP)) and a state-of-the-art deep neural network based EEGNet algorithm. The experiments were performed on an open-source EEG dataset of hemiparetic stroke patients and both within subject and cross subject performance of the aforementioned algorithms was evaluated based on kappa scores. We empirically found that, for within subject classification, FBCSP method still is the gold-standard for motor imagery task with a mean kappa score of about 0.70 (84.8% accuracy) while for cross subject classification, due to the availability of a large amount of data, deep learning based EEGNet method outperformed all the other methods with a large margin and gave kappa value of 0.54 (77.0% accuracy). We believe these results would help BCI researchers to select a suitable BCI pipeline for their task that could help in the development of robot assisted therapies or as an interface for assistive devices. © 2021 IEEE.","Assistive Devices; Brain Computer Interface (BCI); EEGNet; FBCSP; Motor Imagery Classification","Benchmarking; Brain computer interface; Deep learning; Deep neural networks; Electroencephalography; Electrophysiology; Image compression; Learning systems; Neural networks; Pattern recognition systems; Pipeline processing systems; Pipelines; Spectral density; Wavelet transforms; Common spatial patterns; Computer vision system; EEG signal processing; Motor imagery tasks; Pattern recognition and classification; Robot-assisted therapies; Signal processing technique; Subject classification; Biomedical signal processing","","","Institute of Electrical and Electronics Engineers Inc.",""
"Meyer A.; Ghosh S.; Schindele D.; Schostak M.; Stober S.; Hansen C.; Rak M.","Meyer, Anneke (56405903100); Ghosh, Suhita (57219563841); Schindele, Daniel (55390061000); Schostak, Martin (6603964261); Stober, Sebastian (14027561800); Hansen, Christian (55890379200); Rak, Marko (56435800100)","56405903100; 57219563841; 55390061000; 6603964261; 14027561800; 55890379200; 56435800100","Uncertainty-aware temporal self-learning (UATS): Semi-supervised learning for segmentation of prostate zones and beyond","2021","116","","102073","","","","10.1016/j.artmed.2021.102073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104658608&doi=10.1016%2fj.artmed.2021.102073&partnerID=40&md5=feb5bd756dfad84d89ed3bfedb6018b4","Various convolutional neural network (CNN) based concepts have been introduced for the prostate's automatic segmentation and its coarse subdivision into transition zone (TZ) and peripheral zone (PZ). However, when targeting a fine-grained segmentation of TZ, PZ, distal prostatic urethra (DPU) and the anterior fibromuscular stroma (AFS), the task becomes more challenging and has not yet been solved at the level of human performance. One reason might be the insufficient amount of labeled data for supervised training. Therefore, we propose to apply a semi-supervised learning (SSL) technique named uncertainty-aware temporal self-learning (UATS) to overcome the expensive and time-consuming manual ground truth labeling. We combine the SSL techniques temporal ensembling and uncertainty-guided self-learning to benefit from unlabeled images, which are often readily available. Our method significantly outperforms the supervised baseline and obtained a Dice coefficient (DC) of up to 78.9%, 87.3%, 75.3%, 50.6% for TZ, PZ, DPU and AFS, respectively. The obtained results are in the range of human inter-rater performance for all structures. Moreover, we investigate the method's robustness against noise and demonstrate the generalization capability for varying ratios of labeled data and on other challenging tasks, namely the hippocampus and skin lesion segmentation. UATS achieved superiority segmentation quality compared to the supervised baseline, particularly for minimal amounts of labeled data. © 2021 Elsevier B.V.","Biomedical segmentation; Prostate zones; Semi-supervised deep learning","Hippocampus; Humans; Male; Neural Networks, Computer; Prostate; Supervised Machine Learning; Uncertainty; Convolutional neural networks; Labeled data; Urology; Automatic segmentations; Generalization capability; Human performance; Robustness against noise; Segmentation quality; Semi-supervised learning (SSL); Supervised trainings; Transition zones; Article; comparative study; cross validation; dice coefficient; entropy; hippocampus; human; image segmentation; interrater reliability; kinetic parameters; Monte Carlo method; priority journal; prostate; qualitative analysis; segmentation algorithm; semi supervised machine learning; signal noise ratio; skin defect; task positive network; three dimensional u net algorithm; uncertainty aware temporal self learning; diagnostic imaging; male; supervised machine learning; uncertainty; Semi-supervised learning","EUand the federal state of Saxony-Anhalt, (numberZS/2016/08/80388); Otto von Guericke University; National Institutes of Health, NIH; National Cancer Institute, NCI; Nvidia; SPIE; European Commission, EC; European Social Fund, ESF, (ZS/2016/08/80646); Radboud Universitair Medisch Centrum, RUNMC","","Elsevier B.V.","34020751"
"Hoar D.; Lee P.Q.; Guida A.; Patterson S.; Bowen C.V.; Merrimen J.; Wang C.; Rendon R.; Beyea S.D.; Clarke S.E.","Hoar, David (57247745000); Lee, Peter Q. (57208753589); Guida, Alessandro (57201347780); Patterson, Steven (57543543500); Bowen, Chris V. (7103158567); Merrimen, Jennifer (13610935600); Wang, Cheng (57208751752); Rendon, Ricardo (6602247041); Beyea, Steven D. (7005347832); Clarke, Sharon E. (7402969177)","57247745000; 57208753589; 57201347780; 57543543500; 7103158567; 13610935600; 57208751752; 6602247041; 7005347832; 7402969177","Combined Transfer Learning and Test-Time Augmentation Improves Convolutional Neural Network-Based Semantic Segmentation of Prostate Cancer from Multi-Parametric MR Images","2021","210","","106375","","","","10.1016/j.cmpb.2021.106375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114302101&doi=10.1016%2fj.cmpb.2021.106375&partnerID=40&md5=0181490d89442e17b0ad0bd9e1eddfa8","Purpose: Multiparametric MRI (mp-MRI) is a widely used tool for diagnosing and staging prostate cancer. The purpose of this study was to evaluate whether transfer learning, unsupervised pre-training and test-time augmentation significantly improved the performance of a convolutional neural network (CNN) for pixel-by-pixel prediction of cancer vs. non-cancer using mp-MRI datasets. Methods: 154 subjects undergoing mp-MRI were prospectively recruited, 16 of whom subsequently underwent radical prostatectomy. Logistic regression, random forest and CNN models were trained on mp-MRI data using histopathology as the gold standard. Transfer learning, unsupervised pre-training and test-time augmentation were used to boost CNN performance. Models were evaluated using Dice score and area under the receiver operating curve (AUROC) with leave-one-subject-out cross validation. Permutation feature importance testing was performed to evaluate the relative value of each MR contrast to CNN model performance. Statistical significance (p<0.05) was determined using the paired Wilcoxon signed rank test with Benjamini-Hochberg correction for multiple comparisons. Results: Baseline CNN outperformed logistic regression and random forest models. Transfer learning and unsupervised pre-training did not significantly improve CNN performance over baseline; however, test-time augmentation resulted in significantly higher Dice scores over both baseline CNN and CNN plus either of transfer learning or unsupervised pre-training. The best performing model was CNN with transfer learning and test-time augmentation (Dice score of 0.59 and AUROC of 0.93). The most important contrast was apparent diffusion coefficient (ADC), followed by Ktrans and T2, although each contributed significantly to classifier performance. Conclusions: The addition of transfer learning and test-time augmentation resulted in significant improvement in CNN segmentation performance in a small set of prostate cancer mp-MRI data. Results suggest that these techniques may be more broadly useful for the optimization of deep learning algorithms applied to the problem of semantic segmentation in biomedical image datasets. However, further work is needed to improve the generalizability of the specific model presented herein. © 2021 Elsevier B.V.","Computer aided diagnosis; Convolutional neural network; Machine learning; MRI; Prostate cancer; Segmentation","Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Neural Networks, Computer; Prostatic Neoplasms; Semantics; Calcium compounds; Computer aided diagnosis; Computer aided instruction; Convolution; Convolutional neural networks; Decision trees; Deep learning; Diseases; Image enhancement; Image segmentation; Learning algorithms; Medical imaging; Pixels; Regression analysis; Semantics; Surface diffusion; Urology; fleet enema; gadobenate dimeglumine; Computer-aided; Convolutional neural network; Learning time; Machine-learning; Performance; Pre-training; Prostate cancers; Segmentation; Test time; Transfer learning; adult; aged; apparent diffusion coefficient; Article; cancer diagnosis; cancer patient; cancer surgery; classifier; comparative study; computer assisted diagnosis; controlled study; convolutional neural network; data analysis software; diagnostic accuracy; diagnostic test accuracy study; diffusion weighted imaging; dynamic contrast-enhanced magnetic resonance imaging; false positive result; gold standard; histopathology; human; human tissue; image segmentation; leave one out cross validation; logistic regression analysis; machine learning; major clinical study; male; multiparametric magnetic resonance imaging; prospective study; prostate cancer; prostatectomy; random forest; receiver operating characteristic; test time augmentation; transfer of learning; unsupervised machine learning; diagnostic imaging; image processing; machine learning; nuclear magnetic resonance imaging; prostate tumor; semantics; Magnetic resonance imaging","Atlantic Innovation Fund; Google Cloud; Radiology Research Foundation; GE Healthcare","","Elsevier Ireland Ltd","34500139"
"Yıldız E.; Arslan A.T.; Taş A.Y.; Acer A.F.; Demir S.; Şahin A.; Barkana D.E.","Yıldız, Erdost (57210635308); Arslan, Abdullah Taha (57188848702); Taş, Ayşe Yıldız (57221969763); Acer, Ali Faik (57224813531); Demir, Sertaç (57224832881); Şahin, Afsun (12808854500); Barkana, Duygun Erol (57472154100)","57210635308; 57188848702; 57221969763; 57224813531; 57224832881; 12808854500; 57472154100","Generative adversarial network based automatic segmentation of corneal subbasal nerves on in vivo confocal microscopy images","2021","10","6","33","","","","10.1167/TVST.10.6.33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108365679&doi=10.1167%2fTVST.10.6.33&partnerID=40&md5=34575807452970b85c318d16763cf9cf","Purpose: In vivo confocal microscopy (IVCM) is a noninvasive, reproducible, and inexpensive diagnostic tool for corneal diseases. However, widespread and effortless image acquisition in IVCM creates serious image analysis workloads on ophthalmol-ogists, and neural networks could solve this problem quickly. We have produced a novel deep learning algorithm based on generative adversarial networks (GANs), and we compare its accuracy for automatic segmentation of subbasal nerves in IVCM images with a fully convolutional neural network (U-Net) based method. Methods: We have collected IVCM images from 85 subjects. U-Net and GAN-based image segmentation methods were trained and tested under the supervision of three clinicians for the segmentation of corneal subbasal nerves. Nerve segmentation results for GAN and U-Net-based methods were compared with the clinicians by using Pearson’s R correlation, Bland-Altman analysis, and receiver operating characteristics (ROC) statis-tics. Additionally, different noises were applied on IVCM images to evaluate the perfor-mances of the algorithms with noises of biomedical imaging. Results: The GAN-based algorithm demonstrated similar correlation and Bland-Altman analysis results with U-Net. The GAN-based method showed significantly higher accuracy compared to U-Net in ROC curves. Additionally, the performance of the U-Net deteriorated significantly with different noises, especially in speckle noise, compared to GAN. Conclusions: This study is the first application of GAN-based algorithms on IVCM images. The GAN-based algorithms demonstrated higher accuracy than U-Net for automatic corneal nerve segmentation in IVCM images, in patient-acquired images and noise applied images. This GAN-based segmentation method can be used as a facilitat-ing diagnostic tool in ophthalmology clinics. Translational Relevance: Generative adversarial networks are emerging deep learning models for medical image processing, which could be important clinical tools for rapid segmentation and analysis of corneal subbasal nerves in IVCM images. © 2021 The Authors.","Convolutional neural networks; Cornea; Generative adversarial networks (GAN); Image segmentation; In vivo confocal microscopy (IVCM); Medical image analysis","","Koç University Research Center for Translational Medicine; Türkiye Bilimsel ve Teknolojik Araştırma Kurumu, TÜBİTAK, (1180232)","","Association for Research in Vision and Ophthalmology Inc.",""
"Takhchidi H.P.; Gliznitsa P.V.; Svetozarskiy S.N.; Bursov A.I.; Shusterzon K.A.","Takhchidi, H.P. (6505906192); Gliznitsa, P.V. (57210731803); Svetozarskiy, S.N. (56097185700); Bursov, A.I. (56493125300); Shusterzon, K.A. (57254584500)","6505906192; 57210731803; 56097185700; 56493125300; 57254584500","Labelling of data on fundus color pictures used to train a deep learning model enhances its macular pathology recognition capabilities; [РАЗМЕТКА ЦВЕТНЫХ ФОТОГРАФИЙ ГЛАЗНОГО ДНА УЛУЧШАЕТ РАСПОЗНАВАНИЕ МАКУЛЯРНОЙ ПАТОЛОГИИ С ПОМОЩЬЮ ГЛУБОКОГО ОБУЧЕНИЯ]","2021","","4","","28","33","5","10.24075/brsmu.2021.040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114694128&doi=10.24075%2fbrsmu.2021.040&partnerID=40&md5=de5aa1cea349a3ee117fb873ccb7c7b4","Retinal diseases remain one of the leading causes of visual impairments in the world. The development of automated diagnostic methods can improve the efficiency and availability of the macular pathology mass screening programs. The objective of this work was to develop and validate deep learning algorithms detecting macular pathology (age-related macular degeneration, AMD) based on the analysis of color fundus photographs with and without data labeling. We used 1200 color fundus photographs from local databases, including 575 retinal images of AMD patients and 625 pictures of the retina of healthy people. The deep learning algorithm was deployed in the Faster RCNN neural network with ResNet50 for convolution. The process employed the transfer learning method. As a result, in the absence of labeling, the accuracy of the model was unsatisfactory (79%) because the neural network selected the areas of attention incorrectly. Data labeling improved the efficacy of the developed method: with the test dataset, the model determined the areas with informative features adequately, and the classification accuracy reached 96.6%. Thus, image data labeling significantly improves the accuracy of retinal color images recognition by a neural network and enables development and training of effective models with limited datasets. © 2021 Pirogov Russian National Research Medical University. All rights reserved.","Biomedical visualization; Data labeling; Fundus camera; Machine learning; Retinal diseases; Screening","adult; age related macular degeneration; Article; convolution algorithm; convolutional neural network; data analysis; data base; data labeling; deep learning; eye photography; female; human; learning algorithm; machine learning; major clinical study; male; molecular recognition; retina image; retina maculopathy; sensitivity and specificity; transfer of learning","Foundation for Assistance to Small Innovative Enterprises in Science and Technology, FASIE, (150ГС1ЦТНТИС5/64226); Foundation for Assistance to Small Innovative Enterprises in Science and Technology, FASIE","","Pirogov Russian National Research Medical University",""
"Jeantet L.; Vigon V.; Geiger S.; Chevallier D.","Jeantet, Lorène (57202257443); Vigon, Vincent (6507496627); Geiger, Sébastien (57217080432); Chevallier, Damien (36240348900)","57202257443; 6507496627; 57217080432; 36240348900","Fully Convolutional Neural Network: A solution to infer animal behaviours from multi-sensor data","2021","450","","109555","","","","10.1016/j.ecolmodel.2021.109555","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110529764&doi=10.1016%2fj.ecolmodel.2021.109555&partnerID=40&md5=7d67f838681dc93dbd3a62075322419e","Animal-attached accelerometers have been widely used to monitor species that are difficult to observe, alongside the use of machine learning to identify behaviours from the obtained sequences. Artificial neural networks are powerful supervised learning algorithms that are based on deep learning and have been poorly exploited in movement ecology. Recently, the availability of sophisticated algorithmic architectures via open source libraries facilitates their use. In this study, we adapt a fully convolutional neural network that was originally developed for biomedical 3D image segmentation: the V-net. We test it on a labelled dataset collected from animal-borne video recorders combined with multi-sensors (accelerometers, gyroscopes and depth recorders) deployed on free-ranging immature green turtles (Chelonia mydas). The proposed model, fitted for 1D data, is able to predict six behavioural categories for green turtles with an AUC score of 88%. It shows a high ability to detect rare behaviours with low discriminative signals such as Feeding and Scratching. With a precision down to one centisecond, the V-net circumvents the segmentation process. We also show that the gyroscope is more informative than the accelerometer in identifying sea turtle behaviours and that the V-net is not able to discriminate Feeding from the raw data of accelerometer alone. However, human expertise can help to correct it with precise and adapted pre-processing. Thus, diverted from its initial purpose and tested on sea turtle, the V-net is a very efficient method of behavioural identification that should be easily generalized to a wide range of species. It could lead to considerable progress in remote accelerometric monitoring and help to understand the ecology of the species that are difficult to observe. Furthermore, as the model is light, there is also a huge potential to implement a trained V-net in satellite-relay data tag to remotely predict the expressed behaviours almost instantly. © 2021","Accelerometer; Behavioural classification; Convolutional neural network; Deep learning; Ecology; Sea turtle","Chelonia mydas; Testudines; Varanidae; Animals; Convolution; Deep learning; Ecology; Gyroscopes; Image segmentation; Learning algorithms; Neural networks; Statistical tests; Video recording; Algorithmic architectures; Animal behaviour; Behavioral classification; Convolutional neural network; Deep learning; Machine-learning; Movement ecologies; Multi-sensor data; Neural-networks; Sea turtles; accelerometer; algorithm; artificial neural network; data processing; machine learning; segmentation; supervised learning; three-dimensional modeling; turtle; Accelerometers","CNES Guyane; DEAL Guyane; Explorations de Monaco; ONCFS Martinique; Subvention Mission pour l'Interdisciplinarité; Tortues marines des Antilles et the Plan National d'Action Tortues marines de Guyane Fran?aise; EGI; Centre National d’Etudes Spatiales, CNES; Fondation de France; Centre National de la Recherche Scientifique, CNRS; European Regional Development Fund, ERDF, (008–03–2018, 014–03–2015, 2012/DEAL/0010/4–4/31,882, 2014/DEAL/0008/4–4/32,947)","","Elsevier B.V.",""
"","","","2020 6th International Conference on Robotics and Artificial Intelligence, ICRAI 2020","2020","","","","","","288","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123040323&partnerID=40&md5=7a943022f71ab2aeaefd0aacb2c75ef4","The proceedings contain 48 papers. The topics discussed include:  nodule slices detection based with a novel deep learning method; anomaly detection of bolt tightening process based on improved SMOTE; face recognition from depth images with convolutional neural network; research on real-time semantic SLAM based on object detection network; application of convolutional neural network for facial expression recognition; motion driven temporal adaptive enhanced graph convolutional networks for skeleton-based action recognition; implementing game strategies based on reinforcement learning; tensor voting based 3-D point cloud processing for downsampling and registration; low illumination image enhancement based on image fusion; classification of liver cancer subtypes based on hierarchical integrated stacked autoencoder; low light image enhancement algorithm based on retinex and dehazing model; and analysis of different encoder-decoder-based approaches for biomedical imaging segmentation.","","","","","Association for Computing Machinery",""
"Kumar D.; Mehta M.A.; Chatterjee I.","Kumar, Dheeraj (57205393714); Mehta, Mayuri A. (56220509400); Chatterjee, Indranath (57201465828)","57205393714; 56220509400; 57201465828","Empirical Analysis of Deep Convolutional Generative Adversarial Network for Ultrasound Image Synthesis","2021","15","","","71","77","6","10.2174/1874120702115010071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128928956&doi=10.2174%2f1874120702115010071&partnerID=40&md5=9876d77fdd72b38a729903d5ace21543","Introduction: Recent research on Generative Adversarial Networks (GANs) in the biomedical field has proven the effectiveness in generating synthetic images of different modalities. Ultrasound imaging is one of the primary imaging modalities for diagnosis in the medical domain. In this paper, we present an empirical analysis of the state-of-the-art Deep Convolutional Generative Adversarial Network (DCGAN) for generating synthetic ultrasound images. Aims: This work aims to explore the utilization of deep convolutional generative adversarial networks for the synthesis of ultrasound images and to leverage its capabilities. Background: Ultrasound imaging plays a vital role in healthcare for timely diagnosis and treatment. Increasing interest in automated medical image analysis for precise diagnosis has expanded the demand for a large number of ultrasound images. Generative adversarial networks have been proven beneficial for increasing the size of data by generating synthetic images. Objective: Our main purpose in generating synthetic ultrasound images is to produce a sufficient amount of ultrasound images with varying representations of a disease. Methods: DCGAN has been used to generate synthetic ultrasound images. It is trained on two ultrasound image datasets, namely, the common carotid artery dataset and nerve dataset, which are publicly available on Signal Processing Lab and Kaggle, respectively. Results: Results show that good quality synthetic ultrasound images are generated within 100 epochs of training of DCGAN. The quality of synthetic ultrasound images is evaluated using Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR), and Structural Similarity Index Measure (SSIM). We have also presented some visual representations of the slices of generated images for qualitative comparison. Conclusion: Our empirical analysis reveals that synthetic ultrasound image generation using DCGAN is an efficient approach. Other: In future work, we plan to compare the quality of images generated through other adversarial methods such as conditional GAN, progressive GAN. © 2021 Austin et al.","Convolutional neural network; Data synthesis; Deep Convolutional Generative Adversarial Network; Deep learning; Generative adversarial network; Healthcare; Image augmentation; Medical imaging; Radiology; Synthetic image generator; Ultrasound","analysis; Article; artificial neural network; common carotid artery; convolutional neural network; data synthesis; deep convolutional generative adversarial network; deep learning; diagnostic imaging; echography; empirical analysis; human; image analysis; image processing; image quality; image segmentation; learning algorithm; mean squared error; signal noise ratio; signal processing","","","Bentham Science Publishers",""
"Behura A.","Behura, Aradhana (57216374591)","57216374591","Congruence of Deep Learning in Medical Image Processing: Future Prospects and Challenges","2021","936","","","197","221","24","10.1007/978-981-33-4698-7_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102080369&doi=10.1007%2f978-981-33-4698-7_10&partnerID=40&md5=6dcb672ef762524d0d59f0f1bf9f1f1b","Machine Learning and deep learning procedures, in particular deep reinforcement neural networks, have quickly become a smart approach for scrutinizing medical signal and image datasets. The perilous problem like Cancer takes place when the cellular reproduction procedure goes out of control when some parts of the human body’s cells arise to spread into contiguous fleshy tissue and divide without discontinuing which may be a clue to death. This fatal cancer is a dangerous disease categorized by undesirable, uncontrolled, and uncoordinated cell division. So early cancer diagnosis can protect a patient. Here, various types of deep learning techniques are applied for optimized feature extraction, normalization or dataset pre-processing (used to eliminate null value, noises, and outlier), data segmentation, accurate classification, and the common description of flow chart is described in Figs. 1 and 7. The survey of deep learning is used for image classification, carotid ultrasound data investigation, cardi tocography, intravascular ultrasound report, lung CT report, brain tumor prediction from the MRI report, object detection, segmentation, breast cancer prediction, ECG (electrocardiogram) signal, EEG (electroencephalogram), PPG signal registration and psoriasis skin disease as well as cancer detection. Concise summaries are delivered of trainings per application zone: pulmonary, musculoskeletal neuro, digital pathology, abdominal, retinal, breast, cardiac. There are various type of deep learning techniques are present to improve accuracy of the medical dataset. Deep reinforcement learning, Recursive neural network, Multilayer perceptron, Recurrent neural network, Boltzmann machine, Convolution neural network are different types of deep learning techniques used to train the image and signal dataset. Generative adversarial network, Auto encoder and deep belief neural network are coming under unsupervised pretrained neural network. Some well known architectural models of convolution neural networks are ResNet (2015), VGGNet (2014), GoogLeNet (2014), ZFNet (2013) is introduced as the visualization concept of the De-convolutional network, AlexNet (2012) and LeNet are basically used to train image dataset, LSTM technique (long short term memory) is used to train signalized dataset and RHSBoost, genetically optimized neural network are used for multiple classification of datasets efficiently. Dimensionality reduction, feature extraction, overfitting, underfitting and normalization problems can be solved using various types of optimization algorithm. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Attention module; Biomedical image and signal processing; Brain tumor; Breast cancer; Data prediction; Deep learning; Hyper-parameter; Hypercolumn technique; Magnetic resonance image","","","","Springer Science and Business Media Deutschland GmbH",""
"Hu Y.; Xu Y.; Tian Q.; Chen F.; Shi X.; Moran C.J.; Daniel B.L.; Hargreaves B.A.","Hu, Yuxin (57204430105); Xu, Yunyingying (57218482567); Tian, Qiyuan (48862168000); Chen, Feiyu (56472078200); Shi, Xinwei (56472126900); Moran, Catherine J. (8074129700); Daniel, Bruce L. (7102039861); Hargreaves, Brian A. (7003436291)","57204430105; 57218482567; 48862168000; 56472078200; 56472126900; 8074129700; 7102039861; 7003436291","RUN-UP: Accelerated multishot diffusion-weighted MRI reconstruction using an unrolled network with U-Net as priors","2021","85","2","","709","720","11","10.1002/mrm.28446","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089297969&doi=10.1002%2fmrm.28446&partnerID=40&md5=988946cdf04bc05443fe19fe164bc695","Purpose: To accelerate and improve multishot diffusion-weighted MRI reconstruction using deep learning. Methods: An unrolled pipeline containing recurrences of model-based gradient updates and neural networks was introduced for accelerating multishot DWI reconstruction with shot-to-shot phase correction. The network was trained to predict results of jointly reconstructed multidirection data using single-direction data as input. In vivo brain and breast experiments were performed for evaluation. Results: The proposed method achieves a reconstruction time of 0.1 second per image, over 100-fold faster than a shot locally low-rank reconstruction. The resultant image quality is comparable to the target from the joint reconstruction with a peak signal-to-noise ratio of 35.3 dB, a normalized root-mean-square error of 0.0177, and a structural similarity index of 0.944. The proposed method also improves upon the locally low-rank reconstruction (2.9 dB higher peak signal-to-noise ratio, 29% lower normalized root-mean-square error, and 0.037 higher structural similarity index). With training data from the brain, this method also generalizes well to breast diffusion-weighted imaging, and fine-tuning further reduces aliasing artifacts. Conclusion: A proposed data-driven approach enables almost real-time reconstruction with improved image quality, which improves the feasibility of multishot DWI in a wide range of clinical and neuroscientific studies. © 2020 International Society for Magnetic Resonance in Medicine","convolution neural network; multishot diffusion-weighted imaging; phase variation; unrolled network","Algorithms; Artifacts; Brain; Diffusion Magnetic Resonance Imaging; Image Processing, Computer-Assisted; Reproducibility of Results; Biomedical signal processing; Deep learning; Diffusion; Image enhancement; Image quality; Image reconstruction; Mean square error; Medical imaging; Neurophysiology; Aliasing artifacts; Data-driven approach; Diffusion weighted imaging; Diffusion-weighted MRI; Peak signal to noise ratio; Real-time reconstruction; Root mean square errors; Structural similarity indices; arthroplasty; article; artifact; brain; breast; controlled study; convolutional neural network; diffusion weighted imaging; feasibility study; human; image quality; pipeline; signal noise ratio; algorithm; diagnostic imaging; image processing; reproducibility; Signal to noise ratio","National Institutes of Health, NIH, (P41-EB015891, R01-EB009055); National Institute of Biomedical Imaging and Bioengineering, NIBIB, (R01EB009690); GE Healthcare","","John Wiley and Sons Inc","32783339"
"Zhang H.; Li Q.; Guan X.","Zhang, Hengliang (57222557855); Li, Qiang (56312497400); Guan, Xin (57192257319)","57222557855; 56312497400; 57192257319","An Improved Three-Dimensional Dual-Path Brain Tumor Image Segmentation Network; [一种改进的三维双路径脑肿瘤图像分割网络]","2021","41","3","0310002","","","","10.3788/AOS202141.0310002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103215412&doi=10.3788%2fAOS202141.0310002&partnerID=40&md5=ba575ce5a2595d458b5aec43fc165686","In recent years, the application of deep learning in biomedical image processing has received widespread attention. Based on the basic theories of deep learning and medical applications, this paper proposes an improved three-dimensional dual-path brain tumor image segmentation network to improve the detection accuracy of brain tumors in nuclear magnetic resonance imaging sequences. The proposed algorithm is based on 3D-UNet. First, the improved dual-path network unit is used to form the encoder-decoder structure similar to UNet. While retaining the original features, the network unit can also generate new features in texture, shape, and edge of the brain tumor to improve the accuracy of network segmentation. Second, the multi-fiber structure is added to the dual-path network module, which reduces the amount of parameters while ensuring the accuracy of the segmentation. Finally, after the group convolution in each network module, the channel random mixing module is added to solve the problem of accuracy reduction caused by group convolution, and the weighted Tversky loss function is used to replace the Dice loss function to improve the segmentation accuracy of small targets. The average Dice_ET, Dice_WT, and Dice_TC of the proposed model are better than 3D-ESPNet, DeepMedic, DMFNet, and other algorithms. The research results have certain practical significance and application prospects. © 2021, Chinese Lasers Press. All right reserved.","Brain tumor image segmentation; Dual-path network; Image processing; Neural networks; Weighted-loss function","Brain; Convolution; Deep learning; Image segmentation; Magnetic resonance imaging; Medical applications; Medical imaging; Textures; Three dimensional computer graphics; Tumors; Application prospect; Detection accuracy; Encoder-decoder; Loss functions; Network segmentation; Research results; Segmentation accuracy; Small targets; Image enhancement","","","Chinese Optical Society",""
"Wu L.; Zhang X.; Wang K.; Chen X.; Chen X.","Wu, Le (57856066100); Zhang, Xu (36007982800); Wang, Kun (57200920993); Chen, Xiang (57192255114); Chen, Xun (36456894700)","57856066100; 36007982800; 57200920993; 57192255114; 36456894700","Improved High-Density Myoelectric Pattern Recognition Control against Electrode Shift Using Data Augmentation and Dilated Convolutional Neural Network","2020","28","12","9223702","2637","2646","9","10.1109/TNSRE.2020.3030931","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100295852&doi=10.1109%2fTNSRE.2020.3030931&partnerID=40&md5=4bd23700e94a3b27b7e5db07fca37242","Objective: the objective of this work is to develop a robust method for myoelectric control towards alleviating the interference of electrode shift. M ethods: In the proposed method, a preprocessing approach was first performed to convert high-density surface electromyogram (HD-sEMG) signals into a series of images, and the electrode shift appeared as pixel shift in these images. Next, a data augmentation approach was applied to the training data from just one position (no shift), so as to simulate HD-sEMG images derived from fictitious shift positions. The dilated convolutional neural network (DCNN) was subsequently adopted for classification. Compared to common convolutional neural network, DCNN always contained a larger receptive field that was supposed to be adept at mining wider spatial contextual information in images. This property was further confirmed to facilitate the classification of myoelectric patterns using HD-sEMG. The performance of the proposed method was evaluated with HD-sEMG data recorded by a mathbf {10times 10} electrode array placed over forearm extensors of ten subjects during their performance of six wrist and finger extension tasks. Results: Under a variety of actual electrode shift conditions, the proposed method achieved a mean classification accuracy of 95.34%, and it outperformed other common methods. Conclusion: This work demonstrated feasibility and usability of combining data augmentation and DCNN in predicting myoelectric patterns in the context of electrode shifts. Significance: The proposed method is a practical solution for robust myoelectric control against electrode array shifts.  © 2001-2011 IEEE.","Data augmentation; deep learning; dilated convolutional neural network; electrode shift; myoelectric control","Algorithms; Electrodes; Electromyography; Humans; Neural Networks, Computer; Pattern Recognition, Automated; Biomedical signal processing; Convolution; Electrodes; Pattern recognition; Contextual information; Data augmentation; Electrode arrays; Mean classification; Myoelectric control; Practical solutions; Preprocessing approaches; Receptive fields; algorithm; automated pattern recognition; electrode; electromyography; human; Convolutional neural networks","National Key Research and Development Program of China, NKRDPC, (2018YFB1005001)","","Institute of Electrical and Electronics Engineers Inc.","33052847"
"Anwar S.; Alam A.","Anwar, Shamama (24437866500); Alam, Afrin (57219836271)","24437866500; 57219836271","A convolutional neural network–based learning approach to acute lymphoblastic leukaemia detection with automated feature extraction","2020","58","12","","3113","3121","8","10.1007/s11517-020-02282-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095685563&doi=10.1007%2fs11517-020-02282-x&partnerID=40&md5=4b567c9646124f8a7b20214c41fd13dc","Leukaemia is a type of blood cancer which mainly occurs when bone marrow produces excess white blood cells in our body. This disease not only affects adult but also is a common cancer type among children. Treatment of leukaemia depends on its type and how far the disease has spread in the body. Leukaemia is classified into two types depending on how rapidly it grows: acute and chronic leukaemia. The early diagnosis of this disease is vital for effective treatment and recovery. This paper presents an automated diagnostic system to detect acute lymphoblastic leukaemia (ALL) using a convolutional neural network (CNN) model. The model uses labeled microscopic blood smear images to detect the malignant leukaemia cells. The current work uses data obtained from the Acute Lymphoblastic Leukaemia Image DataBase (ALL_IDB) and performs various data augmentation techniques to increase the number of training data which in effect reduces the over-training problem. The model has been trained on 515 images using a fivefold validation technique achieving an accuracy of 95.54% and further tested on the remaining 221 images achieving almost 100% accuracy during most of the trials, maintaining an average of 99.5% accuracy. The method does not need any pre-processing or segmentation technique and works efficiently on raw data. This method can, hence, prove profitable for pathologist in diagnosing ALL efficiently. [Figure not available: see fulltext.]. © 2020, International Federation for Medical and Biological Engineering.","Acute lymphoblastic leukaemia (ALL); Augmentation; Convolutional neural network; Feature extraction; Leukaemia","Databases, Factual; Humans; Leukocytes; Neural Networks, Computer; Precursor Cell Lymphoblastic Leukemia-Lymphoma; Biomedical signal processing; Blood; Convolution; Diagnosis; Diseases; Feature extraction; Acute lymphoblastic leukaemias; Automated diagnostic systems; Automated feature extraction; Data augmentation; Early diagnosis; Learning approach; Segmentation techniques; White blood cells; acute lymphoblastic leukemia; Article; blast cell; cancer diagnosis; classification algorithm; computer assisted diagnosis; convolutional neural network; cross validation; deep learning; diagnostic accuracy; feature detection; feature extraction; image processing; priority journal; factual database; human; leukocyte; Convolutional neural networks","","","Springer Science and Business Media Deutschland GmbH","33159270"
"Butt F.S.; La Blunda L.; Wagner M.F.; Schäfer J.; Medina-Bulo I.; Gómez-Ullate D.","Butt, Fatima Sajid (57221947309); La Blunda, Luigi (57190877612); Wagner, Matthias F. (57210548333); Schäfer, Jörg (56028606000); Medina-Bulo, Inmaculada (22433447400); Gómez-Ullate, David (6602128849)","57221947309; 57190877612; 57210548333; 56028606000; 22433447400; 6602128849","Fall detection from electrocardiogram (ECG) signals and classification by deep transfer learning","2021","12","2","63","1","22","21","10.3390/info12020063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100789095&doi=10.3390%2finfo12020063&partnerID=40&md5=80698eaf51318a9d2d130147324999c5","Fall is a prominent issue due to its severe consequences both physically and mentally. Fall detection and prevention is a critical area of research because it can help elderly people to depend less on caregivers and allow them to live and move more independently. Using electrocardiograms (ECG) signals independently for fall detection and activity classification is a novel approach used in this paper. An algorithm has been proposed which uses pre-trained convolutional neural networks AlexNet and GoogLeNet as a classifier between the fall and no fall scenarios using electrocardiogram signals. The ECGs for both falling and no falling cases were obtained as part of the study using eight volunteers. The signals are pre-processed using an elliptical filter for signal noises such as baseline wander and power-line interface. As feature extractors, frequency-time representations (scalograms) were obtained by applying a continuous wavelet transform on the filtered ECG signals. These scalograms were used as inputs to the neural network and a significant validation accuracy of 98.08% was achieved in the first model. The trained model is able to distinguish ECGs with a fall activity from an ECG with a no fall activity with an accuracy of 98.02%. For the verification of the robustness of the proposed algorithm, our experimental dataset was augmented by adding two different publicly available datasets to it. The second model can classify fall, daily activities and no activities with an accuracy of 98.44%. These models were developed by transfer learning from the domain of real images to the medical images. In comparison to traditional deep learning approaches, the transfer learning not only avoids “reinventing the wheel,” but also presents a lightweight solution to otherwise computationally heavy problems. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Electrocardiogram (ECG); Human activity recognition; Neural network; Signal processing; Transfer learning; Wavelet transform","Accident prevention; Convolutional neural networks; Deep learning; Electrocardiography; Medical imaging; Transfer learning; Wavelet transforms; Activity classifications; Baseline wander; Continuous Wavelet Transform; Electrocardiogram signal; Fall detection; Feature extractor; Frequency time representation; Learning approach; Biomedical signal processing","Ministerio de Ciencia, Innovación y Universidades, MCIU, (RTI2018-093608-BC33); Ministerio de Ciencia, Innovación y Universidades, MCIU; European Commission, EC; Ministerio de Ciencia e Innovación, MICINN, (PGC2018-096504-B-C33, RTI2018-100754-B-I00); Ministerio de Ciencia e Innovación, MICINN; European Regional Development Fund, FEDER, (FEDER-UCA18-108393); European Regional Development Fund, FEDER; Frankfurt University of Applied Sciences","","MDPI AG",""
"Chauhan N.K.; Singh K.","Chauhan, Nitin Kumar (57208298625); Singh, Krishna (57225733979)","57208298625; 57225733979","Impact of Variation in Number of Channels in CNN Classification model for Cervical Cancer Detection","2021","","","","","","","10.1109/ICRITO51393.2021.9596366","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123376253&doi=10.1109%2fICRITO51393.2021.9596366&partnerID=40&md5=b503f53521b8457e9130115eb65c2cd3","Development in Computer vision applications, most prominently in Artificial Intelligence (AI) over the past decade, has encouraged researchers to use computational algorithms. Machine Learning (ML) and Deep Learning (DL) algorithms are getting attention in the biomedical area to early diagnosis and prognosis of lethiferous diseases with higher accuracy using statistical analysis. Cervical cancer is one of the predominant gynecological infectious forms of cancer in females ecumenically, generally transpiring in less-developed nations. DL algorithms are more optimized and convenient due to the automatic feature extraction in Cervical lesion detection at an early phase. Here we analyze the convolutional neural network (CNN) models' performance using variation in channels depth comprises in the convolution layers to classify multi-class liquid-based cytology (LBC) Whole slide images (WSI). We propose three CNN models having two convolution layers with the number of channels (4,8), (8,16), and (32,64) and two pooling layers. CNN model with the highest number of channels in the convolution layers gives the leading performance with an accuracy of 96.89%, precision of 93.38%, the sensitivity of 93.75%, and F-score of 94.15%. © 2021 IEEE.","Cervical cancer; Channels; Classification models; CNN; DL; ML; Testing","Bioinformatics; Convolution; Cytology; Deep learning; Diagnosis; Diseases; Feature extraction; Multilayer neural networks; Neural network models; Cancer detection; Cervical cancers; Channel; Classification models; Computer vision applications; Convolutional neural network; Deep learning; Machine-learning; Neural network classification; Neural network model; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Brunese L.; Mercaldo F.; Reginelli A.; Santone A.","Brunese, Luca (7003807892); Mercaldo, Francesco (55842609700); Reginelli, Alfonso (21741233000); Santone, Antonella (6603700255)","7003807892; 55842609700; 21741233000; 6603700255","Explainable Deep Learning for Pulmonary Disease and Coronavirus COVID-19 Detection from X-rays","2020","196","","105608","","","","10.1016/j.cmpb.2020.105608","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086819887&doi=10.1016%2fj.cmpb.2020.105608&partnerID=40&md5=24239343cee532cdf4ed72bf620e8db7","Background and Objective: Coronavirus disease (COVID-19) is an infectious disease caused by a new virus never identified before in humans. This virus causes respiratory disease (for instance, flu) with symptoms such as cough, fever and, in severe cases, pneumonia. The test to detect the presence of this virus in humans is performed on sputum or blood samples and the outcome is generally available within a few hours or, at most, days. Analysing biomedical imaging the patient shows signs of pneumonia. In this paper, with the aim of providing a fully automatic and faster diagnosis, we propose the adoption of deep learning for COVID-19 detection from X-rays. Method: In particular, we propose an approach composed by three phases: the first one to detect if in a chest X-ray there is the presence of a pneumonia. The second one to discern between COVID-19 and pneumonia. The last step is aimed to localise the areas in the X-ray symptomatic of the COVID-19 presence. Results and Conclusion: Experimental analysis on 6,523 chest X-rays belonging to different institutions demonstrated the effectiveness of the proposed approach, with an average time for COVID-19 detection of approximately 2.5 seconds and an average accuracy equal to 0.97. © 2020 Elsevier B.V.","Artificial intelligence; Chest; Coronavirus; COVID-19; Deep learning; Transfer learning","Algorithms; Betacoronavirus; Coronavirus Infections; Deep Learning; Humans; Image Processing, Computer-Assisted; Lung Diseases; Neural Networks, Computer; Pandemics; Pneumonia, Viral; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Reproducibility of Results; X-Rays; Diagnosis; Medical imaging; Pulmonary diseases; Viruses; X rays; Biomedical imaging; Blood samples; Chest x-rays; Coronaviruses; Experimental analysis; Infectious disease; Three phasis; Article; blood sampling; coronavirus disease 2019; deep learning; diagnostic accuracy; false negative result; human; lung disease; major clinical study; symptom; thorax radiography; virus pneumonia; algorithm; Betacoronavirus; computer assisted diagnosis; Coronavirus infection; diagnostic imaging; image processing; pandemic; procedures; reproducibility; thorax radiography; virus pneumonia; X ray; Deep learning","","","Elsevier Ireland Ltd","32599338"
"","","","12th National Conference on Recent Advancements in Biomedical Engineering, NCRABE 2021","2021","47","","","","","500","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135198855&partnerID=40&md5=f5642d7031805583c08a1b5c03ac5108","The proceedings contain 80 papers. The topics discussed include: applications of Internet of things for smart farming – a survey; speech and gesture recognition interactive robot; obstructive sleep apnea detection and alerting system using piezoelectric sensor array embedded quilt; energetic improvement of smart healthcare system using Internet of things; evolving insight of adverse drug reaction associated with breast cancer drugs; smart access development for classifying lung disease with chest x-ray images using deep learning; patient health care intensive care system using wearable band sensor network; economic authentic and anonymous data sharing with forward security; mathematical model automotive part shape optimization using metaheuristic method-review; and wind power forecasting based on time series model using deep machine learning algorithms.","","Internet of things; mHealth; Neural networks; Speech recognition; Wind power; Wireless sensor networks; Adverse drug reactions; Alerting systems; Breast Cancer; Detection system; Gestures recognition; Interactive robot; Obstructive sleep apnea; Piezoelectric sensor arrays; Sleep apnea detection; Smart healthcare systems; Learning algorithms","","Ramji K.; Sivaraman J.","Elsevier Ltd",""
"","","","7th International Conference on Life System Modeling and Simulation, LSMS 2021, and 7th International Conference on Intelligent Computing for Sustainable Energy and Environment, ICSEE 2021","2021","1468","","","","","1669","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118153946&partnerID=40&md5=a72a8077563fb3529e1263ffa24297e0","The proceedings contain 159 papers. The special focus in this conference is on Life System Modeling and Simulation. The topics include: Endoscopic Single Image Super-Resolution Based on Transformer and Convolutional Neural Network; investigation of Wear Amounts on Artificial Hip Joints with Different Femoral Head Diameter; Based on Advanced Connected Domain and Contour Filter for CASA; Classification of LFPs Signals in Autistic and Normal Mice Based on Convolutional Neural Network; human Grasping Force Prediction Based on Surface Electromyography Signals; simulation of Pedicle Screw Extraction Based on Galerkin Smooth Particle Meshless Method; improved One-Stage Algorithm with Attention Fusion for Human Sperm Detection Based on Deep Learning; inelastic Modelling of Bone Damage Under Compressive Loading; constrained Adversarial Attacks Against Image-Based Malware Classification System; Research on CT Image Grading of Superior Mesenteric Artery Based on AA Res-Unet; application of a New Attribute Reduction Algorithm in Intracranial Aneurysm Prediction; Classification of Coronary Artery Lesions Based on XGBoost; design of Mechanical Property Verification System for Drug Dissolution Meter Based on Non-contact Measurement; PF-OLSR Routing Algorithm for Self-organizing Networks of Pigeon Flocks; Image Enhancement and Corrosion Detection for UAV Visual Inspection of Pressure Vessels; a Study of Force Feedback Master-Slave Teleoperation System Based on Biological Tissue Interaction; Surface EMG Real-Time Chinese Language Recognition Using Artificial Neural Networks; support Vector Machine Classification Method Based on Convex Hull Clipping; Research on Reconstruction of CT Images Based on AA-R2Unet in Inferior Mesenteric Artery Classification; Pedestrian Detection Based on Improved YOLOv3 Algorithm; melanoma Classification Method Based on Ensemble Convolutional Neural Network.","","Bioinformatics; Biomechanics; Biomedical signal processing; Classification (of information); Computer aided diagnosis; Convolution; Damage detection; Data mining; Deep learning; Extraction; Feature extraction; Forecasting; Image classification; Image reconstruction; Learning algorithms; Neural networks; Reverse engineering; Robotics; Statistics; Classification methods; Convolutional neural network; CT Image; Energy and environment; Image super resolutions; Image-based; Single images; Sustainable energy; Sustainable environment; System modeling and simulation; Computerized tomography","","Li K.; Coombs T.; He J.; Tian Y.; Niu Q.; Yang Z.","Springer Science and Business Media Deutschland GmbH",""
"Liu J.; Zhang Z.; Zu L.; Wang H.; Zhong Y.","Liu, Jingxin (57210233605); Zhang, Zhong (57221604712); Zu, Lihui (57221605636); Wang, Hairihan (57221605981); Zhong, Yutong (57193742136)","57210233605; 57221604712; 57221605636; 57221605981; 57193742136","Intelligent Detection for CT Image of COVID-19 using Deep Learning","2020","","","9263690","76","81","5","10.1109/CISP-BMEI51763.2020.9263690","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099604635&doi=10.1109%2fCISP-BMEI51763.2020.9263690&partnerID=40&md5=2413e58ca652665635046f51ef7e4456","Purpose: Use artificial intelligence technology to identify the characteristics of covid-19 in CT images, quickly screen COVID-19 patients, achieve rapid diversion and treatment of suspected patients, reduce the risk of infection and control the spread of the disease.Materials and methods: This article combines deep learning target detection and image classification methods to study the CT images of COVID-19 patients. By extracting and analyzing the features of lesions in different periods, a new detection model of covid-19 based on time-spatial sequence convolution is obtained. The algorithm is based on a recurrent neural network structure and a 2D convolutional layer structure.Results: The spatiotemporal sequence convolution kernel based on time and space attributes can effectively extract the latent image semantic features of multiple image data of COVID-19 patients. By comparing with Faster RCNN, YOLO3 and SSD algorithm models, the detection method proposed in this paper can obtain more accurate comprehensive detection results.Conclusion: The time-spatial sequence convolution model can quickly complete the automatic detection of COVID-19 and improve the efficiency of preliminary diagnosis. By correlating images from different stages of the same patient, more accurate auxiliary preliminary screening results can be obtained. © 2020 IEEE.","component; convolution neural network; COVID-19; CT images; detection","Biomedical engineering; Convolution; Diagnosis; Multilayer neural networks; Patient treatment; Recurrent neural networks; Semantics; Artificial intelligence technologies; Automatic Detection; Classification methods; Convolution kernel; Convolution model; Detection methods; Intelligent detection; Spatial sequences; Computerized tomography","JLUSTIRT, (2017TD-27); Jilin Province Science and Technology Development Plan Project, (20200901017SF); Jilin Province Key R&D Plan Project, (2018YFC0116900, 2018YFC1315604); Program for Jilin University Science and Technology Innovative Research Team","Zheng Q.; Zheng X.; Zhao X.; Yan W.; Zhang N.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"Zhang J.; Wu C.; Ruan C.; Zhang R.; Zhao Z.; Cheng X.","Zhang, Jixiang (57833909600); Wu, Chengqin (57221327608); Ruan, Chenzhao (57272586800); Zhang, Rongxia (57273319400); Zhao, Zengshun (55667575500); Cheng, Xiangqian (57274055300)","57833909600; 57221327608; 57272586800; 57273319400; 55667575500; 57274055300","ECG Signal Classification Based on Fusion of Hybrid CNN and Wavelet Features by D-S Evidence Theory","2021","2021","","4222881","","","","10.1155/2021/4222881","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115793812&doi=10.1155%2f2021%2f4222881&partnerID=40&md5=ed2ec37f51d0411fe78adb086e04fe88","At present, cardiovascular disease is regarded as one of the dangerous diseases that threaten human life. The morbidity and lethality caused by cardiovascular disease are constantly increasing every year. In this paper, we propose a two-stream style operation to handle the electrocardiogram (ECG) classification: one for time-domain features and another for frequency-domain features. For the time-domain features, convolutional neural networks (CNN) are constructed for feature learning and classification of ECG signals. For the frequency-domain features, support vector regression (SVR) machines are designed to perform the regression prediction on each signal. Finally, the D-S evidence theory is adopted to perform the decision fusion strategy on the time-domain and frequency-domain classification results. We confirm a recognition performance of 99.64% from the experiment result for the D-S evidence theory recognition system upon the MIT-BIH arrhythmia database. The analysis of various methods of ECG classification shows that the model delivers superior performance promotion across all these scenarios. © 2021 Jixiang Zhang et al.","","Algorithms; Arrhythmias, Cardiac; Electrocardiography; Humans; Neural Networks, Computer; Signal Processing, Computer-Assisted; Support Vector Machine; Biomedical signal processing; Cardiology; Classification (of information); Convolutional neural networks; Decision theory; Electrocardiography; Frequency domain analysis; Time domain analysis; Cardiovascular disease; Convolutional neural network; D S evidence theory; Domain feature; Electrocardiogram signal classifications; Frequency domains; Neural network features; Performance; Time domain features; Wavelet features; Article; artificial neural network; atrial fibrillation; cardiologist; complete heart block; controlled study; convolutional neural network; cross validation; decision making; deep belief network; ectopic atrial tachycardia; electrocardiogram; feature extraction; heart arrhythmia; heart atrium flutter; heart left bundle branch block; heart right bundle branch block; heart ventricle extrasystole; heart ventricle fibrillation; heart ventricle tachycardia; human; image segmentation; low frequency noise; major clinical study; multilayer perceptron; prediction; QRS complex; R wave; radial basis function; restricted Boltzmann machine; signal processing; support vector machine; supraventricular premature beat; wavelet analysis; wavelet transform; algorithm; electrocardiography; heart arrhythmia; signal processing; Diseases","","","Hindawi Limited","34531965"
"Wang Z.; Zhu Y.; Shi H.; Zhang Y.; Yan C.","Wang, Zijian (56074709600); Zhu, Yaqin (57210588489); Shi, Haibo (57200672711); Zhang, Yanting (57224990353); Yan, Cairong (37018977900)","56074709600; 57210588489; 57200672711; 57224990353; 37018977900","A 3D multiscale view convolutional neural network with attention for mental disease diagnosis on MRI images","2021","18","5","","6978","6994","16","10.3934/MBE.2021347","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114444015&doi=10.3934%2fMBE.2021347&partnerID=40&md5=14ab529e55138b8879503695a7fdf67d","Computer Assisted Diagnosis (CAD) based on brain Magnetic Resonance Imaging (MRI) is a popular research field for the computer science and medical engineering. Traditional machine learning and deep learning methods were employed in the classification of brain MRI images in the previous studies. However, the current algorithms rarely take into consideration the influence of multi-scale brain connectivity disorders on some mental diseases. To improve this defect, a deep learning structure was proposed based on MRI images, which was designed to consider the brain’s connections at different sizes and the attention of connections. In this work, a Multiscale View (MV) module was proposed, which was designed to detect multi-scale brain network disorders. On the basis of the MV module, the path attention module was also proposed to simulate the attention selection of the parallel paths in the MV module. Based on the two modules, we proposed a 3D Multiscale View Convolutional Neural Network with Attention (3D MVA-CNN) for classification of MRI images for mental disease. The proposed method outperformed the previous 3D CNN structures in the structural MRI data of ADHD-200 and the functional MRI data of schizophrenia. Finally, we also proposed a preliminary framework for clinical application using 3D CNN, and discussed its limitations on data accessing and reliability. This work promoted the assisted diagnosis of mental diseases based on deep learning and provided a novel 3D CNN method based on MRI data. © 2021 the Author(s), licensee AIMS Press.","ADHD; Attention; Convolutional neural netwoks; Deep learning; MRI; Schizophrenia","Attention; Brain; Magnetic Resonance Imaging; Neural Networks, Computer; Reproducibility of Results; Biomedical engineering; Computer aided diagnosis; Convolution; Convolutional neural networks; Deep learning; Image classification; Image enhancement; Learning systems; Medical computing; Medical imaging; Attention selection; Brain connectivity; Brain mri images; Clinical application; Computer assisted diagnosis; Learning methods; Learning structure; Medical engineering; attention; brain; diagnostic imaging; nuclear magnetic resonance imaging; reproducibility; Magnetic resonance imaging","Fundamental Research Funds for the Central Universities, (2232021D-26)","","American Institute of Mathematical Sciences","34517567"
"Mou L.; Zhao Y.; Fu H.; Liu Y.; Cheng J.; Zheng Y.; Su P.; Yang J.; Chen L.; Frangi A.F.; Akiba M.; Liu J.","Mou, Lei (57211999350); Zhao, Yitian (56583188900); Fu, Huazhu (35317209500); Liu, Yonghuai (7410228990); Cheng, Jun (57535555300); Zheng, Yalin (55948134900); Su, Pan (55507687000); Yang, Jianlong (57212326066); Chen, Li (57192579689); Frangi, Alejandro F. (7005249248); Akiba, Masahiro (35868367900); Liu, Jiang (23389932700)","57211999350; 56583188900; 35317209500; 7410228990; 57535555300; 55948134900; 55507687000; 57212326066; 57192579689; 7005249248; 35868367900; 23389932700","CS2-Net: Deep learning segmentation of curvilinear structures in medical imaging","2021","67","","101874","","","","10.1016/j.media.2020.101874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095451000&doi=10.1016%2fj.media.2020.101874&partnerID=40&md5=b009f6bc25ab7c596e88855ddb43479e","Automated detection of curvilinear structures, e.g., blood vessels or nerve fibres, from medical and biomedical images is a crucial early step in automatic image interpretation associated to the management of many diseases. Precise measurement of the morphological changes of these curvilinear organ structures informs clinicians for understanding the mechanism, diagnosis, and treatment of e.g. cardiovascular, kidney, eye, lung, and neurological conditions. In this work, we propose a generic and unified convolution neural network for the segmentation of curvilinear structures and illustrate in several 2D/3D medical imaging modalities. We introduce a new curvilinear structure segmentation network (CS2-Net), which includes a self-attention mechanism in the encoder and decoder to learn rich hierarchical representations of curvilinear structures. Two types of attention modules - spatial attention and channel attention - are utilized to enhance the inter-class discrimination and intra-class responsiveness, to further integrate local features with their global dependencies and normalization, adaptively. Furthermore, to facilitate the segmentation of curvilinear structures in medical images, we employ a 1×3 and a 3×1 convolutional kernel to capture boundary features. Besides, we extend the 2D attention mechanism to 3D to enhance the network's ability to aggregate depth information across different layers/slices. The proposed curvilinear structure segmentation network is thoroughly validated using both 2D and 3D images across six different imaging modalities. Experimental results across nine datasets show the proposed method generally outperforms other state-of-the-art algorithms in various metrics. © 2020","Attention mechanism; Blood vessel; Curvilinear structure; Deep neural network; Nerve fiber; Segmentation","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Neural Networks, Computer; Blood vessels; Convolution; Deep learning; Diagnosis; Image segmentation; Attention mechanisms; Convolution neural network; Curvilinear structures; Hierarchical representation; Image interpretation; Morphological changes; Precise measurements; State-of-the-art algorithms; Article; convolutional neural network; deep learning; diagnostic accuracy; diagnostic imaging; human; image analysis; image segmentation; priority journal; systematic review; three-dimensional imaging; two-dimensional imaging; algorithm; image processing; Medical imaging","Leeds Radiotherapy Research Centre of Excellence, (CRUK RadNetC19942/A28832); Ningbo “2025 S&T Megaprojects, (2019B10033, 2019B10061); Shenzhen Ministry of Education; Horizon 2020 Framework Programme, H2020, (777119); Key Technology Research and Development Program of Shandong, (2020C03036); Cancer Research UK, CRUK, (C19942/A28832); National Natural Science Foundation of China, NSFC, (61906181); Natural Science Foundation of Zhejiang Province, ZJNSF, (LQ20F030002, LZ19F010001); Horizon 2020, (SC1-PM-16-2017-777119); Shenzhen University, SZU","","Elsevier B.V.","33166771"
"Mahmood H.; Iqbal A.; Islam S.M.S.","Mahmood, Hassan (57212544403); Iqbal, Asim (57211112931); Islam, Syed Mohammed Shamsul (56574462700)","57212544403; 57211112931; 56574462700","Exploring Intensity Invariance in Deep Neural Networks for Brain Image Registration","2020","","","9363409","","","","10.1109/DICTA51227.2020.9363409","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102648969&doi=10.1109%2fDICTA51227.2020.9363409&partnerID=40&md5=b65e0203c7ed83f59e8e845d3b66da71","Image registration is a widely-used technique in analysing large scale datasets that are captured through various imaging modalities and techniques in biomedical imaging such as MRI, X-Rays, etc. These datasets are typically collected from various sites and under different imaging protocols using a variety of scanners. Such heterogeneity in the data collection process causes inhomogeneity or variation in intensity (brightness) and noise distribution. These variations play a detrimental role in the performance of image registration, segmentation and detection algorithms. Classical image registration methods are computationally expensive but are able to handle these artifacts relatively better. However, deep learning-based techniques are shown to be computationally efficient for automated brain registration but are sensitive to the intensity variations. In this study, we investigate the effect of variation in intensity distribution among input image pairs for deep learning-based image registration methods. We find a performance degradation of these models when brain image pairs with different intensity distribution are presented even with similar structures. To overcome this limitation, we incorporate a structural similarity-based loss function in a deep neural network and test its performance on the validation split separated before training as well as on a completely unseen new dataset. We report that the deep learning models trained with structure similarity-based loss seems to perform better for both datasets. This investigation highlights a possible performance limiting factor in deep learning-based registration models and suggests a potential solution to incorporate the intensity distribution variation in the input image pairs. Our code and models are available at https://github.com/hassaanmahmood/DeepIntense. © 2020 IEEE.","brain image registration; deep learning; intensity invariance; structural similarity","Brain mapping; Deep neural networks; Image registration; Image segmentation; Large dataset; Learning systems; Magnetic resonance imaging; Neural networks; Statistical tests; Computationally efficient; Data collection process; Intensity distribution; Performance degradation; Performance limiting factor; Registration methods; Structural similarity; Structure similarity; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Mengoudi K.; Ravi D.; Yong K.X.X.; Primativo S.; Pavisic I.M.; Brotherhood E.; Lu K.; Schott J.M.; Crutch S.J.; Alexander D.C.","Mengoudi, Kyriaki (57210202731); Ravi, Daniele (57201696886); Yong, Keir X. X. (57204880602); Primativo, Silvia (55831755300); Pavisic, Ivanna M. (57195351982); Brotherhood, Emilie (56079056500); Lu, Kirsty (57205113051); Schott, Jonathan M. (7103177641); Crutch, Sebastian J. (6602191607); Alexander, Daniel C. (7402830766)","57210202731; 57201696886; 57204880602; 55831755300; 57195351982; 56079056500; 57205113051; 7103177641; 6602191607; 7402830766","Augmenting dementia cognitive assessment with instruction-less eye-tracking tests","2020","24","11","9124654","3066","3075","9","10.1109/JBHI.2020.3004686","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095799060&doi=10.1109%2fJBHI.2020.3004686&partnerID=40&md5=ff169d1227903ea0592bdbe2a2893704","Eye-tracking technology is an innovative tool that holds promise for enhancing dementia screening. In this work, we introduce a novel way of extracting salient features directly from the raw eye-tracking data of a mixed sample of dementia patients during a novel instruction-less cognitive test. Our approach is based on self-supervised representation learning where, by training initially a deep neural network to solve a pretext task using well-defined available labels (e.g. recognising distinct cognitive activities in healthy individuals), the network encodes high-level semantic information which is useful for solving other problems of interest (e.g. dementia classification). Inspired by previous work in explainable AI, we use the Layer-wise Relevance Propagation (LRP) technique to describe our network's decisions in differentiating between the distinct cognitive activities. The extent to which eye-tracking features of dementia patients deviate from healthy behaviour is then explored, followed by a comparison between self-supervised and handcrafted representations on discriminating between participants with and without dementia. Our findings not only reveal novel self-supervised learning features that are more sensitive than handcrafted features in detecting performance differences between participants with and without dementia across a variety of tasks, but also validate that instruction-less eye-tracking tests can detect oculomotor biomarkers of dementia-related cognitive dysfunction. This work highlights the contribution of self-supervised representation learning techniques in biomedical applications where the small number of patients, the non-homogenous presentations of the disease and the complexity of the setting can be a challenge using state-of-the-art feature extraction methods. © 2013 IEEE.","cognition; deep-learning; dementia; Eye-tracking; representation learning","Cognition; Cognitive Dysfunction; Dementia; Eye-Tracking Technology; Humans; Neuropsychological Tests; Backpropagation; Classification (of information); Deep learning; Deep neural networks; Diagnosis; Feature extraction; Learning systems; Medical applications; Network coding; Neurodegenerative diseases; Semantics; biological marker; Biomedical applications; Cognitive activities; Cognitive assessments; Dementia screenings; Eye tracking technologies; Feature extraction methods; High level semantics; Learning techniques; adult; aged; Article; behavior change; body weight loss; classification algorithm; clinical article; cognitive defect; computer assisted tomography; controlled study; deep learning; deep neural network; dementia; dementia assessment; electroencephalography; emotionality; episodic memory; eye tracking; feature extraction; female; frontal variant frontotemporal dementia; functional magnetic resonance imaging; human; human experiment; human tissue; image quality; learning algorithm; machine learning; male; memory disorder; middle aged; mild cognitive impairment; Mini Mental State Examination; social cognition; social interaction test; stimulus; support vector machine; task performance; very elderly; visual field; visual stimulation; cognition; cognitive defect; dementia; neuropsychological test; Eye tracking","Alzheimer’s Research U.K., (ARUK-PG2014–1946, ARUK-PG2017–1946); Dementias Platform UK; Horizon 2020 Framework Programme, H2020, (666992); Medical Research Council, MRC; Engineering and Physical Sciences Research Council, EPSRC, (EP/M006093/1, EP/M020533/1); Wolfson Foundation; UCLH Biomedical Research Centre, NIHR BRC; Alzheimer’s Society, (453, AS-JF-18-003)","","Institute of Electrical and Electronics Engineers Inc.","32749977"
"Ayodele K.P.; Ogunlade O.; Olugbon O.J.; Akinwale O.B.; Kehinde L.O.","Ayodele, K.P. (25654510000); Ogunlade, O. (55322751900); Olugbon, O.J. (57219936719); Akinwale, O.B. (15727223500); Kehinde, L.O. (6602425609)","25654510000; 55322751900; 57219936719; 15727223500; 6602425609","A medical percussion instrument using a wavelet-based method for archivable output and automatic classification","2020","127","","104100","","","","10.1016/j.compbiomed.2020.104100","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096175005&doi=10.1016%2fj.compbiomed.2020.104100&partnerID=40&md5=16d6d6dab0722126d5657c3375624970","There is no standard instrument for carrying out medical percussion even though the procedure has been in continuous use since 1761. This study developed one such instrument. It generates medical percussion sounds in a reproducible manner and accurately classifies them into one of three classes. Percussion signals were generated using a push-pull solenoid plessor applying mechanical impulses through a polyvinyl chloride plessimeter. Signals were acquired using a National Instruments USB 6251 data acquisition card at a rate of 8.192 kHz through an air-coupled omnidirectional electret microphone located 60 mm from the impact site. Signal acquisition, processing, and classification were controlled by an NVIDIA Jetson TX2 computational device. A complex Morlet wavelet was selected as the base wavelet for the wavelet decomposition using the maximum wavelet energy method. It was also used to generate a scalogram suitable for manual or automatic classification. Automatic classification was achieved using a MobileNetv2 convolutional neural network with 17 inverted residual layers on the basis of 224 × 224 x 1 images generated by downsampling each scalogram. Testing was carried out using five human subjects with impulses applied at three thoracic sites each to elicit dull, resonant, and tympanic signals respectively. Classifier training utilized the Adam algorithm with a learning rate of 0.001, and first and second moments of 0.9 and 0.999 respectively for 100 epochs, with early stopping. Mean subject-specific validation and test accuracies of 95.9±1.6% and 93.8±2.3% respectively were obtained, along with cross-subject validation and test accuracies of 94.9% and 94.0% respectively. These results compare very favorably with previously-reported systems for automatic generation and classification of percussion sounds. © 2020","Convolutional neural network; Medical percussion; MobileNetV2; Percussograph; Scalogram","Chlorine compounds; Convolutional neural networks; Data acquisition; Multilayer neural networks; Musical instruments; Polyvinyl chlorides; Wavelet decomposition; Automatic classification; Automatic Generation; Complex Morlet Wavelet; Computational devices; Data acquisition cards; National Instruments; Percussion instruments; Wavelet-based methods; accuracy; adult; algorithm; Article; automation; classifier; construct validity; convolutional neural network; criterion related validity; deep learning; dimensionality reduction; feature extraction; female; human; human experiment; male; muscle contraction; percussion; percussion instrument; priority journal; sensitivity and specificity; signal detection; signal noise ratio; signal processing; sound; wavelet transform; Biomedical signal processing","","","Elsevier Ltd","33171290"
"Çınar A.; Tuncer S.A.","Çınar, Ahmet (7006387288); Tuncer, Seda Arslan (55903601800)","7006387288; 55903601800","Classification of normal sinus rhythm, abnormal arrhythmia and congestive heart failure ECG signals using LSTM and hybrid CNN-SVM deep neural networks","2021","24","2","","203","214","11","10.1080/10255842.2020.1821192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091319499&doi=10.1080%2f10255842.2020.1821192&partnerID=40&md5=a1795589b9ae5c0195239ea64aabf21d","Effective monitoring of heart patients according to heart signals can save a huge amount of life. In the last decade, the classification and prediction of heart diseases according to ECG signals has gained great importance for patients and doctors. In this paper, the deep learning architecture with high accuracy and popularity has been proposed in recent years for the classification of Normal Sinus Rhythm, (NSR) Abnormal Arrhythmia (ARR) and Congestive Heart Failure (CHF) ECG signals. The proposed architecture is based on Hybrid Alexnet-SVM (Support Vector Machine). 96 Arrhythmia, 30 CHF, 36 NSR signals are available in a total of 192 ECG signals. In order to demonstrate the classification performance of deep learning architectures, ARR, CHR and NSR signals are firstly classified by SVM, KNN algorithm, achieving 68.75% and 65.63% accuracy. The signals are then classified in their raw form with LSTM (Long Short Time Memory) with 90.67% accuracy. By obtaining the spectrograms of the signals, Hybrid Alexnet-SVM algorithm is applied to the images and 96.77% accuracy is obtained. The results show that with the proposed deep learning architecture, it classifies ECG signals with higher accuracy than conventional machine learning classifiers. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","arrhythmia; CNN; congestive heart failure; Electrocardiography; LSTM; normal sinus rhythm","Adult; Algorithms; Arrhythmias, Cardiac; Electrocardiography; Female; Heart Failure; Humans; Male; Middle Aged; Neural Networks, Computer; Signal Processing, Computer-Assisted; Support Vector Machine; Young Adult; Cardiology; Deep learning; Deep neural networks; Diseases; Electrocardiography; Heart; Learning systems; Long short-term memory; Network architecture; Support vector machines; Classification performance; Congestive heart failures; Conventional machines; Learning architectures; Normal sinus rhythm; Prediction of heart disease; Proposed architectures; SVM(support vector machine); accuracy; Article; atrial fibrillation; congestive heart failure; convolutional neural network; deep learning; deep neural network; electrocardiogram; electrocardiography; heart arrhythmia; heart failure; heart palpitation; human; k nearest neighbor; long short term memory network; machine learning; memory; nerve cell network; P wave; polysomnography; PQ interval; PR interval; pulse rate; Q wave; QRS complex; QT dispersion; QT interval; R wave; S wave amplitude; sensitivity and specificity; sinus rhythm; support vector machine; T wave; three-dimensional imaging; adult; algorithm; diagnostic imaging; female; heart arrhythmia; male; middle aged; signal processing; support vector machine; young adult; Biomedical signal processing","","","Taylor and Francis Ltd.","32955928"
"Albahli S.; Hassan Yar G.N.A.","Albahli, Saleh (56548902300); Hassan Yar, Ghulam Nabi Ahmad (57221982320)","56548902300; 57221982320","Fast and accurate detection of COVID-19 along with 14 other chest pathologies using a multi-level classification: Algorithm development and validation study","2021","23","2","e23693","","","","10.2196/23693","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100839961&doi=10.2196%2f23693&partnerID=40&md5=e8c93fc69d7ce4930886ae539b7cd637","Background: COVID-19 has spread very rapidly, and it is important to build a system that can detect it in order to help an overwhelmed health care system. Many research studies on chest diseases rely on the strengths of deep learning techniques. Although some of these studies used state-of-the-art techniques and were able to deliver promising results, these techniques are not very useful if they can detect only one type of disease without detecting the others. Objective: The main objective of this study was to achieve a fast and more accurate diagnosis of COVID-19. This study proposes a diagnostic technique that classifies COVID-19 x-ray images from normal x-ray images and those specific to 14 other chest diseases. Methods: In this paper, we propose a novel, multilevel pipeline, based on deep learning models, to detect COVID-19 along with other chest diseases based on x-ray images. This pipeline reduces the burden of a single network to classify a large number of classes. The deep learning models used in this study were pretrained on the ImageNet dataset, and transfer learning was used for fast training. The lungs and heart were segmented from the whole x-ray images and passed onto the first classifier that checks whether the x-ray is normal, COVID-19 affected, or characteristic of another chest disease. If it is neither a COVID-19 x-ray image nor a normal one, then the second classifier comes into action and classifies the image as one of the other 14 diseases. Results: We show how our model uses state-of-the-art deep neural networks to achieve classification accuracy for COVID-19 along with 14 other chest diseases and normal cases based on x-ray images, which is competitive with currently used state-of-the-art models. Due to the lack of data in some classes such as COVID-19, we applied 10-fold cross-validation through the ResNet50 model. Our classification technique thus achieved an average training accuracy of 96.04% and test accuracy of 92.52% for the first level of classification (ie, 3 classes). For the second level of classification (ie, 14 classes), our technique achieved a maximum training accuracy of 88.52% and test accuracy of 66.634% by using ResNet50. We also found that when all the 16 classes were classified at once, the overall accuracy for COVID-19 detection decreased, which in the case of ResNet50 was 88.92% for training data and 71.905% for test data. Conclusions: Our proposed pipeline can detect COVID-19 with a higher accuracy along with detecting 14 other chest diseases based on x-ray images. This is achieved by dividing the classification task into multiple steps rather than classifying them collectively. © Saleh Albahli, Ghulam Nabi Ahmad Hassan Yar.","Automatic detection; Biomedical imaging; Chest x-ray; Convolutional neural network; COVID-19; Data augmentation","Algorithms; COVID-19; Deep Learning; Humans; Neural Networks, Computer; Radiography, Thoracic; SARS-CoV-2; Thoracic Diseases; Thorax; accuracy; area under the curve; Article; artificial intelligence; atelectasis; cardiomegaly; classification algorithm; classifier; convolutional neural network; coronavirus disease 2019; data processing; deep learning; deep neural network; diagnostic test accuracy study; disease classification; emphysema; female; hernia; human; image analysis; image segmentation; lung consolidation; lung edema; lung fibrosis; lung infiltrate; major clinical study; male; pleura thickening; pneumonia; pneumothorax; sensitivity and specificity; thorax disease; transfer of learning; validation study; algorithm; diagnostic imaging; thorax; thorax disease; thorax radiography","Deanship of Scientific Research, King Saud University; Qassim University, QU","","JMIR Publications Inc.","33529154"
"Alhudhaif A.; Cömert Z.; Polat K.","Alhudhaif, Adi (56404673400); Cömert, Zafer (36543652400); Polat, Kemal (8945093900)","56404673400; 36543652400; 8945093900","Otitis media detection using tympanic membrane images with a novel multi-class machine learning algorithm","2021","7","","","1","22","21","10.7717/PEERJ-CS.405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102847468&doi=10.7717%2fPEERJ-CS.405&partnerID=40&md5=d579a118956eff6bd2f0fd6cb9d67610","Background: Otitis media (OM) is the infection and inflammation of the mucous membrane covering the Eustachian with the airy cavities of the middle ear and temporal bone. OM is also one of the most common ailments. In clinical practice, the diagnosis of OM is carried out by visual inspection of otoscope images. This vulnerable process is subjective and error-prone. Methods: In this study, a novel computer-aided decision support model based on the convolutional neural network (CNN) has been developed. To improve the generalized ability of the proposed model, a combination of the channel and spatial model (CBAM), residual blocks, and hypercolumn technique is embedded into the proposed model. All experiments were performed on an open-access tympanic membrane dataset that consists of 956 otoscopes images collected into five classes. Results: The proposed model yielded satisfactory classification achievement. The model ensured an overall accuracy of 98.26%, sensitivity of 97.68%, and specificity of 99.30%. The proposed model produced rather superior results compared to the pre-trained CNNs such as AlexNet, VGG-Nets, GoogLeNet, and ResNets. Consequently, this study points out that the CNN model equipped with the advanced image processing techniques is useful for OM diagnosis. The proposed model may help to field specialists in achieving objective and repeatable results, decreasing misdiagnosis rate, and supporting the decision-making processes. © 2021. Alhudhaif et al.","Biomedical image processing; Convolutional neural networks; Decision support system; Deep learning; Otitis media","Convolutional neural networks; Decision making; Decision support systems; Image processing; Learning algorithms; Clinical practices; Computer-aided decision supports; Decision making process; Image processing technique; Misdiagnosis rate; Overall accuracies; Repeatable results; Tympanic membranes; Machine learning","Prince Sattam bin Abdulaziz University, Alkharj, Saudi Arabia; Deanship of Scientific Research, King Saud University","","PeerJ Inc.",""
"Hauptmann A.; Cox B.","Hauptmann, Andreas (56180904900); Cox, Ben (7403198742)","56180904900; 7403198742","Deep learning in photoacoustic tomography: Current approaches and future directions","2020","25","11","112903","","","","10.1117/1.JBO.25.11.112903","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096056066&doi=10.1117%2f1.JBO.25.11.112903&partnerID=40&md5=de5b10460f66c8e3e257aff61316caf3","Biomedical photoacoustic tomography, which can provide high-resolution 3D soft tissue images based on optical absorption, has advanced to the stage at which translation from the laboratory to clinical settings is becoming possible. The need for rapid image formation and the practical restrictions on data acquisition that arise from the constraints of a clinical workflow are presenting new image reconstruction challenges. There are many classical approaches to image reconstruction, but ameliorating the effects of incomplete or imperfect data through the incorporation of accurate priors is challenging and leads to slow algorithms. Recently, the application of deep learning (DL), or deep neural networks, to this problem has received a great deal of attention. We review the literature on learned image reconstruction, summarizing the current trends and explain how these approaches fit within, and to some extent have arisen from, a framework that encompasses classical reconstruction methods. In particular, it shows how these techniques can be understood from a Bayesian perspective, providing useful insights. We also provide a concise tutorial demonstration of three prototypical approaches to learned image reconstruction. The code and data sets for these demonstrations are available to researchers. It is anticipated that it is in in vivo applications - where data may be sparse, fast imaging critical, and priors difficult to construct by hand - that DL will have the most impact. With this in mind, we conclude with some indications of possible future research directions.  © The Authors(s) 2020.","data-driven methods; deep learning; in vivo imaging; learned image reconstruction; neural networks; photoacoustic tomography","Data acquisition; Deep neural networks; Image reconstruction; Light absorption; Photoacoustic effect; Tomography; Bayesian perspective; Classical approach; Clinical settings; Clinical workflow; High resolution; Photoacoustic tomography; Possible futures; Reconstruction method; attention; deep learning; deep neural network; human; image display; image reconstruction; in vivo study; photoacoustic tomography; review; soft tissue; systematic review; workflow; Deep learning","CMIC-EPSRC, (EP/M020533/1); European Union’s Horizon 2020 Research and Innovation Program H2020 ICT; Horizon 2020 Framework Programme, H2020, (732411); Academy of Finland","","SPIE",""
"Yu X.; Fan Z.; Jamil M.; Aziz M.Z.; Hou Y.; Li H.; Lv J.","Yu, Xiaojun (55230983300); Fan, Zeming (7402099781); Jamil, Mudasir (57220769879); Aziz, Muhammad Zulkifal (57218953782); Hou, Yiyan (57465526100); Li, Haopeng (58433522800); Lv, Jialin (57465970300)","55230983300; 7402099781; 57220769879; 57218953782; 57465526100; 58433522800; 57465970300","Transacting Multiple Mother Wavelets in Continuous Wavelet Transform for Epilepsy EEG Classification via CNN","2021","","","","76","80","4","10.1109/ICICN52636.2021.9673990","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125207376&doi=10.1109%2fICICN52636.2021.9673990&partnerID=40&md5=f9496dc2da8778fa18ec13b45794022e","Epileptic electroencephalogram (EEG) is one of the most adopted schemes to localize epileptiform discharge via brain signal recordings during seizure, and neurologists typically derive conjectures via ocular assessment. However, such a scheme is time-consuming with immense dependency on scrutinizer's expertise, and thus, automated models are deemed to be the most feasible solutions to this predicament. This paper studies, for the first time, on the impact of transacting multiple mother wavelets (TMMW) on a benchmark signal decomposition algorithm known as Continuous Wavelet Transform (CWT). 1D signals are transformed into 2D scalograms discretely for three mother wavelets, namely 'amor', 'bump', and 'mores' first, and then, the such images are categorized with a pre-trained alexnet for classifications. The configured approach finally capitalizes on the repercussions of directing variables, which are adam, rmsprop, sgdm, and four learning rates, i.e., 10{-3}, 10{-4}, 10{-5}, and 10{-6}. Simulations are trialed on the renowned Bern-Barcelona dataset for verification. Results imply that deep learning classifier yields better results on morse based images, while the highest segregation is achieved when alexnet is operated on adam at 10{-5}, where classification mark up secures 90.4% with parametric values of 87.6%, 84.3%, and 85.5% for sensitivity, specificity, and specificity f1-score, respectively. This study offers an expanded understanding of the feasibility of mother wavelets on the skeleton of CWT for the classification of epileptic seizures via Convolutional Neural Network (CNN) classifier.  © 2021 IEEE.","alexnet; continuous wavelet transform; convolutional neural network; Electroencephalogram; mother wavelets","Biomedical signal processing; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Wavelet decomposition; Alexnet; Automated modelling; Brain signals; Continuous Wavelet Transform; Convolutional neural network; Epileptiform discharges; Feasible solution; Mother wavelets; Signal decomposition; Signal recording; Electroencephalography","National Natural Science Foundation of China, NSFC, (61705184); China Postdoctoral Science Foundation, (2018M641013); Shaanxi Province Postdoctoral Science Foundation, (2018BSHY-DZZ05); Shanxi Provincial Key Research and Development Project, (2021SF-342)","","Institute of Electrical and Electronics Engineers Inc.",""
"Memon M.H.; Golilarz N.A.; Li J.; Yazdi M.; Addeh A.","Memon, Muhammad Hammad (56221902500); Golilarz, Noorbakhsh Amiri (57220182067); Li, Jianping (56003087700); Yazdi, Mohammad (57204366396); Addeh, Abdoljalil (57212685214)","56221902500; 57220182067; 56003087700; 57204366396; 57212685214","Early Detection of Covid-19 Disease using Computed Tomography Images and Optimized CNN-LSTM","2020","","","9317334","161","165","4","10.1109/ICCWAMTIP51612.2020.9317334","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100001467&doi=10.1109%2fICCWAMTIP51612.2020.9317334&partnerID=40&md5=b05b3e59e78b17a9c4f7fb35be9a714d","Since the novel Coronavirus (COVID-19) pandemic showed up in China, it became a big problem for health authorities to counter this life-threatening disease. Early light signs such as fever and nonproductive cough give a chance for early detection of disease and appropriate treatment. Imaging features that can be obtained using computed tomography (CT) images are of the most significant aspects of COVID-19 for screening, examination, therapy evaluation, and follow-up. This paper proposes an intelligent method for early detection of COVID-19 based on CT images and deep neural networks. In the developed method, the convolutional neural network (CNN) is used for automatic feature extraction from CT images and long-short term memory (LSTM) is used for final classification. Moreover, the Harris hawk optimization (HHO) algorithm is implemented for finding the best possible value of internal parameters of CNN and LSTM, such as the number of convolution/pooling layers, size, and the number of convolution kernels with the aim of increasing the classification accuracy. The developed method tested on data collected in Mashi Daneshvari Hospital in Iran. The obtained results showed that the developed method could detect the COVID-19 with high accuracy without needing radiologist experts.  © 2020 IEEE.","Biomedical image processing; CNN; LSTM; Machine-learning algorithms; Optimization","Computerized tomography; Convolution; Convolutional neural networks; Deep neural networks; Diagnosis; Automatic feature extraction; Classification accuracy; Computed tomography images; Convolution kernel; Coronaviruses; Imaging features; Intelligent method; Internal parameters; Long short-term memory","Science and Technology Department of Chongqing Municipality, Chengdu Chengdian Network Technology Co., Ltd., Chengdu Civil-military Integration Project Management Co., Ltd.; Sichuan Yin Ten Gu Technology Co., Ltd.; National Natural Science Foundation of China, NSFC, (61370073); National Natural Science Foundation of China, NSFC; Department of Science and Technology of Sichuan Province, SPDST; National High-tech Research and Development Program, (2007AA01Z423); National High-tech Research and Development Program","","Institute of Electrical and Electronics Engineers Inc.",""
"Tao Y.; Sun T.; Muhamed A.; Genc S.; Jackson D.; Arsanjani A.; Yaddanapudi S.; Li L.; Kumar P.","Tao, Yunzhe (59273912600); Sun, Tao (56097319000); Muhamed, Aashiq (57405366100); Genc, Sahika (57216547921); Jackson, Dylan (57405198800); Arsanjani, Ali (57405037700); Yaddanapudi, Suri (57404715600); Li, Liang (57405366200); Kumar, Prachi (57405037800)","59273912600; 56097319000; 57405366100; 57216547921; 57405198800; 57405037700; 57404715600; 57405366200; 57405037800","Gated Transformer for Decoding Human Brain EEG Signals","2021","","","","125","130","5","10.1109/EMBC46164.2021.9630210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122533274&doi=10.1109%2fEMBC46164.2021.9630210&partnerID=40&md5=09881c8b5dc68b698543c39e300fe37a","In this work, we propose to use a deep learning framework for decoding the electroencephalogram (EEG) signals of human brain activities. More specifically, we learn an end-to-end model that recognizes natural images or motor imagery by the EEG data that is collected from the corresponding human neural activities. In order to capture the temporal information encoded in the long EEG sequences, we first employ an enhanced version of Transformer, i.e., gated Transformer, on EEG signals to learn the feature representation along a sequence of embeddings. Then a fully-connected Softmax layer is used to predict the classification results of the decoded representations. To demonstrate the effectiveness of the gated Transformer approach, we conduct experiments on the image classification task for a human brain-visual dataset and the classification task for a motor imagery dataset. The experimental results show that our method achieves new state-of-the-art performance compared to multiple existing methods that are widely used for EEG classification. © 2021 IEEE.","","Algorithms; Brain; Brain-Computer Interfaces; Electroencephalography; Humans; Neural Networks, Computer; Biomedical signal processing; Classification (of information); Decoding; Deep learning; Electroencephalography; Neurophysiology; Brain activity; Classification tasks; Electroencephalogram signals; End-to-end models; Human brain; Learn+; Learning frameworks; Motor imagery; Natural images; Neural activity; algorithm; brain; brain computer interface; electroencephalography; human; Brain","","","Institute of Electrical and Electronics Engineers Inc.","34891254"
"Sathiyamoorthi V.; Ilavarasi A.K.; Murugeswari K.; Thouheed Ahmed S.; Aruna Devi B.; Kalipindi M.","Sathiyamoorthi, V. (54785086900); Ilavarasi, A.K. (57195529643); Murugeswari, K. (58876342100); Thouheed Ahmed, Syed (57191614497); Aruna Devi, B. (57226618044); Kalipindi, Murali (57210473528)","54785086900; 57195529643; 58876342100; 57191614497; 57226618044; 57210473528","A deep convolutional neural network based computer aided diagnosis system for the prediction of Alzheimer's disease in MRI images","2021","171","","108838","","","","10.1016/j.measurement.2020.108838","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098067466&doi=10.1016%2fj.measurement.2020.108838&partnerID=40&md5=e81c810fe0b650a217e46e2f556b80d3","In the recent past, biomedical domain has become popular due to digital image processing of accurate and efficient diagnosis of clinical patients using Computer-Aided Diagnosis (CAD). Appropriate and punctual disease identification and treatment arrangement directs to enhance superiority of life and improved life hope in Alzheimer Disease (AD) patients. The cutting-edge approaches that believe multimodal analysis have been shown to be efficient and accurate are improved compared with manual analysis. Many tools have been introduced for detection of Alzheimer but still it is a financially high costly diagnosis system gives detection of disease with low accuracy and efficient due to performance of Magnetic Resonance Imaging (MRI) scanning devices. A novel methodology is proposed in this research as CAD process using various algorithms for predicting AD. The MRI images from scanning device are a highly noisy image due to thermal activities of hardware involved in scanning device. The image restoration technique is applied using 2D Adaptive Bilateral Filter (2D-ABF) algorithm. The quality of image in terms of brightness and contrast are improved using image enhancement techniques based on Adaptive Histogram Adjustment (AHA) algorithm. The Region of Interest of Alzheimer disease is segmented using Adaptive Mean Shift Modified Expectation Maximization (AMS-MEM) algorithm. The various features are calculated using second order 2-Dimensional Gray Level Co-Occurrence Matrix (2D-GLCM). Based on selection of features, the Deep Learning (DL) approach is used to classify the disease images and its stages. The Deep Convolutional Neural Network (DCNN) is the classification technique implemented to classify disease for proper diagnostic decision making. The experimental results prove that the proposed methodology provides better accuracy and efficiency than existing system. © 2020 Elsevier Ltd","2D-ABF; AHA; CAD; GLCM; ML; MRI","Adaptive filters; Convolution; Convolutional neural networks; Decision making; Deep learning; Deep neural networks; Image enhancement; Image reconstruction; Image segmentation; Magnetic resonance imaging; Maximum principle; Medical computing; Modal analysis; Neurodegenerative diseases; Patient treatment; Profilometry; Scanning; Adaptive mean shifts; Classification technique; Computer aided diagnosis systems; Computer Aided Diagnosis(CAD); Diagnostic decision makings; Gray level co-occurrence matrix; Image restoration techniques; Modified expectation-maximization; Computer aided diagnosis","","","Elsevier B.V.",""
"Solorzano-Espindola C.E.; Zamora E.; Sossa H.","Solorzano-Espindola, Carlos Emiliano (57204773295); Zamora, Erik (56038568300); Sossa, Humberto (6602238115)","57204773295; 56038568300; 6602238115","Multi-subject classification of Motor Imagery EEG signals using transfer learning in neural networks","2021","","","","1006","1009","3","10.1109/EMBC46164.2021.9630155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122543041&doi=10.1109%2fEMBC46164.2021.9630155&partnerID=40&md5=017b914e86356e9218610d60729bf8e7","Brain-Computer Interfaces are new technologies with a fast development due to their possible usages, which still require overcoming some challenges to be readily usable. The paradigm of motor imagery is among the ones in these types of systems where the pipeline is tuned to work with only one person as it fails to classify the signals of a different person. Deep Learning methods have been gaining attention for tasks involving high-dimensional unstructured data, like EEG signals, but fail to generalize when trained on small datasets. In this work, to acquire a benchmark, we evaluate the performance of several classifiers while decoding signals from a new subject using a leave-one-out approach. Then we test the classifiers on the previous experiment and a method based on transfer learning in neural networks to classify the signals of multiple persons at a time. The resulting neural network classifier achieves a classification accuracy of 73% on the evaluation sessions of four subjects at a time and 74% on three at a time on the BCI competition IV 2a dataset. © 2021 IEEE.","","Algorithms; Electroencephalography; Humans; Imagination; Machine Learning; Neural Networks, Computer; Benchmarking; Biomedical signal processing; Brain computer interface; Classification (of information); Image classification; EEG signals; High-dimensional; Higher-dimensional; Learning methods; Motor imagery; Motor imagery EEG; Neural-networks; Small data set; Subject classification; Unstructured data; algorithm; electroencephalography; human; imagination; machine learning; Deep learning","CIC-IPN; FORDECYT-PRONACES, (60055); SIP-IPN, (20200651, 20210316, 20210788); Consejo Nacional de Ciencia y Tecnología, CONACYT","","Institute of Electrical and Electronics Engineers Inc.","34891458"
"Mitra S.; Saha S.; Hasanuzzaman M.","Mitra, Sayantan (8892893100); Saha, Sriparna (17435835500); Hasanuzzaman, Mohammed (57214401673)","8892893100; 17435835500; 57214401673","A multi-view deep neural network model for chemical-disease relation extraction from imbalanced datasets","2020","24","11","9050814","3315","3325","10","10.1109/JBHI.2020.2983365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095800035&doi=10.1109%2fJBHI.2020.2983365&partnerID=40&md5=72bacb1ed4f8a1180fe75073152cc2f4","Understanding the chemical-disease relations (CDR) is a crucial task in various biomedical domains. Manual mining of these information from biomedical literature is costly and time-consuming. To address these issues, various researches have been carried out to design an efficient automatic tool. In this paper, we propose a multi-view based deep neural network model for CDR task. Typically, multiple representations (or views) of the datasets are not available for this task. So, we train multiple conceptually different deep neural network models on the dataset to generate different abstract features, treated as different views. A novel loss function, 'Penalized LF', is defined to address the problem of imbalance dataset. The proposed loss function is generic in nature. The model is designed as a combination of Convolution Neural Network (CNN) and Bidirectional Long Short Term Memory (Bi-LSTM) network along with a Multi-Layer Perceptron (MLP). To show the efficacy of our proposed model, we have compared it with six baseline models and other state-of-the-art techniques, on 'chemicals-and-disease-DFE' dataset, a free text dataset created by Li et al. from BioCreative V Chemical Disease Relation dataset. Results show that the proposed model attains highest F1-score for individual classes, proving its efficiency in handling class imbalance problem in the dataset. To further demonstrate the efficacy of the proposed model, we have presented results on BioCreative V dataset and two Protein-Protein Interaction Identification (PPI) datasets, viz., AiMed and BioInfer. All these results are also compared with the state-of-the-art models. © 2013 IEEE.","chemical-disease relations; imbalanced class; Multi-view classification; relation extraction; text mining","Humans; Neural Networks, Computer; Clock and data recovery circuits (CDR circuits); Deep neural networks; Long short-term memory; Proteins; Biomedical literature; Class imbalance problems; Convolution neural network; Imbalanced Data-sets; Multi layer perceptron; Multiple representation; Protein-protein interactions; State-of-the-art techniques; Article; artificial neural network; atrial fibrillation; attention network; chemically induced disorder; convolutional neural network; deep neural network; diagnostic test accuracy study; entropy; feature extraction; human; image segmentation; learning algorithm; long short term memory network; loss of function mutation; mathematical model; measurement precision; mining; multilayer perceptron; nerve cell network; prediction; protein protein interaction; receiver operating characteristic; support vector machine; Multilayer neural networks","Digital India Corporation; Ministry of Electronics and Information technology, Meity","","Institute of Electrical and Electronics Engineers Inc.","32248129"
"Seum A.; Raj A.H.; Sakib S.; Hossain T.","Seum, Ashek (57223048161); Raj, Amir Hossain (57223044264); Sakib, Shadman (56296982100); Hossain, Tonmoy (57208082515)","57223048161; 57223044264; 56296982100; 57208082515","A comparative study of CNN transfer learning classification algorithms with segmentation for COVID-19 detection from CT scan images","2020","","","9393129","234","237","3","10.1109/ICECE51571.2020.9393129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104673230&doi=10.1109%2fICECE51571.2020.9393129&partnerID=40&md5=3297d86c230010e2d5eedfee1fc208f6","After it's inception, COVID-19 has spread rapidly all across the globe. Considering this outbreak, by far, it is the most decisive task to detect early and isolate the patients quickly to contain the spread of this virus. In such cases, artificial intelligence and machine learning or deep learning methods can come to aid. For that purpose, we have conducted a qualitative investigation to inspect 12 off-the-shelf Convolution Neural Network (CNN) architectures in classifying COVID-19 from CT scan images. Furthermore, a segmentation algorithm for biomedical images - U-Net, is analyzed to evaluate the performance of the CNN models. A publicly available dataset (SARS-COV-2 CT-Scan) containing a total of 2481 CT scan images is employed for the performance evaluation. In terms of feature extraction by excluding the segmentation technique, a performance of 88.60% as the F1 Score and 89.31% as accuracy is achieved by training DenseNet169 architecture. Adopting the U-Net segmentation method, we accomplished the most optimal accuracy and F1 Scores as 89.92% and 89.67% respectively on DenseNet201 model. Furthermore, evaluating the performances, we can affirm that a combination of a Transfer Learning architecture with a segmentation technique (U-Net) enhances the performance of the classification model. © 2020 IEEE.","CNN; COVID-19; CT scan; DenseNet; Transfer learning; U-Net","Bioinformatics; Deep learning; Diseases; Image classification; Image segmentation; Learning algorithms; Learning systems; Network architecture; Transfer learning; Classification algorithm; Classification models; Comparative studies; Convolution neural network; Learning architectures; Segmentation algorithms; Segmentation methods; Segmentation techniques; Computerized tomography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Liu X.; Song L.; Liu S.; Zhang Y.","Liu, Xiangbin (15077163000); Song, Liping (57221765586); Liu, Shuai (56434677500); Zhang, Yudong (35786830100)","15077163000; 57221765586; 56434677500; 35786830100","A review of deep-learning-based medical image segmentation methods","2021","13","3","1224","1","29","28","10.3390/su13031224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100085131&doi=10.3390%2fsu13031224&partnerID=40&md5=14135b26ced230c5cdc28001ad7dd3eb","As an emerging biomedical image processing technology, medical image segmentation has made great contributions to sustainable medical care. Now it has become an important research direction in the field of computer vision. With the rapid development of deep learning, medical image processing based on deep convolutional neural networks has become a research hotspot. This paper focuses on the research of medical image segmentation based on deep learning. First, the basic ideas and characteristics of medical image segmentation based on deep learning are introduced. By explaining its research status and summarizing the three main methods of medical image segmentation and their own limitations, the future development direction is expanded. Based on the discussion of different pathological tissues and organs, the specificity between them and their classic segmentation algorithms are summarized. Despite the great achievements of medical image segmentation in recent years, medical image segmentation based on deep learning has still encountered difficulties in research. For example, the segmentation accuracy is not high, the number of medical images in the data set is small and the resolution is low. The inaccurate segmentation results are unable to meet the actual clinical requirements. Aiming at the above problems, a comprehensive review of current medical image segmentation methods based on deep learning is provided to help researchers solve existing problems. © 2021 by the authors.","Convolutional neural network; Deep learning; Image segmentation; Medical image","accuracy assessment; algorithm; artificial neural network; computer vision; image processing; image resolution; numerical method; segmentation","Scientific Research Fund of Hunan Provincial Education, (14C0710); Natural Science Foundation of Hunan Province, (2020JJ4434); Education Department of Henan Province, (19A312); Science and Technology Program of Hunan Province, (2018RS3065, 2018TP1018)","","MDPI",""
"Li W.; Wu Q.; Luo H.; Zhang G.; Peng Z.; Chen K.","Li, Wenzhen (57248837700); Wu, Qirui (57208779067); Luo, Hanwu (12802905300); Zhang, Guoli (57211234396); Peng, Zhonghan (57220115374); Chen, Kai (57218852635)","57248837700; 57208779067; 12802905300; 57211234396; 57220115374; 57218852635","Research on Active Learning Method Based on Domain Adaptation and Collaborative Training","2021","653","","","220","227","7","10.1007/978-981-15-8599-9_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102516180&doi=10.1007%2f978-981-15-8599-9_27&partnerID=40&md5=559b32a38c483231c4bcc3d1b74c601b","In recent years, more and more deep learning technologies have been widely applied in various fields, such as intelligent medical, intelligent manufacturing, to realize the intelligence of various systems. In order to solve the problems of traditional manual inspection of power equipment, we propose a Convolutional Neural Network (CNN) has brought a revolutionary change to computer vision, but the ability of CNN to study relies heavily on the amount of labeled data. Currently, most of the labeled datasets are made up of natural images, which makes it a difficult problem to acquire labeled data in specific fields such as biomedical because of the high cost of human labeling. Active learning is an important method to solve this problem. This thesis is oriented to the problem of image classification and studies the current challenges and solutions of active learning. How to select the samples to be labeled so that the best neural network model can be learned at the minimum labeling cost is the core of the active learning algorithm. This thesis focuses on the selection strategy of the samples to be labeled, analyzes, and summarizes the advantages and disadvantages of current active learning methods, and designs a learning model. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Active learning; Co-training; Fine-tuning; Sample diversity","Convolutional neural networks; Deep learning; Engineering education; Labeled data; Learning systems; Active learning methods; Active-learning algorithm; Collaborative training; Domain adaptation; Intelligent Manufacturing; Learning technology; Neural network model; Revolutionary changes; Learning algorithms","Science and Technology Project of State Grid","Liang Q.; Wang W.; Mu J.; Liu X.; Na Z.; Cai X.","Springer Science and Business Media Deutschland GmbH",""
"","","","17th International Computer Engineering Conference, ICENCO 2021","2021","","","","","","142","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126538325&partnerID=40&md5=118e8bc61ed170d4ff0e6d5cd136d977","The proceedings contain 25 papers. The topics discussed include: opposition-based learning tunicate swarm algorithm for biomedical classification; iridology-based human health examination; analysis of US COVID-19 twitter data social interest and topic changes; optimization of multiplier-less algorithm in the neural network trigger for a detection of cosmic rays; active fault tolerant control of discrete event system subjected to sensors fault; forecasting healthcare cost in australia using health insurance claims data; a comparative study of machine learning techniques for automatic rice crop irrigation; a quantitative analysis in CTP images for ischemic stroke lesion segmentation; road traffic accidents detection based on crash estimation; innovative deep learning-based video editing tool; and a heuristic approach for optimizing resource allocation in D2D underlaying cellular networks.","","","","","Institute of Electrical and Electronics Engineers Inc.",""
"Li C.; Yang H.; Wu X.; Zhang Y.","Li, Cong (57465380500); Yang, Honghong (55968539600); Wu, Xia (36060899000); Zhang, Yumei (55739928600)","57465380500; 55968539600; 36060899000; 55739928600","Improving EEG-Based Motor Imagery Classification Using Hybrid Neural Network","2021","","","","486","489","3","10.1109/ICICN52636.2021.9673861","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125173056&doi=10.1109%2fICICN52636.2021.9673861&partnerID=40&md5=5cf40d994cf247be4ef96869ce945a22","Motor imagery EEG (MI-EEG) is a subjective signal generated by testers, which is collected through brain-computer interface (BCI). With the characteristics of noninvasive, inexpensive, and easily applied to human beings, MI-EEG classification is a popular research area in recent years. Due to the low signal-To-noise ratio and incomplete EEG signals, high accuracy rate classification is still a challenging problem. Most existing works of deep learning only regard EEG signals as chain-like sequences data and use single neural network for classification. To solve the above issues, we propose an improved EEG signals classification method via a hybrid neural network (HNN). In our work, we first use the origin EEG signals without removing noise and any filtering process, to ensure real-Time property. Then, the EEG signals are divided into some small segments, and we arrange the data by considering the spatial position of electrodes. Finally, we propose a hybrid neural network by combing CNN, DNN, LSTM network. Experimental results for two challenging EEG signal classification benchmark datasets show that the proposed method has a good classification performance compared with several state-of-The-Art EEG signal classification algorithms. After multiple sample testing, the average experiment result is 75.52%, which is 7.32% higher than the latest method.  © 2021 IEEE.","classification; deep learning; EEG signal; motor imagination","Benchmarking; Biomedical signal processing; Brain computer interface; Image classification; Image enhancement; Long short-term memory; Signal to noise ratio; Deep learning; EEG classification; EEG signals; EEG signals classification; Human being; Hybrid neural networks; Motor imagery classification; Motor imagery EEG; Motor imagination; Research areas; Classification (of information)","Shaanxi Science and Technology Plan Project, (2019GY-217); National Natural Science Foundation of China, NSFC, (11872036, 61701291, 61907028); Fundamental Research Funds for the Central Universities","","Institute of Electrical and Electronics Engineers Inc.",""
"Malkawi A.; Al-Assi R.; Salameh T.; Sheyab B.; Alquran H.; Alqudah A.M.","Malkawi, Areej (57221529677); Al-Assi, Rawan (57221521902); Salameh, Taimaa (57221518840); Sheyab, Bara'ah (57221536342); Alquran, Hiam (56198738900); Alqudah, Ali Mohammad (57189294287)","57221529677; 57221521902; 57221518840; 57221536342; 56198738900; 57189294287","White Blood Cells Classification Using Convolutional Neural Network Hybrid System","2020","2020-October","","9265154","","","","10.1109/MECBME47393.2020.9265154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099396256&doi=10.1109%2fMECBME47393.2020.9265154&partnerID=40&md5=c68992b4b7f431030feb7f76a6305d35","Blood and its components play a very important role in human life and it considers the best indicator in determining many biological conditions. Pathologists used optical microscopic blood images to diagnose diseases; some of these diseases are Acquired Immune Deficiency Syndrome (AIDS), Leukemia, after recognizing white blood cells (WBCs) from those images. Recently, a Computer-aided diagnosis system is used for diagnosing blood from its microscopic images. In this research, microscopic WBCs images were classified using a hybrid system where Convolutional Neural Network (CNN) used as features extractor and different machine learning algorithms used as classifiers, then the performances of these classifiers were evaluated to recognize the best of them. These algorithms include Support Vector Machine (SVM), k-Nearest Neighbor (KNN) and Random Forest, for training and test parameters we used five features that were extracted from the images. According to results of performance, the RF performed better than the other methods with a testing accuracy reached 98.7%.  © 2020 IEEE.","blood cells; Deep Learning; leukocytes; WBC classification","Biomedical engineering; Cells; Computer aided diagnosis; Convolution; Convolutional neural networks; Decision trees; Diseases; Hybrid systems; Image processing; Learning algorithms; Nearest neighbor search; Support vector machines; Acquired immune deficiency syndrome; Biological conditions; Computer aided diagnosis systems; Diagnose disease; K nearest neighbor (KNN); Microscopic image; Testing accuracy; White blood cells; Blood","","","IEEE Computer Society",""
"Zhou L.; Li X.; Liu Y.; Zuo W.","Zhou, Liying (55886846800); Li, Xiaomin (57221615600); Liu, Yi (57221615645); Zuo, Wenge (56237415200)","55886846800; 57221615600; 57221615645; 56237415200","Data Analytics for Artificial Intelligence Research from 2018 to 2020","2020","","","9263542","994","998","4","10.1109/CISP-BMEI51763.2020.9263542","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099605344&doi=10.1109%2fCISP-BMEI51763.2020.9263542&partnerID=40&md5=4bad80180b786b11d9e3c6de134026c2","This paper is based on literature dataset about Artificial Intelligence from SCI and EL A series of indices, such as Documents, Times Cited, CNCI, Highly Cited Papers, Hot Papers and EI Controlled Terms are used to analyze the research status and trends in the field of artificial intelligence in 2018-2020. Based on Documents, Times Cited and CNCI, high-yield countries, high-yield institutions, high-impact countries and high-impact institutions are identified. Based on Highly Cited Papers, Hot Papers and EI Controlled Terms, the most productive topics and the most influential topics in AI subject are identified. The results show that: AI is the third most productive sub-field in the Computer Science, and it produces the most highly cited papers and hot papers; the three countries with most total paper output are China mainland, USA, and Japan, while the top three countries with highest average paper impact are USA, England and United Kingdom; China mainland has the most high-yield institutions, among which Tsinghua University ranks first; the most influential topics discussed in highly cited papers are Decision Making, Neural Networks, Convolution, Fuzzy Sets, Deep Learning, Learning Algorithms, etc. © 2020 IEEE.","artificial intelligence; EI Thesaurus; highly cited papers; research topics","Biomedical engineering; Data Analytics; Decision making; Deep learning; Image processing; Artificial intelligence research; High impact; Highly-cited papers; Paper output; Research status; Sub fields; Tsinghua University; United kingdom; Learning algorithms","South China University of Technology, SCUT, (2019TC090); Fundamental Research Funds for the Central Universities","Zheng Q.; Zheng X.; Zhao X.; Yan W.; Zhang N.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"Devi M.; Singh S.; Tiwari S.; Chandra Patel S.; Ayana M.T.","Devi, Manju (57220479357); Singh, Sukhdip (57210947709); Tiwari, Shailendra (56896742600); Chandra Patel, Subhash (56878067900); Ayana, Melkamu Teshome (57219804658)","57220479357; 57210947709; 56896742600; 56878067900; 57219804658","A Survey of Soft Computing Approaches in Biomedical Imaging","2021","2021","","1563844","","","","10.1155/2021/1563844","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112864588&doi=10.1155%2f2021%2f1563844&partnerID=40&md5=f6c6803910e03a282b849bbbaba33612","Medical imaging is an essential technique for the diagnosis and treatment of diseases in modern clinics. Soft computing plays a major role in the recent advances in medical imaging. It handles uncertainties and improves the qualities of an image. Until now, various soft computing approaches have been proposed for medical applications. This paper discusses various medical imaging modalities and presents a short review of soft computing approaches such as fuzzy logic, artificial neural network, genetic algorithm, machine learning, and deep learning. We also studied and compared each approach used for other imaging modalities based on the certain parameter used for the system evaluation. Finally, based on comparative analysis, the possible research strategies for further development are proposed. As far as we know, no previous work examined this issue.  © 2021 Manju Devi et al.","","Algorithms; Artificial Intelligence; Fuzzy Logic; Humans; Machine Learning; Neural Networks, Computer; Deep learning; Diagnosis; Fuzzy logic; Genetic algorithms; Image enhancement; Medical applications; Neural networks; Soft computing; Biomedical imaging; Comparative analysis; Imaging modality; Research strategy; Soft computing approaches; System evaluation; artificial intelligence; artificial neural network; deep learning; diagnostic imaging; fuzzy logic; generative adversarial network; genetic algorithm; machine learning; nuclear magnetic resonance imaging; optical coherence tomography; positron emission tomography; Review; single photon emission computed tomography; ultrasound; algorithm; artificial intelligence; fuzzy logic; human; machine learning; Medical imaging","","","Hindawi Limited","34394885"
"Yang C.; Ojha B.D.; Aranoff N.D.; Green P.; Tavassolian N.","Yang, Chenxi (57188737614); Ojha, Banish D. (57219010934); Aranoff, Nicole D. (57214068772); Green, Philip (55156712200); Tavassolian, Negar (24483883200)","57188737614; 57219010934; 57214068772; 55156712200; 24483883200","Classification of aortic stenosis using conventional machine learning and deep learning methods based on multi-dimensional cardio-mechanical signals","2020","10","1","17521","","","","10.1038/s41598-020-74519-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092570374&doi=10.1038%2fs41598-020-74519-6&partnerID=40&md5=dd0ef775ef3b595002e5ddfb714c5ec8","This paper introduces a study on the classification of aortic stenosis (AS) based on cardio-mechanical signals collected using non-invasive wearable inertial sensors. Measurements were taken from 21 AS patients and 13 non-AS subjects. A feature analysis framework utilizing Elastic Net was implemented to reduce the features generated by continuous wavelet transform (CWT). Performance comparisons were conducted among several machine learning (ML) algorithms, including decision tree, random forest, multi-layer perceptron neural network, and extreme gradient boosting. In addition, a two-dimensional convolutional neural network (2D-CNN) was developed using the CWT coefficients as images. The 2D-CNN was made with a custom-built architecture and a CNN based on Mobile Net via transfer learning. After the reduction of features by 95.47%, the results obtained report 0.87 on accuracy by decision tree, 0.96 by random forest, 0.91 by simple neural network, and 0.95 by XGBoost. Via the 2D-CNN framework, the transfer learning of Mobile Net shows an accuracy of 0.91, while the custom-constructed classifier reveals an accuracy of 0.89. Our results validate the effectiveness of the feature selection and classification framework. They also show a promising potential for the implementation of deep learning tools on the classification of AS. © 2020, The Author(s).","","Aged; Algorithms; Aortic Valve Stenosis; Biomedical Engineering; Decision Trees; Deep Learning; Elasticity; Female; Finite Element Analysis; Heart; Humans; Machine Learning; Male; Middle Aged; Neural Networks, Computer; Pilot Projects; Reproducibility of Results; Signal Processing, Computer-Assisted; Wavelet Analysis; aged; algorithm; aortic valve stenosis; biomedical engineering; classification; decision tree; elasticity; female; finite element analysis; heart; human; machine learning; male; middle aged; pathophysiology; pilot study; reproducibility; signal processing; wavelet analysis","National Science Foundation, NSF; Directorate for Engineering, ENG, (1855394)","","Nature Research","33067495"
"Habib G.; Qureshi S.","Habib, Gousia (57221589277); Qureshi, Shaima (26325864200)","57221589277; 26325864200","Biomedical Image Classification using CNN by Exploiting Deep Domain Transfer Learning","2021","10","1","","1075","1083","8","10.12785/ijcds/100197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122768002&doi=10.12785%2fijcds%2f100197&partnerID=40&md5=f3f6430ee3623ef8a7289af25c067020","Accurate biomedical image classification is essential for the clinical investigation of different hazardous maladies. A fair diagnosis of the disease is essential to provide proper treatment and to save precious human lives. Classification methods that support handcrafted features and use artificial neural networks trained with restricted data-set cannot viably enhance the precision rate and meet the stipulations for classification of biomedical images End-to-End deep learning machines empowers direct mapping from crude information to the desired output, eliminating the need for handcrafted features. Deep learning has proven as a powerful classification method as evidenced by its success in recent computer vision competitions. A unique deep convolutional neural network (CNN) model for brain tumor classification has been proposed in this paper. The model tested on the OASIS MRI data-set and gives an average accuracy of 90:84%. The present model is based on a pre- trained vgg-19 model on a large Image-Net database. Novel CNN model does not require training from scratch wasting weeks or days, rather uses transfer learning for knowledge distillation. Also to further enhance the training acceleration other optimization methods have been used, weights are initialized by the Gaussian initialization method followed by the ReLu activation function. ADAMS SGD optimization has been used and a drop-out algorithm is implemented to get rid of the overfitting of the model. The model when implemented on the biomedical image dataset has achieved the highest classification accuracy rate, outperforming all existing techniques with lesser training time. © 2021 University of Bahrain. All rights reserved.","ADAMS; CNN; CONVONET; FC; HOG; LRN; MRI; OASIS; PHT; ReLu; SGD; SIFT; Soft-max","","","","University of Bahrain",""
"Gelpud J.; Castillo S.; Jojoa M.; Garcia-Zapirain B.; Achicanoy W.; Rodrigo D.","Gelpud, John (57262977600); Castillo, Silvia (57262977700); Jojoa, Mario (57192165756); Garcia-Zapirain, Begonya (35732954700); Achicanoy, Wilson (55420960100); Rodrigo, David (58319141700)","57262977600; 57262977700; 57192165756; 35732954700; 55420960100; 58319141700","Deep Learning for Heart Sounds Classification Using Scalograms and Automatic Segmentation of PCG Signals","2021","12861 LNCS","","","583","596","13","10.1007/978-3-030-85030-2_48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115120670&doi=10.1007%2f978-3-030-85030-2_48&partnerID=40&md5=d98efa68e74976cadecdda240532c832","This paper proposes a set of Deep Learning algorithms for classifying Phonocardiogram (PCG) scalogram. PCG signals contain valuable information about the heart health status, and they could help us in early detection and diagnosis of potential abnormalities. The system will classify into normal or abnormal categories, supported on reliable signal processing algorithms to automatically denoise and segment the sounds to improve the Deep Learning detection task. At the first stage, we denoised the PCG signal using a multi-resolution analysis based on the Discrete Wavelet Transform (DWT). At the second one, we segment automatically the sounds using an algorithm based on the Teager Energy Operator (TEO) and the autocorrelation. This is very important, because it is needed to select the S1 component related to the systole, and S2 component related to the diastole. Finally, scalogram images are obtained using Continuous Wavelet Transform (CWT). The classification task has been executed using the heart sounds from the 2016 PhysioNet/CinC Challenge database, and pretrained Convolutional Neural Networks (CNNs) ResNet152 and VGG16, achieving an accuracy of 91.19% and 90.75%, respectively. The results of our proposed model presents a good contribution to heart sounds classification area, in comparison with the state of the art accuracy which is 87%. © 2021, Springer Nature Switzerland AG.","Automatic segmentation; Classification; Deep learning; Heart sounds; Phonocardiogram; Scalograms","Biomedical signal processing; Cardiology; Classification (of information); Convolutional neural networks; Discrete wavelet transforms; Heart; Intelligent computing; Learning algorithms; Phonocardiography; Signal denoising; Automatic segmentations; Classification tasks; Continuous wavelet transforms; Detection and diagnosis; Phonocardiograms; Signal processing algorithms; State of the art; Teager energy operators; Deep learning","University of Deusto; University of Nari?o; Universidad de Nariño, (IT905-16)","Rojas I.; Joya G.; Catala A.","Springer Science and Business Media Deutschland GmbH",""
"Chen J.; Yi W.; Wang D.","Chen, Jiaming (57892375800); Yi, Weibo (55878285300); Wang, Dan (9275444300)","57892375800; 55878285300; 9275444300","Filter Bank Sinc-ShallowNet with EMD-based Mixed Noise Adding Data Augmentation for Motor Imagery Classification","2021","","","","5837","5841","4","10.1109/EMBC46164.2021.9629728","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122526059&doi=10.1109%2fEMBC46164.2021.9629728&partnerID=40&md5=2d02e295621bb5bec4a9ba3505a44a77","Motor imagery-based brain computer interface (MI-BCI) is a representative active BCI paradigm which is widely employed in the rehabilitation field. In MI-BCI, a classification model is built to identify the target limb from MI-based EEG signals, but the performance of models cannot meet the demand for practical use. Lightweight neural networks in deep learning methods are used to build high performance models in MI-BCI. Small sample sizes and the lack of multi-scale information extraction in frequency domain limit the performance improvement of lightweight neural networks. To solve these problems, the Filter Bank Sinc-ShallowNet (FB-Sinc-ShallowNet) algorithm combined with the mixed noise adding method based on empirical mode decomposition (EMD) was proposed. The FB-Sinc-ShallowNet algorithm improves a lightweight neural network Sinc-ShallowNet with a filter bank structure corresponding to four sensory motor rhythms. The mixed noise adding method employs the EMD method to improve the quality of generated data. The proposed method was evaluated on the BCI competition IV IIa dataset and can achieve highest average accuracy of 77.2%, about 6.34% higher than state-of-the-art method Sinc-ShallowNet. This work implies the effectiveness of filter bank structure in lightweight neural networks and provides a novel option for data augmentation and classification of MI-based EEG signals, which can be applied in the rehabilitation field for decoding MI-EEG with few samples. © 2021 IEEE.","","Algorithms; Brain-Computer Interfaces; Electroencephalography; Imagination; Neural Networks, Computer; Biomedical signal processing; Brain computer interface; Deep learning; Frequency domain analysis; Image classification; Adding methods; Data augmentation; EEG signals; Empirical Mode Decomposition; Filters bank; Mixed noise; Motor imagery; Neural-networks; Noise adding; Performance; algorithm; brain computer interface; electroencephalography; imagination; Filter banks","National Natural Science Foundation of China, NSFC, (62006014)","","Institute of Electrical and Electronics Engineers Inc.","34892447"
"Kondratenko Y.; Sidenko I.; Kondratenko G.; Petrovych V.; Taranov M.; Sova I.","Kondratenko, Yuriy (6602324472); Sidenko, Ievgen (55991342900); Kondratenko, Galyna (55991478400); Petrovych, Valentyn (57220779336); Taranov, Mykyta (57195135302); Sova, Ivan (57221292558)","6602324472; 55991342900; 55991478400; 57220779336; 57195135302; 57221292558","Artificial Neural Networks for Recognition of Brain Tumors on MRI Images","2021","1308","","","119","140","21","10.1007/978-3-030-77592-6_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111787493&doi=10.1007%2f978-3-030-77592-6_6&partnerID=40&md5=3b3f34e5f149e5219af9a3235183e815","In this paper, artificial neural networks for recognition of brain tumors on MRI images are analyzed. This analysis allows to choose the most appropriate neural network architecture and various preprocessing techniques to increase the precision of tumor instance recognition. Understanding the image and extracting information from it to accomplish some result is an important area of application in digital image technology. Image recognition has quickly found its use in medicine and specifically oncology. Precise recognition masks may not be critical in other cases, but marginal recognition errors in medical images may render the results unreliable for clinical use. Therefore, biomedical problems require much higher boundary detection precision to improve further analysis. Various methods and algorithms for image recognition and segmentation are considered. The advantages and disadvantages of neural network architectures (ResNet, U-Net, SegNet, YOLO v3) are considered and analyzed in more detail. Additionally, the analysis of data preprocessing methods was carried out, as well as a study of the input data. Comparison of different artificial neural networks algorithms and architectures will achieve the highest accuracy of recognition. During the comparison, a system of the U-Net architecture with additional processing methods was selected as the final model. Its accuracy reached 94%, which is a significant result compared to manual image recognition. © 2021, Springer Nature Switzerland AG.","Biomedicine; Deep learning; Instance recognition; MRI image; Neoplasm; Neural network","Brain; Educational technology; Image recognition; Image segmentation; Industrial research; Magnetic resonance imaging; Medical imaging; Network architecture; Tumors; Analysis of data; Biomedical problems; Boundary detection; Digital image technology; Extracting information; Preprocessing techniques; Processing method; Recognition error; Neural networks","","Bollin A.; Ermolayev V.; Mayr H.C.; Nikitchenko M.; Spivakovsky A.; Tkachuk M.; Yakovyna V.; Zholtkevych G.","Springer Science and Business Media Deutschland GmbH",""
"Ye X.; Lu Q.","Ye, Xiaohong (57221608290); Lu, Qiang (57221605265)","57221608290; 57221605265","Automatic Classification of 12-lead ECG Based on Model Fusion","2020","","","9263559","733","738","5","10.1109/CISP-BMEI51763.2020.9263559","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099569938&doi=10.1109%2fCISP-BMEI51763.2020.9263559&partnerID=40&md5=7b61a0a5d09de14c424c61f51510c661","Aiming at the growing demand for automatic analysis of standard 12-lead electrocardiogram (ECG) in the medical diagnosis process, an automatic classification of 12-lead ECG based on model fusion is proposed. The algorithm extracts local features by Convolutional Neural Networks (CNN), and then extracts temporal features by Bi-directional Long Short-term Memory (BiLSTM). Finally, eXtreme Gradient Boosting (XGBoost) is used to fuse the 12-lead models to get the classification results. The experiment result shows that, in classifying 9 types of ECG singles, fusion model achieved a mean accuracy of 0.964, a micro-average area under the curve (AUC) of 0.908, an average F1 score of 0.812, a mean precision of 0.836, and a mean recall of 0.788. We demonstrated the feasibility and effectiveness of the fusion model based on XGBoost for interpreting 9 common heart rhythms according to 12-lead ECG. The findings may have clinical relevance for the early diagnosis of cardiac-rhythm disorders. © 2020 IEEE.","12 lead; arrhythmia; BiLSTM; deep learning; ECG classification; model fusion; XGBoost","Biomedical engineering; Computer aided diagnosis; Convolutional neural networks; Image processing; Area under the curves; Automatic analysis; Automatic classification; Cardiac rhythms; Classification results; Early diagnosis; Gradient boosting; Temporal features; Electrocardiography","Educational-Scientific Research Foundation for Middle-aged and Young Teachers of Fujian Province, (JAT191158)","Zheng Q.; Zheng X.; Zhao X.; Yan W.; Zhang N.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"Scherr T.; Löffler K.; Böhland M.; Mikut R.","Scherr, Tim (57211299072); Löffler, Katharina (57201877127); Böhland, Moritz (57211291189); Mikut, Ralf (6603574925)","57211299072; 57201877127; 57211291189; 6603574925","Cell segmentation and tracking using CNN-based distance predictions and a graph-based matching strategy","2020","15","12 December","e0243219","","","","10.1371/journal.pone.0243219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097514619&doi=10.1371%2fjournal.pone.0243219&partnerID=40&md5=d158f9307212cfa002548b7d422e3760","The accurate segmentation and tracking of cells in microscopy image sequences is an important task in biomedical research, e.g., for studying the development of tissues, organs or entire organisms. However, the segmentation of touching cells in images with a low signal-to-noise-ratio is still a challenging problem. In this paper, we present a method for the segmentation of touching cells in microscopy images. By using a novel representation of cell borders, inspired by distance maps, our method is capable to utilize not only touching cells but also close cells in the training process. Furthermore, this representation is notably robust to annotation errors and shows promising results for the segmentation of microscopy images containing in the training data underrepresented or not included cell types. For the prediction of the proposed neighbor distances, an adapted U-Net convolutional neural network (CNN) with two decoder paths is used. In addition, we adapt a graph-based cell tracking algorithm to evaluate our proposed method on the task of cell tracking. The adapted tracking algorithm includes a movement estimation in the cost function to re-link tracks with missing segmentation masks over a short sequence of frames. Our combined tracking by detection method has proven its potential in the IEEE ISBI 2020 Cell Tracking Challenge (http://celltrackingchallenge.net/) where we achieved as team KIT-Sch-GE multiple top three rankings including two top performances using a single segmentation model for the diverse data sets. © 2020 Scherr et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Algorithms; Cell Tracking; Deep Learning; HeLa Cells; Humans; Image Processing, Computer-Assisted; Microscopy; Neural Networks, Computer; Optical Imaging; algorithm; animal cell; Article; benchmarking; cell tracking; cell tracking algorithm; controlled study; convolutional neural network; HeLa cell line; hematopoietic stem cell; human; human cell; microscopy; mouse; muscle stem cell; nonhuman; fluorescence imaging; image processing; procedures","Helmholtz Information & Data Science School for Health; Karlsruhe Institute of Technology, KIT; Helmholtz Association","","Public Library of Science","33290432"
"Faggioli G.; Varile M.","Faggioli, Guglielmo (58328502800); Varile, Mattia (57377557100)","58328502800; 57377557100","Onboard explainable Artificial Intelligence","2021","B5","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127451136&partnerID=40&md5=3720bd8d13593c559eb90a24fcd970e5","Deep Learning is perhaps one of the most promising technology in the development of forthcoming autonomous space systems. The improvements made in sectors like image-recognition, natural language processing, or in areas like biology, suggest that the space sector should seriously consider the implementation of DL systems in future projects. The main challenge will concern achieving reliable and efficient onboard DL-based space systems. DL models are seen by many as black boxes, in the sense that a complete view of information learned during the training phase is missing. This lack of knowledge represents a big issue in order to trust their predictions. Due to this nature, it is difficult to understand which aspects and features of the input data drive the decisions of the network. Moreover, decisions are driven by combinations of data features, and understanding the decision-making process of neural networks is challenging. These are big issues to deal with in order to achieve high confidence in AI predictions. One step closer to the solution of these issues is using new validation methods, which do not solve directly our lack of knowledge but which provide tools capable of giving useful interpretations about how a model is working. Explainable Artificial Intelligence framework provides interesting tools in this direction. This work focuses on exploiting the theory of Shapley's value to contribute in the direction of XAI. The proposed approach is a concept of game theory, that tries to understand what is the contribution of each agent in a collaborative system. The Machine Learning community focused on validation is already applying widely this method to DL techniques, for example in the biomedical sector, and they are obtaining reliable interpretations about what their models are actually learning and how they do so. In this framework, Neural Networks are seen as cooperative systems while their input features are seen as agents that cooperate in order to make the best prediction. Understanding the contribution of each feature to the overall network output provides a better view of the information learned by the network. Shapley's value quantifies this contribution by averaging among all the possible ordered subset of the features and of the related contribution. This work shows the potential of using explainability tools on NN, highlighting how this approach makes the results human-readable and understandable. This work aims to extend the background on XAI for space applications, promoting their use in space missions. Copyright © 2021 by the International Astronautical Federation (IAF). All rights reserved.","Artificial Intelligence; Clarity; Deep Learning; Explainable Artificial Intellgience; SHAP; Shapley's value","Decision making; Deep learning; Digital storage; Forecasting; Image enhancement; Learning algorithms; Natural language processing systems; Space applications; Black boxes; Clarity; Deep learning; Explainable artificial intellgience; Neural-networks; SHAP; Shapley value; Space sectors; Space systems; Training phasis; Game theory","","","International Astronautical Federation, IAF",""
"Termine A.; Fabrizio C.; Strafella C.; Caputo V.; Petrosini L.; Caltagirone C.; Giardina E.; Cascella R.","Termine, Andrea (57214825973); Fabrizio, Carlo (57214825070); Strafella, Claudia (56397012500); Caputo, Valerio (56814565900); Petrosini, Laura (7003484820); Caltagirone, Carlo (35228717800); Giardina, Emiliano (56416074600); Cascella, Raffaella (26025846800)","57214825973; 57214825070; 56397012500; 56814565900; 7003484820; 35228717800; 56416074600; 26025846800","Multi-layer picture of neurodegenerative diseases: Lessons from the use of big data through artificial intelligence","2021","11","4","280","","","","10.3390/jpm11040280","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104641063&doi=10.3390%2fjpm11040280&partnerID=40&md5=c86b70e9b674c3ef6c60b3de30c00228","In the big data era, artificial intelligence techniques have been applied to tackle traditional issues in the study of neurodegenerative diseases. Despite the progress made in understanding the complex (epi)genetics signatures underlying neurodegenerative disorders, performing early diagnosis and developing drug repurposing strategies remain serious challenges for such conditions. In this context, the integration of multi-omics, neuroimaging, and electronic health records data can be exploited using deep learning methods to provide the most accurate representation of patients possible. Deep learning allows researchers to find multi-modal biomarkers to develop more effective and personalized treatments, early diagnosis tools, as well as useful information for drug discovering and repurposing in neurodegenerative pathologies. In this review, we will describe how relevant studies have been able to demonstrate the potential of deep learning to enhance the knowledge of neurodegenerative disorders such as Alzheimer’s and Parkinson’s diseases through the integration of all sources of biomedical data. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; Big data; Deep learning; Neurodegenerative diseases; Precision medicine","algorithm; Alzheimer disease; artificial intelligence; artificial neural network; autoencoder; big data; bradykinesia; cancer research; cognitive defect; convolutional neural network; deep learning; degenerative disease; drug repositioning; early diagnosis; electronic health record; human; image segmentation; machine learning; neuroimaging; nuclear magnetic resonance imaging; Parkinson disease; personalized medicine; phenotype; recurrent neural network; restricted Boltzmann machine; Review; speech discrimination; telerehabilitation","Consiglio Nazionale delle Ricerche, CNR, (FOE 2019)","","MDPI AG",""
"Madanu R.; Rahman F.; Abbod M.F.; Fan S.-Z.; Shieh J.-S.","Madanu, Ravichandra (57223246112); Rahman, Farhan (57224807373); Abbod, Maysam F (7004273385); Fan, Shou-Zen (7402677972); Shieh, Jiann-Shing (35580284800)","57223246112; 57224807373; 7004273385; 7402677972; 35580284800","Depth of anesthesia prediction via EEG signals using convolutional neural network and ensemble empirical mode decomposition","2021","18","5","","5047","5068","21","10.3934/mbe.2021257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108328032&doi=10.3934%2fmbe.2021257&partnerID=40&md5=751f8a2e3eebdc2a23e39c0753bb63e2","According to a recently conducted survey on surgical complication mortality rate, 47% of such cases are due to anesthetics overdose. This indicates that there is an urgent need to moderate the level of anesthesia. Recently deep learning (DL) methods have played a major role in estimating the depth of Anesthesia (DOA) of patients and has played an essential role in control anesthesia overdose. In this paper, Electroencephalography (EEG) signals have been used for the prediction of DOA. EEG signals are very complex signals which may require months of training and advanced signal processing techniques. It is a point of debate whether DL methods are an improvement over the already existing traditional EEG signal processing approaches. One of the DL algorithms is Convolutional neural network (CNN) which is very popular algorithm for object recognition and is widely growing its applications in processing hierarchy in the human visual system. In this paper, various decomposition methods have been used for extracting the features EEG signal. After acquiring the necessary signals values in image format, several CNN models have been deployed for classification of DOA depending upon their Bispectral Index (BIS) and the signal quality index (SQI). The EEG signals were converted into the frequency domain using and Empirical Mode Decomposition (EMD), and Ensemble Empirical Mode Decomposition (EEMD). However, because of the inter mode mixing observed in EMD method; EEMD have been utilized for this study. The developed CNN models were used to predict the DOA based on the EEG spectrum images without the use of handcrafted features which provides intuitive mapping with high efficiency and reliability. The best trained model gives an accuracy of 83.2%. Hence, this provides further scope and research which can be carried out in the domain of visual mapping of DOA using EEG signals and DL methods. © 2021 American Institute of Mathematical Sciences. All rights reserved.","Convolutional neural network; Depth of anesthesia; Electroencephalography; Empirical mode decomposition; Ensemble empirical mode decomposition","Algorithms; Anesthesia; Electroencephalography; Humans; Neural Networks, Computer; Reproducibility of Results; Signal Processing, Computer-Assisted; Anesthesiology; Convolution; Convolutional neural networks; Deep learning; Electroencephalography; Electrophysiology; Forecasting; Frequency domain analysis; Mapping; Object recognition; Advanced signal processing; Decomposition methods; Depth of anesthesia; EEG signal processing; Empirical Mode Decomposition; Ensemble empirical mode decomposition; Ensemble empirical mode decompositions (EEMD); Human Visual System; algorithm; anesthesia; electroencephalography; human; reproducibility; signal processing; Biomedical signal processing","Ministry of Science and Technology, Taiwan, MOST, (107-2221-E-155-009-MY2)","","American Institute of Mathematical Sciences","34517477"
"Wang Q.; Wang X.","Wang, Qi (57196473748); Wang, Xianping (56431240600)","57196473748; 56431240600","EMG-based Hand Gesture Recognition by Deep Time-frequency Learning for Assisted Living Rehabilitation","2020","","","9298181","0558","0561","3","10.1109/UEMCON51285.2020.9298181","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099758597&doi=10.1109%2fUEMCON51285.2020.9298181&partnerID=40&md5=22c07b74bed92b49b3ef63180268457c","As a user-friendly human-computer interaction approach, EMG is regarded as one of the most promising modalities for hand gesture recognition. Though EMG-based hand gesture recognition has been advanced in recent years, to effective detect the patterns from the noisy EMG signal, more advanced algorithms are still highly necessary. Convolutional neural network (CNN) is a popular deep learning algorithm and its unique architecture has gained a great success in the image processing area. In this study, we propose a new deep learning framework for hand gesture recognition from the multi-session EMG signal. In the data representation stage, we also transform the time domain EMG signal to the time-frequency domain by short-term Fourier transform (STFT) to get more time-varying frequency characteristics. Our experiment shows that the proposed framework can effectively detect hand gestures from the multi-session EMG data. This work will greatly advance the hand gesture recognition. © 2020 IEEE.","Convolutional neural network; Deep learning; EMG; Hand gesture recognition; Short-term Fourier transform","Assisted living; Biomedical signal processing; Convolutional neural networks; Deep learning; Frequency domain analysis; Human computer interaction; Learning algorithms; Mobile telecommunication systems; Palmprint recognition; Time domain analysis; Ubiquitous computing; Data representations; Hand-gesture recognition; Learning frameworks; Short term fourier transforms; Time frequency; Time frequency domain; Time-varying frequency; User friendly; Gesture recognition","","Paul R.","Institute of Electrical and Electronics Engineers Inc.",""
"Akay M.; Du Y.; Sershen C.L.; Wu M.; Chen T.Y.; Assassi S.; Mohan C.; Akay Y.M.","Akay, Metin (7102443027); Du, Yong (36481166800); Sershen, Cheryl L. (56648012300); Wu, Minghua (55542054500); Chen, Ting Y. (57201241989); Assassi, Shervin (8907543700); Mohan, Chandra (55981196400); Akay, Yasemin M. (6603545494)","7102443027; 36481166800; 56648012300; 55542054500; 57201241989; 8907543700; 55981196400; 6603545494","Deep Learning Classification of Systemic Sclerosis Skin Using the MobileNetV2 Model","2021","2","","9380371","104","110","6","10.1109/OJEMB.2021.3066097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113535926&doi=10.1109%2fOJEMB.2021.3066097&partnerID=40&md5=dbc2396da2d4782ac021d286210b66fe","Goal: Systemic sclerosis (SSc) is a rare autoimmune, systemic disease with prominent fibrosis of skin and internal organs. Early diagnosis of the disease is crucial for designing effective therapy and management plans. Machine learning algorithms, especially deep learning, have been found to be greatly useful in biology, medicine, healthcare, and biomedical applications, in the areas of medical image processing and speech recognition. However, the need for a large training data set and the requirement for a graphics processing unit (GPU) have hindered the wide application of machine learning algorithms as a diagnostic tool in resource-constrained environments (e.g., clinics). Methods: In this paper, we propose a novel mobile deep learning network for the characterization of SSc skin. The proposed network architecture consists of the UNet, a dense connectivity convolutional neural network (CNN) with added classifier layers that when combined with limited training data, yields better image segmentation and more accurate classification, and a mobile training module. In addition, to improve the computational efficiency and diagnostic accuracy, the highly efficient training model called 'MobileNetV2,' which is designed for mobile and embedded applications, was used to train the network. Results: The proposed network was implemented using a standard laptop (2.5 GHz Intel Core i7). After fine tuning, our results showed the proposed network reached 100% accuracy on the training image set, 96.8% accuracy on the validation image set, and 95.2% on the testing image set. The training time was less than 5 hours. We also analyzed the same normal vs SSc skin image sets using the CNN using the same laptop. The CNN reached 100% accuracy on the training image set, 87.7% accuracy on the validation image set, and 82.9% on the testing image set. Additionally, it took more than 14 hours to train the CNN architecture. We also utilized the MobileNetV2 model to analyze an additional dataset of images and classified them as normal, early (mid and moderate) SSc or late (severe) SSc skin images. The network reached 100% accuracy on the training image set, 97.2% on the validation set, and 94.8% on the testing image set. Using the same normal, early and late phase SSc skin images, the CNN reached 100% accuracy on the training image set, 87.7% accuracy on the validation image set, and 82.9% on the testing image set. These results indicated that the MobileNetV2 architecture is more accurate and efficient compared to the CNN to classify normal, early and late phase SSc skin images. Conclusions: Our preliminary study, intended to show the efficacy of the proposed network architecture, holds promise in the characterization of SSc. We believe that the proposed network architecture could easily be implemented in a clinical setting, providing a simple, inexpensive, and accurate screening tool for SSc.  © 2020 IEEE.","Autoimmune; deep learning; mobilenet; SSc skin; unet","Bioinformatics; Classification (of information); Computational efficiency; Computer graphics; Computer graphics equipment; Convolutional neural networks; Deep learning; Diagnosis; Disease control; Graphics processing unit; Image analysis; Image segmentation; Laptop computers; Learning algorithms; Learning systems; Medical applications; Medical imaging; mHealth; Multilayer neural networks; Program processors; Speech recognition; Biomedical applications; Clinical settings; Diagnostic accuracy; Effective therapy; Embedded application; Learning network; Limited training data; Training data sets; Network architecture","","","Institute of Electrical and Electronics Engineers Inc.",""
"Seo H.; Bassenne M.; Xing L.","Seo, Hyunseok (56125023000); Bassenne, Maxime (57188758635); Xing, Lei (7103349003)","56125023000; 57188758635; 7103349003","Closing the Gap between Deep Neural Network Modeling and Biomedical Decision-Making Metrics in Segmentation via Adaptive Loss Functions","2021","40","2","9229101","585","593","8","10.1109/TMI.2020.3031913","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100619608&doi=10.1109%2fTMI.2020.3031913&partnerID=40&md5=4fc1fa2e77105550d925236ee2b28ec6","Deep learning is becoming an indispensable tool for various tasks in science and engineering. A critical step in constructing a reliable deep learning model is the selection of a loss function, which measures the discrepancy between the network prediction and the ground truth. While a variety of loss functions have been proposed in the literature, a truly optimal loss function that maximally utilizes the capacity of neural networks for deep learning-based decision-making has yet to be established. Here, we devise a generalized loss function with functional parameters determined adaptively during model training to provide a versatile framework for optimal neural network-based decision-making in small target segmentation. The method is showcased by more accurate detection and segmentation of lung and liver cancer tumors as compared with the current state-of-The-Art. The proposed formalism opens new opportunities for numerous practical applications such as disease diagnosis, treatment planning, and prognosis. © 1982-2012 IEEE.","Decision making; Deep learning; Loss function; Machine learning; Segmentation","Benchmarking; Image Processing, Computer-Assisted; Neural Networks, Computer; Decision making; Deep learning; Deep neural networks; Diagnosis; Diseases; Adaptive loss functions; Functional parameters; Indispensable tools; Network prediction; Neural network model; Optimal neural network; Science and engineering; Treatment planning; Article; cancer diagnosis; decision making; deep learning; deep neural network; human; image segmentation; liver cancer; loss of function mutation; lung cancer; segmentation algorithm; tumor volume; x-ray computed tomography; benchmarking; image processing; Neural networks","National Institutes of Health, NIH, (R01CA227713); National Institutes of Health, NIH; National Cancer Institute, NCI, (R01CA176553); National Cancer Institute, NCI; Google; Korea Institute of Science and Technology, KIST, (2E30342, 2K02540); Korea Institute of Science and Technology, KIST","","Institute of Electrical and Electronics Engineers Inc.","33074800"
"Revathi M.; Jeya I.J.S.; Deepa S.N.","Revathi, M. (57224133994); Jeya, I. Jasmine Selvakumari (56878977600); Deepa, S.N. (9636847300)","57224133994; 56878977600; 9636847300","Deep learning-based soft computing model for image classification application","2020","24","24","","18411","18430","19","10.1007/s00500-020-05048-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085500550&doi=10.1007%2fs00500-020-05048-7&partnerID=40&md5=d1857ab8fd686a27258b7674d4a4fd62","The growth of swarm intelligence approaches and machine learning models in the field of medical image processing is extravagant, and the applicability of these approaches for various types of cancer classification has as well grown in the recent years. Considering the growth of these machine learning models, in this work attempt is taken to develop an optimized deep learning neural network classifier for classifying the nodule tissues in the lung cancer images which is an important application in biomedical area. The optimized model developed is the hybrid version of adaptive multi-swarm particle swarm optimizer with the new improved firefly algorithm resulting in better exploration and exploitation mechanism to determine near-optimal solutions. Multi-swarm particle swarm optimizer (MSPSO) possesses strong exploration capability due to its regrouping schedule nature, and the improved firefly algorithm (ImFFA) possesses better exploitation mechanism due to its inherit attractiveness and intensity feature. At this juncture, the new adaptive MSPSO–ImFFA is applied to the deep learning neural classifier to overcome the local and global minima occurrences and premature convergence by tuning its weight values. As a result, in this work the new adaptive MSPSO–ImFFA-based deep learning neural network classifier is employed to classify the lung cancer tissues of the considered lung computed tomography images. Results obtained prove the effectiveness of the deep learning classifier for the considered lung image sample datasets in comparison with the other methods compared from the previous literature works. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Biomedical application; Deep learning; Lung cancer; Soft computing model; Sustainable model; Swarm intelligence","Biological organs; Bioluminescence; Classification (of information); Computerized tomography; Deep neural networks; Diseases; Global optimization; Histology; Image classification; Learning systems; Medical imaging; Neural networks; Particle swarm optimization (PSO); Soft computing; Swarm intelligence; Tissue; Cancer classification; Computed tomography images; Exploration and exploitation; Learning neural networks; Machine learning models; Near-optimal solutions; Pre-mature convergences; Soft computing models; Deep learning","","","Springer Science and Business Media Deutschland GmbH",""
"Bo Z.-H.; Qiao H.; Tian C.; Guo Y.; Li W.; Liang T.; Li D.; Liao D.; Zeng X.; Mei L.; Shi T.; Wu B.; Huang C.; Liu L.; Jin C.; Guo Q.; Yong J.-H.; Xu F.; Zhang T.; Wang R.; Dai Q.","Bo, Zi-Hao (57548085000); Qiao, Hui (57204785118); Tian, Chong (57204931792); Guo, Yuchen (55924087200); Li, Wuchao (57204933825); Liang, Tiantian (57221939617); Li, Dongxue (57207734580); Liao, Dan (58461667500); Zeng, Xianchun (55506959400); Mei, Leilei (57221921802); Shi, Tianliang (59163377700); Wu, Bo (57226540079); Huang, Chao (57309028100); Liu, Lu (59235530600); Jin, Can (57225727060); Guo, Qiping (57221941703); Yong, Jun-Hai (13907549600); Xu, Feng (57189663151); Zhang, Tijiang (26326091700); Wang, Rongpin (24476635900); Dai, Qionghai (59157641000)","57548085000; 57204785118; 57204931792; 55924087200; 57204933825; 57221939617; 57207734580; 58461667500; 55506959400; 57221921802; 59163377700; 57226540079; 57309028100; 59235530600; 57225727060; 57221941703; 13907549600; 57189663151; 26326091700; 24476635900; 59157641000","Toward human intervention-free clinical diagnosis of intracranial aneurysm via deep neural network","2021","2","2","100197","","","","10.1016/j.patter.2020.100197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100645455&doi=10.1016%2fj.patter.2020.100197&partnerID=40&md5=1235c5128f2f854587b578be48ed5b29","Intracranial aneurysm (IA) diagnosis on CTA images is laborious and time consuming in clinical routine. By combining global risk prediction with local IA recognition, the proposed GLIA-Net can robustly and efficiently assist radiologists in clinical practice without any pre- or postprocessing. The state-of-the-art performance has been validated via a multi-cohort dataset, which has been publicly released to democratize deep learning algorithms for biomedical research. © 2020 The Authors; Intracranial aneurysm (IA) is an enormous threat to human health, which often results in nontraumatic subarachnoid hemorrhage or dismal prognosis. Diagnosing IAs on commonly used computed tomographic angiography (CTA) examinations remains laborious and time consuming, leading to error-prone results in clinical practice, especially for small targets. In this study, we propose a fully automatic deep-learning model for IA segmentation that can be applied to CTA images. Our model, called Global Localization-based IA Network (GLIA-Net), can incorporate the global localization prior and generates the fine-grain three-dimensional segmentation. GLIA-Net is trained and evaluated on a big internal dataset (1,338 scans from six institutions) and two external datasets. Evaluations show that our model exhibits good tolerance to different settings and achieves superior performance to other models. A clinical experiment further demonstrates the clinical utility of our technique, which helps radiologists in the diagnosis of IAs. © 2020 The Authors; Intracranial aneurysms (IAs) are enormous threats to human health with a prevalence of approximately 4%. The rupture of IAs usually causes death or severe damage to the patients. To enhance the clinical diagnosis of IAs, we present a deep learning model (GLIA-Net) for IA detection and segmentation without laborious human intervention, which achieves superior diagnostic performance validated by quantitative evaluations as well as a sophisticated clinical study. We anticipate that the publicly released data and the artificial intelligence technique would help to transform the clinical diagnostics and precision treatments of cerebrovascular diseases. They may also revolutionize the landscape of healthcare and biomedical research in the future. © 2020 The Authors","computer-aided diagnosis; deep learning; DSML 3: Development/Pre-production: Data science output has been rolled out/validated across multiple domains/problems; intracranial aneurysm","Bioinformatics; Deep neural networks; Diagnosis; Health risks; Image segmentation; Learning algorithms; Learning systems; Neural networks; Artificial intelligence techniques; Cerebrovascular disease; Computed tomographic angiography; Diagnostic performance; Quantitative evaluation; State-of-the-art performance; Subarachnoid hemorrhages; Three dimensional segmentation; Deep learning","Guizhou Provincial People's Hospital; Guizhou Science and Technology Department Key Lab Project, (QKF[2017]25); Guizhou University of Traditional Chinese Medicine, and Renhuai City People Hospital; Second People's Hospital of Guiyang; National Natural Science Foundation of China, NSFC, (61822111, 62071271, 81960314); National Natural Science Foundation of China, NSFC; Guizhou Science and Technology Department, (QKHJC[2016]1096, QKHPTRC[2017]5724, QKHPTRC[2019]5803, QKHZC[2019]2810); Guizhou Science and Technology Department; Natural Science Foundation of Beijing Municipality, (JQ19015); Natural Science Foundation of Beijing Municipality; National Postdoctoral Program for Innovative Talents, (BX20190173); National Postdoctoral Program for Innovative Talents; National Key Research and Development Program of China, NKRDPC, (2018YFA0704000); National Key Research and Development Program of China, NKRDPC","","Cell Press",""
"Siddique N.; Paheding S.; Alom M.Z.; Devabhaktuni V.","Siddique, Nahian (55900730400); Paheding, Sidike (56585990900); Alom, Md Zahangir (35566178100); Devabhaktuni, Vijay (6602156750)","55900730400; 56585990900; 35566178100; 6602156750","Recurrent residual U-net with efficientnet encoder for medical image segmentation","2021","11735","","117350L","","","","10.1117/12.2591343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108804530&doi=10.1117%2f12.2591343&partnerID=40&md5=de5378a1b715eff2561eaedfdfd32eac","In recent years, deep learning for health care is rapidly infiltrating and transforming medical fields thanks to the advances in computing power, data availability, and algorithm development. In particular, U-Net, a deep learning technique, has achieved remarkable success in medical image segmentation and has become one of the premier tools in this area. While the accomplishments of U-Net and other deep learning algorithms are evident, there still exist many challenges in medical image processing to achieve human-like performance. In this paper, we propose a U-net architecture that integrates a residual skip connections and recurrent feedback with EfficientNet as a pretrained encoder. Residual connections help feature propagation in deep neural networks and significantly improve performance against networks with a similar number of parameters while recurrent connections ameliorate gradient learning. We also propose a second model that utilizes densely connected layers aiding deeper neural networks. EfficientNet is a family of powerful pretrained encoders that streamline neural network design. The use of EfficientNet as an encoder provides the network with robust feature extraction that can be used by the U-Net decoder to create highly accurate segmentation maps. The proposed networks are evaluated against state-of-the-art deep learning based segmentation techniques to demonstrate their superior performance. © 2021 SPIE","Biomedical imaging; DenseNet; EfficientNet encoder; ResNet; Segmentation; U-net","Backpropagation; Deep neural networks; Image segmentation; Medical image processing; Metadata; Multilayer neural networks; Pattern recognition; Signal encoding; Algorithm development; Data availability; Gradient learning; Improve performance; Learning techniques; Learning-based segmentation; Neural network designs; Robust feature extractions; Recurrent neural networks","","Alam M.S.","SPIE",""
"Bian X.; Luo X.; Wang C.; Liu W.; Lin X.","Bian, Xuesheng (57211312635); Luo, Xiongbiao (36630380200); Wang, Cheng (36990982800); Liu, Weiquan (57200601725); Lin, Xiuhong (57210911855)","57211312635; 36630380200; 36990982800; 57200601725; 57210911855","Optic disc and optic cup segmentation based on anatomy guided cascade network","2020","197","","105717","","","","10.1016/j.cmpb.2020.105717","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091042991&doi=10.1016%2fj.cmpb.2020.105717&partnerID=40&md5=7a0a87b66a408f1e10aad424009effcf","Background and Objective: Glaucoma, a worldwide eye disease, may cause irreversible vision damage. If not treated properly at an early stage, glaucoma eventually deteriorates into blindness. Various glaucoma screening methods, e.g. Ultrasound Biomicroscopy (UBM), Optical Coherence Tomography (OCT), and Heidelberg Retinal Scanner (HRT), are available. However, retinal fundus image photography examination, because of its low cost, is one of the most common solutions used to diagnose glaucoma. Clinically, the cup-to-disk ratio is an important indicator in glaucoma diagnosis. Therefore, precise fundus image segmentation to calculate the cup-to-disk ratio is the basis for screening glaucoma. Methods: In this paper, we propose a deep neural network that uses anatomical knowledge to guide the segmentation of fundus images, which accurately segments the optic cup and the optic disc in a fundus image to accurately calculate the cup-to-disk ratio. Optic disc and optic cup segmentation are typical small target segmentation problems in biomedical images. We propose to use an attention-based cascade network to effectively accelerate the convergence of small target segmentation during training and accurately reserve detailed contours of small targets. Results: Our method, which was validated in the MICCAI REFUGE fundus image segmentation competition, achieves 93.31% dice score in optic disc segmentation and 88.04% dice score in optic cup segmentation. Moreover, we win a high CDR evaluation score, which is useful for glaucoma screening. Conclusions: The proposed method successfully introduce anatomical knowledge into segmentation task, and achieve state-of-the-art performance in fundus image segmentation. It also can be used for both automatic segmentation and semiautomatic segmentation with human interaction. © 2020","Attention; Generative adversarial learning; Glaucoma; Segmentation","Diagnostic Techniques, Ophthalmological; Fundus Oculi; Glaucoma; Humans; Neural Networks, Computer; Optic Disk; Deep neural networks; Diagnosis; Ophthalmology; Optical tomography; Ultrasonic applications; Automatic segmentations; Biomedical images; Cup-to-disk ratios; Human interactions; Retinal fundus images; Semi-automatic segmentation; State-of-the-art performance; Ultrasound biomicroscopy; Article; binocular convergence; cup-to-disc ratio; deep neural network; eye fundus; generative adversarial learning; glaucoma; image analysis; image processing; image segmentation; instrument validation; intermethod comparison; measurement accuracy; optic disk; optic disk cup; segmentation algorithm; diagnostic imaging; glaucoma; human; visual system examination; Image segmentation","National Natural Science Foundation of China, NSFC, (U1605254)","","Elsevier Ireland Ltd","32957060"
"Liu D.; Zhang D.; Song Y.; Huang H.; Cai W.","Liu, Dongnan (57221104987); Zhang, Donghao (57189297987); Song, Yang (55722226800); Huang, Heng (57221180537); Cai, Weidong (14022230800)","57221104987; 57189297987; 55722226800; 57221180537; 14022230800","Panoptic Feature Fusion Net: A Novel Instance Segmentation Paradigm for Biomedical and Biological Images","2021","30","","9325955","2045","2059","14","10.1109/TIP.2021.3050668","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099723819&doi=10.1109%2fTIP.2021.3050668&partnerID=40&md5=4cc0b9ffb1679832de58cd09df7f2bc4","Instance segmentation is an important task for biomedical and biological image analysis. Due to the complicated background components, the high variability of object appearances, numerous overlapping objects, and ambiguous object boundaries, this task still remains challenging. Recently, deep learning based methods have been widely employed to solve these problems and can be categorized into proposal-free and proposal-based methods. However, both proposal-free and proposal-based methods suffer from information loss, as they focus on either global-level semantic or local-level instance features. To tackle this issue, we present a Panoptic Feature Fusion Net (PFFNet) that unifies the semantic and instance features in this work. Specifically, our proposed PFFNet contains a residual attention feature fusion mechanism to incorporate the instance prediction with the semantic features, in order to facilitate the semantic contextual information learning in the instance branch. Then, a mask quality sub-branch is designed to align the confidence score of each object with the quality of the mask prediction. Furthermore, a consistency regularization mechanism is designed between the semantic segmentation tasks in the semantic and instance branches, for the robust learning of both tasks. Extensive experiments demonstrate the effectiveness of our proposed PFFNet, which outperforms several state-of-The-Art methods on various biomedical and biological datasets.  © 1992-2012 IEEE.","fluorescence microscopy images; histopathology images; Instance segmentation; panoptic segmentation; plant phenotype images","Algorithms; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Plants; Semantics; Deep learning; Semantics; Background components; Biological image analysis; Contextual information; Learning-based methods; Object boundaries; Regularization mechanism; Semantic segmentation; State-of-the-art methods; algorithm; diagnostic imaging; human; image processing; plant; procedures; semantics; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.","33449878"
"Lampreave P.; Jimenez-Perez G.; Sanz I.; Gomez A.; Camara O.","Lampreave, P. (57219612997); Jimenez-Perez, G. (57215546973); Sanz, I. (57219607697); Gomez, A. (55429442800); Camara, O. (13907961100)","57219612997; 57215546973; 57219607697; 55429442800; 13907961100","Towards assisted electrocardiogram interpretation using an AI-enabled Augmented Reality headset","2021","9","4","","349","356","7","10.1080/21681163.2020.1835544","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094219168&doi=10.1080%2f21681163.2020.1835544&partnerID=40&md5=8350ee14b15230e28e24fe07860442ce","The interpretation of electrocardiograms (ECGs) is key for the diagnosis and monitoring of cardiovascular health. Despite the progressive digital transformation in healthcare, it is still common for clinicians to analyse ECG printed on paper. Although some systems provide signal processing-based ECG classification, clinicians often find it unreliable. Artificial Intelligence (AI) techniques are becoming state-of-the-art for ECG processing but the lack of digitised ECG has hampered the clinical translation of these techniques. Concurrently, we are living a rise in augmented reality (AR) technologies, with an increasing availability of devices. In this work, we present an automatic digitisation and assisted interpretation of ECG based on an AI-enabled Augmented Reality headset. The AR headset is used to acquire an image of the printed ECG, from which the digitised ECG signal is extracted. Afterwards, the digitised ECG is introduced into a Deep Learning (DL) algorithm pre-trained on a public database of 12-lead ECG recordings. The output of the DL algorithm classifies the ECG signal onto different cardiomyopathy categories, which is then visualized back in the AR headset. Preliminary classification results on simulated ECG images (96.5% of accuracy) confirm the potential of the developed approach to contribute on the digital transformation of ECG processing. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","augmented reality; deep learning; Electrocardiogram; medical data digitisation","Augmented reality; Biomedical signal processing; Deep learning; Artificial intelligence techniques; Data digitization; Deep learning; Digital transformation; Electrocardiogram signal; Healthcare IT; Medical data; Medical data digitization; Signal-processing; State of the art; Article; augmented reality; cardiomyopathy; convolutional neural network; deep learning; electrocardiogram; heart ventricle extrasystole; ST segment depression; supraventricular premature beat; Electrocardiography","Formation of Doctors, (PRE2018-084062); King's College Hospital NHS Foundation Trust; Ministerio de Ciencia, Innovación y Universidades, MCIU, (MDM-2015-0502, RTI2018-101193-B-I00); Ministerio de Ciencia, Innovación y Universidades, MCIU; National Institute for Health and Care Research, NIHR; Department of Health and Social Care, DH; King's College London; Ministerio de Economía y Competitividad, MINECO; Centro Singular de Investigación de Galicia, CINBIO","","Taylor and Francis Ltd.",""
"Contreras G.; Pabon J.; Garcia H.; Rojas F.; Arguello H.","Contreras, Ghiordy (57422578400); Pabon, Jhon (57422727600); Garcia, Hans (57192275191); Rojas, Fernando (58625491200); Arguello, Henry (44061135000)","57422578400; 57422727600; 57192275191; 58625491200; 44061135000","Correction of Designed Compressive Spectral Imaging Measurements Using a Deep Learning-Based Method","2021","","","","","","","10.1109/STSIVA53688.2021.9592024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123319777&doi=10.1109%2fSTSIVA53688.2021.9592024&partnerID=40&md5=c67ee5a3b1b27a6fb2787f03ff39a407","Spectral imaging offers useful additional information to improve or expand imaging applications such as biomedical images, identification of cultures, and surveillance. These applications take advantage of features involved in a spectral scene captured using, for instance, the Coded Aperture Snapshot Spectral Imagers (CASSI), that naturally embodies the compressing sensing principles, whose potential is diminished because in practice, sensing matrix loses the ideal characteristics. This paper uses a deep learning based method in order to correct the real-compressed measurements and estimate the ideal-corrected measurements. The correction is estimated from a matrix form of compressed measurements, with the representation of compressed spatial dimensions and the number of projections captured as shots. The performance of the model is measured using peak signal-To-noise ratio, and the structural similarity index, upon the recovered data cube with the gradient projection for sparse reconstruction algorithm. The outcomes show how the deep learning-based method improves the quality in reconstruction against image ground truth when the noise is not concerning. © 2021 IEEE.","compressing sensing; convolutional neural network; cost function; deep learning; real calibration; Sensing matrix","Convolutional neural networks; Cost functions; Deep learning; Image enhancement; Matrix algebra; Signal to noise ratio; Compressing sensing; Convolutional neural network; Cost-function; Deep learning; Imaging measurements; Learning-based methods; matrix; Real calibration; Sensing matrix; Spectral imaging; Spectroscopy","","","Institute of Electrical and Electronics Engineers Inc.",""
"He Z.; Liu X.; He H.; Wang H.","He, Zixiao (57222277243); Liu, Xinwen (57405531600); He, Hao (57404716500); Wang, Huan (55328611800)","57222277243; 57405531600; 57404716500; 55328611800","Dual Attention Convolutional Neural Network Based on Adaptive Parametric ReLU for Denoising ECG Signals with Strong Noise","2021","","","","779","782","3","10.1109/EMBC46164.2021.9630123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122515536&doi=10.1109%2fEMBC46164.2021.9630123&partnerID=40&md5=93a2abcea9ef0efd52189318fd165161","Electrocardiogram (ECG) signal is one of the most important methods for diagnosing cardiovascular diseases but is usually affected by noises. Denoising is therefore necessary before further analysis. Deep learning-related methods have been applied to image processing and other domains with great success but are rarely used for denoising ECG signals. This paper proposes an effective and simple model of encoder-decoder structure for denoising ECG signals (APR-CNN). Specifically, Adaptive Parametric ReLU (APReLU) and Dual Attention Module (DAM) are introduced in the model. Rectified Linear Unit (ReLU) is replaced with the APReLU for better negative information retainment. The DAM is an attention-based module consisting of a channel attention module and spatial attention module, through which the inter-spatial and inter-channel relationship of the input data are exploited. We tested our model on the MIT-BIH dataset, and the results show that the APR-CNN can handle ECG signals with a different signal-to-noise ratio (SNR). The comparative experiment proves our model is better than other deep learning and traditional methods.Clinical Relevance - This paper proposed a method capable of denoising ECG signals with strong noise to alleviate difficulties for further medical analysis. © 2021 IEEE.","","Algorithms; Electrocardiography; Image Processing, Computer-Assisted; Neural Networks, Computer; Signal-To-Noise Ratio; Biomedical signal processing; Convolutional neural networks; Deep learning; Electrocardiography; Image processing; Signal denoising; Cardiovascular disease; Convolutional neural network; De-noising; Decoder structures; Electrocardiogram signal; Encoder-decoder; Images processing; Linear units; Network-based; Simple modeling; algorithm; electrocardiography; image processing; signal noise ratio; Signal to noise ratio","Sichuan Province Science and Technology Support Program, (2020108)","","Institute of Electrical and Electronics Engineers Inc.","34891406"
"Khetrapal P.; Kadambari S.","Khetrapal, Pushkar (57222121871); Kadambari, Saraja (57222124037)","57222121871; 57222124037","Classification of Motor Imagery Waves using Hybrid-Convolutional Neural Network","2020","","","9342415","","","","10.1109/INDICON49873.2020.9342415","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101537652&doi=10.1109%2fINDICON49873.2020.9342415&partnerID=40&md5=79030b7d0cc4367e9b6bd2ca7b44824e","Brain Computer Interfaces augments, alters, or replaces a lost biological function. Recently, classification methods using CNN were proposed to achieve higher accuracy levels. Nonetheless, they use a single convolution for classification while the best scale differs from subject to subject. This paper proposes a different architecture of Deep learning that takes 'n' different uncorrelated features of same signal parallelly into non-shareable convolution input layers in the same network to predict kinetic motion of patients. That is referred to as 1-D Hybrid-Convolutional Neural Network. The general motivation towards this being accurate feature extraction when minimal dataset is available. This approach is performed over three features namely Power, Frequency Spectrum components and Power Spectral Density of a same segment of a signal. A detailed analysis on more than 1500 EEG recordings from 109 healthy subjects and a comparative edge to this study was performed using previous algorithms and the relative strength highlighted. © 2020 IEEE.","Brain Computer Interfaces; Convolutional Neural Networks; Deep Learning; Electroencephalogram; Hybrid-Convolutional Neural Networks","Biomedical signal processing; Brain computer interface; Convolution; Deep learning; Image classification; Spectral density; Accuracy level; Biological functions; Classification methods; Frequency spectra; Healthy subjects; Kinetic motion; Relative strength; Uncorrelated features; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Sharma K.; Alsadoon A.; Prasad P.W.C.; Al-Dala'in T.; Nguyen T.Q.V.; Pham D.T.H.","Sharma, Kiran (35410220500); Alsadoon, Abeer (56575128400); Prasad, P.W.C. (57215215975); Al-Dala'in, Thair (24824225200); Nguyen, Tran Quoc Vinh (57219026033); Pham, Duong Thu Hang (57219026095)","35410220500; 56575128400; 57215215975; 24824225200; 57219026033; 57219026095","A novel solution of using deep learning for left ventricle detection: Enhanced feature extraction","2020","197","","105751","","","","10.1016/j.cmpb.2020.105751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091056401&doi=10.1016%2fj.cmpb.2020.105751&partnerID=40&md5=dbd0f56fa4968bb1ab35c65eb250c9e2","Background and aim: deep learning algorithms have not been successfully used for the left ventricle (LV) detection in echocardiographic images due to overfitting and vanishing gradient descent problem. This research aims to increase accuracy and improves the processing time of the left ventricle detection process by reducing the overfitting and vanishing gradient problem. Methodology: the proposed system consists of an enhanced deep convolutional neural network with an extra convolutional layer, and dropout layer to solve the problem of overfitting and vanishing gradient. Data augmentation was used for increasing the accuracy of feature extraction for left ventricle detection. Results: four pathological groups of datasets were used for training and evaluation of the model: heart failure without infarction, heart failure with infarction, and hypertrophy, and healthy. The proposed model provided an accuracy of 94% in left ventricle detection for all the groups compared to the other current systems. The results showed that the processing time was reduced from 0.45 s to 0.34 s in an average. Conclusion: the proposed system enhances accuracy and decreases processing time in the left ventricle detection. This paper solves the issues of overfitting of the data. © 2020","Convolutional neural network; Deep learning; Left ventricle; Myocardium; Normalization Feature extraction; Overfitting","Algorithms; Deep Learning; Heart Ventricles; Neural Networks, Computer; Biomedical signal processing; Cardiology; Convolution; Convolutional neural networks; Deep neural networks; Echocardiography; Extraction; Feature extraction; Gradient methods; Learning algorithms; Multilayer neural networks; Data augmentation; Detection process; Echocardiographic images; Heart failure; Left ventricles; Overfitting; Processing time; Vanishing gradient; Article; augmentation index; cardiovascular magnetic resonance; clinical evaluation; comparative study; controlled study; convolutional neural network; deep learning; diagnostic accuracy; echocardiography; feature extraction; heart; heart failure; heart infarction; heart left ventricle; heart left ventricle failure; heart left ventricle hypertrophy; histopathology; human; human tissue; image processing; image reconstruction; image segmentation; algorithm; diagnostic imaging; heart ventricle; Deep learning","","","Elsevier Ireland Ltd","32957061"
"Karim M.R.; Beyan O.; Zappa A.; Costa I.G.; Rebholz-Schuhmann D.; Cochez M.; Decker S.","Karim, Md Rezaul (57549413100); Beyan, Oya (35785660100); Zappa, Achille (36674289300); Costa, Ivan G. (57061996900); Rebholz-Schuhmann, Dietrich (6507852707); Cochez, Michael (55814163300); Decker, Stefan (8846837500)","57549413100; 35785660100; 36674289300; 57061996900; 6507852707; 55814163300; 8846837500","Deep learning-based clustering approaches for bioinformatics","2021","22","1","","393","415","22","10.1093/bib/bbz170","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100279573&doi=10.1093%2fbib%2fbbz170&partnerID=40&md5=4b04dd8d4299eefc5f2ba693d0d73723","Clustering is central to many data-driven bioinformatics research and serves a powerful computational method. In particular, clustering helps at analyzing unstructured and high-dimensional data in the form of sequences, expressions, texts and images. Further, clustering is used to gain insights into biological processes in the genomics level, e.g. clustering of gene expressions provides insights on the natural structure inherent in the data, understanding gene functions, cellular processes, subtypes of cells and understanding gene regulations. Subsequently, clustering approaches, including hierarchical, centroid-based, distribution-based, density-based and self-organizing maps, have long been studied and used in classical machine learning settings. In contrast, deep learning (DL)-based representation and feature learning for clustering have not been reviewed and employed extensively. Since the quality of clustering is not only dependent on the distribution of data points but also on the learned representation, deep neural networks can be effective means to transform mappings from a high-dimensional data space into a lower-dimensional feature space, leading to improved clustering results. In this paper, we review state-of-the-art DL-based approaches for cluster analysis that are based on representation learning, which we hope to be useful, particularly for bioinformatics research. Further, we explore in detail the training procedures of DL-based clustering algorithms, point out different clustering quality metrics and evaluate several DL-based approaches on three bioinformatics use cases, including bioimaging, cancer genomics and biomedical text mining. We believe this review and the evaluation results will provide valuable insights and serve a starting point for researchers wanting to apply DL-based unsupervised methods to solve emerging bioinformatics research problems.  © 2021 The Author(s) 2020. Published by Oxford University Press.","","Cluster Analysis; Computational Biology; Deep Learning; article; bioinformatics; cluster analysis; clustering algorithm; deep learning; deep neural network; mining; oncogenomics; biology; procedures","","","Oxford University Press","32008043"
"Lee D.-Y.; Lee M.; Lee S.-W.","Lee, Dong-Yeon (57219791912); Lee, Minji (57196187332); Lee, Seong-Whan (7601390519)","57219791912; 57196187332; 7601390519","Decoding Imagined Speech Based on Deep Metric Learning for Intuitive BCI Communication","2021","29","","9481777","1363","1374","11","10.1109/TNSRE.2021.3096874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110849691&doi=10.1109%2fTNSRE.2021.3096874&partnerID=40&md5=ecbcc9b5f1ada9e2aa787b2a9484925c","Imagined speech is a highly promising paradigm due to its intuitive application and multiclass scalability in the field of brain-computer interfaces. However, optimal feature extraction and classifiers have not yet been established. Furthermore, retraining still requires a large number of trials when new classes are added. The aim of this study is (i) to increase the classification performance for imagined speech and (ii) to apply a new class using a pretrained classifier with a small number of trials. We propose a novel framework based on deep metric learning that learns the distance by comparing the similarity between samples. We also applied the instantaneous frequency and spectral entropy used for speech signals to electroencephalography signals during imagined speech. The method was evaluated on two public datasets (6-class Coretto DB and 5-class BCI Competition DB). We achieved a 6-class accuracy of 45.00 ± 3.13% and a 5-class accuracy of 48.10 ± 3.68% using the proposed method, which significantly outperformed state-of-the-art methods. Additionally, we verified that the new class could be detected through incremental learning with a small number of trials. As a result, the average accuracy is 44.50 ± 0.26% for Coretto DB and 47.12 ± 0.27% for BCI Competition DB, which shows similar accuracy to baseline accuracy without incremental learning. Our results have shown that the accuracy can be greatly improved even with a small number of trials by selecting appropriate features from imagined speech. The proposed framework could be directly used to help construct an extensible intuitive communication system based on brain-computer interfaces. © 2001-2011 IEEE.","brain-computer interface; deep metric learning; Imagined speech; instantaneous frequency; spectral entropy","Algorithms; Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Speech; Biomedical signal processing; Deep learning; Electroencephalography; Electrophysiology; Speech; Speech communication; Baseline accuracy; Classification performance; Incremental learning; Instantaneous frequency; Metric learning; Spectral entropy; Speech signals; State-of-the-art methods; Article; artificial neural network; body movement; classification algorithm; classifier; comparative study; controlled study; convolutional neural network; entropy; extracellular matrix; feature extraction; Fourier transform; human; image analysis; learning algorithm; machine learning; magnetoencephalography; mathematical analysis; measurement accuracy; nerve cell network; selectivity index; short term memory; signal noise ratio; signal processing; signal transduction; spectral entropy; speech intelligibility; support vector machine; algorithm; brain computer interface; electroencephalography; imagination; speech; Brain computer interface","Artificial Intelligence Graduate School Program; Institute of Information and Communications Technology Planning and Evaluation; Korea University, KU, (2019-0-00079); Institute for Information and Communications Technology Promotion, IITP, (2017-0-00451); Ministry of Science and ICT, South Korea, MSIT","","Institute of Electrical and Electronics Engineers Inc.","34255630"
"Schoppe O.; Pan C.; Coronel J.; Mai H.; Rong Z.; Todorov M.I.; Müskes A.; Navarro F.; Li H.; Ertürk A.; Menze B.H.","Schoppe, Oliver (55873688200); Pan, Chenchen (57190853799); Coronel, Javier (57212245605); Mai, Hongcheng (57217617875); Rong, Zhouyi (57192696587); Todorov, Mihail Ivilinov (57210661021); Müskes, Annemarie (57219839293); Navarro, Fernando (57204015066); Li, Hongwei (57007362000); Ertürk, Ali (19933317600); Menze, Bjoern H. (35299840300)","55873688200; 57190853799; 57212245605; 57217617875; 57192696587; 57210661021; 57219839293; 57204015066; 57007362000; 19933317600; 35299840300","Deep learning-enabled multi-organ segmentation in whole-body mouse scans","2020","11","1","5626","","","","10.1038/s41467-020-19449-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095683226&doi=10.1038%2fs41467-020-19449-7&partnerID=40&md5=7ec8ba159e4431f7a80fffbe139ba3ca","Whole-body imaging of mice is a key source of information for research. Organ segmentation is a prerequisite for quantitative analysis but is a tedious and error-prone task if done manually. Here, we present a deep learning solution called AIMOS that automatically segments major organs (brain, lungs, heart, liver, kidneys, spleen, bladder, stomach, intestine) and the skeleton in less than a second, orders of magnitude faster than prior algorithms. AIMOS matches or exceeds the segmentation quality of state-of-the-art approaches and of human experts. We exemplify direct applicability for biomedical research for localizing cancer metastases. Furthermore, we show that expert annotations are subject to human error and bias. As a consequence, we show that at least two independently created annotations are needed to assess model performance. Importantly, AIMOS addresses the issue of human bias by identifying the regions where humans are most likely to disagree, and thereby localizes and quantifies this uncertainty for improved downstream analysis. In summary, AIMOS is a powerful open-source tool to increase scalability, reduce bias, and foster reproducibility in many areas of biomedical research. © 2020, The Author(s).","","Algorithms; Animal Structures; Animals; Brain; Deep Learning; Female; Image Processing, Computer-Assisted; Kidney; Liver; Lung; Male; Mice; Mice, Inbred C57BL; Reproducibility of Results; Spleen; Whole Body Imaging; X-Ray Microtomography; biome; cancer; error analysis; performance assessment; quantitative analysis; research work; rodent; segmentation; skeleton; ambiguity; animal experiment; Article; bladder; brain; cancer localization; computer prediction; contrast enhancement; controlled study; convolutional neural network; data processing; deep learning; error; female; heart; image segmentation; interpretation bias; intestine; kidney; liver; lung; male; medical research; metastasis; micro-computed tomography; mouse; nonhuman; quantitative analysis; reproducibility; sensitivity analysis; skeleton; spleen; stomach; uncertainty; volumetry; whole body scintiscanning; algorithm; animal; animal structures; C57BL mouse; diagnostic imaging; image processing; whole body imaging","Deutsche Forschungsgemeinschaft, DFG, (390857198); Bundesministerium für Bildung und Forschung, BMBF; Fritz Thyssen Stiftung, (ER 810/2-1); Stiftung zur Erforschung der Vaskulären Demenz","","Nature Research","33159057"
"","","","17th International Conference on Biomedical Engineering, ICBME 2019","2021","79","","","","","186","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101388125&partnerID=40&md5=d5a97e9aceea99cd27b256be9a361efa","The proceedings contain 17 papers. The special focus in this conference is on Biomedical Engineering. The topics include: Predictive Biomechanical Study on the Human Cervical Spine Under Complex Physiological Loading; influence of Compressive Preloading on Range of Motion and Endplate Stresses in the Cervical Spine During Flexion/Extension; Classification of Dementia MRI Images Using Hybrid Meta-Heuristic Optimization Techniques Based on Harmony Search Algorithm; classification of B-Cell Acute Lymphoblastic Leukemia Microscopic Images Using Crow Search Algorithm; Development of Optical Parametric Oscillator Source for Investigating Two-Photon Excitation PDT; skeletal Bone Age Assessment in Radiographs Based on Convolutional Neural Networks; an Evaluation on Effectiveness of Deep Learning in Detecting Small Object Within a Large Image; meshless Method for Numerical Solution of Fractional Pennes Bioheat Equation; a Dynamic Finite Element Simulation of the Mitral Heart Valve Closure; choroid Segmentation in Optical Coherence Tomography Images Using Deep Learning; design Concept for an Automated Lower Extremity Dressing Aid for Monoplegic and Elderly People; obstacle Detector and Qibla Finder for Visually Impaired Muslim Community; rejecting Artifacts Based on Identification of Optimal Independent Components in an Electroencephalogram During Cognitive Tasks; HydroGEV: Extracellular Vesicle-Laden Hydrogel for Wound Healing Applications; explainable and Actionable Machine Learning Models for Electronic Health Record Data.","","","","Lim C.T.; Leo H.L.; Yeow R.","Springer Science and Business Media Deutschland GmbH",""
"Tan X.; Su A.T.; Hajiabadi H.; Tran M.; Nguyen Q.","Tan, Xiao (57216313951); Su, Andrew T. (57216315385); Hajiabadi, Hamideh (54583546800); Tran, Minh (59103307100); Nguyen, Quan (57190382590)","57216313951; 57216315385; 54583546800; 59103307100; 57190382590","Applying Machine Learning for Integration of Multi-Modal Genomics Data and Imaging Data to Quantify Heterogeneity in Tumour Tissues","2021","2190","","","209","228","19","10.1007/978-1-0716-0826-5_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090226335&doi=10.1007%2f978-1-0716-0826-5_10&partnerID=40&md5=6426e6ebc9cb50056c8f7acf5ad4b349","With rapid advances in experimental instruments and protocols, imaging and sequencing data are being generated at an unprecedented rate contributing significantly to the current and coming big biomedical data. Meanwhile, unprecedented advances in computational infrastructure and analysis algorithms are realizing image-based digital diagnosis not only in radiology and cardiology but also oncology and other diseases. Machine learning methods, especially deep learning techniques, are already and broadly implemented in diverse technological and industrial sectors, but their applications in healthcare are just starting. Uniquely in biomedical research, a vast potential exists to integrate genomics data with histopathological imaging data. The integration has the potential to extend the pathologist’s limits and boundaries, which may create breakthroughs in diagnosis, treatment, and monitoring at molecular and tissue levels. Moreover, the applications of genomics data are realizing the potential for personalized medicine, making diagnosis, treatment, monitoring, and prognosis more accurate. In this chapter, we discuss machine learning methods readily available for digital pathology applications, new prospects of integrating spatial genomics data on tissues with tissue morphology, and frontier approaches to combining genomics data with pathological imaging data. We present perspectives on how artificial intelligence can be synergized with molecular genomics and imaging to make breakthroughs in biomedical and translational research for computer-aided applications. © 2021, Springer Science+Business Media, LLC, part of Springer Nature.","Cancer; Data integration; Gene expression; Genomics; Histopathological images; Machine learning; Spatial transcriptomics","Algorithms; Artificial Intelligence; Diagnostic Imaging; Genomics; Humans; Machine Learning; Neoplasms; Precision Medicine; Prognosis; autoencoder; cancer cell; cancer diagnosis; cancer tissue; cell heterogeneity; convolutional neural network; data integration; deep learning; genomics; histopathology; human; image analysis; machine learning; medical research; molecular genetics; molecular imaging; transfer of learning; translational research; algorithm; artificial intelligence; diagnostic imaging; genomics; neoplasm; pathology; personalized medicine; procedures; prognosis","Australian Research Council, ARC, (DE190100116); Australian Research Council, ARC; University of Queensland, UQ","","Humana Press Inc.","32804368"
"Mohammad A.; Siddiqui F.; Afshar Alam M.","Mohammad, Awwab (57222723357); Siddiqui, Farheen (55392678200); Afshar Alam, M. (20435724700)","57222723357; 55392678200; 20435724700","Feature extraction from EEG signals: A deep learning perspective","2021","","","9377108","757","760","3","10.1109/Confluence51648.2021.9377108","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103859071&doi=10.1109%2fConfluence51648.2021.9377108&partnerID=40&md5=d9ad48155ed0cc09365feb21fcce8447","The implementation of the learning model is primarily dependent on the features extracted from the EEG signals for any mental task classification model. A feature depicts an identifiable measurement, a unique property and a functional factor achieved from a section of a pattern. The main features which are extracted are mainly intended to limit the damage of significant data embedded in the signal and are also used to reduce resources required to illustrate a vast set of data precisely. This is important to reduce the expense of data handling, to limit the intricacy of usage and to remove the necessity of compressing the data. Different methods are applied to extract the features from EEG signals; among these methods are Empirical Wavelet Transform (EWT), Fuzzy C-means algorithm, Fuzzy Region of Interest Activity (FURIA). Studies have been made on EEG signals because of its capability to produce a method to calculate brain stimulation which is broadly used in brain-computer interface researches with uses in rehabilitation engineering and medical studies. The main objectives of this paper are to discuss some established methods of EEG feature extraction methods, comparing their performances for a particular task and suggesting the most appropriate method for feature extraction based on performance. © 2021 IEEE","BCI (Brain Computer Interface); CNN (Convolutional Neural Network); DWT (Discrete Wavelet Transform); EEG (Electroencephalography); EMD (Empirical Mode Decomposition); FCM (Fuzzy C-Means); IMF (Intrinsic Mode Function); LSTM (Long Short-Term Memory); RNN (Recurrent Neural Network); WPD (Wavelet Packet Decomposition); WT (Wavelet Transform)","Biomedical signal processing; Brain computer interface; Cloud computing; Clustering algorithms; Copying; Data Science; Extraction; Feature extraction; Fuzzy clustering; Image segmentation; Wavelet transforms; Brain stimulation; Feature extraction methods; Fuzzy C-means algorithms; Fuzzy region; Learning models; Medical studies; Mental task classification; Rehabilitation engineering; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","10th International Workshop on Clinical Image-Based Procedures, CLIP 2021, 2nd MICCAI Workshop on Distributed and Collaborative Learning, DCL 2021, 1st MICCAI Workshop, LL-COVID19, 1st Secure and Privacy-Preserving Machine Learning for Medical Imaging Workshop and Tutorial, PPML 2021, held in conjunction with 24th International Conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2021","2021","12969 LNCS","","","","","188","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120670667&partnerID=40&md5=d2d8d0fe0bacf848b549c7c0113ca065","The proceedings contain 17 papers. The special focus in this conference is on Clinical Image-Based Procedures. The topics include: DCL preface; LL-COVID-19 preface; PPML preface; intestine Segmentation with Small Computational Cost for Diagnosis Assistance of Ileus and Intestinal Obstruction; multi-task Federated Learning for Heterogeneous Pancreas Segmentation; federated Learning in the Cloud for Analysis of Medical Images - Experience with Open Source Frameworks; on the Fairness of Swarm Learning in Skin Lesion Classification; Lessons Learned from the Development and Application of Medical Imaging-Based AI Technologies for Combating COVID-19: Why Discuss, What Next; The Role of Pleura and Adipose in Lung Ultrasound AI; DuCN: Dual-Children Network for Medical Diagnosis and Similar Case Recommendation Towards COVID-19; data Imputation and Reconstruction of Distributed Parkinson’s Disease Clinical Assessments: A Comparative Evaluation of Two Aggregation Algorithms; defending Medical Image Diagnostics Against Privacy Attacks Using Generative Methods: Application to Retinal Diagnostics; generation of Patient-Specific, Ligamentoskeletal, Finite Element Meshes for Scoliosis Correction Planning; Bayesian Graph Neural Networks for EEG-Based Emotion Recognition; ViTBIS: Vision Transformer for Biomedical Image Segmentation; Attention-Guided Pancreatic Duct Segmentation from Abdominal CT Volumes; development of the Next Generation Hand-Held Doppler with Waveform Phasicity Predictive Capabilities Using Deep Learning; learning from Mistakes: An Error-Driven Mechanism to Improve Segmentation Performance Based on Expert Feedback.","","","","Oyarzun Laura C.; Cardoso M.J.; Rosen-Zvi M.; Kaissis G.; Linguraru M.G.; Shekhar R.; Wesarg S.; Erdt M.; Drechsler K.; Chen Y.; Albarqouni S.; Bakas S.; Landman B.; Rieke N.; Roth H.; Li X.; Xu D.; Gabrani M.; Konukoglu E.; Guindy M.; Rueckert D.; Ziller A.; Usynin D.; Passerat-Palmbach J.; Oyarzun Laura C.; Cardoso M.J.; Rosen-Zvi M.; Kaissis G.; Linguraru M.G.; Shekhar R.; Wesarg S.; Erdt M.; Drechsler K.; Chen Y.; Albarqouni S.; Bakas S.; Landman B.; Rieke N.; Roth H.; Li X.; Xu D.; Gabrani M.; Konukoglu E.; Guindy M.; Rueckert D.; Ziller A.; Usynin D.; Passerat-Palmbach J.","Springer Science and Business Media Deutschland GmbH",""
"Alqudah A.M.; Alquran H.; Qasmieh I.A.","Alqudah, Ali Mohammad (57189294287); Alquran, Hiam (56198738900); Qasmieh, Isam Abu (38961032500)","57189294287; 56198738900; 38961032500","Classification of heart sound short records using bispectrum analysis approach images and deep learning","2020","9","1","66","","","","10.1007/s13721-020-00272-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092328424&doi=10.1007%2fs13721-020-00272-5&partnerID=40&md5=a5b2e2de14a3fb202612769a2d9977d0","The diagnosis of cardiac disorders using heart sounds is one of the hottest topics in recent years. In general, diagnosing in the early stage is usually performed using routine auscultation examination using a stethoscope which requires human interpretation. Recording of heart sounds using an electronic microphone embedded inside the stethoscope provides a digital recording which is known as a phonocardiogram (PCG). This PCG signal carries very informative data about the status of the heart and its valves. Recently, several machines and deep learning techniques employed signal processing to classify heart disorders using PCG. Based on the used datasets, heart sound can be exploited to classify five types of heart sounds, one is normal, and the others are abnormal and two classes of heart sound, normal and abnormal. This research used a modified version of previously proposed convolutional neural network (CNN) which is AOCTNet architecture for automatic diagnosis of heart valves conditions based on higher order spectral estimation using bispectrum of heart sounds recordings. The results show that the proposed system has a comparable performance comparing to other methods. The methodology proposed in this paper can detect heart valves disorders using PCG signals with an overall accuracy of 98.70 and 97.10% using full bispectrum images and contour bispectrum images, respectively, for five classes dataset and overall accuracy of 99.47 and 98.74% using full bispectrum images and contour bispectrum images, respectively, for two classes dataset. © 2020, Springer-Verlag GmbH Austria, part of Springer Nature.","Bispectrum; Classification; Convolutional neural network; Deep learning; PCG","Biomedical signal processing; Cardiology; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Image classification; Learning systems; Phonocardiography; Spectrum analysis; Analysis approach; Bispectra; Bispectrum analysis; Classification of heart sounds; Convolutional neural network; Deep learning; Heart sounds; Heart valves; Overall accuracies; Phonocardiograms; accuracy; aortic stenosis; Article; artificial neural network; auscultation; convolutional neural network; deep learning; electroencephalography; Fourier transform; frequency; heart sound; human; image analysis; learning algorithm; machine learning; mathematical model; mitral valve prolapse; mitral valve regurgitation; mitral valve stenosis; phonocardiography; priority journal; sensitivity and specificity; signal processing; sound; systolic heart murmur; training; two-dimensional imaging; waveform; Heart","","","Springer",""
"Zhang R.; Guo Z.; Sun Y.; Lu Q.; Xu Z.; Yao Z.; Duan M.; Liu S.; Ren Y.; Huang L.; Zhou F.","Zhang, Ruochi (57196041167); Guo, Zhehao (57219109743); Sun, Yue (57221122033); Lu, Qi (57219110127); Xu, Zijian (57219109575); Yao, Zhaomin (57192304471); Duan, Meiyu (57212005263); Liu, Shuai (57200844289); Ren, Yanjiao (57201310055); Huang, Lan (55770288600); Zhou, Fengfeng (55634210800)","57196041167; 57219109743; 57221122033; 57219110127; 57219109575; 57192304471; 57212005263; 57200844289; 57201310055; 55770288600; 55634210800","COVID19XrayNet: A Two-Step Transfer Learning Model for the COVID-19 Detecting Problem Based on a Limited Number of Chest X-Ray Images","2020","12","4","","555","565","10","10.1007/s12539-020-00393-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091267952&doi=10.1007%2fs12539-020-00393-5&partnerID=40&md5=0573121222167824ca5b815cf49aedb4","The novel coronavirus severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a major pandemic outbreak recently. Various diagnostic technologies have been under active development. The novel coronavirus disease (COVID-19) may induce pulmonary failures, and chest X-ray imaging becomes one of the major confirmed diagnostic technologies. The very limited number of publicly available samples has rendered the training of the deep neural networks unstable and inaccurate. This study proposed a two-step transfer learning pipeline and a deep residual network framework COVID19XrayNet for the COVID-19 detection problem based on chest X-ray images. COVID19XrayNet firstly tunes the transferred model on a large dataset of chest X-ray images, which is further tuned using a small dataset of annotated chest X-ray images. The final model achieved 0.9108 accuracy. The experimental data also suggested that the model may be improved with more training samples being released. Graphic abstract: COVID19XrayNet, a two-step transfer learning framework designed for biomedical images.[Figure not available: see fulltext.] © 2020, International Association of Scientists in the Interdisciplinary Areas.","COVID19XrayNet; Feature extraction layer (FEL); Feature smoothing layer (FSL); ResNet34; Two-step transfer learning","Algorithms; Betacoronavirus; Clinical Laboratory Techniques; Coronavirus; Coronavirus Infections; Databases, Factual; Datasets as Topic; Deep Learning; Humans; Lung; Machine Learning; Models, Biological; Neural Networks, Computer; Pandemics; Pneumonia; Pneumonia, Viral; Radiography; Reference Values; Tomography, X-Ray Computed; X-Rays; algorithm; Betacoronavirus; biological model; complication; Coronavirinae; Coronavirus infection; diagnostic imaging; factual database; human; information processing; laboratory technique; lung; machine learning; pandemic; pneumonia; procedures; radiography; reference value; virology; virus pneumonia; X ray; x-ray computed tomography","High Performance Computing Center of Jilin University; Jilin Provincial Key Laboratory of Big Data Intelligent Computing, (20180622002JC); Jilin University, JLU, (BMCPP-2018-001); Education Department of Jilin Province, (JJKH20180145KJ); Fundamental Research Funds for the Central Universities","","Springer Science and Business Media Deutschland GmbH","32959234"
"Montalbo F.J.P.; Alon A.S.","Montalbo, Francis Jesmar P. (57212309186); Alon, Alvin S. (57212308862)","57212309186; 57212308862","Empirical analysis of a fine-tuned deep convolutional model in classifying and detecting Malaria parasites from blood smears","2021","15","1","","147","165","18","10.3837/TIIS.2021.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101860046&doi=10.3837%2fTIIS.2021.01.009&partnerID=40&md5=d7576a5820f229226a2a1dcf6d22bb13","In this work, we empirically evaluated the efficiency of the recent EfficientNetB0 model to identify and diagnose malaria parasite infections in blood smears. The dataset used was collected and classified by relevant experts from the Lister Hill National Centre for Biomedical Communications (LHNCBC). We prepared our samples with minimal image transformations as opposed to others, as we focused more on the feature extraction capability of the EfficientNetB0 baseline model. We applied transfer learning to increase the initial feature sets and reduced the training time to train our model. We then fine-tuned it to work with our proposed layers and re-trained the entire model to learn from our prepared dataset. The highest overall accuracy attained from our evaluated results was 94.70% from fifty epochs and followed by 94.68% within just ten. Additional visualization and analysis using the Gradient-weighted Class Activation Mapping (Grad-CAM) algorithm visualized how effectively our fine-tuned EfficientNetB0 detected infections better than other recent state-of-the-art DCNN models. This study, therefore, concludes that when fine-tuned, the recent EfficientNetB0 will generate highly accurate deep learning solutions for the identification of malaria parasites in blood smears without the need for stringent pre-processing, optimization, or data augmentation of images. © 2021 Korean Society for Internet Information. All rights reserved.","Convolutional Neural Networks; Deep Learning; Fine-Tuning; Malaria; Transfer Learning","Activation analysis; Deep learning; Diseases; Image processing; Transfer learning; Activation mapping; Biomedical communication; Convolutional model; Empirical analysis; Extraction capability; Image transformations; Overall accuracies; Visualization and analysis; Blood","","","Korean Society for Internet Information",""
"Greeshma K.V.; Viji Gripsy J.","Greeshma, K.V. (57207827443); Viji Gripsy, J. (56153136500)","57207827443; 56153136500","A Review on Classification and Retrieval of Biomedical Images Using Artificial Intelligence","2021","","","","47","66","19","10.1007/978-3-030-75220-0_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113298343&doi=10.1007%2f978-3-030-75220-0_3&partnerID=40&md5=8a60c66169c30ef76a75dd4c257d5b3c","Image retrieval and classification are the most prominent area of research in computer vision. Nowadays, bounteous medical images are generated through different types of medical imaging modalities in healthcare systems. It is often very difficult for researchers and doctors to access manage and retrieve images easily. The efficient and effective analysis and usage of heterogeneous biomedical images growing rapidly are a tedious task. Content-based image retrieval (CBIR) is one of the most widely used methods for automatic retrieval of images and widely used in medical images. Abundant research articles are published in different domain of applications related to CBIR and classification. The aim of this study is to provide a road map for researchers by exploring the various approaches, techniques, and algorithms used for medical image retrieval and classification. Feature extraction is the main subject for improving the performance of image classification and retrieval. Bag of visual words techniques and deep convolutional neural networks are widely used in content-based medical image retrieval (CBMIR). The state-of-the-art methods presented in this review are well suited to classify and retrieve multimodal medical images for different body organs. The methods include preprocessing of images, feature extraction, classification, and retrieval steps to develop an efficient biomedical image retrieval system. This chapter briefly reviews the various techniques used for biomedical images, and different methods adopted in classification and retrieval are focused. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Artificial intelligence; Bag of visual words; BoVW; CBIR; CBMIR; CNN; Content-based image retrieval; Content-based medical image retrieval; CT; Deep learning; Image classification; Internet of medical things; IoMT; IOT; Machine learning; MRI; Support vector machine","Biomedical signal processing; Classification (of information); Content based retrieval; Convolutional neural networks; Deep neural networks; Extraction; Feature extraction; Image classification; Image enhancement; Medical imaging; Automatic retrieval; Bag-of-visual-words; Content based medical image retrieval; Content-Based Image Retrieval; Effective analysis; Multimodal medical images; Preprocessing of image; State-of-the-art methods; Search engines","","","Springer Science and Business Media Deutschland GmbH",""
"Larrazabal A.J.; Martínez C.; Glocker B.; Ferrante E.","Larrazabal, Agostina J. (57208260242); Martínez, César (8118083200); Glocker, Ben (23396784900); Ferrante, Enzo (55892013900)","57208260242; 8118083200; 23396784900; 55892013900","Post-DAE: Anatomically Plausible Segmentation via Post-Processing with Denoising Autoencoders","2020","39","12","9126830","3813","3820","7","10.1109/TMI.2020.3005297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092739004&doi=10.1109%2fTMI.2020.3005297&partnerID=40&md5=2370e176dd25be3b12b72b563fed9c85","We introduce Post-DAE, a post-processing method based on denoising autoencoders (DAE) to improve the anatomical plausibility of arbitrary biomedical image segmentation algorithms. Some of the most popular segmentation methods (e.g. based on convolutional neural networks or random forest classifiers) incorporate additional post-processing steps to ensure that the resulting masks fulfill expected connectivity constraints. These methods operate under the hypothesis that contiguous pixels with similar aspect should belong to the same class. Even if valid in general, this assumption does not consider more complex priors like topological restrictions or convexity, which cannot be easily incorporated into these methods. Post-DAE leverages the latest developments in manifold learning via denoising autoencoders. First, we learn a compact and non-linear embedding that represents the space of anatomically plausible segmentations. Then, given a segmentation mask obtained with an arbitrary method, we reconstruct its anatomically plausible version by projecting it onto the learnt manifold. The proposed method is trained using unpaired segmentation mask, what makes it independent of intensity information and image modality. We performed experiments in binary and multi-label segmentation of chest X-ray and cardiac magnetic resonance images. We show how erroneous and noisy segmentation masks can be improved using Post-DAE. With almost no additional computation cost, our method brings erroneous segmentations back to a feasible space. © 1982-2012 IEEE.","Anatomical segmentation; autoencoders; convolutional neural networks; learning representations; post-processing","Algorithms; Brain; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Bioinformatics; Convolutional neural networks; Decision trees; Image enhancement; Learning systems; Magnetic resonance; Magnetic resonance imaging; Processing; Biomedical image segmentation; Cardiac magnetic resonance images; Connectivity constraints; Intensity information; Latest development; Postprocessing methods; Random forest classifier; Segmentation methods; Article; cardiovascular magnetic resonance; deep learning; denoising autoencoder; human; image processing; image segmentation; quantitative analysis; random forest; segmentation algorithm; thorax radiography; algorithm; brain; diagnostic imaging; image processing; nuclear magnetic resonance imaging; Image segmentation","ANPyCT, (PICT 2016-0651, PICT 2018-03907); AXA Research Fund, AXA; Agencia Nacional de Promoción Científica y Tecnológica, ANPCyT; Universidad Nacional del Litoral, UNL, (CAID-PIC-50220140100084LI, CAID-PIC-50420150100098LI)","","Institute of Electrical and Electronics Engineers Inc.","32746125"
"Viteri J.A.; Loayza F.R.; Pelaez E.; Layedra F.","Viteri, José A. (57194440742); Loayza, Francis R. (28267792700); Pelaez, Enrique (57350001200); Layedra, Fabricio (57195297086)","57194440742; 28267792700; 57350001200; 57195297086","Automatic brain white matter hypertinsities segmentation using deep learning techniques","2021","","","","244","252","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103841806&partnerID=40&md5=0361162c42c1de0094dd9bbff7552711","White Matter Hyperintensities (WMH) are lesions observed in the brain as bright regions in Fluid Attenuated Inversion Recovery (FLAIR) images from Magnetic Resonance Imaging (MRI). Its presence is related to conditions such as aging, small vessel diseases, stroke, depression, and neurodegenerative diseases. Currently, WMH detection is done by specialized radiologists. However, deep learning techniques can learn the patterns from images and later recognize this kind of lesions automatically. This team participated in the MICCAI WMH segmentation challenge, which was released in 2017. A dataset of 60 pairs of human MRI images was provided by the contest, which consisted of T1, FLAIR and ground-truth images per subject. For segmenting the images a 21 layer Convolutional Neural Network-CNN with U-Net architecture was implemented. For validating the model, the contest reserved 110 additional images, which were used to test this method’s accuracy. Results showed an average of 78% accuracy and lesion recall, 74% of lesion f1, 6.24mm of Hausdorff distance, and 28% of absolute percentage difference. In general, the algorithm performance showed promising results, with the validation images not used for training. This work could lead other research teams to push the state of the art in WMH images segmentation. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.","Convolutional Neural Network; U-Net; WMH Segmentation","Biomedical engineering; Convolutional neural networks; Engineering research; Image segmentation; Learning systems; Magnetic resonance imaging; Medical informatics; Multilayer neural networks; Network layers; Neurodegenerative diseases; Algorithm performance; Fluid attenuated inversion recoveries; Hausdorff distance; Images segmentations; Learning techniques; NET architecture; State of the art; White matter hyperintensities; Deep learning","","Pesquita C.; Fred A.; Gamboa H.","SciTePress",""
"Zolfaghari S.; Rezaii T.Y.; Meshgini S.; Farzamnia A.","Zolfaghari, Sepideh (57218271665); Rezaii, Tohid Yousefi (24776924800); Meshgini, Saeed (26648943100); Farzamnia, Ali (48761265400)","57218271665; 24776924800; 26648943100; 48761265400","Using convolution neural networks pattern for classification of motor imagery in bci system","2021","666","","","683","692","9","10.1007/978-981-15-5281-6_48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088531023&doi=10.1007%2f978-981-15-5281-6_48&partnerID=40&md5=05941653dd047f70a81f9da9a219171d","The Electroencephalography (EEG) based Brain-computer interfaces (BCI) enable humans to control external devices through extracts informative features from brain signals and convert these features into control commands. Deep learning methods have been the advanced classification algorithms used in various applications. In this paper, the informative features of EEG signals are obtained using the filter-bank common spatial pattern (FBCSP), then the selected features which are prepared using the mutual information method are fed to the classifiers as input. Convolution neural network (CNN), Naive Bayesian (NB), multiple support vector machines (SVM) and linear discriminant analysis (LDA) algorithms are used to classify EEG signals into left and right hand motor imagery (MI) across nine subjects. Our framework has been tested on BCI competition IV-2a 4-class dataset. The results are shown that the CNN classifier has yielded the best average classification accuracy, with 99.77% as compared to other classification methods. The experimental results represent that our proposed method can obtain more refined control in the BCI applications such as controlling robot arm movement. © Springer Nature Singapore Pte Ltd 2021.","Brain-computer interface (BCI); Convolution neural network (CNN); Electroencephalography (EEG); Filter-bank common spatial pattern (FBCSP); Motor imagery (MI)","Brain computer interface; Convolution; Deep learning; Discriminant analysis; Electroencephalography; Electrophysiology; Image classification; Learning systems; Neural networks; Support vector machines; Classification accuracy; Classification algorithm; Classification methods; Common spatial patterns; Convolution neural network; Hand motor imageries; Linear discriminant analysis; Mutual information method; Biomedical signal processing","Center for Research and Innovation; Faculty of Engineering, Universiti Malaysia Sabah; Pusat Pengurusan Penyelidikan dan Instrumentasi, CRIM-UKM; Universitas Muhammadiyah Surakarta, UMS, (SBK0393-2018)","Md Zain Z.; Ahmad H.; Pebrianti D.; Mustafa M.; Abdullah N.R.H.; Samad R.; Mat Noh M.","Springer",""
"Samuel O.W.; Asogbon M.G.; Ejay E.; Geng Y.; Lopez-Delis A.; Jarrah Y.A.; Idowu O.P.; Chen S.; Fang P.; Li G.","Samuel, Oluwarotimi Williams (57188828713); Asogbon, Mojisola Grace (57195775424); Ejay, Esugbe (57404743600); Geng, Yanjuan (36813330600); Lopez-Delis, Alberto (55976515500); Jarrah, Yazan Ali (57223108450); Idowu, Oluwagbenga Paul (57206899099); Chen, Shixiong (35236039500); Fang, Peng (55435067200); Li, Guanglin (7407054228)","57188828713; 57195775424; 57404743600; 36813330600; 55976515500; 57223108450; 57206899099; 35236039500; 55435067200; 7407054228","A Low-rank Spatiotemporal based EEG Multi-Artifacts Cancellation Method for Enhanced ConvNet-DL's Motor Imagery Characterization","2021","","","","791","794","3","10.1109/EMBC46164.2021.9629547","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122507349&doi=10.1109%2fEMBC46164.2021.9629547&partnerID=40&md5=86a86d4c19140dd6d734fe46ff591c72","Multi-channel Electroencephalograph (EEG) signal is an important source of neural information for motor imagery (MI) limb movement intent decoding. The decoded MI movement intent often serve as potential control input for brain-computer interface (BCI) based rehabilitation robots. However, the presence of multiple dynamic artifacts in EEG signal leads to serious processing challenge that affects the BCI system in practical settings. Hence, this study propose a hybrid approach based on Low-rank spatiotemporal filtering technique for concurrent elimination of multiple EEG artifacts. Afterwards, a convolutional neural network based deep learning model (ConvNet-DL) that extracts neural information from the cleaned EEG signal for MI tasks decoding was built. The proposed method was studied in comparison with existing artifact removal methods using EEG signals of transhumeral amputees who performed five different MI tasks. Remarkably, the proposed method led to significant improvements in MI task decoding accuracy for the ConvNet-DL model in the range of 8.00~13.98%, while up to 14.38% increment was recorded in terms of the MCC: Mathew correlation coefficients at p<0.05. Also, a signal to error ratio of more than 11 dB was recorded by the proposed method.Clinical Relevance - This study showed that a combination of the proposed hybrid EEG artifact removal method and ConvNet-DL can significantly improve the decoding accuracy of MI upper limb movement tasks. Our findings may provide potential control input for BCI rehabilitation robotic systems. © 2021 IEEE.","","Algorithms; Artifacts; Brain-Computer Interfaces; Electroencephalography; Imagination; Biomedical signal processing; Brain computer interface; Convolutional neural networks; Deep learning; Electroencephalography; Image enhancement; Control inputs; Convolutional neural network; Electroencephalograph signals; Learning models; Limb movements; Motor imagery; Motor imagery tasks; Network-based; Neural information; Potential control; algorithm; artifact; brain computer interface; electroencephalography; imagination; Decoding","National Natural Science Foundation of China, NSFC, (82050410452)","","Institute of Electrical and Electronics Engineers Inc.","34891409"
"bouny L.E.; Khalil M.; Adib A.","bouny, Lahcen El (57200512586); Khalil, Mohammed (55628523934); Adib, Abdellah (57222401572)","57200512586; 55628523934; 57222401572","An End-to-End Multi-Level Wavelet Convolutional Neural Networks for heart diseases diagnosis","2020","417","","","187","201","14","10.1016/j.neucom.2020.07.056","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089814880&doi=10.1016%2fj.neucom.2020.07.056&partnerID=40&md5=990be8fe0d338e87ebe07f2cbc1aec94","This paper presents a new End-to-End Deep Learning method for heart diseases diagnosis from single channel ECG signal. Motivated by the great efficiency and popularity of deep learning algorithms for time series classification, the proposed work is mainly based on the One Dimensional Convolutional Neural Networks (1D-CNN). Unlike the traditional CNN models based classification, a new Multi-Level Wavelet Convolutional Neural Networks (ML-WCNN) is proposed to recognize automatically various types of cardiac arrhythmias. The proposed approach incorporates the 1D-CNN model and the Stationary Wavelet Transform (SWT) to extract discriminative features from different wavelet sub-bands and from the raw ECG signal simultaneously. The extracted features by the ML-WCNN model are then merged using different fusion strategies, especially by concatenation and maximization. This improves greatly the features learning process at different scales of the ECG signal, providing better diagnosis performances. The proposed ML-WCNN framework is evaluated on the Standard Database MIT-BIH Arrhythmia considering six classes of heart Beats: Normal (N), Premature Ventricular Contraction (PVC), Right Bundle Brunch Block (RBBB), Left Bundle Brunch Block (LBBB), Atrial Premature Contraction (APC) and Paced beats (PAC). The experimental results demonstrate the superiority of the proposed ML-WCNN, in comparison with the state-of-the-art heart diseases diagnosis based Machine/Deep learning algorithms, with a maximum Accuracy of 99.57% using the 10-fold cross validation technique. © 2020 Elsevier B.V.","Convolutional Neural Networks; Deep learning; ECG classification; Heart diseases; Stationary Wavelet Transform","Biomedical signal processing; Cardiology; Convolution; Convolutional neural networks; Deep learning; Diseases; Electrocardiography; Heart; Learning systems; Wavelet transforms; 10-fold cross-validation; Atrial premature contraction; Diagnosis performance; Different wavelets; Discriminative features; Premature ventricular contraction; Stationary wavelet transforms; Time series classifications; Article; bidirectional long short term memory network; continuous wavelet transform; convolutional neural network; deep learning; diagnostic accuracy; discrete wavelet transform; electroencephalography; empirical mode decomposition; end to end multi level wavelet convolutional neural network; heart arrhythmia; heart disease; heart left bundle branch block; heart right bundle branch block; heart ventricle extrasystole; human; image processing; k nearest neighbor; long short term memory network; machine learning; multilayer perceptron; priority journal; sensitivity and specificity; signal processing; stationary wavelet transform; support vector machine; supraventricular premature beat; validation process; Learning algorithms","Center for Scientific and Technical Research of Morocco, (18UH2C2017)","","Elsevier B.V.",""
"Alsaade F.W.; Aldhyani T.H.H.; Al-Adhaileh M.H.","Alsaade, Fawaz Waselallah (22937047900); Aldhyani, Theyazn H. H. (57191275820); Al-Adhaileh, Mosleh Hmoud (24464269700)","22937047900; 57191275820; 24464269700","Developing a Recognition System for Diagnosing Melanoma Skin Lesions Using Artificial Intelligence Algorithms","2021","2021","","9998379","","","","10.1155/2021/9998379","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107175102&doi=10.1155%2f2021%2f9998379&partnerID=40&md5=77fd5d112a8db69e57c4d04d501c0764","In recent years, computerized biomedical imaging and analysis have become extremely promising, more interesting, and highly beneficial. They provide remarkable information in the diagnoses of skin lesions. There have been developments in modern diagnostic systems that can help detect melanoma in its early stages to save the lives of many people. There is also a significant growth in the design of computer-aided diagnosis (CAD) systems using advanced artificial intelligence. The purpose of the present research is to develop a system to diagnose skin cancer, one that will lead to a high level of detection of the skin cancer. The proposed system was developed using deep learning and traditional artificial intelligence machine learning algorithms. The dermoscopy images were collected from the PH2 and ISIC 2018 in order to examine the diagnose system. The developed system is divided into feature-based and deep leaning. The feature-based system was developed based on feature-extracting methods. In order to segment the lesion from dermoscopy images, the active contour method was proposed. These skin lesions were processed using hybrid feature extractions, namely, the Local Binary Pattern (LBP) and Gray Level Co-occurrence Matrix (GLCM) methods to extract the texture features. The obtained features were then processed using the artificial neural network (ANNs) algorithm. In the second system, the convolutional neural network (CNNs) algorithm was applied for the efficient classification of skin diseases; the CNNs were pretrained using large AlexNet and ResNet50 transfer learning models. The experimental results show that the proposed method outperformed the state-of-art methods for HP2 and ISIC 2018 datasets. Standard evaluation metrics like accuracy, specificity, sensitivity, precision, recall, and F-score were employed to evaluate the results of the two proposed systems. The ANN model achieved the highest accuracy for PH2 (97.50%) and ISIC 2018 (98.35%) compared with the CNN model. The evaluation and comparison, proposed systems for classification and detection of melanoma are presented.  © 2021 Fawaz Waselallah Alsaade et al.","","Algorithms; Artificial Intelligence; Computational Biology; Databases, Factual; Deep Learning; Dermoscopy; Diagnosis, Computer-Assisted; Early Detection of Cancer; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Melanoma; Neural Networks, Computer; Skin Diseases; Skin Neoplasms; Arts computing; Chemical detection; Computer aided diagnosis; Convolutional neural networks; Deep learning; Dermatology; Diseases; Image segmentation; Learning algorithms; Medical imaging; Oncology; Textures; Transfer learning; Active contour method; Artificial intelligence algorithms; Computer Aided Diagnosis(CAD); Feature extracting method; Gray level co occurrence matrix(GLCM); Hybrid-feature extraction; Local binary patterns; State-of-art methods; Article; artificial intelligence; artificial neural network; basal cell carcinoma; cancer classification; cancer diagnosis; comparative study; controlled study; convolutional neural network; cutaneous melanoma; deep learning; diagnostic accuracy; diagnostic test accuracy study; dysplastic nevus; epiluminescence microscopy; feature detection; feature extraction; gray level co occurrence matrix; human; image processing; keratosis; local binary pattern; nevus; pigmented nevus; segmentation algorithm; sensitivity and specificity; signal processing; skin defect; transfer of learning; algorithm; artificial intelligence; biology; classification; computer assisted diagnosis; diagnostic imaging; early cancer diagnosis; factual database; image enhancement; melanoma; procedures; skin disease; skin tumor; Learning systems","","","Hindawi Limited","34055044"
"Hassan N.; Ming K.W.; Wah C.K.","Hassan, Nazirah (57217575538); Ming, Kong Wai (57481114100); Wah, Choo Keng (56243102900)","57217575538; 57481114100; 56243102900","An Evaluation on Effectiveness of Deep Learning in Detecting Small Object Within a Large Image","2021","79","","","175","186","11","10.1007/978-3-030-62045-5_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101405183&doi=10.1007%2f978-3-030-62045-5_17&partnerID=40&md5=4bb5f8ec902d2483e43fdf382a7177cf","Multiple Deep Learning (DL) algorithms have been developed recently and are shown to be achieving very high accuracy in object detection. However, challenges have been reported in detecting small objects within a large image (e.g. &gt; 2000 by 2000 in resolution). Various methods have been proposed using different detection algorithms in order to detect small objects. However, these approaches require high computational resources and are not suitable for edge computing devices that are used for practical applications such as pedestrian traffic light detection. We explored two different methods of detection to evaluate which method is best at detecting small objects. The first method is a two—part procedure with the first step being image processing and the second step, a R-CNN based detection using Edge Boxes algorithm for the extraction of region proposals. The second method is solely Faster R-CNN Object Detection with Instance Segmentation, termed as Mask R-CNN. A total of 4000 streets images of Singapore with pedestrian traffic lights were used as training data. The dimensions of the images range from 1200 by 900 to 4000 by 3000. The small object to be detected is the green or red man within pedestrian traffic lights. We evaluated these methods based on training time required, detection time, accuracy as well as suitability for deployment in edge computing devices. From the results, it is shown that the HSV + R-CNN approach is preferred as it achieves an accuracy of 95.5% and can be deployed in edge devices. © 2020, Springer Nature Switzerland AG.","Deep learning; Image segmentation; Mask R-CNN; Object classification; Object detection","Biomedical engineering; Convolutional neural networks; Deep learning; Edge computing; Edge detection; Object recognition; Computational resources; Computing devices; Detection algorithm; Detection time; High-accuracy; Pedestrian traffic; Training data; Training time; Object detection","","Lim C.T.; Leo H.L.; Yeow R.","Springer Science and Business Media Deutschland GmbH",""
"Yacin Sikkandar M.; Alrasheadi B.A.; Prakash N.B.; Hemalakshmi G.R.; Mohanarathinam A.; Shankar K.","Yacin Sikkandar, Mohamed (57219030202); Alrasheadi, Bader Awadh (57217594254); Prakash, N.B. (56490089000); Hemalakshmi, G.R. (56491355500); Mohanarathinam, A. (57211432916); Shankar, K. (56884031900)","57219030202; 57217594254; 56490089000; 56491355500; 57211432916; 56884031900","Deep learning based an automated skin lesion segmentation and intelligent classification model","2021","12","3","","3245","3255","10","10.1007/s12652-020-02537-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091064709&doi=10.1007%2fs12652-020-02537-3&partnerID=40&md5=09ef0a555326a28612eb6df4fe8a638a","Internet of Medical Things (IoMT) includes interconnected sensors, wearable devices, medical devices, and clinical systems. At the same time, skin cancer is a commonly available type of cancer that exists all over the globe. This study projects a new segmentation based classification model for skin lesion diagnosis by combining a GrabCut algorithm and Adaptive Neuro-Fuzzy classifier (ANFC) model. The proposed method involves four main steps: preprocessing, segmentation, feature extraction, and classification. Initially, the preprocessing step is carried out using a Top hat filter and inpainting technique. Then, the Grabcut algorithm is used to segment the preprocessed images. Next, the feature extraction process takes place by the use of a deep learning based Inception model. Finally, an adaptive neuro-fuzzy classifier (ANFC) system gets executed to classify the dermoscopic images into different classes. The proposed model is simulated using a benchmark International Skin Imaging Collaboration (ISIC) dataset and the results are examined interms of accuracy, sensitivity and specificity. The proposed model exhibits better identification and classification of skin cancer. For examining the effective outcome of the projected technique, an extensive comparison of the presented method with earlier models takes place. The experimental values indicated that the proposed method has offered a maximum sensitivity of 93.40%, specificity of 98.70% and accuracy of 97.91%. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Artifact removal; Deep learning; Feature extraction; IoMT; Skin lesion","Biomedical signal processing; Computer aided diagnosis; Dermatology; Diseases; Extraction; Feature extraction; Fuzzy inference; Fuzzy neural networks; Fuzzy sets; Image segmentation; Learning systems; Adaptive neuro-fuzzy; Classification models; Experimental values; Inpainting techniques; Intelligent classification; Maximum sensitivity; Pre-processing step; Sensitivity and specificity; Deep learning","Majmaah University, MU, (R-1441-165)","","Springer Science and Business Media Deutschland GmbH",""
"Karhan Z.; Akal F.","Karhan, Zehra (55806658100); Akal, Fuat (22233542100)","55806658100; 22233542100","Comparison of Tissue Classification Performance by Deep Learning and Conventional Methods on Colorectal Histopathological Images","2020","","","9299277","","","","10.1109/TIPTEKNO50054.2020.9299277","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099449885&doi=10.1109%2fTIPTEKNO50054.2020.9299277&partnerID=40&md5=6de6e73c6c0d02c5c99fa14f36fbb3c9","The automatic evaluation is essential for the diagnosis and treatment of the disease of pathological images. Computer-aided systems are becoming more common day by day in this area. In this study, multi-class (8 different classes) tissue types were studied in colon cancer histopathological images. Data mining algorithms are used in the diagnosis phase in the health field. As a conventional method, first of all, the properties of the images are extracted and then the texture classification process is performed with data mining algorithms. The Gray Level Co-occurrence Matrix (GLCM), Discrete Cosine Transform (DCT), Local Binary Pattern (LBP) are used in textural feature extraction. Along with these attributes, machine learning algorithms, such as k-nearest neighbors (KNN), support vector machines (SVM), random forests (RF), logistic regression (LR) were used for classification. As another method, to remove the attributes and perform classification at the same time, tissue classification was performed using deep learning (convolutional neural network) on histopathological images. Tissue classification was automated using transfer learning based on ResNet-18 architecture, one of the convolutional neural network architectures. According to the determined feature and classification algorithm, the performance rates are also given comparatively. Our experiments showed that RF classifier with LBP and GLCM features provided 82% accuracy, while the deep learning method based on ResNet-18 architecture achieved 88.5% accuracy. © 2020 IEEE.","Deep Learning; Feature Extraction; Histopathology; Pathology; Tissue Classification","Biomedical engineering; Classification (of information); Convolution; Convolutional neural networks; Decision trees; Deep learning; Diagnosis; Discrete cosine transforms; Diseases; Image classification; Learning systems; Logistic regression; Nearest neighbor search; Network architecture; Support vector machines; Support vector regression; Text mining; Textures; Tissue; Transfer learning; Classification algorithm; Computer-aided systems; Data mining algorithm; Discrete Cosine Transform(DCT); Gray level co occurrence matrix(GLCM); Histopathological images; K nearest neighbor (KNN); Texture classification; Learning algorithms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Račić L.; Popović T.; Čakić S.; Šandi S.","Račić, Luka (57223008261); Popović, Tomo (7006324784); Čakić, Stevan (57216726692); Šandi, Stevan (57193401703)","57223008261; 7006324784; 57216726692; 57193401703","Pneumonia Detection Using Deep Learning Based on Convolutional Neural Network","2021","","","9390137","","","","10.1109/IT51528.2021.9390137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104431624&doi=10.1109%2fIT51528.2021.9390137&partnerID=40&md5=220b902e2ad99c28a98cb623fc75984f","Artificial intelligence has found its use in various fields during the course of its development, especially in recent years with the enormous increase in available data. Its main task is to assist making better, faster and more reliable decisions. Artificial intelligence and machine learning are increasingly finding their application in medicine. This is especially true for medical fields that utilize various types of biomedical images and where diagnostic procedures rely on collecting and processing a large number of digital images. The application of machine learning in processing of medical images helps with consistency and boosts accuracy in reporting. This paper describes the use of machine learning algorithms to process chest X-ray images in order to support the decision making process in determining the correct diagnosis. Specifically, the research is focused on the use of deep learning algorithm based on convolutional neural network in order to build a processing model. This model has the task to help with a classification problem that is detecting whether a chest X-ray shows changes consistent with pneumonia or not, and classifying the X-ray images in two groups depending on the detection results.  © 2021 IEEE.","artificial intelligence; artificial intelligence; convolutional neural network; deep learning; image processing; convolutional neural network; deep learning; image processing, machine learning; machine learning; pneumonia detection; pneumonia detection","Convolution; Convolutional neural networks; Decision making; Deep learning; Diagnosis; Learning systems; Medical image processing; Biomedical images; Chest X-ray image; Chest x-rays; Decision making process; Diagnostic procedure; Digital image; Medical fields; Processing model; Learning algorithms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Ahmad M.F.; Akbar S.; Hassan S.A.E.; Rehman A.; Ayesha N.","Ahmad, Muhammad Faraz (57537256000); Akbar, Shahzad (57193566707); Hassan, Syed Al E (57221866077); Rehman, Amjad (35093155800); Ayesha, Noor (57205762422)","57537256000; 57193566707; 57221866077; 35093155800; 57205762422","Deep Learning Approach to Diagnose Alzheimer's Disease through Magnetic Resonance Images","2021","","","","","","","10.1109/ICIC53490.2021.9693041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126721988&doi=10.1109%2fICIC53490.2021.9693041&partnerID=40&md5=66494c0bc55cc887d969d8709f6774a3","Alzheimer's disease (AD) is the disease that is neurodegenerative which causes 70 to 80% of cases of dementia worldwide. Even though over the past few years' research on Alzheimer's disease has risen, Although, the brain function and structure complexity enables diagnosis still a difficult task. In recent years, Machine Learning approaches have played an essential role in understanding the deep analysis of diseases detection with the help of drug delivery and image processing units in biomedical science. These techniques have enhanced the efficiency and ability to understand complex medical situations. This paper investigates a Convolutional Neural Networks (CNN) based Algorithm of Deep learning and Computer-Aided Diagnosis (CAD) for the Alzheimer's disease (AD) early diagnosis by differentiating the affected brain and normal brain. Since detection of AD has been a difficult task. However, using CNN-based CAD, we successfully classify the MRI data of AD subjects with an accuracy rate of 97%. This research suggests that Deep Learning algorithms are the most successful methods for classifying clinical MRI subjects by the scale and shift homogeneous distill features extracted by a Convolutional Neural Network. In addition, this approach will help doctors and clinicians to understand and predict more complex systems in the biomedical field.  © 2021 IEEE.","Alzheimer Disease Detection; Computer-Aided Diagnosis (CAD); Convolutional Neural Network; Health care; Medical Reasoning Images","Clinical research; Complex networks; Computer aided instruction; Convolution; Convolutional neural networks; Deep learning; Learning algorithms; Magnetic resonance; Magnetic resonance imaging; Medical imaging; Neurodegenerative diseases; Alzheimer disease detection; Alzheimers disease; Brain structure; Computer-aided diagnose; Convolutional neural network; Disease detection; Learning approach; Medical reasoning image; Medical reasonings; Neurodegenerative; Computer aided diagnosis","Riphah Artificial Intelligence Research","","Institute of Electrical and Electronics Engineers Inc.",""
"Isensee F.; Jaeger P.F.; Kohl S.A.A.; Petersen J.; Maier-Hein K.H.","Isensee, Fabian (57194378532); Jaeger, Paul F. (57201075948); Kohl, Simon A. A. (57204142298); Petersen, Jens (56343682900); Maier-Hein, Klaus H. (55647018100)","57194378532; 57201075948; 57204142298; 56343682900; 55647018100","nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation","2021","18","2","","203","211","8","10.1038/s41592-020-01008-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097254681&doi=10.1038%2fs41592-020-01008-z&partnerID=40&md5=ec84e152cb0adba256bd723c59b59329","Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training. © 2020, The Author(s), under exclusive licence to Springer Nature America, Inc.","","Algorithms; Deep Learning; Image Processing, Computer-Assisted; Neural Networks, Computer; article; competition; deep learning; image segmentation; algorithm; image processing; procedures","","","Nature Research","33288961"
"Moon I.","Moon, Inkyu (55388941800)","55388941800","Artificial Intelligence in Digital Holographic Imaging: Technical Basis and Biomedical Applications","2021","","","","1","326","325","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145525317&partnerID=40&md5=10e63315c92a5467de73932bca3ea094","Artificial Intelligence in Digital Holographic Imaging Technical Basis and Biomedical Applications An eye-opening discussion of 3D optical sensing, imaging, analysis, and pattern recognition Artificial intelligence (AI) has made great progress in recent years. Digital holographic imaging has recently emerged as a powerful new technique well suited to explore cell structure and dynamics with a nanometric axial sensitivity and the ability to identify new cellular biomarkers. By combining digital holography with AI technology, including recent deep learning approaches, this system can achieve a record-high accuracy in non-invasive, label-free cellular phenotypic screening. It opens up a new path to data-driven diagnosis. Artificial Intelligence in Digital Holographic Imaging introduces key concepts and algorithms of AI to show how to build intelligent holographic imaging systems drawing on techniques from artificial neural networks, convolutional neural networks, and generative adversarial network. Readers will be able to gain an understanding of the basics for implementing AI in holographic imaging system designs and connecting practical biomedical questions that arise from the use of digital holography with various AI algorithms in intelligence models. What’s Inside • Introductory background on digital holography • Key concepts of digital holographic imaging • Deep-learning techniques for holographic imaging • AI techniques in holographic image analysis • Holographic image-classification models • Automated phenotypic analysis of live cells For readers with various backgrounds, this book provides a detailed discussion of the use of intelligent holographic imaging system in biomedical fields with great potential for biomedical application. © 2023 John Wiley and Sons, Inc.","","","","","wiley",""
"","","","7th International Conference on Life System Modeling and Simulation, LSMS 2021, and 7th International Conference on Intelligent Computing for Sustainable Energy and Environment, ICSEE 2021","2021","1467","","","","","1669","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118156202&partnerID=40&md5=5fa0da295dc8caf7ab90ff39588180a1","The proceedings contain 159 papers. The special focus in this conference is on Life System Modeling and Simulation. The topics include: Endoscopic Single Image Super-Resolution Based on Transformer and Convolutional Neural Network; investigation of Wear Amounts on Artificial Hip Joints with Different Femoral Head Diameter; Based on Advanced Connected Domain and Contour Filter for CASA; Classification of LFPs Signals in Autistic and Normal Mice Based on Convolutional Neural Network; human Grasping Force Prediction Based on Surface Electromyography Signals; simulation of Pedicle Screw Extraction Based on Galerkin Smooth Particle Meshless Method; improved One-Stage Algorithm with Attention Fusion for Human Sperm Detection Based on Deep Learning; inelastic Modelling of Bone Damage Under Compressive Loading; constrained Adversarial Attacks Against Image-Based Malware Classification System; Research on CT Image Grading of Superior Mesenteric Artery Based on AA Res-Unet; application of a New Attribute Reduction Algorithm in Intracranial Aneurysm Prediction; Classification of Coronary Artery Lesions Based on XGBoost; design of Mechanical Property Verification System for Drug Dissolution Meter Based on Non-contact Measurement; PF-OLSR Routing Algorithm for Self-organizing Networks of Pigeon Flocks; Image Enhancement and Corrosion Detection for UAV Visual Inspection of Pressure Vessels; a Study of Force Feedback Master-Slave Teleoperation System Based on Biological Tissue Interaction; Surface EMG Real-Time Chinese Language Recognition Using Artificial Neural Networks; support Vector Machine Classification Method Based on Convex Hull Clipping; Research on Reconstruction of CT Images Based on AA-R2Unet in Inferior Mesenteric Artery Classification; Pedestrian Detection Based on Improved YOLOv3 Algorithm; melanoma Classification Method Based on Ensemble Convolutional Neural Network.","","Bioinformatics; Biomechanics; Biomedical signal processing; Classification (of information); Computer aided diagnosis; Convolution; Damage detection; Data mining; Deep learning; Extraction; Feature extraction; Forecasting; Image classification; Image reconstruction; Learning algorithms; Neural networks; Reverse engineering; Robotics; Statistics; Classification methods; Convolutional neural network; CT Image; Energy and environment; Image super resolutions; Image-based; Single images; Sustainable energy; Sustainable environment; System modeling and simulation; Computerized tomography","","Fei M.; Chen L.; Ma S.; Li X.","Springer Science and Business Media Deutschland GmbH",""
"Ghose S.; Datta S.; Batta V.; Malathy C.; Gayathri M.","Ghose, Smaranjit (57218448497); Datta, Suhrid (57218454624); Batta, Vineet (36514222300); Malathy, C. (36704830100); Gayathri, M. (57194585718)","57218448497; 57218454624; 36514222300; 36704830100; 57194585718","Artificial intelligence based identification of total knee arthroplasty implants","2020","","","9315956","302","307","5","10.1109/ICISS49785.2020.9315956","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100759843&doi=10.1109%2fICISS49785.2020.9315956&partnerID=40&md5=0e890c27affb9b65f8bd36ddaf09157e","The identification of the make and model of the primary knee implant is an essential step for planning a revision surgery. Currently, the surgeons email the radiographs of the implant to the medical representatives of the manufacturing companies to get this information. This manual process is prone to errors and involves a considerable amount of resources and surgeon time that could be otherwise spent on more useful tasks. This study proposes an artificial intelligence based solution for the automatic identification of 6 makes of orthopedic knee implants. Deep Convolutional Neural Networks were trained on a dataset comprising 878 images of radiographs of orthopedic knee implants including both anterior posterior and lateral views. The results of the experiments showed a validation accuracy of 96.66%. Furthermore, class activation maps generated on the images when passed through the deep learning algorithm provided visual conformance to the region of interests that a surgeon would consider for identification of the make of the implant. The outcomes of this study demonstrates the effectiveness of the usage of Deep Convolutional Neural Networks for assisting orthopedic surgeons in pre-operative planning of revision surgery by accurate automated identification of make and model of orthopedic knee implant. © 2020 IEEE.","Biomedical Imaging; Computer Vision; Deep Learning; Orthopedics; Total Knee Arthoplasty","Arthroplasty; Automation; Convolution; Deep learning; Deep neural networks; Implants (surgical); Learning algorithms; Orthopedics; Radiography; Activation maps; Anterior posteriors; Automated identification; Manufacturing companies; Pre-operative planning; Region of interest; Revision surgery; Total knee arthroplasty; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Thamizhvani T.R.; Chandrasekaran R.; Ineyathendral T.R.","Thamizhvani, T.R. (57200797631); Chandrasekaran, R. (57202291886); Ineyathendral, T.R. (58068602400)","57200797631; 57202291886; 58068602400","Deep Learning Interpretation of Biomedical Data","2021","","","","121","142","21","10.1002/9781119769200.ch6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146412424&doi=10.1002%2f9781119769200.ch6&partnerID=40&md5=9d5f0bbc3f424f7f1fa531abdde0ba25","Deep learning can be stated as a new field in the area of machine learning related with artificial intelligence. This learning technique resembles human functions in processing and defining patterns used for decision making. Deep learning algorithms are mainly developed using neural networks performing unsupervised data that are unstructured. These learning algorithms perform feature extraction and classification for identification of the system patterns. Deep learning also defined as deep neural network or deep neural layer possess different layers for processing of the learning algorithms that helps in active functioning and detection of patterns. Deep learning network consists of basic conceptual features like layer and activation function. Layer is the highest building block of deep learning process which can be categorised based on its function. Deep learning used in various applications, one among them is the field of Biomedical Engineering where big data observations are made in form of bio signals, medical images, pathological reports, patient history and medical reports. Biomedical data possess time and frequency domain features for analysis and classification. The study of large amount of data can be performed using deep learning algorithms. Thus, deep learning algorithms are used for interpretation and classification of biomedical big data. © 2022 Scrivener Publishing LLC.","Biomedical applications; Deep learning algorithms; Interpretation; Learning models","","","","wiley",""
"Siregar O.R.; Sasongko P.S.; Endah S.N.","Siregar, Obed Reinhard (58062863800); Sasongko, Priyo Sidik (56027168300); Endah, Sukmawati Nur (35731392400)","58062863800; 56027168300; 35731392400","Optic Disc Segmentation on Eye Retinal Image with U-Net Convolutional Neural Network Architecture","2021","2021-November","","","69","74","5","10.1109/ICICoS53627.2021.9651795","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199704&doi=10.1109%2fICICoS53627.2021.9651795&partnerID=40&md5=2178038a33b09bf16207307879114e6f","Glaucoma is a disease that causes blindness of the eye. This blindness occurs due to failure of tissue embryogenesis in the eye drainage structure. There are various approaches to early detection of glaucoma. One of them is the optic disc and optic cup segmentation. However, the delineation of the boundaries of the optic disc and the optic cup by experts is highly subjective, time-consuming, and impractical. On the other hand, the automatic segmentation approach using computers is a more attractive method because it can be more objective and faster than human segmentation. Therefore, automatic segmentation using computers is the right solution. U-Net is one of the first convolutional networks designed specifically for biomedical image segmentation. This study only performs semantic optic disc segmentation on eye retinal images using U-Net architecture. This network optimization is done by looking for the parameters of the U-Net architecture which include image size, epoch value, learning rate value, and dropout value. The data used consisted of three public retinal eye image datasets, namely the DRIONS-DB, Drishti-GS, and RIM-ONE dataset. The total data distribution was 287 training data, 16 validation data, and 16 test data. The training and data testing process resulted in the highest Intersection over Union (IoU) score of 93.34% and the highest F1-Score of 96.56%. These results were obtained using epochs 100, learning rate 0.0001, dropout 0.3, and image size 256×256.  © 2021 IEEE.","deep learning; glaucoma; optic disc; semantic segmentation; u-net","Convolution; Convolutional neural networks; Deep learning; Eye protection; Learning algorithms; Network architecture; Ophthalmology; Semantics; Automatic segmentations; Deep learning; Glaucoma; Learning rates; NET architecture; Optic cups; Optic disks; Retinal image; Semantic segmentation; U-net; Semantic Segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Shirazi A.Z.; Fornaciari E.; McDonnell M.D.; Yaghoobi M.; Cevallos Y.; Tello-Oquendo L.; Inca D.; Gomez G.A.","Shirazi, Amin Zadeh (55320828900); Fornaciari, Eric (57215673150); McDonnell, Mark D. (7102564709); Yaghoobi, Mahdi (56234245700); Cevallos, Yesenia (57209662798); Tello-Oquendo, Luis (56028218500); Inca, Deysi (57209652996); Gomez, Guillermo A. (7202293576)","55320828900; 57215673150; 7102564709; 56234245700; 57209662798; 56028218500; 57209652996; 7202293576","The application of deep convolutional neural networks to brain cancer images: A survey","2020","10","4","224","1","27","26","10.3390/jpm10040224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096146619&doi=10.3390%2fjpm10040224&partnerID=40&md5=f5b07afb73940044dc85caaf111a4e0b","In recent years, improved deep learning techniques have been applied to biomedical image processing for the classification and segmentation of different tumors based on magnetic resonance imaging (MRI) and histopathological imaging (H&E) clinical information. Deep Convolutional Neural Networks (DCNNs) architectures include tens to hundreds of processing layers that can extract multiple levels of features in image-based data, which would be otherwise very difficult and time-consuming to be recognized and extracted by experts for classification of tumors into different tumor types, as well as segmentation of tumor images. This article summarizes the latest studies of deep learning techniques applied to three different kinds of brain cancer medical images (histology, magnetic resonance, and computed tomography) and highlights current challenges in the field for the broader applicability of DCNN in personalized brain cancer care by focusing on two main applications of DCNNs: classification and segmentation of brain cancer tumors images. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Brain cancer; Classification; Convolutional neural networks; DCNN; Deep learning; Histology; MRI; Segmentation","accuracy; algorithm; artificial neural network; brain cancer; convolutional neural network; deep learning; diagnostic accuracy; histopathology; human; human tissue; image processing; image segmentation; learning algorithm; measurement accuracy; neuroimaging; nuclear magnetic resonance imaging; Review; sensitivity and specificity; support vector machine; total quality management; training; tumor microenvironment","Cancer Council; National Health and Medical Research Council of Australia, (1067405, 1123816); Australian Research Council, ARC, (FT160100366); Neurosurgical Research Foundation, NRF; University of South Australia, UniSA; Cure Brain Cancer Foundation, CBCF","","MDPI AG",""
"Sujatha K.; Krishnakumar R.; Deepalakshmi B.; Bhavani N.P.G.; Srividhya V.","Sujatha, K. (36643006900); Krishnakumar, R. (58716916600); Deepalakshmi, B. (56737238300); Bhavani, N.P.G. (56461276800); Srividhya, V. (57190966585)","36643006900; 58716916600; 56737238300; 56461276800; 57190966585","Soft sensors for screening and detection of pancreatic tumor using nanoimaging and deep learning neural networks","2021","","","","449","463","14","10.1016/B978-0-12-820783-3.00002-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127636673&doi=10.1016%2fB978-0-12-820783-3.00002-6&partnerID=40&md5=6c64287c448f6a38a7c7fc346aba9a61","Screening of nanosized pancreatic tumors, both benign and malignant, is a very important issue in the medical field because it is directly influences the digestive system, which has an effect on human health. Nanobiosensor is the application of nanotechnology in the medical field. This is a multidisciplinary field that currently involves nanotechnology and biomedical applications. The malfunctioning of the pancreas is a health concern because it helps maintain the blood glucose level at a nominal value. Day-to-day food habits have driven the need to develop rapid, responsive, and reliable methods to detect pancreatic tumors. The rapid development of nanosensors that have an advantage to detect variations in the texture of the pancreas in nanometers has paved way to diagnose a malfunctioning pancreas at the onset stage linking nanosensors with modern Information and Communication Technologies (ICTs) enabling novel and online ways of detection accompanied with high accuracy. Various types of nanosensors are being developed to meet different requirements in the field of medicine for detection of various abnormalities related to the organs of the human body. Detection of nanosized pancreatic tumors is the focus of this work. The existence of nanosized pancreatic tumors in the patient leads to early diagnosis. If the tumor is identified in the chronic stage, the chances of survival of the patient are very less. Detection of nanosized tumors will enhance the analysis, diagnosis, and prognosis at the onset stage leading to suitable and timely medication. Currently, this work depends on feature analysis of Magnetic Resonance Imaging (MRI) images obtained from the database to identify the nanosized pancreatic tumors at the onset stage. A distinct diagnosis method is proposed for identification of pancreatic tumors using image texture characters, which were statistically evaluated using MATLAB. Diagnosis was done using Deep Wavelet Neural Networks (DWNN). Using DWNN method, combined with intelligent and pattern recognition algorithms, nearly 99% of sensitivity in the detection of nanosized pancreatic tumors is achieved. © 2021 Elsevier Inc. All rights reserved.","Deep learning; Image decomposition; MRI image; Nanosized; Pancreatic tumor; Wavelet transform","","","","Elsevier",""
"Mahanty M.; Bhattacharyya D.; Midhunchakkaravarthy D.","Mahanty, Mohan (57220483702); Bhattacharyya, Debnath (57216142572); Midhunchakkaravarthy, Divya (56380232700)","57220483702; 57216142572; 56380232700","Su-net based colorectal polyp segmentation from colon cancer morphology images","2021","8","4","","649","659","10","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119325222&partnerID=40&md5=43e1216cf0665997590d3c2ab0adec9b","Precise demarcation of glands from clinical histology images are pre-requirement for accurate medical diagnosis. Colorectal polyps that originate and expandsover the rectum or colon membrane are the decisive reason for colorectal Cancer(CRC). The early-stage recognition and of polyps and treatment can decrease the mortality rate. To lower the polyp miss-rate in colonoscopy, a Computer-Aided Medical Diagnosing(CAD) system with high accuracy is needed. In recent times, researchers develop deep learning models for accurate polyp detection from histomorphology images, but accuracy is still the most requisite factor for reliable results. In this paper, we propose to develop and test a Convolutional Neural Network(CNN) based U-shape network (SU-NET) model for semantic segmentation of colorectal polyps from colonoscopy images.SU-NET is an Encoder-Decoder-based architecture, inspired by the popular segmentation architectures SegNet and U-Net for improved colon polyp segmentation. In the proposed model the top most layers transfer the Pooling indices whereas the lower-level layers transfer the feature-maps to incorporate fine multiscale information for better colon polyp contour identification.We evaluated the proposed algorithm in contrast with various prominentdeep learning architectures across multi-modal biomedical image segmentation tasks to segment polyps from the colonoscopy and histopathology images.For evaluating the proposed model, an accredited and publicly available colonoscopy image dataset CVC-ColonDB is employed. The model achieves a recall of 91.3%, F1-Score of 90.81%, F2-Score of 86.39%, Precision of 89.21%, and the Dice similarity coefficient of 0.895 outshines the existing advanced deep learning CNN models. © 2021, Badebio Biotechnololgy Ltd. All rights reserved.","Colonoscopy; Colorectal cancer; Deep convolutional neural network; Medical image analysis; Polyp semantic segmentation; SU-NET","","","","Badebio Biotechnololgy Ltd",""
"Gümüslü E.; Erol Barkana D.; Köse H.","Gümüslü, Elif (57219850359); Erol Barkana, Duygun (57472154100); Köse, Hatice (25031883600)","57219850359; 57472154100; 25031883600","Emotion recognition using EEG and physiological data for robot-assisted rehabilitation systems","2020","","","","379","387","8","10.1145/3395035.3425199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096658742&doi=10.1145%2f3395035.3425199&partnerID=40&md5=3bd77d49ad1b96cc1f64637c2efc5455","Robot-assisted rehabilitation systems are developed to monitor the performance of the patients and adapt the rehabilitation task intensity and difficulty level accordingly to meet the needs of the patients. The robot-assisted rehabilitation systems can be more prosperous if they are able to recognize the emotions of patients, and modify the difficulty level of task considering these emotions to increase patient's engagement. We aim to develop an emotion recognition model using electroencephalography (EEG) and physiological signals (blood volume pulse (BVP), skin temperature (ST) and skin conductance (SC)) for a robot-assisted rehabilitation system. The emotions are grouped into three categories, which are positive (pleasant), negative (unpleasant) or neutral. A machine-learning algorithm called Gradient Boosting Machines (GBM) and a deep learning algorithm called Convolutional Neural Networks (CNN) are used to classify pleasant, unpleasant and neutral emotions from the recorded EEG and physiological signals. We ask the subjects to look at pleasant, unpleasant and neutral images from IAPS database and collect EEG and physiological signals during the experiments. The classification accuracies are compared for both GBM and CNN methods when only one sensory data (EEG, BVP, SC and ST) or the combination of the sensory data from both EEG and physiological signals are used. © 2020 ACM.","Assistive robotic systems; Convolutional neural networks; Emotion recognition; Gradient boosting machines; Physiological signal","Adaptive boosting; Biomedical signal processing; Convolutional neural networks; Deep learning; Electroencephalography; Electrophysiology; Interactive computer systems; Physiological models; Robots; Speech recognition; Turing machines; Blood volume pulse; Classification accuracy; Emotion recognition; Gradient boosting; Physiological data; Physiological signals; Robot-assisted rehabilitation; Skin temperatures; Patient rehabilitation","TÜBA-GEBİP; Türkiye Bilimler Akademisi","","Association for Computing Machinery, Inc",""
"Jayatilake S.M.D.A.C.; Ganegoda G.U.","Jayatilake, Senerath Mudalige Don Alexis Chinthaka (57221954095); Ganegoda, Gamage Upeksha (36975802900)","57221954095; 36975802900","Involvement of Machine Learning Tools in Healthcare Decision Making","2021","2021","","6679512","","","","10.1155/2021/6679512","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100720440&doi=10.1155%2f2021%2f6679512&partnerID=40&md5=9ee1798a9c741aa4268b156af128fd3d","In the present day, there are many diseases which need to be identified at their early stages to start relevant treatments. If not, they could be uncurable and deadly. Due to this reason, there is a need of analysing complex medical data, medical reports, and medical images at a lesser time but with greater accuracy. There are even some instances where certain abnormalities cannot be directly recognized by humans. In healthcare for computational decision making, machine learning approaches are being used in these types of situations where a crucial data analysis needs to be performed on medical data to reveal hidden relationships or abnormalities which are not visible to humans. Implementing algorithms to perform such tasks itself is difficult, but what makes it even more challenging is to increase the accuracy of the algorithm while decreasing the required time for the algorithm to execute. In the early days, processing of large amount of medical data was an important task which resulted in machine learning being adapted in the biological domain. Since this happened, the biology and biomedical fields have been reaching higher levels by exploring more knowledge and identifying relationships which were never observed before. Reaching to its peak now the concern is being diverted towards treating patients not only based on the type of disease but also their genetics, which is known as precision medicine. Modifications in machine learning algorithms are being performed and tested daily to improve the performance of the algorithms in analysing and presenting more accurate information. In the healthcare field, starting from information extraction from medical documents until the prediction or diagnosis of a disease, machine learning has been involved. Medical imaging is a section that was greatly improved with the integration of machine learning algorithms to the field of computational biology. Nowadays, many disease diagnoses are being performed by medical image processing using machine learning algorithms. In addition, patient care, resource allocation, and research on treatments for various diseases are also being performed using machine learning-based computational decision making. Throughout this paper, various machine learning algorithms and approaches that are being used for decision making in the healthcare sector will be discussed along with the involvement of machine learning in healthcare applications in the current context. With the explored knowledge, it was evident that neural network-based deep learning methods have performed extremely well in the field of computational biology with the support of the high processing power of modern sophisticated computers and are being extensively applied because of their high predicting accuracy and reliability. When giving concern towards the big picture by combining the observations, it is noticeable that computational biology and biomedicine-based decision making in healthcare have now become dependent on machine learning algorithms, and thus they cannot be separated from the field of artificial intelligence. © 2021 Senerath Mudalige Don Alexis Chinthaka Jayatilake and Gamage Upeksha Ganegoda.","","Algorithms; Artificial Intelligence; Decision Making; Delivery of Health Care; Humans; Machine Learning; Reproducibility of Results; Bioinformatics; Biology; Decision making; Deep learning; Diagnosis; Diseases; Health care; Information analysis; Learning systems; Medical imaging; drug; Biological domain; Computational biology; Disease diagnosis; Health care application; Health-care decisions; Healthcare sectors; High processing power; Machine learning approaches; acute lymphoblastic leukemia; artificial neural network; Bayesian learning; breast cancer; cancer diagnosis; chronic kidney failure; classification algorithm; clinical decision making; decision tree; deep learning; density based clustering; diabetes mellitus; drug repositioning; evolutionary learning; graph based clustering; heart disease; hierarchical clustering; human; k nearest neighbor; logistic regression analysis; lung cancer; machine learning; nonhuman; Parkinson disease; partition clustering; polypharmacology; random forest; reinforcement learning (machine learning); Review; semi supervised machine learning; skin disease; supervised machine learning; support vector machine; unsupervised machine learning; algorithm; artificial intelligence; decision making; health care delivery; reproducibility; Learning algorithms","","","Hindawi Limited","33575021"
"Luijten B.; Cohen R.; De Bruijn F.J.; Schmeitz H.A.W.; Mischi M.; Eldar Y.C.; Van Sloun R.J.G.","Luijten, Ben (55814776700); Cohen, Regev (57202447637); De Bruijn, Frederik J. (7006908440); Schmeitz, Harold A. W. (37075774200); Mischi, Massimo (6602380164); Eldar, Yonina C. (35562426100); Van Sloun, Ruud J. G. (56052857600)","55814776700; 57202447637; 7006908440; 37075774200; 6602380164; 35562426100; 56052857600","Adaptive Ultrasound Beamforming Using Deep Learning","2020","39","12","9138451","3967","3978","11","10.1109/TMI.2020.3008537","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097003932&doi=10.1109%2fTMI.2020.3008537&partnerID=40&md5=1c5f2e96db461ff4a353b4a4208b2c7f","Biomedical imaging is unequivocally dependent on the ability to reconstruct interpretable and high-quality images from acquired sensor data. This reconstruction process is pivotal across many applications, spanning from magnetic resonance imaging to ultrasound imaging. While advanced data-adaptive reconstruction methods can recover much higher image quality than traditional approaches, their implementation often poses a high computational burden. In ultrasound imaging, this burden is significant, especially when striving for low-cost systems, and has motivated the development of high-resolution and high-contrast adaptive beamforming methods. Here we show that deep neural networks, that adopt the algorithmic structure and constraints of adaptive signal processing techniques, can efficiently learn to perform fast high-quality ultrasound beamforming using very little training data. We apply our technique to two distinct ultrasound acquisition strategies (plane wave, and synthetic aperture), and demonstrate that high image quality can be maintained when measuring at low data-rates, using undersampled array designs. Beyond biomedical imaging, we expect that the proposed deep learning based adaptive processing framework can benefit a variety of array and signal processing applications, in particular when data-efficiency and robustness are of importance.  © 1982-2012 IEEE.","adaptive beamforming; deep learning; Ultrasound","Deep Learning; Image Processing, Computer-Assisted; Phantoms, Imaging; Signal Processing, Computer-Assisted; Ultrasonography; Beamforming; Biomedical signal processing; Deep neural networks; Image quality; Image reconstruction; Magnetic resonance imaging; Medical imaging; Synthetic apertures; Ultrasonic imaging; Acquisition strategies; Adaptive Beamforming; Adaptive reconstruction; Adaptive signal processing techniques; Algorithmic structure; Reconstruction process; Signal processing applications; Traditional approaches; algorithm; article; deep learning; deep neural network; image quality; signal processing; ultrasound; echography; image processing; imaging phantom; Deep learning","Nederlandse Organisatie voor Wetenschappelijk Onderzoek, NWO, (17144)","","Institute of Electrical and Electronics Engineers Inc.","32746139"
"Sarwar A.; Javed K.; Khan M.J.; Rubab S.; Song O.-Y.; Tariq U.","Sarwar, Ayesha (57222494766); Javed, Kashif (24776418700); Khan, Muhammad Jawad (55607228600); Rubab, Saddaf (56594904900); Song, Oh-Young (8901190400); Tariq, Usman (14827558600)","57222494766; 24776418700; 55607228600; 56594904900; 8901190400; 14827558600","Enhanced accuracy formotor imagery detection using deep learning for BCI","2021","68","3","","3825","3840","15","10.32604/cmc.2021.016893","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105681669&doi=10.32604%2fcmc.2021.016893&partnerID=40&md5=3799215fd878c288b50a8d45a1e8fc09","Brain-Computer Interface (BCI) is a system that provides a link between the brain of humans and the hardware directly. The recorded brain data is converted directly to the machine that can be used to control external devices. There are four major components of the BCI system: Acquiring signals, preprocessing of acquired signals, features extraction, and classification. In traditional machine learning algorithms, the accuracy is insignificant and not up to the mark for the classification of multi-class motor imagery data. The major reason for this is, features are selected manually, and we are not able to get those features that give higher accuracy results. In this study, motor imagery (MI) signals have been classified using different deep learning algorithms. We have explored two different methods: Artificial Neural Network (ANN) and Long Short-Term Memory (LSTM). We test the classification accuracy on two datasets: BCI competition III-dataset IIIa and BCI competition IV-dataset IIa. The outcome proved that deep learning algorithms provide greater accuracy results than traditionalmachine learning algorithms. Amongst the deep learning classifiers, LSTM outperforms the ANN and gives higher classification accuracy of 96.2%. © 2021 Tech Science Press. All rights reserved.","Artificial neural network; Brain-computer interface; Classification; Long-short term memory; Motor imagery","Biomedical signal processing; Brain computer interface; Classification (of information); Deep learning; Image enhancement; Long short-term memory; Statistical tests; Brain data; Classification accuracy; Features extraction; Learning classifiers; Motor imagery; Learning algorithms","Institute for Information & communications Technology Planning & Evaluation; National University of Sciences; Ministry of Trade, Industry and Energy, MOTIE; Ministry of Science, ICT and Future Planning, MSIP, (IITP-2021-2016-0-00312); Korea Institute for Advancement of Technology, KIAT, (P0016038)","","Tech Science Press",""
"Zhang X.; Noga M.; Martin D.G.; Punithakumar K.","Zhang, Xiaoran (57207473032); Noga, Michelle (8432881100); Martin, David Glynn (57207466274); Punithakumar, Kumaradevan (57203348259)","57207473032; 8432881100; 57207466274; 57203348259","Fully automated left atrium segmentation from anatomical cine long-axis MRI sequences using deep convolutional neural network with unscented Kalman filter","2021","68","","101916","","","","10.1016/j.media.2020.101916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097334776&doi=10.1016%2fj.media.2020.101916&partnerID=40&md5=7dbda886e14fa90d0032beafcbfb1ebc","This study proposes a fully automated approach for the left atrial segmentation from routine cine long-axis cardiac magnetic resonance image sequences using deep convolutional neural networks and Bayesian filtering. The proposed approach consists of a classification network that automatically detects the type of long-axis sequence and three different convolutional neural network models followed by unscented Kalman filtering (UKF) that delineates the left atrium. Instead of training and predicting all long-axis sequence types together, the proposed approach first identifies the image sequence type as to 2, 3 and 4 chamber views, and then performs prediction based on neural nets trained for that particular sequence type. The datasets were acquired retrospectively and ground truth manual segmentation was provided by an expert radiologist. In addition to neural net based classification and segmentation, another neural net is trained and utilized to select image sequences for further processing using UKF to impose temporal consistency over cardiac cycle. A cyclic dynamic model with time-varying angular frequency is introduced in UKF to characterize the variations in cardiac motion during image scanning. The proposed approach was trained and evaluated separately with varying amount of training data with images acquired from 20, 40, 60 and 80 patients. Evaluations over 1515 images with equal number of images from each chamber group acquired from an additional 20 patients demonstrated that the proposed model outperformed state-of-the-art and yielded a mean Dice coefficient value of 94.1%, 93.7% and 90.1% for 2, 3 and 4-chamber sequences, respectively, when trained with datasets from 80 patients. © 2020","Deep convolutional neural network; Left atrial segmentation; Long-axis sequences; Magnetic resonance imaging; Unscented Kalman filter","Bayes Theorem; Heart Atria; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Retrospective Studies; Bayesian networks; Biomedical signal processing; Convolution; Deep neural networks; Image segmentation; Kalman filters; Magnetic resonance imaging; Angular frequencies; Bayesian filtering; Cardiac magnetic resonance images; Classification networks; Manual segmentation; Temporal consistency; Unscented Kalman Filter; Unscented Kalman filtering; adolescent; adult; aged; algorithm; Article; Bayesian filtering; cardiac imaging; cardiovascular magnetic resonance; child; cine magnetic resonance imaging; circadian rhythm; classification algorithm; classifier; comparative study; computer language; convolutional neural network; cross validation; female; heart cycle; heart left atrium; heart movement; heart rate; human; image processing; image segmentation; machine learning; major clinical study; male; prediction; priority journal; radiologist; reliability; unscented Kalman filter; white noise; Bayes theorem; diagnostic imaging; heart atrium; image processing; nuclear magnetic resonance imaging; retrospective study; Convolutional neural networks","Servier Canada Inc.; University of Alberta Radiology Endowed Fund; Compute Canada; Mitacs","","Elsevier B.V.","33285484"
"Ahmad M.; Penberthy J.S.; Powell A.","Ahmad, Mak (57686159300); Penberthy, J. Scott (57687198000); Powell, Abigail (57213558536)","57686159300; 57687198000; 57213558536","Path to Automating Ocean Health Monitoring","2021","17B","","","15240","15246","6","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130025853&partnerID=40&md5=764811339890bab6d2eb3f8aef5f8a7f","Marine ecosystems directly and indirectly impact human health, providing benefits such as essential food sources, coastal protection and biomedical compounds. Monitoring changes in marine species is important because impacts such as overfishing, ocean acidification and hypoxic zones can negatively affect both human and ocean health. The US west coast supports a diverse assemblage of deep-sea corals that provide habitats for fish and numerous other invertebrates. Currently, National Oceanic Atmospheric Administration (NOAA) scientists manually track the health of coral species using extractive methods. In this paper, we test the viability of using a machine learning algorithm Convolutional Neural Network (CNN) to automatically classify coral species, using field-collected coral images in collaboration with NOAA. We fine tune the hyperparameters of our model to surpass the human F-score. We also highlight a scalable opportunity to monitor ocean health automatically while preserving corals. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved","","Coastal zones; Ecosystems; Learning algorithms; Machine learning; Neural networks; Oceanography; Coastal protection; Deep-sea corals; Food sources; Health monitoring; Human health; Marine species; Monitoring change; National oceanic atmospheric administrations; Ocean acidifications; West coast; Health","","","Association for the Advancement of Artificial Intelligence",""
"Daroach G.B.; Yoder J.A.; Iczkowski K.A.; LaViolette P.S.","Daroach, Gagandeep B. (57222719770); Yoder, Josiah A. (55561941300); Iczkowski, Kenneth A. (7005139638); LaViolette, Peter S. (25951451800)","57222719770; 55561941300; 7005139638; 25951451800","High-resolution controllable prostatic histology synthesis using StyleGAN","2021","","","","103","114","11","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103843838&partnerID=40&md5=0ad61249a85cd15ee4e8ea92ff8941df","For use of deep learning algorithms in clinical practice, detailed justification for diagnosis is necessary. Convolutional Neural Networks (CNNs) have been demonstrated to classify prostatic histology using the same diagnostic signals as pathologists. Using the StyleGAN series of networks, we demonstrate that recent advances in high-resolution image synthesis with Generative Adversarial Networks (GANs) can be applied to prostatic histology. The trained network can produce novel histology samples indistinguishable from real histology at 1024x1024 resolution and can learn disentangled representations of histologic semantics that separates at a variety of scales. Through blending of the latent representations, users have the ability to control the projection of histologic semantics onto a reconstructed image. When applied to the medical domain without modification, StyleGAN2 is able to achieve a Fréchet Inception Distance (FID) of 3.69 and perceptual path length (PPL) of 33.25. © 2021 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved","Deep learning; GAN; Generative adversarial networks; Gleason; Histology; Latent space; Machine learning; Medical imaging; Prostate; Prostate cancer; StyleGAN; StyleGAN2","Biomedical engineering; Convolutional neural networks; Deep learning; Diagnosis; Image processing; Learning algorithms; Semantics; Adversarial networks; Clinical practices; High resolution; High resolution image; Medical domains; Path length; Reconstructed image; Histology","MSOE; State of Wisconsin Tax Check-off Program for Prostate Cancer Research; National Institutes of Health, NIH, (RO1CA218144); National Institutes of Health, NIH; National Cancer Institute, NCI","Douplik A.; Fred A.; Gamboa H.","SciTePress",""
"Du J.; Fang M.; Yu Y.; Lu G.","Du, Jiao (55416429400); Fang, Meie (56266034300); Yu, Yufeng (57192163579); Lu, Gang (57709221200)","55416429400; 56266034300; 57192163579; 57709221200","An adaptive two-scale biomedical image fusion method with statistical comparisons","2020","196","","105603","","","","10.1016/j.cmpb.2020.105603","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086575506&doi=10.1016%2fj.cmpb.2020.105603&partnerID=40&md5=a989b2bcfe7fb7f9f06f6b3d4dee296d","Two-scale image representation of base and detail in the spatial-domain is a well-known decomposition scheme for its lower computational complexity than that performed in the transform-domain in the field of image fusion. Unfortunately, for a pseudo-colour input image, the base and detail images in the spatial-domain obtained via image decomposition scheme always display in greyscale. In this paper, a two-scale image fusion method with adaptive threshold obtained by Otsu's method is proposed for pseudo-colour image in the colour space domain. For greyscale image, detail and base image are obtained using structural information extracted from the difference image between a global and a local patch size. Consequently, local edge-preserving filter for preserving luminance information and local energy with the discussed window size are adopted to combine base and detail image. Experimental results show that structural and luminance information has been better preserved in terms of subjective and objective evaluations for medical image and protein image fusion. Specially, a two-step non-parametric statistical test (Friedman test and Nemenyi post-hoc test) with p-values is adopted to analysis the statistical significant of the relative difference between the proposed and compared methods in terms of values of objective metrics including 30 co-registered pairs of imaging data. © 2020","Adaptive two-scale representation; Base and detail; Friedman test; Otsu's method; Statistical significant analysis","Algorithms; Color; Luminance; Medical imaging; Decomposition scheme; Edge-preserving filter; Image fusion methods; Image representations; Non-parametric statistical tests; Statistical comparisons; Structural information; Subjective and objective evaluations; Article; blood flow; comparative study; controlled study; convolutional neural network; decomposition; deep learning; Friedman test; human; image analysis; image processing; image quality; luminance; neuroimaging; nuclear magnetic resonance imaging; positron emission tomography; pulse coupled neural network; signal noise ratio; single photon emission computed tomography; statistical analysis; wavelet transform; algorithm; Image fusion","National Natural Science Foundation of China, NSFC, (61772164, 61802148); Natural Science Foundation of Guangdong Province, (2019A1515011266)","","Elsevier Ireland Ltd","32570007"
"Pranav M.V.; Koushik C.; Shreyas Madhav A.V.; Ganapathy S.","Pranav, M.V. (57312856400); Koushik, C. (58862890400); Shreyas Madhav, A.V. (57224919240); Ganapathy, S. (55675224090)","57312856400; 58862890400; 57224919240; 55675224090","Analyzing the Diagnostic Efficacy of Deep Vision Networks for Malignant Skin Lesion Recognition","2021","","","","194","199","5","10.1109/CENTCON52345.2021.9687979","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126814900&doi=10.1109%2fCENTCON52345.2021.9687979&partnerID=40&md5=e63f95f658478a05703aac8544b8aa27","Cancerous skin lesions affect millions of people worldwide each year and is one of the most treatable forms of cancer. While intensive biopsy testing and processing is required to confirm the presence of a malignant skin lesion, the detection of skin lesions by dermatologists on the primary level has always been based upon visual markers and sight-based perception based upon a defined set of diagnostic rules. The automation of this classification process has been achieved in the past for traditional machine learning algorithms and novel deep networks but faces challenges when the diagnosis is performed upon images of varied illumination and spatial orientation. This paper proposes a novel ensemble approach towards skin lesion classification by employing transfer learned pretrained deep learning image networks for the automated diagnosis process. Popular ImageNet Trained Networks such as DenseNet, Inception ResNetV2, VGG16 and MobileNet have been individually fine-tuned, tested and evaluated for identifying the type of skin lesion. A final integration of the best ensemble combination was performed based upon a search- based strategy to find the optimal combination for maximal reliability. The system was tested against benchmark datasets including HAM1000 and ISIC, showcasing an accuracy of 90%, precision of 0.895, and recall of 0.89 and the proposed combinational network showcases significantly better results than several existent state of the art skin cancer classification models in terms of accuracy, precision and recall.  © 2021 IEEE.","Assistive Diagnosis; Biomedical Imaging; Convolutional Neural Networks; Deep Learning; Lesion Classification; Skin Cancer","Classification (of information); Computer aided diagnosis; Convolutional neural networks; Deep learning; Dermatology; Diseases; Learning algorithms; Assistive; Assistive diagnose; Biomedical imaging; Convolutional neural network; Deep learning; Lesion classification; Malignant skin; Skin cancers; Skin lesion; Visual markers; Medical imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"Salehi H.S.; Barchini M.; Mahdian M.","Salehi, Hassan S. (56198619900); Barchini, Majd (57215664469); Mahdian, Mina (35208763000)","56198619900; 57215664469; 35208763000","Optimization methods for deep neural networks classifying OCT images to detect dental caries","2020","11217","","112170G","","","","10.1117/12.2545421","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081639850&doi=10.1117%2f12.2545421&partnerID=40&md5=2cec26fe78fa737357169fc78d8d76b8","Dental caries are common chronic infectious oral diseases affecting most teenagers and adults worldwide. Optical coherence tomography (OCT) has been studied extensively for the detection of early carious lesions. Deep learning techniques are a rapidly emerging new area of biomedical research and have yielded impressive results in diagnosis and prediction in the field of oral radiology. Deep learning models particularly deep convolutional neural networks (CNN) can be employed along with OCT imaging system to more accurately identify early dental caries. In this work, after OCT data acquisition, data augmentation was performed to obtain a large amount of training data in order to effectively learn, where collection of such training data is often expensive and laborious. For the backpropagation process, seven optimization methods, namely Adadelta, AdaGrad, Adam, AdaMax, Nadam, RMSProp, and Stochastic Gradient Descent (SGD) were utilized to improve the accuracy of a CNN classifier for diagnosing dental caries. In this study, 75% of the data were utilized for training and 25% for testing. The diagnostic accuracy, sensitivity, specificity, positive predictive value, negative predictive value, and receiver operating characteristic (ROC) curve were calculated for detection and diagnostic performance of the deep CNN algorithm. This study highlighted the performance of various optimization methods for deep CNN models with OCT images to detect dental caries. © 2020 SPIE.","Convolutional neural networks; Deep learning; Dental caries detection; Image processing; Machine learning; Optical coherence tomography; Optimization methods","Convolution; Convolutional neural networks; Data acquisition; Deep learning; Dentistry; Diagnosis; Gradient methods; Image classification; Image processing; Learning algorithms; Learning systems; Optical data processing; Optical tomography; Optimization; Stochastic systems; Tomography; Dental caries; Detection and diagnostics; Learning techniques; Negative predictive value; Optimization method; Positive predictive values; Receiver operating characteristic curves; Stochastic gradient descent; Deep neural networks","California State University, CSU","Rechmann P.; Fried D.","SPIE",""
"Tianyu Z.; Xu J.","Tianyu, Zhao (59185068100); Xu, Jindong (35176864300)","59185068100; 35176864300","Hyperspectral Remote Sensing Image Segmentation Based on the Fuzzy Deep Convolutional Neural Network","2020","","","9263563","181","186","5","10.1109/CISP-BMEI51763.2020.9263563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099553889&doi=10.1109%2fCISP-BMEI51763.2020.9263563&partnerID=40&md5=664a7b4ada702958de4d44a6f29180bf","The ""synonyms spectrum""and ""foreign body with the spectrum""of remote sensing images have caused the traditional segmentation methods to be greatly limited. Existing segmentation methods represented by deep convolution neural network have made breakthrough progress. However, traditional deep learning is a completely deterministic model, which can not describe the data uncertainty well. To solve this problem, a new fuzzy deep neural network is proposed in this paper, called RSFCNN (Remote Sensing image segmentation with Fuzzy Convolutional Neural Network). The network integrates fuzzy unit and traditional convolution unit. Convolution unit is used to extract discriminant features with different proportions, thus providing comprehensive information for pixel-level remote sensing image segmentation. Fuzzy logic unit is used to deal with various uncertainties and provide more reliable segmentation results. In this paper, end-to-end training scheme is used to learn the parameters of fuzzy and convolution units. Experiments were carried out on the data set of ISPRS Vaihingen. According to the experimental results, the proposed method has higher segmentation accuracy and better performance than other algorithms. © 2020 IEEE.","convolutional neural network; fuzzy neural network; remote sensing image segmentation; semantic segmentation","Biomedical engineering; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Fuzzy inference; Fuzzy logic; Fuzzy neural networks; Remote sensing; Comprehensive information; Convolution neural network; Deterministic modeling; Different proportions; Hyperspectral Remote Sensing Image; Remote sensing images; Segmentation accuracy; Segmentation results; Image segmentation","Yantai Science and Technology Plan, (2018YT06000271); Natural Science Foundation of Shandong Province, (ZR2017MF008, ZR2019MF060); Natural Science Foundation of Shandong Province; Project of Shandong Province Higher Educational Science and Technology Program, (J18KZ016); Project of Shandong Province Higher Educational Science and Technology Program","Zheng Q.; Zheng X.; Zhao X.; Yan W.; Zhang N.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"Mewada H.K.; Patel A.V.; Hassaballah M.; Alkinani M.H.; Mahant K.","Mewada, Hiren K. (35766889700); Patel, Amit V. (58237103800); Hassaballah, Mahmoud (36602545600); Alkinani, Monagi H. (57190278212); Mahant, Keyur (56878975200)","35766889700; 58237103800; 36602545600; 57190278212; 56878975200","Spectral–spatial features integrated convolution neural network for breast cancer classification","2020","20","17","4747","1","15","14","10.3390/s20174747","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089715387&doi=10.3390%2fs20174747&partnerID=40&md5=7c3d9abe058a330b36db548242af4641","Cancer identification and classification from histopathological images of the breast depends greatly on experts, and computer-aided diagnosis can play an important role in disagreement of experts. This automatic process has increased the accuracy of the classification at a reduced cost. The advancement in Convolution Neural Network (CNN) structure has outperformed the traditional approaches in biomedical imaging applications. One of the limiting factors of CNN is it uses spatial image features only for classification. The spectral features from the transform domain have equivalent importance in the complex image classification algorithm. This paper proposes a new CNN structure to classify the histopathological cancer images based on integrating the spectral features obtained using a multi-resolution wavelet transform with the spatial features of CNN. In addition, batch normalization process is used after every layer in the convolution network to improve the poor convergence problem of CNN and the deep layers of CNN are trained with spectral–spatial features. The proposed structure is tested on malignant histology images of the breast for both binary and multi-class classification of tissue using the BreaKHis Dataset and the Breast Cancer Classification Challenge 2015 Datasest. Experimental results show that the combination of spectral–spatial features improves classification accuracy of the CNN network and requires less training parameters in comparison with the well known models (i.e., VGG16 and ALEXNET). The proposed structure achieves an average accuracy of 97.58% and 97.45% with 7.6 million training parameters on both datasets, respectively. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Biomedical imaging; Breast cancer classification; Convolutional neural network; Deep learning; Wavelet transform","Algorithms; Breast; Breast Neoplasms; Female; Humans; Neural Networks, Computer; Wavelet Analysis; Computer aided diagnosis; Convolution; Diseases; Image classification; Image segmentation; Medical imaging; Neural networks; Wavelet transforms; Biomedical imaging applications; Breast cancer classifications; Classification accuracy; Convolution neural network; Histopathological images; Multi-class classification; Multi-resolution wavelet transform; Traditional approaches; algorithm; breast; breast tumor; classification; diagnostic imaging; female; human; wavelet analysis; Classification (of information)","","","MDPI AG","32842640"
"Bird J.J.; Kobylarz J.; Faria D.R.; Ekart A.; Ribeiro E.P.","Bird, Jordan J. (57203547990); Kobylarz, Jhonatan (57215684622); Faria, Diego R. (26031469100); Ekart, Aniko (6603036791); Ribeiro, Eduardo P. (8339159800)","57203547990; 57215684622; 26031469100; 6603036791; 8339159800","Cross-Domain MLP and CNN Transfer Learning for Biological Signal Processing: EEG and EMG","2020","8","","9027853","54789","54801","12","10.1109/ACCESS.2020.2979074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082671713&doi=10.1109%2fACCESS.2020.2979074&partnerID=40&md5=5ed1d2460351b4dfffdaa7c592c120ec","In this work, we show the success of unsupervised transfer learning between Electroencephalographic (brainwave) classification and Electromyographic (muscular wave) domains with both MLP and CNN methods. To achieve this, signals are measured from both the brain and forearm muscles and EMG data is gathered from a 4-class gesture classification experiment via the Myo Armband, and a 3-class mental state EEG dataset is acquired via the Muse EEG Headband. A hyperheuristic multi-objective evolutionary search method is used to find the best network hyperparameters. We then use this optimised topology of deep neural network to classify both EMG and EEG signals, attaining results of 84.76% and 62.37% accuracy, respectively. Next, when pre-trained weights from the EMG classification model are used for initial distribution rather than random weight initialisation for EEG classification, 93.82%(+29.95) accuracy is reached. When EEG pre-trained weights are used for initial weight distribution for EMG, 85.12% (+0.36) accuracy is achieved. When the EMG network attempts to classify EEG, it outperforms the EEG network even without any training (+30.25% to 82.39% at epoch 0), and similarly the EEG network attempting to classify EMG data outperforms the EMG network (+2.38% at epoch 0). All transfer networks achieve higher pre-training abilities, curves, and asymptotes, indicating that knowledge transfer is possible between the two signal domains. In a second experiment with CNN transfer learning, the same datasets are projected as 2D images and the same learning process is carried out. In the CNN experiment, EMG to EEG transfer learning is found to be successful but not vice-versa, although EEG to EMG transfer learning did exhibit a higher starting classification accuracy. The significance of this work is due to the successful transfer of ability between models trained on two different biological signal domains, reducing the need for building more computationally complex models in future research. © 2013 IEEE.","Applied machine learning; biological signal processing; EEG; EMG; knowledge adaptation; neural networks; transfer learning","Classification (of information); Deep learning; Deep neural networks; Electroencephalography; Evolutionary algorithms; Knowledge management; Learning systems; Neural networks; Transfer learning; Applied machine learning; Biological signal processing; Classification accuracy; Classification models; Gesture classifications; Knowledge adaptations; Multi-objective evolutionary; Unsupervised transfer learning; Biomedical signal processing","National Academies of Sciences, Engineering, and Medicine, NASEM; Fundação Araucária, (50715.538.33202.06072018); Aston University","","Institute of Electrical and Electronics Engineers Inc.",""
"Xu C.; Zeng X.; Song Z.; Tang X.","Xu, Chunyuan (57219564934); Zeng, Xiaotian (57211582048); Song, Zeyu (57221981461); Tang, Xiaoying (7404101292)","57219564934; 57211582048; 57221981461; 7404101292","Research status and trend of 4D spatiotemporal longitudinal analysis in biomedical field; [4D时空纵向分析在生物医学领域中的应用现状与趋势]","2020","25","10","","2100","2109","9","10.11834/jig.200188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093984908&doi=10.11834%2fjig.200188&partnerID=40&md5=4ee4eaf64b06e838aa6d1f945f535250","Clinicians and experimenters can obtain a time series of three-dimensional images in a fixed time period, that is, 4D (3D + time) longitudinal data with both time and space information, such as two-photon microscopy, CT/MRI(computer tomography/magnetic resonance imaging) Cine scanning mode, or artificially select a time point to scan, and use 4D tensor representation to integrate the collected data in one time and three spatial dimensions, which is suitable for longitudinal analysis. Longitudinal analysis describes the collection of data on one or more variables of the same object at multiple time points to study their changes over time or a set of diachronic research methods that track the influence of some variables, which are commonly used in the medical field: disease changes and causes. However, many studies in the past sliced 4D data into 2D/3D pictures due to the lack of suitable processing algorithms, resulting in significant information loss. In recent years, artificial intelligence has given full play to its natural advantages in massive data processing and has brought new solutions to solve the problems of 4D longitudinal data with high dimensions, large amount of calculation, and difficulty in analysis. Among the solutions, convolutional neural networks, long- and short-term memory networks, and other deep learning algorithms have achieved good results in the processing of different modalities, such as natural language, audio, image, and video. They have exceeded the traditional methods. In the longitudinal medical image analysis using 4D data, deep learning uses spatial information and time-varying information and plays an important role in studying the dynamic changes of goals over time. The main application directions can be divided into two categories: moving target tracking and positioning in the field of biomedicine and tumor growth prediction and auxiliary diagnosis, where moving target tracking and positioning includes matching between complex moving targets in the biological field, 4D longitudinal medical imaging, automatic data segmentation, and vascular dynamics research. Tumor growth prediction and auxiliary diagnosis use volume longitudinal data with time information to model tumor growth, calculate the change in tumor size over a period of time, that is, the growth characteristics of the tumor, and assist the doctor in the diagnostic stage from the perspective of growth rate (benign tumors generally grow slower than malignant tumors). Cancer grades are recommended for patients to review. During the treatment phase, tumor changes are accurately measured; the effects of radiotherapy or drug treatment are evaluated; survival is predicted; personalized treatment plans for patients are developed, and drug development is promoted. However, the abovementioned longitudinal analysis only focuses on the change of the macroscopic morphology of the lesion and cannot reflect all tumor biological information or predict the clinically relevant tumor properties. In the future, horizontal correlation analysis can include temporal features, capture the relationship between temporal and spatial changes, and map the quantitative values of molecular features to histopathological changes, thereby proving the relationship between the secretion of cytokines and the severity of lesions in the image relevance to explain the causality of the disease from the table and achieve personalized treatment. In addition, the accuracy and generalization of the abovementioned artificial intelligence algorithms depend on large-scale and high-quality data. Medical data have fewer samples, larger acquisition costs, and higher resolution requirements than data in other fields. Problem and longitudinal data make data collection difficult because they contain time information not previously involved. Future medical longitudinal data points can be combined with federal learning and transfer learning: federal learning is used to ensure that no data exchange is observed while improving the generalization of the model, making the same model suitable for data from other hospitals, and protecting the privacy of medical data. On the contrary, transfer learning is used to solve the problem of few high-quality samples and the lack of frame-by-frame labels, improve the accuracy of the model, and solve hidden security risks such as user privacy when the product is launched in the future. © 2020, Editorial and Publishing Board of Journal of Image and Graphics. All right reserved.","4D image; Artificial intelligence; Longitudinal analysis; Medical image processing; Spatiotemporal data","","National Natural Science Foundation of China, NSFC, (81471743)","","Editorial and Publishing Board of JIG",""
"Huerta A.; Martinez-Rodrigo A.; Rieta J.J.; Alcaraz R.","Huerta, Alvaro (57215134290); Martinez-Rodrigo, Arturo (56728840300); Rieta, Jose J (6603449399); Alcaraz, Rael (22333522900)","57215134290; 56728840300; 6603449399; 22333522900","A Deep Learning Solution for Automatized Interpretation of 12-Lead ECGs","2020","2020-September","","9344416","","","","10.22489/CinC.2020.305","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100944900&doi=10.22489%2fCinC.2020.305&partnerID=40&md5=a7e59927312484cbcc209ebdf71aff79","A broad variety of algorithms for detection and classification of rhythm and morphology abnormalities in ECG recordings have been proposed in the last years. Although some of them have reported very promising results, they have been mostly validated on short and non-public datasets, thus making their comparison extremely difficult. PhysioNet/CinC Challenge 2020 provides an interesting opportunity to compare these and other algorithms on a wide set of ECG recordings. The present model was created by 'ELBIT' team. The algorithm is based on deep learning, and the segmentation of all beats in the 12-lead ECG recording, generating a new signal for each one by concatenating sequentially the information found in each lead. The resulting signal is then transformed into a 2-D image through a continuous Wavelet transform and inputted to a convolutional neural network. According to the competition guidelines, classification results were evaluated in terms of a class-weighted F-score (Fßand a generalization of the Jaccard measure (Gß). In average for all training signals, these metrics were 0.933 and 0.811, respectively. Regarding validation on the testing set from the first phase of the challenge, mean values for both performance indices were 0.654 and 0.372, respectively. © 2020 Creative Commons; the authors hold their copyright.","","Biomedical signal processing; Cardiology; Convolutional neural networks; Electrocardiography; Wavelet transforms; Classification results; Continuous Wavelet Transform; ECG recording; F-score; Mean values; Performance indices; PhysioNet; Training signal; Deep learning","FEDER EU, (SBPLY/17/180501/000411); Ministerio de Economía y Competitividad, MINECO; Generalitat Valenciana, GVA; European Regional Development Fund, FEDER, (2018/11744); Agencia Estatal de Investigación, AEI; Junta de Comunidades de Castilla-La Mancha, JCCM, (AICO/2019/036)","","IEEE Computer Society",""
"Wahid A.; Shah J.A.; Khan A.U.; Ahmed M.; Razali H.","Wahid, Abdul (58028307700); Shah, Jawad Ali (54930956400); Khan, Adnan Umar (57188694672); Ahmed, Manzoor (55605708400); Razali, Hanif (57222478885)","58028307700; 54930956400; 57188694672; 55605708400; 57222478885","Multi-layer basis pursuit for compressed sensing mr image reconstruction","2020","8","","","186222","186231","9","10.1109/ACCESS.2020.3028877","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102807859&doi=10.1109%2fACCESS.2020.3028877&partnerID=40&md5=0f0ce6fbeb9d4bcf0e6a30e6bfbc49b6","Compressive Sensing (CS) is a widely used technique in biomedical signal acquisition and reconstruction. The technique is especially useful for reducing acquisition time for magnetic resonance imaging (MRI) signal acquisitions and reconstruction, where effects of patient fatigue and Claustrophobia need mitigation. In addition to improving patient experience, faster MRI scans are important for time sensitive imaging, such as functional or cardiac MRI, where target movement is unavoidable. Inspired from recent research works on multi-layer convolutional sparse coding (ML-CSC) theory to model deep neural networks, this work proposes a multi-layer basis pursuit framework which combines the benefit from objective-based CS reconstructions and deep learning-based reconstruction by employing iterative thresholding algorithms for successfully training a CS-MRI restoration framework on GPU and reconstruct test images using parameters of the trained model. Extensive experiments show the effectiveness of the proposed framework on four MRI datasets in terms of faster convergence, improved PSNR/SSIM, and better restoration efficiency as compared to the state of the art frameworks with different CS ratios. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Compressive sensing; Inverse problems in imaging; Iterative thresholding algorithms; Multi-layered convolutional sparse coding","Biomedical signal processing; Compressed sensing; Deep learning; Deep neural networks; Image coding; Iterative methods; Magnetic resonance imaging; Multilayer neural networks; Restoration; Biomedical signal acquisition; Compressive sensing; Faster convergence; Iterative thresholding; Patient experiences; Recent researches; Signal acquisitions; Target movements; Image reconstruction","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","International Conference on Medical Imaging and Computer-Aided Diagnosis, MICAD 2020","2020","633 LNEE","","","","","241","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088600500&partnerID=40&md5=bbf9e3e2cd490a976452739051187509","The proceedings contain 23 papers. The special focus in this conference is on Medical Imaging and Computer-Aided Diagnosis. The topics include: A Novel Classification Method of Medical Image Segmentation Algorithm; pathological Changes Discover Network: Discover the Pathological Changes of Perivascular Dermatitis by Semi-supervised Learning; optical Micro-scanning Reconstruction Technique for a Thermal Microscope Imaging System; a Survey for Traditional, Cascaded Regression, and Deep Learning-Based Face Alignment; automatic Detection and Counting of Malaria Parasite-Infected Blood Cells; classification of Chest Diseases Using Wavelet Transforms and Transfer Learning; Performance Analysis of Different 2D and 3D CNN Model for Liver Semantic Segmentation: A Review; application of Image Segmentation and Convolutional Neural Network in Classification Algorithms for Mammary X-ray Molybdenum Target Image; fusion Segmentation of Head Medical Image with Partially Annotated Data; Sparse Representation Label Fusion Method Combining Pixel Grayscale Weight for Brain MR Segmentation; Application of U-Shaped Convolutional Neural Network Based on Attention Mechanism in Liver CT Image Segmentation; design of Photovoltaic Power Intelligent Patrol Robot; application of Intelligent Calculation Method in the Cage Simulation; An Analysis of Multi-organ Segmentation Performance of CNNs on Abdominal Organs with an Emphasis on Kidney; Deep Learning for Mental Illness Detection Using Brain SPECT Imaging; vessel Segmentation and Stenosis Quantification from Coronary X-Ray Angiograms; Improved Brain Tumor Segmentation and Diagnosis Using an SVM-Based Classifier; 3D-Reconstruction and Semantic Segmentation of Cystoscopic Images; a Biomedical Survey on Osteoporosis Classification Techniques; segment Medical Image Using U-Net Combining Recurrent Residuals and Attention; a New Importance-Performance Analysis by Size-Insensitive Integrity-Based Fuzzy C-Means.","","","","Su R.; Liu H.","Springer",""
"Wahid A.; Shah J.A.; Khan A.U.; Ullah M.; Ayob M.Z.","Wahid, Abdul (58028307700); Shah, Jawad Ali (54930956400); Khan, Adnan Umar (57188694672); Ullah, Mukhtar (57192412884); Ayob, Mohd Zaki (24463629400)","58028307700; 54930956400; 57188694672; 57192412884; 24463629400","Multi-layered basis pursuit algorithms for classification of MR images of Knee ACL tear","2020","8","","","205424","205435","11","10.1109/ACCESS.2020.3037745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102800545&doi=10.1109%2fACCESS.2020.3037745&partnerID=40&md5=2d987b3b1c1d71cb6ff6cb4277fcb5d3","Deep learning architectures have been extensively used in recent years for the classification of biomedical images to assist clinicians for diagnosis and treatment management of patients with different health conditions. These architectures have demonstrated expert level diagnosis, and in some cases, surpassed human experts in diagnosing health conditions. The automation tools based on deep learning frameworks have the potential to transform all stages of medical imaging pipeline from image acquisition to interpretation and analysis. One of the most common areas where these techniques are applied is knee MR image classification for different types of Anterior Cruciate Ligament (ACL) tears. If properly and timely managed, the diagnosis and treatment of ACL tear can avoid further degradation of patients' knee joints and can also help slow the process of subsequent knee arthritis. In this work, we have implemented a novel classification framework based on multilayered basis pursuit algorithms inspired from recent research work in the area of the theoretical foundation of deep learning with the help of celebrated sparse coding theory. We implement an optimal multi-layered Convolutional Sparse Coding (ML-CSC) framework for classification of a labelled dataset of knee MR images with the coronal view and compare the results with traditional convolutional neural network (CNN) based classifiers. Empirical results demonstrate the effectiveness of the ML-CSC framework and show that the framework can successfully learn distinct features on a small dataset and achieve a good efficiency of more than 92% without employing regularization techniques and extensive training on large datasets. In addition to 95% average accuracy on the presence and absence of ACL tears, the framework also performs well on the imbalanced and challenging classification of partial ACL tear with 85% accuracy. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Basis pursuit; Iterative shrinkage algorithms; Knee MR image classification; Multi-layer convolutional sparse coding","Classification (of information); Computer aided diagnosis; Computer programming; Convolution; Convolutional neural networks; Deep learning; Image coding; Joints (anatomy); Large dataset; Magnetic resonance imaging; Medical imaging; Multilayer neural networks; Network architecture; Patient monitoring; Patient treatment; Anterior cruciate ligament; Classification framework; Learning architectures; Learning frameworks; Pursuit algorithms; Regularization technique; Theoretical foundations; Treatment management; Image classification","British Malaysian Institute, Universiti Kuala Lumpur, BMI, UniKL, (FRGS/1/2019/TK04/UNIKL/02/6); British Malaysian Institute, Universiti Kuala Lumpur, BMI, UniKL","","Institute of Electrical and Electronics Engineers Inc.",""
"Ke J.; Shen Y.; Guo Y.; Wright J.D.; Liang X.","Ke, Jing (57193131816); Shen, Yiqing (57218177551); Guo, Yi (55712471200); Wright, Jason D. (35622622300); Liang, Xiaoyao (7401735951)","57193131816; 57218177551; 55712471200; 35622622300; 7401735951","A Prediction Model of Microsatellite Status from Histology Images","2020","","","","334","338","4","10.1145/3397391.3397442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088159109&doi=10.1145%2f3397391.3397442&partnerID=40&md5=12e9c46f219987a0b07efb3ef09a37f9","Machine learning approaches have received sufficient attention in tumor detection in histopathology, and the very recent researches show their potential in extraction of molecular information for biomarker prediction. However, as we can only obtain label information of the whole slide, the patch-wise prediction classification results are simply summarized to reach the final diagnosis in previous work. In this paper, we develop a novel framework to precisely predict biomarker from hematoxylin and eosin (H&E) stained histology slides, where microsatellite instability (MSI) status in colorectal cancer is used as a case study. We develop a patch-wise binary classifier to detect tumor tissue as biomarker is tightly associated with tumor tissues. To obtain a precise predication of MSI status, a noise-robust convolutional neural network is trained by relabeling patch-wise output iteratively and feed back as input information. We employ a distillation framework for the dataset relabeling task. We also design a mathematical algorithm to sort out representative patches towards the final MSI status prediction. The model is evaluated by a large patient cohort from The Cancer Genome Atlas (TCGA), and tested on the state-of-the-art deep learning device NVIDIA GPU TeslaTM V100. The experimental results demonstrate the improved reliability in MSI prediction from histology images. © 2020 ACM.","computational pathology; deep learning; MSI prediction; tumor detection; WSI","Biomarkers; Biomedical engineering; Classification (of information); Computer aided diagnosis; Convolutional neural networks; Deep learning; Diseases; Distillation; DNA sequences; Forecasting; Histology; Image enhancement; Iterative methods; Learning systems; Tumors; Binary classifiers; Classification results; Colorectal cancer; Machine learning approaches; Mathematical algorithms; Microsatellite instability; Molecular information; Recent researches; Predictive analytics","","","Association for Computing Machinery",""
"Bai C.; Qian J.; Dang S.; Peng T.; Min J.; Lei M.; Dan D.; Yao B.","Bai, Chen (57192544698); Qian, Jia (55616129500); Dang, Shipei (57205286689); Peng, Tong (56432076600); Min, Junwei (36657468000); Lei, Ming (57203456278); Dan, Dan (54895220500); Yao, Baoli (7202334945)","57192544698; 55616129500; 57205286689; 56432076600; 36657468000; 57203456278; 54895220500; 7202334945","Full-color optically-sectioned imaging by wide-field microscopy via deep-learning","2020","11","5","","2619","2632","13","10.1364/BOE.389852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084666395&doi=10.1364%2fBOE.389852&partnerID=40&md5=5a5eb2d02e6510db0cf1b65eb7adf6ef","Wide-field microscopy (WFM) is broadly used in experimental studies of biological specimens. However, combining the out-of-focus signals with the in-focus plane reduces the signal-to-noise ratio (SNR) and axial resolution of the image. Therefore, structured illumination microscopy (SIM) with white light illumination has been used to obtain full-color 3D images, which can capture high SNR optically-sectioned images with improved axial resolution and natural specimen colors. Nevertheless, this full-color SIM (FC-SIM) has a data acquisition burden for 3D-image reconstruction with a shortened depth-of-field, especially for thick samples such as insects and large-scale 3D imaging using stitching techniques. In this paper, we propose a deep-learning-based method for full-color WFM, i.e., FC-WFM-Deep, which can reconstruct high-quality full-color 3D images with an extended optical sectioning capability directly from the FC-WFM z-stack data. Case studies of different specimens with a specific imaging system are used to illustrate this method. Consequently, the image quality achievable with this FC-WFM-Deep method is comparable to the FC-SIM method in terms of 3D information and spatial resolution, while the reconstruction data size is 21-fold smaller and the in-focus depth is doubled. This technique significantly reduces the 3D data acquisition requirements without losing detail and improves the 3D imaging speed by extracting the optical sectioning in the depth-of-field. This cost-effective and convenient method offers a promising tool to observe high-precision color 3D spatial distributions of biological samples. © 2020 Optical Society of America under the terms of the OSA Open Access Publishing Agreement","","Biomedical signal processing; Color; Cost effectiveness; Data acquisition; Image enhancement; Image reconstruction; Imaging systems; Signal to noise ratio; 3D data acquisition; 3D image reconstruction; Biological specimens; Learning-based methods; Stitching techniques; Structured illumination microscopies (SIM); White-light illumination; Wide-field microscopies; algorithm; Article; artificial neural network; Chrysomelidae; deep learning; fluorescence imaging; fluorescence microscopy; functional magnetic resonance imaging; histogram; human; illumination; image analysis; image quality; image reconstruction; image segmentation; learning; learning algorithm; microscopy; multiphoton microscopy; noise; polarization; quality control; refraction index; signal noise ratio; three-dimensional imaging; training; white light; wide field microscopy; Deep learning","Key Research and Development Program of Shaanxi Province; National Natural Science Foundation of China, NSFC, (61705256, 61905277, 81427802, 91750106); China Postdoctoral Science Foundation, (2019M663849); Shanxi Provincial Key Research and Development Project, (2020GY-008)","","OSA - The Optical Society",""
"Berisha S.; Shahraki F.F.; Mayerich D.; Prasad S.","Berisha, Sebastian (56642641000); Shahraki, Farideh Foroozandeh (57033991400); Mayerich, David (7801383946); Prasad, Saurabh (14018500100)","56642641000; 57033991400; 7801383946; 14018500100","Deep learning for hyperspectral image analysis, part I: Theory and algorithms","2020","","","","37","68","31","10.1007/978-3-030-38617-7_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085171075&doi=10.1007%2f978-3-030-38617-7_3&partnerID=40&md5=193bf45a963c1feba6d6a3099c754fa5","Deep neural networks have emerged as a set of robust machine learning tools for computer vision. The suitability of convolutional and recurrent neural networks, along with their variants, is well documented for color image analysis. However, remote sensing and biomedical imaging often rely on hyperspectral images containing more than three channels for pixel-level characterization. Deep learning can facilitate image analysis in multi-channel images; however, network architecture and design choices must be tailored to the unique characteristics of this data. In this two-part series, we review convolution and recurrent neural networks as applied to hyperspectral imagery. Part I focuses on the algorithms and techniques, while Part II focuses on application-specific design choices and real-world remote sensing and biomedical test cases. These chapters also survey recent advances and future directions for deep learning with hyperspectral images. © 2020, Springer Nature Switzerland AG.","","","","","Springer",""
"Wang C.; Qin H.; Lai G.; Zheng G.; Xiang H.; Wang J.; Zhang D.","Wang, Cheng (55684068300); Qin, Haotian (57204803949); Lai, Guangyun (36337857700); Zheng, Gang (57184792400); Xiang, Huazhong (56825044500); Wang, Jun (57211089952); Zhang, Dawei (8365460000)","55684068300; 57204803949; 36337857700; 57184792400; 56825044500; 57211089952; 8365460000","Automated classification of dual channel dental imaging of auto-fluorescence and white lightby convolutional neural networks","2020","13","4","2050014","","","","10.1142/S1793545820500145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085397372&doi=10.1142%2fS1793545820500145&partnerID=40&md5=094e684b9ac92ac3f75d1db014d222d0","Prevention is the most effective way to reduce dental caries. In order to provide a simple way to achieve oral healthcare direction in daily life, dual Channel, portable dental Imaging system that combine white light with autofluorescence techniques was established, and then, a group of volunteers were recruited, 7200 tooth pictures of different dental caries stage and dental plaque were taken and collected. In this work, a customized Convolutional Neural Networks (CNNs) have been designed to classify dental image with early stage caries and dental plaque. Eighty percentage (n=6000) of the pictures taken were used to supervised training of the CNNs based on the experienced dentists' advice and the rest 20% (n=1200) were used to a test dataset to test the trained CNNs. The accuracy, sensitivity and specificity were calculated to evaluate performance of the CNNs. The accuracy for the early stage caries and dental plaque were 95.3% and 95.9%, respectively. These results shown that the designed image system combined the customized CNNs that could automatically and efficiently find early caries and dental plaque on occlusal, lingual and buccal surfaces. Therefore, this will provide a novel approach to dental caries prevention for everyone in daily life. © 2020 The Author(s).","auto-flourescence; automatic classification; Biomedical imaging; caries; deep-learning; tooth healthcare","Convolution; Statistical tests; Autofluorescence; Automated classification; Dental caries; Dental images; Dental imaging; Dental plaques; Sensitivity and specificity; Supervised trainings; Article; autofluorescence; automation; cheek; classification algorithm; convolutional neural network; dental caries; dentist; diagnostic accuracy; human; sensitivity and specificity; supervised machine learning; tongue; tooth occlusion; tooth plaque; white light; Convolutional neural networks","National Natural Science Foundation of China, NSFC, (61775140); National Natural Science Foundation of China, NSFC","","World Scientific Publishing Co. Pte Ltd",""
"Panigrahi S.; Swarnkar T.","Panigrahi, Santisudha (57205744642); Swarnkar, Tripti (34881196300)","57205744642; 34881196300","Machine learning techniques used for the histopathological image analysis of oral cancer-a review","2020","13","1","","106","118","12","10.2174/1875036202013010106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098521678&doi=10.2174%2f1875036202013010106&partnerID=40&md5=05b605e54a5c613bdae5bec7eb02128c","Oral diseases are the 6th most revealed malignancy happening in head and neck regions found mainly in south Asian countries. It is the most common cancer with fourteen deaths in an hour on a yearly basis, as per the WHO oral cancer incidence in India. Due to the cost of tests, mistakes in the recognition procedure, and the enormous remaining task at hand of the cytopathologist, oral growths cannot be diagnosed promptly. This area is open to be looked into by biomedical analysts to identify it at an early stage. At present, with the advent of entire slide computerized scanners and tissue histopathology, there is a gigantic aggregation of advanced digital histopathological images, which has prompted the necessity for their analysis. A lot of computer aided analysis techniques have been developed by utilizing machine learning strategies for prediction and prognosis of cancer. In this review paper, first various steps of obtaining histopathological images, followed by the visualization and classification done by the doctors are discussed. As machine learning techniques are well known, in the second part of this review, the works done for histopathological image analysis as well as other oral datasets using these strategies for growth prognosis and anticipation are discussed. Comparing the pitfalls of machine learning and how it has overcome by deep learning mostly for image recognition tasks are also discussed subsequently. The third part of the manuscript describes how deep learning is beneficial and widely used in different cancer domains. Due to the remarkable growth of deep learning and wide applicability, it is best suited for the prognosis of oral disease. The aim of this review is to provide insight to the researchers opting to work for oral cancer by implementing deep learning and artificial neural networks. © 2020 Swarnkar & Panigrahi.","Convolutional neural network; Cytopathologist; Deep learning; Histopathology; Machine learning; Oral cancer","artificial neural network; biopsy; cancer prognosis; computer aided design; computer assisted tomography; convolutional neural network; decision tree; deep learning; electrospray mass spectrometry; histopathology; human; human tissue; image analysis; image segmentation; keratinization; learning algorithm; machine learning; mass spectrometry; matrix assisted laser desorption ionization time of flight mass spectrometry; mouth cancer; mouth squamous cell carcinoma; nerve cell network; predictive value; Review; sensitivity and specificity; support vector machine","","","Bentham Science Publishers",""
"Mittal S.; Hasija Y.","Mittal, Shubham (57216287416); Hasija, Yasha (55293651100)","57216287416; 55293651100","Applications of Deep Learning in Healthcare and Biomedicine","2020","68","","","57","77","20","10.1007/978-3-030-33966-1_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132939972&doi=10.1007%2f978-3-030-33966-1_4&partnerID=40&md5=51e6ed0d8622d02fbb178c8480fb4497","The increasing advancements and improvements in medicine and healthcare in the past few decades have ushered us into a data-driven era where a huge amount of data is collected and stored. With this change, there is a need for analytical and technological upgradation of existing systems and processes. Data collected is in the form of Electronic Health Data taken from individuals or patients which can be in the form of readings, texts, speeches or images. A means to Artificial Intelligence—‘Machine Learning’ is the study of models that computer systems use to self-learn instructions based on the weight of parameters without being provided explicit instructions. Parallelly with biomedical advancements in the past decade, it has been observed that there has been an increasing refinement of algorithms and tools of machine learning. Deep Learning is one of the more promising of these algorithms. It is an Artificial Neural Network that designs models computationally that are composed of many processing layers, in order to learn data representations with numerous levels of abstraction. Research suggests that deep learning might have benefits over previous algorithms of machine learning and its’ suggestive better predictive performance is, hence garnering significant attention. With their multiple levels of representation and results that surpass human accuracy, deep learning has particularly found widespread applications in health informatics and biomedicine. These are in the field of molecular diagnostics comprising pharmacogenomics and identification of pathogenic variants, in experimental data interpretation comprising DNA sequencing and gene splicing, in protein structure classification and prediction, in biomedical imaging, drug discovery, medical informatics and more. The aim of this chapter is to discuss these applications and to elaborate on how they are being instrumental in improving healthcare and medicine in the modern context. Algorithms of deep learning show an improved potential in learning patterns and extracting attributes from a complex dataset. We would first introduce deep learning and developments in artificial neural network and then go on to discuss its applications in healthcare and finally talk about its’ relevance in biomedical informatics and computational biology research in the public health domain. In the end future scope of deep learning algorithms would be discussed from a modern healthcare perspective. © 2020, Springer Nature Switzerland AG.","","Deep learning; Diagnosis; DNA sequences; Gene encoding; Health care; Learning algorithms; Medical imaging; Medical informatics; Multilayer neural networks; Data driven; Design models; Electronic health; Existing systems; Health data; Machine-learning; Self-learn; System use; Systems and process; Up gradations; Bioinformatics","","","Springer Science and Business Media Deutschland GmbH",""
"Zhang Q.; Heldermon C.D.; Toler-Franklin C.","Zhang, Qingchao (57219505792); Heldermon, Coy D. (6507590205); Toler-Franklin, Corey (23053181400)","57219505792; 6507590205; 23053181400","Multiscale Detection of Cancerous Tissue in High Resolution Slide Scans","2020","12510 LNCS","","","139","153","14","10.1007/978-3-030-64559-5_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098169542&doi=10.1007%2f978-3-030-64559-5_11&partnerID=40&md5=f1442d3d6a95a990547b5126f2a8967c","We present an algorithm for multi-scale tumor (chimeric cell) detection in high resolution slide scans. The broad range of tumor sizes in our dataset pose a challenge for current Convolutional Neural Networks (CNN) which often fail when image features are very small (8 pixels). Our approach modifies the effective receptive field at different layers in a CNN so that objects with a broad range of varying scales can be detected in a single forward pass. We define rules for computing adaptive prior anchor boxes which we show are solvable under the equal proportion interval principle. Two mechanisms in our CNN architecture alleviate the effects of non-discriminative features prevalent in our data - a foveal detection algorithm that incorporates a cascade residual-inception module and a deconvolution module with additional context information. When integrated into a Single Shot MultiBox Detector (SSD), these additions permit more accurate detection of small-scale objects. The results permit efficient real-time analysis of medical images in pathology and related biomedical research fields. © 2020, Springer Nature Switzerland AG.","Classification; Convolutional neural networks; Deep learning; Digital pathology; Tumor tissue","Convolutional neural networks; Medical imaging; Tumors; Biomedical research; Cancerous tissues; Context information; Discriminative features; Foveal detection; Multiscale detection; Real time analysis; Receptive fields; Object detection","GILMLab; American Cancer Society, ACS","Bebis G.; Yin Z.; Kim E.; Bender J.; Subr K.; Kwon B.C.; Zhao J.; Kalkofen D.; Baciu G.","Springer Science and Business Media Deutschland GmbH",""
"Kwon Y.; Won J.-H.; Kim B.J.; Paik M.C.","Kwon, Yongchan (57189761007); Won, Joong-Ho (23974997400); Kim, Beom Joon (56415337700); Paik, Myunghee Cho (7005745962)","57189761007; 23974997400; 56415337700; 7005745962","Uncertainty quantification using Bayesian neural networks in classification: Application to biomedical image segmentation","2020","142","","106816","","","","10.1016/j.csda.2019.106816","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069976043&doi=10.1016%2fj.csda.2019.106816&partnerID=40&md5=069f35478fdd549d5da380d7d4c17e25","Most recent research of deep neural networks in the field of computer vision has focused on improving performances of point predictions by developing network architectures or learning algorithms. Reliable uncertainty quantification accompanied by point estimation can lead to a more informed decision, and the quality of prediction can be improved. In this paper, we invoke a Bayesian neural network and propose a natural way of quantifying uncertainties in classification problems by decomposing the moment-based predictive uncertainty into two parts: aleatoric and epistemic uncertainty. The proposed method takes into account the discrete nature of the outcome, yielding the correct interpretation of each uncertainty. We demonstrate that the proposed uncertainty quantification method provides additional insights into the point prediction using two Ischemic Stroke Lesion Segmentation Challenge datasets and the Digital Retinal Images for Vessel Extraction dataset. © 2019 Elsevier B.V.","Aleatoric and epistemic uncertainty; Bayesian neural network; Ischemic stroke lesion segmentation; Retinal blood vessel segmentation; Uncertainty quantification","Bayesian networks; Blood vessels; Deep neural networks; Forecasting; Image classification; Network architecture; Neural networks; Ophthalmology; Uncertainty analysis; Bayesian neural networks; Epistemic uncertainties; Ischemic strokes; Retinal blood vessels; Uncertainty quantifications; Image segmentation","National Research Foundation of Korea, NRF, (NRF-2017R1A2B4008956)","","Elsevier B.V.",""
"Wang G.; Yang L.; Liu M.; Yuan X.; Xiong P.; Lin F.; Liu X.","Wang, Ge (57212305621); Yang, Lin (57212305597); Liu, Ming (56603389700); Yuan, Xin (57205468165); Xiong, Peng (36449520300); Lin, Feng (53982814000); Liu, Xiuling (35115326500)","57212305621; 57212305597; 56603389700; 57205468165; 36449520300; 53982814000; 35115326500","ECG signal denoising based on deep factor analysis","2020","57","","101824","","","","10.1016/j.bspc.2019.101824","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076406301&doi=10.1016%2fj.bspc.2019.101824&partnerID=40&md5=26edc721baeac603beeab07f375ccff0","Objective: In telemedicine, dynamic electrocardiogram (ECG) monitoring is important for preventing and diagnosing cardiovascular diseases. However, the interference of the external environment causes a large amount of noises in the dynamic ECG signal, affecting the subsequent automated analysis. Therefore, reduction of the noises in the ECG signal is particularly important. Approach: This study proposed a novel ECG signal denoising algorithm based on the deep factor analysis. The major technical innovations include a layer-by-layer denoising deep neural network built based on the factor analysis, in which a top-down strategy is used to reconstruct the signal. The Gaussian-distribution noise can be effectively removed at each layer; and complex noises can be represented by the sum of Gaussian components, thus also removed by the proposed deep network. Moreover, the noise reduction of the network is further improved through a supervised fine-tuning of the parameters of the proposed deep network model, thus increasing the robustness of the whole system in clinical applications. Results: The excellent performance of the proposed method has been verified on the MIT-BIH database, and the noise reduction results are evaluated using the signal-to-noise ratio and root mean square error. Significance: First of all, the algorithm does not rely on the setting of the frequency domain information and the threshold. Secondly, the algorithm preserves useful information while removing noises from the ECG signal. Finally, a gradient descent algorithm is used to supervise the training of the network, which can learn and preserve the small waveform features in the ECG signal. The performance of noise reduction is outstanding. © 2019","Deep learning; Dynamic electrocardiogram; Electrocardiograph (ECG) signal denoising; Factor analysis","Deep learning; Deep neural networks; Electrocardiography; Factor analysis; Frequency domain analysis; Gaussian noise (electronic); Gradient methods; Mean square error; Multilayer neural networks; Multivariant analysis; Signal denoising; Signal to noise ratio; Cardio-vascular disease; Clinical application; De-noising algorithm; External environments; Gaussian components; Gradient descent algorithms; Root mean square errors; Technical innovation; Article; artifact; back propagation neural network; data base; deep neural network; electrocardiogram; factor analysis; image processing; machine learning; noise reduction; priority journal; signal noise ratio; wavelet transform; Biomedical signal processing","National Natural Science Foundation of China, NSFC, (61673158, 61703133); Natural Science Foundation of Hebei Province, (17H01, F2016201186, F2017201222, F2018201070)","","Elsevier Ltd",""
"Zhang K.; Xu G.; Han Z.; Ma K.; Zheng X.; Chen L.; Duan N.; Zhang S.","Zhang, Kai (56611003500); Xu, Guanghua (55632209100); Han, Zezhen (57199917003); Ma, Kaiquan (57218512299); Zheng, Xiaowei (57201071086); Chen, Longting (57037203400); Duan, Nan (57215333827); Zhang, Sicong (15754711700)","56611003500; 55632209100; 57199917003; 57218512299; 57201071086; 57037203400; 57215333827; 15754711700","Data augmentation for motor imagery signal classification based on a hybrid neural network","2020","20","16","4485","1","20","19","10.3390/s20164485","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089387995&doi=10.3390%2fs20164485&partnerID=40&md5=48e4a0877f0237b5f3612d0f001a9f38","As an important paradigm of spontaneous brain-computer interfaces (BCIs), motor imagery (MI) has been widely used in the fields of neurological rehabilitation and robot control. Recently, researchers have proposed various methods for feature extraction and classification based on MI signals. The decoding model based on deep neural networks (DNNs) has attracted significant attention in the field of MI signal processing. Due to the strict requirements for subjects and experimental environments, it is difficult to collect large-scale and high-quality electroencephalogram (EEG) data. However, the performance of a deep learning model depends directly on the size of the datasets. Therefore, the decoding of MI-EEG signals based on a DNN has proven highly challenging in practice. Based on this, we investigated the performance of different data augmentation (DA) methods for the classification of MI data using a DNN. First, we transformed the time series signals into spectrogram images using a short-time Fourier transform (STFT). Then, we evaluated and compared the performance of different DA methods for this spectrogram data. Next, we developed a convolutional neural network (CNN) to classify the MI signals and compared the classification performance of after DA. The Fréchet inception distance (FID) was used to evaluate the quality of the generated data (GD) and the classification accuracy, and mean kappa values were used to explore the best CNN-DA method. In addition, analysis of variance (ANOVA) and paired t-tests were used to assess the significance of the results. The results showed that the deep convolutional generative adversarial network (DCGAN) provided better augmentation performance than traditional DA methods: geometric transformation (GT), autoencoder (AE), and variational autoencoder (VAE) (p < 0.01). Public datasets of the BCI competition IV (datasets 1 and 2b) were used to verify the classification performance. Improvements in the classification accuracies of 17% and 21% (p < 0.01) were observed after DA for the two datasets. In addition, the hybrid network CNN-DCGAN outperformed the other classification methods, with average kappa values of 0.564 and 0.677 for the two datasets. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Classification; CNN; Data augmentation; DCGAN; Motor imagery","Algorithms; Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Neural Networks, Computer; Analysis of variance (ANOVA); Biomedical signal processing; Brain computer interface; Convolution; Convolutional neural networks; Decoding; Deep learning; Deep neural networks; Electroencephalography; Fourier series; Image classification; Learning systems; Quality control; Spectrographs; Brain computer interfaces (BCIs); Classification performance; Electroencephalogram (EEG) datum; Experimental environment; Feature extraction and classification; Geometric transformations; Neurological rehabilitation; Short time Fourier transforms; algorithm; brain computer interface; electroencephalography; human; imagination; Classification (of information)","Key Research & Development Plan of Shaanxi Province, (2018ZDCXL-GY-06-01); National Key Research & Development Plan of China, (2017YFC1308500); National Natural Science Foundation of China, NSFC, (51775415)","","MDPI AG","32796607"
"Anwar A.M.; Eldeib A.M.","Anwar, Ayman M. (57215856487); Eldeib, Ayman M. (6507588870)","57215856487; 6507588870","EEG Signal Classification Using Convolutional Neural Networks on Combined Spatial and Temporal Dimensions for BCI Systems","2020","2020-July","","9175894","434","437","3","10.1109/EMBC44109.2020.9175894","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090998252&doi=10.1109%2fEMBC44109.2020.9175894&partnerID=40&md5=8c10f91912687ef26efef85f1446f5e8","EEG signal classification is an important task to build an accurate Brain Computer Interface (BCI) system. Many machine learning and deep learning approaches have been used to classify EEG signals. Besides, many studies have involved the time and frequency domain features to classify EEG signals. On the other hand, a very limited number of studies combine the spatial and temporal dimensions of the EEG signal. Brain dynamics are very complex across different mental tasks, thus it is difficult to design efficient algorithms with features based on prior knowledge. Therefore, in this study, we utilized the 2D AlexNet Convolutional Neural Network (CNN) to learn EEG features across different mental tasks without prior knowledge. First, this study adds spatial and temporal dimensions of EEG signals to a 2D EEG topographic map. Second, topographic maps at different time indices were cascaded to populate a 2D image for a given time window. Finally, the topographic maps enabled the AlexNet to learn features from the spatial and temporal dimensions of the brain signals. The classification performance was obtained by the proposed method on a multiclass dataset from BCI Competition IV dataset 2a. The proposed system obtained an average classification accuracy of 81.09%, outperforming the previous state-of-the-art methods by a margin of 4% for the same dataset. The results showed that converting the EEG classification problem from a (1D) time series to a (2D) image classification problem improves the classification accuracy for BCI systems. Also, our EEG topographic maps enabled CNN to learn subtle features from spatial and temporal dimensions, which better represent mental tasks than individual time or frequency domain features. © 2020 IEEE.","","Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Frequency domain analysis; Image enhancement; Maps; Classification accuracy; Classification performance; EEG classification; EEG signal classification; Learning approach; State-of-the-art methods; Temporal dimensions; Time and frequency domains; Biomedical signal processing","","","Institute of Electrical and Electronics Engineers Inc.",""
"Zhang Y.; Yan J.; Chen S.; Gong M.; Gao D.; Zhu M.; Gan W.","Zhang, Yongqing (34871194100); Yan, Jianrong (57218924053); Chen, Siyu (57218502845); Gong, Meiqin (57220954138); Gao, Dongrui (55647421400); Zhu, Min (57195103398); Gan, Wei (57212654107)","34871194100; 57218924053; 57218502845; 57220954138; 55647421400; 57195103398; 57212654107","Review of the applications of deep learning in bioinformatics","2020","15","8","","898","911","13","10.2174/1574893615999200711165743","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099687145&doi=10.2174%2f1574893615999200711165743&partnerID=40&md5=3cc09a52694a55dc30c8396ea4cdecee","Rapid advances in biological research over recent years have significantly enriched biological and medical data resources. Deep learning-based techniques have been successfully utilized to process data in this field, and they have exhibited state-of-the-art performances even on high-dimensional, nonstructural, and black-box biological data. The aim of the current study is to provide an overview of the deep learning-based techniques used in biology and medicine and their state-of-the-art applications. In particular, we introduce the fundamentals of deep learning and then review the success of applying such methods to bioinformatics, biomedical imaging, biomedicine, and drug discovery. We also discuss the challenges and limitations of this field, and outline possible directions for further research. © 2020 Bentham Science Publishers.","Bioinformatics; Biological data; Biomedical; Deep learning; High-dimensional. s; High-throughput","Deep learning; Medical imaging; Biological data; Biological research; Biomedical; Deep learning; High-dimensional; High-dimensional.; High-throughput; Higher-dimensional; Medical data; S; Article; bioinformatics; biomedicine; convolutional neural network; deep active learning; deep learning; drug development; generative adversarial network; graph convolutional network; human; image processing; information processing; learning algorithm; nonhuman; priority journal; recurrent neural network; Bioinformatics","","","Bentham Science Publishers",""
"Jiabin H.; Yangyu L.; Jian G.","Jiabin, He (57221613672); Yangyu, Luo (7404331764); Jian, Gong (57529095200)","57221613672; 7404331764; 57529095200","Extraction of cutting plans in craniosynostosis using convolutional neural networks","2020","","","9263523","846","851","5","10.1109/CISP-BMEI51763.2020.9263523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099534042&doi=10.1109%2fCISP-BMEI51763.2020.9263523&partnerID=40&md5=6c57da3e44cf0258ec322a808c762596","The extraction of skull cutting trajectory from existing successful cases of experienced specialists is one of the key steps to standardize the planning of craniosynostosis surgery. This paper proposes a new method for extracting the skull cutting trajectory that combines deep learning, binocular stereo vision, and point cloud processing technology. The proposed method is the first-time application of deep learning to segmentation of the external surface of skull. The method automates the extraction and digitization of the cutting trajectory by utilizing Mask R-CNN to detect and segment the surgical area first, then a simplified contour extraction algorithm is explored to extract the cutting trajectory, followed by 2D-3D mapping of the cutting trajectory coordinates with the aid of binocular stereo vision and point cloud processing. Study showed that the proposed method is able to extract the surgical cutting trajectory accurately and efficiently, with the point cloud depth measurement error less than 3mm and the trajectory point positioning error less than 0.3mm, meeting the standard of clinical application. © 2020 IEEE.","deep learning; depth camera; point cloud processing; trajectory extraction","Biomedical engineering; Convolutional neural networks; Deep learning; Extraction; Learning systems; Stereo image processing; Stereo vision; Surgery; Trajectories; Binocular stereo vision; Clinical application; Contour Extraction; Craniosynostosis; External surfaces; Point cloud; Trajectory coordinates; Trajectory points; Cutting","National Key Research and Development Program of China, NKRDPC, (2017YFE0121200)","Zheng Q.; Zheng X.; Zhao X.; Yan W.; Zhang N.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"A J.; M S.; Chhabra H.; Shajil N.; Venkatasubramanian G.","A, Janani (36518757600); M, Sasikala (57725341700); Chhabra, Harleen (55630695600); Shajil, Nijisha (57209661483); Venkatasubramanian, Ganesan (57203267694)","36518757600; 57725341700; 55630695600; 57209661483; 57203267694","Investigation of deep convolutional neural network for classification of motor imagery fNIRS signals for BCI applications","2020","62","","102133","","","","10.1016/j.bspc.2020.102133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089413728&doi=10.1016%2fj.bspc.2020.102133&partnerID=40&md5=943173a0546b9ae922e1ff43a8963972","Brain-Computer Interface (BCI) is a promising technology that enables people affected by neuromuscular disorders to control external devices like a wheelchair or prosthesis with the help of their brain signals. Functional near-infrared spectroscopy (fNIRS) is a non-invasive optical neuroimaging technique that describes the brain hemodynamics. Recently, it has been investigated for the development of BCI application. In the current study, fNIRS signals that report changes in hemoglobin concentrations acquired during imagination of executing four motor tasks namely, right-fist clenching, left-fist clenching, right- and left-foot tapping and rest have been explored. Besides employing conventional machine learning algorithms used in BCI field such as Support Vector Machine (SVM), Multilayer Perceptron (MLP) neural network, and Projection-based learning in a Meta-cognitive Radial Basis Function Network (PBL-McRBFN), a deep learning approach namely, Convolutional Neural Network (CNN) has been explored to classify the motor imagery fNIRS signals. Also, the selection of the best input image representation of the one-dimensional fNIRS signal to be used for CNN architecture is investigated. In comparison to conventional machine learning algorithms, the performance of CNN was superior with respect to the classification of four-class motor imagery fNIRS signals, with an average classification accuracy value of 72.35 ± 4.4%. The results show that the classification of fNIRS signals is possible using deep learning approach for the development of BCI application specifically using spectrogram representation of the fNIRS signal. © 2020 Elsevier Ltd","Brain-Computer Interface; Classification; Deep neural network; fNIRS; Functional near-infrared spectroscopy; Motor imagery","Biomedical signal processing; Brain computer interface; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Image classification; Image segmentation; Infrared devices; Learning algorithms; Learning systems; Multilayer neural networks; Near infrared spectroscopy; One dimensional; Radial basis function networks; Support vector machines; hemoglobin; oxygenated hemoglobin; unclassified drug; Classification accuracy; Conventional machines; Functional near-infrared spectroscopy (fnirs); Hemoglobin concentration; Learning approach; Multilayer perceptron neural networks; Neuroimaging techniques; Neuromuscular disorders; adult; Article; classification; convolutional neural network; data processing; deep neural network; electroencephalogram; feature extraction; female; functional near-infrared spectroscopy; hemodynamics; hemoglobin determination; human; human experiment; imagery; machine learning; male; motor control; motor imagery; multilayer perceptron; normal human; priority journal; radial basis function neural network; support vector machine; task performance; Functional neuroimaging","Centre for Research; Anna University, AU","","Elsevier Ltd",""
"Pelka O.; Friedrich C.M.; Seco de Herrera A.G.; Müller H.","Pelka, Obioma (57190736323); Friedrich, Christoph M. (35232936500); Seco de Herrera, Alba G. (57348565300); Müller, Henning (8501863000)","57190736323; 35232936500; 57348565300; 8501863000","Overview of the ImageCLEFmed 2020 Concept Prediction Task: Medical Image Understanding","2020","2696","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121819918&partnerID=40&md5=70f5ae79f59c26b2d08e01a59db04cf5","This paper describes the ImageCLEFmed 2020 Concept Detection Task. After first being proposed at ImageCLEF 2017, the medical task is in its 4th edition this year, as the automatic detection from medical images still remains a challenging task. In 2020, the format remained the same as in 2019, with a single sub-task. The concept detection task is part of the medical tasks, alongside the tuberculosis and visual question and answering tasks. Similar to the 2019 edition, the data set focuses on radiology images rather than biomedical images, however with an increased number of images. The distributed images were extracted from the biomedical open access literature (PubMed Central). The development data consists of 65,753 training and 15,970 validation images. Each image has corresponding Unified Medical Language System (UMLS™) concepts, that were extracted from the original article image captions. In this edition, additional imaging acquisition technique labels were included in the distributed data, which were adopted for pre-filtering steps, concept selection and ensemble algorithms. Most applied approaches for the automatic detection of concepts were deep learning based architectures. Long short-term memory (LSTM) recurrent neural networks (RNN), adversarial auto-encoder, convolutional neural networks (CNN) image encoders and transfer learning-based multi-label classification models were adopted. The performances of the submitted models (best score 0.3940) were evaluated using F1-scores computed per image and averaged across all 3,534 test images. Copyright © 2020 for this paper by its authors.","Computer vision; Concept detection; Image modality; Image understanding; ImageCLEF 2020; Radiology","Classification (of information); Computer vision; Image understanding; Long short-term memory; Medical imaging; Radiation; Signal encoding; Automatic Detection; Concept detection; Data set; Detection tasks; Image modality; ImageCLEF; ImageCLEF 2020; Medical image understanding; Prediction tasks; Subtask; Radiology","","De Carolis B.; Gena C.; Lieto A.; Rossi S.; Sciutti A.","CEUR-WS",""
"Lahmer H.; Oueslati A.E.; Lachiri Z.","Lahmer, Hiba (57216322941); Oueslati, Afef Elloumi (37662063300); Lachiri, Zied (6507731669)","57216322941; 37662063300; 6507731669","Classification of DNA Microarrays Using Deep Learning to identify Cell Cycle Regulated Genes","2020","","","9231888","","","","10.1109/ATSIP49331.2020.9231888","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096512427&doi=10.1109%2fATSIP49331.2020.9231888&partnerID=40&md5=bb67e259d8af38e397410ffc7c14ec20","The aim of this work is to take advantage of the power and growth of machine learning methods and deep learning algorithms in the biomedical field, and how to use it to predict and recognize repetitive patterns. The ultimate goal is to analyze the large amount set of data produced from the DNA (Deoxyribonucleic acid) microarrays technology. We can use this data to extract facts, information, and skills, such as gene expression level. Our target here is to classify two genes' types. The first represents cell cycle regulated genes and the second represents the non-cell cycle ones. For the classification purpose, we preprocess the data, and we implement deep learning models. Then we evaluate our approach and compare its precision with Liu and al results. In the literature, the latest approaches are depending on processing the numerical data related to the DNA microarrays genes progression. In our work, we adopt a novel approach using directly the Microarrays image data. We use the Convolutional Neural Network and the fully connected neural network algorithms, to classify our processed image data. The experiments demonstrate that our approach outperforms the state of art by a margin of 20 per cent. Our model accomplishes real time test accuracy of 92.39 % at classifying. © 2020 IEEE.","cell cycle regulated gene; CNN; deep learning; DNA microarrays classification; FCNN.; machine learning","Biochips; Bioinformatics; Classification (of information); Convolutional neural networks; Data handling; DNA; Gene expression; Image processing; Learning algorithms; Learning systems; Biomedical fields; DNA micro-array; Fully connected neural network; Gene expression levels; Machine learning methods; Microarrays technology; Processed images; Repetitive pattern; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Cardoen B.; Yedder H.B.; Sharma A.; Chou K.C.; Nabi I.R.; Hamarneh G.","Cardoen, Ben (57190175669); Yedder, Hanene Ben (57196223372); Sharma, Anmol (57212006536); Chou, Keng C (25627428500); Nabi, Ivan Robert (7003506324); Hamarneh, Ghassan (6603568967)","57190175669; 57196223372; 57212006536; 25627428500; 7003506324; 6603568967","ERGO: Efficient Recurrent Graph Optimized Emitter Density Estimation in Single Molecule Localization Microscopy","2020","39","6","8943153","1942","1956","14","10.1109/TMI.2019.2962361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077253183&doi=10.1109%2fTMI.2019.2962361&partnerID=40&md5=b237dcf5ac88370d2553aaf8b5251ba2","Single molecule localization microscopy (SMLM) allows unprecedented insight into the three-dimensional organization of proteins at the nanometer scale. The combination of minimal invasive cell imaging with high resolution positions SMLM at the forefront of scientific discovery in cancer, infectious, and degenerative diseases. By stochastic temporal and spatial separation of light emissions from fluorescent labelled proteins, SMLM is capable of nanometer scale reconstruction of cellular structures. Precise localization of proteins in 3D astigmatic SMLM is dependent on parameter sensitive preprocessing steps to select regions of interest. With SMLM acquisition highly variable over time, it is non-trivial to find an optimal static parameter configuration. The high emitter density required for reconstruction of complex protein structures can compromise accuracy and introduce artifacts. To address these problems, we introduce two modular auto-tuning pre-processing methods: adaptive signal detection and learned recurrent signal density estimation that can leverage the information stored in the sequence of frames that compose the SMLM acquisition process. We show empirically that our contributions improve accuracy, precision and recall with respect to the state of the art. Both modules auto-tune their hyper-parameters to reduce the parameter space for practitioners, improve robustness and reproducibility, and are validated on a reference in silico dataset. Adaptive signal detection and density prediction can offer a practitioner, in addition to informed localization, a tool to tune acquisition parameters ensuring improved reconstruction of the underlying protein complex. We illustrate the challenges faced by practitioners in applying SMLM algorithms on real world data markedly different from the data used in development and show how ERGO can be run on new datasets without retraining while motivating the need for robust transfer learning in SMLM. © 1982-2012 IEEE.","astigmatism; deep learning; density estimation; dSTORM; recurrent network; signal detection; Single molecule localization microscopy","Algorithms; Artifacts; Microscopy; Reproducibility of Results; Single Molecule Imaging; Biomedical signal processing; Complex networks; Deep learning; Molecules; Proteins; Recurrent neural networks; Stochastic systems; astigmatism; Density estimation; dSTORM; Recurrent networks; Single-molecule localizations; Article; computer model; density; human; image processing; learning algorithm; microscopy; reproducibility; signal detection; single molecule localization microscopy; algorithm; artifact; single molecule imaging; Signal detection","Canada Institutes of Health Research; NSERC-CREATE-Bioinformatics; Canada Foundation for Innovation, CFI; Luonnontieteiden ja Tekniikan Tutkimuksen Toimikunta, (PJT-156424, PJT-159845); British Columbia Knowledge Development Fund, BCKDF","","Institute of Electrical and Electronics Engineers Inc.","31880546"
"Lee Y.; Veerubhotla K.; Jeong M.H.; Lee C.H.","Lee, Yugyung (57293981900); Veerubhotla, Krishna (57208081742); Jeong, Myung Ho (58434376200); Lee, Chi H. (27867783500)","57293981900; 57208081742; 58434376200; 27867783500","Deep Learning in Personalization of Cardiovascular Stents","2020","25","2","","110","120","10","10.1177/1074248419878405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074034734&doi=10.1177%2f1074248419878405&partnerID=40&md5=e10eb6ea6fdb3c0fbe6fc7e288d3cd56","Deep learning (DL) application has demonstrated its enormous potential in accomplishing biomedical tasks, such as vessel segmentation, brain visualization, and speech recognition. This review article has mainly covered recent advances in the principles of DL algorithms, existing DL software, and designing strategies of DL models. Latest progresses in cardiovascular devices, especially DL-based cardiovascular stent used for angioplasty, differential and advanced diagnostic means, and the treatment outcomes involved with coronary artery disease (CAD), are discussed. Also presented is DL-based discovery of new materials and future medical technologies that will facilitate the development of tailored and personalized treatment strategies by identifying and forecasting individual impending risks of cardiovascular diseases. © The Author(s) 2019.","cardiovascular stents; deep learning; personalized devices","Clinical Decision-Making; Computer-Aided Design; Coronary Artery Disease; Deep Learning; Humans; Patient Selection; Percutaneous Coronary Intervention; Predictive Value of Tests; Prosthesis Design; Software; Stents; artificial neural network; back propagation; computed tomographic angiography; computer assisted tomography; convolutional neural network; coronary artery blood flow; coronary artery disease; deep learning; follow up; human; image analysis; image segmentation; in-stent restenosis; intravascular ultrasound; k nearest neighbor; limit of quantitation; machine learning; optical coherence tomography; percutaneous transluminal angioplasty; personalized medicine; priority journal; Review; support vector machine; three dimensional printing; validation process; adverse event; clinical decision making; computer aided design; coronary artery disease; devices; diagnostic imaging; pathophysiology; patient selection; percutaneous coronary intervention; predictive value; prosthesis design; software; stent","","","SAGE Publications Ltd","31554426"
"Lee B.; Yamanakkanavar N.; Choi J.Y.","Lee, Bumshik (13006258900); Yamanakkanavar, Nagaraj (57217089774); Choi, Jae Young (57210148644)","13006258900; 57217089774; 57210148644","Automatic segmentation of brain MRI using a novel patch-wise U-net deep architecture","2020","15","8 August","e0236493","","","","10.1371/journal.pone.0236493","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089052582&doi=10.1371%2fjournal.pone.0236493&partnerID=40&md5=68578f2b6fcbb7db94b1b17c5bf96ba2","Accurate segmentation of brain magnetic resonance imaging (MRI) is an essential step in quantifying the changes in brain structure. Deep learning in recent years has been extensively used for brain image segmentation with highly promising performance. In particular, the U-net architecture has been widely used for segmentation in various biomedical related fields. In this paper, we propose a patch-wise U-net architecture for the automatic segmentation of brain structures in structural MRI. In the proposed brain segmentation method, the non-overlapping patch-wise U-net is used to overcome the drawbacks of conventional U-net with more retention of local information. In our proposed method, the slices from an MRI scan are divided into non-overlapping patches that are fed into the U-net model along with their corresponding patches of ground truth so as to train the network. The experimental results show that the proposed patch-wise U-net model achieves a Dice similarity coefficient (DSC) score of 0.93 in average and outperforms the conventional U-net and the SegNetbased methods by 3% and 10%, respectively, for on Open Access Series of Imaging Studies (OASIS) and Internet Brain Segmentation Repository (IBSR) dataset. © 2020 Lee et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Algorithms; Brain; Deep Learning; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; article; brain; human; Internet; nuclear magnetic resonance imaging; algorithm; brain; diagnostic imaging; image processing; nuclear magnetic resonance imaging; procedures","National Institute on Aging, NIA, (P01AG026276)","","Public Library of Science","32745102"
"Teng L.; Fu Z.; Ma Q.; Yao Y.; Zhang B.; Zhu K.; Li P.","Teng, Long (57216179411); Fu, ZhongLiang (56729694600); Ma, Qian (57215010686); Yao, Yu (36071006800); Zhang, Bing (57215008558); Zhu, Kai (57201014715); Li, Ping (57216183973)","57216179411; 56729694600; 57215010686; 36071006800; 57215008558; 57201014715; 57216183973","Interactive Echocardiography Translation Using Few-Shot GAN Transfer Learning","2020","2020","","1487035","","","","10.1155/2020/1487035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082774217&doi=10.1155%2f2020%2f1487035&partnerID=40&md5=f339eb894ad771ddc199609ad67bd93e","Background. Interactive echocardiography translation is an efficient educational function to master cardiac anatomy. It strengthens the student's understanding by pixel-level translation between echocardiography and theoretically sketch images. Previous research studies split it into two aspects of image segmentation and synthesis. This split makes it hard to achieve pixel-level corresponding translation. Besides, it is also challenging to leverage deep-learning-based methods in each phase where a handful of annotations are available. Methods. To address interactive translation with limited annotations, we present a two-step transfer learning approach. Firstly, we train two independent parent networks, the ultrasound to sketch (U2S) parent network and the sketch to ultrasound (S2U) parent network. U2S translation is similar to a segmentation task with sector boundary inference. Therefore, the U2S parent network is trained with the U-Net network on the public segmentation dataset of VOC2012. S2U aims at recovering ultrasound texture. So, the S2U parent network is decoder networks that generate ultrasound data from random input. After pretraining the parent networks, an encoder network is attached to the S2U parent network to translate ultrasound images into sketch images. We jointly transfer learning U2S and S2U within the CGAN framework. Results and conclusion. Quantitative and qualitative contrast from 1-shot, 5-shot, and 10-shot transfer learning show the effectiveness of the proposed algorithm. The interactive translation is achieved with few-shot transfer learning. Thus, the development of new applications from scratch is accelerated. Our few-shot transfer learning has great potential in the biomedical computer-aided image translation field, where annotation data are extremely precious. © 2020 Long Teng et al.","","Algorithms; Computational Biology; Computer-Assisted Instruction; Deep Learning; Echocardiography; Education, Medical, Graduate; Heart; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Computer aided instruction; Computer aided language translation; Deep learning; Echocardiography; Image segmentation; Pixels; Textures; Ultrasonics; Cardiac anatomy; Educational function; Image translation; Learning-based methods; New applications; Research studies; Ultrasound data; Ultrasound images; algorithm; article; deep learning; echocardiography; human; image segmentation; synthesis; transfer of learning; algorithm; anatomy and histology; biology; diagnostic imaging; echocardiography; heart; image processing; medical education; procedures; teaching; Transfer learning","Sichuan Province's New Generation of Artificial Intelligence Major Special Project, (2018GZDZX0036); Sichuan University, SCU","","Hindawi Limited","32256680"
"Zhang Y.; Geng X.; Yan H.","Zhang, Yingjie (57197750602); Geng, Xiaozhong (25821795800); Yan, Hui (57189034361)","57197750602; 25821795800; 57189034361","Research on classification of motor imagery EEG signal based on CNN architecture","2020","","","","446","449","3","10.1109/ICVRIS51417.2020.00112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116333182&doi=10.1109%2fICVRIS51417.2020.00112&partnerID=40&md5=510550cbe99d00526dad245f73d2dce5","BCI based on machine learning could makes use of the EEG signals to communicate to output under the condition of without the participation of peripheral nerves and muscles. Extracting the essential features of the EEG signals in the presence of artifacts, training the classification algorithms and optimizing the performance of classifier is critical procedure for BCI system. In the realization of BCI, the most important step is the feature extraction and classification of EEG signals. Due to the obvious individual difference and low signal-to-noise ratio of EEG signals, the current feature extraction and classification algorithms have low accuracy. The emergence of deep learning has attracted much attention in many fields. At present, some researchers try to apply deep learning algorithm to the recognition of EEG signals, and obtain good results. Based on convolutional Neural Networks (CNN), this paper studies the application of deep learning in motor imagery task classification by end-to-end deep learning.  © 2020 IEEE.","BCI; CNN; Deep learning; Motor imagery","Biomedical signal processing; Brain computer interface; Classification (of information); Deep learning; Extraction; Feature extraction; Image classification; Learning algorithms; Signal to noise ratio; BCI; Classification algorithm; Condition; Convolutional neural network; Deep learning; EEG signals; Feature extraction and classification; Motor imagery; Motor imagery EEG; Neural network architecture; Convolutional neural networks","Fundamental Research Funds for the Jilin Province S&T Development Plan Technology Research Project, (20190302110GX); Platform of Jilin Province Science and Technology (S&T) Department “Jilin Province S&T Innovation Center for Physical Simulation and Security of Water resources and Electric Power Engineering, (20190902011TC)","","Institute of Electrical and Electronics Engineers Inc.",""
"Alghamdi M.; Abdel-Mottaleb M.; Collado-Mesa F.","Alghamdi, Manal (57218453700); Abdel-Mottaleb, Mohamed (7003452763); Collado-Mesa, Fernando (6603210796)","57218453700; 7003452763; 6603210796","DU-Net: Convolutional Network for the Detection of Arterial Calcifications in Mammograms","2020","39","10","9076644","3240","3249","9","10.1109/TMI.2020.2989737","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092679819&doi=10.1109%2fTMI.2020.2989737&partnerID=40&md5=0b26f1d9c52620af4b29489ad18d9e50","Breast arterial calcifications (BACs) are part of several benign findings present on some mammograms. Previous studies have indicated that BAC may provide evidence of general atherosclerotic vascular disease, and potentially be a useful marker of cardiovascular disease (CVD). Currently, there is no technique in use for the automatic detection of BAC in mammograms. Since a majority of women over the age of 40 already undergo breast cancer screening with mammography, detecting BAC may offer a method to screen women for CVD in a way that is effective, efficient, and broad reaching, at no additional cost or radiation. In this paper, we present a deep learning approach for detecting BACs in mammograms. Inspired by the promising results achieved using the U-Net model in many biomedical segmentation problems and the DenseNet in semantic segmentation, we extend the U-Net model with dense connectivity to automaticallydetectBACs inmammograms. The presented model helps to facilitate the reuse of computation and improve the flow of gradients, leading to better accuracy and easier training of the model. We evaluate the performance using a set of full-field digital mammograms collected and prepared for this task from a publicly available dataset. Experimental results demonstrate that the presented model outperforms human experts as well as the other related deep learning models. This confirms the effectiveness of our model in the BACs detection task, which is a promising step in providing a cost-effective risk assessment tool for CVD. © 2020 IEEE.","Cardiovascular; Deep learning; Mammogram; Segmentation. u-net","Atherosclerosis; Breast Diseases; Breast Neoplasms; Early Detection of Cancer; Female; Humans; Mammography; Biomineralization; Bone; Calcification (biochemistry); Cost effectiveness; Deep learning; Diseases; Mammography; Risk assessment; Semantics; X ray screens; Automatic Detection; Breast cancer screening; Cardiovascular disease; Convolutional networks; Full-field digital mammograms; Learning approach; Risk assessment tool; Semantic segmentation; accuracy; adult; artery calcification; Article; breast calcification; breast cancer; cancer screening; cardiovascular disease; cardiovascular risk; convolutional neural network; curated breast imaging subset of digital database for screening mammography; detection algorithm; digital imaging and communications in medicine; feature extraction; female; human; image analysis; image segmentation; information processing; mammography; risk assessment; atherosclerosis; breast disease; breast tumor; diagnostic imaging; early cancer diagnosis; mammography; Convolutional neural networks","","","Institute of Electrical and Electronics Engineers Inc.","32324546"
"Rosati R.; Romeo L.; Silvestri S.; Marcheggiani F.; Tiano L.; Frontoni E.","Rosati, Riccardo (57215373632); Romeo, Luca (56426855300); Silvestri, Sonia (57661100000); Marcheggiani, Fabio (56901130000); Tiano, Luca (6602139720); Frontoni, Emanuele (9737451300)","57215373632; 56426855300; 57661100000; 56901130000; 6602139720; 9737451300","Faster R-CNN approach for detection and quantification of DNA damage in comet assay images","2020","123","","103912","","","","10.1016/j.compbiomed.2020.103912","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087845128&doi=10.1016%2fj.compbiomed.2020.103912&partnerID=40&md5=cf11b628a04c9f128a9791b02fae7239","Background and Objective: DNA damage analysis can provide valuable information in several areas ranging from the diagnosis/treatment of a disease to the monitoring of the effects of genetic and environmental influences. The evaluation of the damage is determined by comet scoring, which can be performed by a skilled operator with a manual procedure. However, this approach becomes very time-consuming and the operator dependency results in the subjectivity of the damage quantification and thus in a high inter/intra-operator variability. Methods: In this paper, we aim to overcome this issue by introducing a Deep Learning methodology based on Faster R-CNN to completely automatize the overall approach while discovering unseen discriminative patterns in comets. Results: The experimental results performed on two real use-case datasets reveal the higher performance (up to mean absolute precision of 0.74) of the proposed methodology against other state-of-the-art approaches. Additionally, the validation procedure performed by expert biologists highlights how the proposed approach is able to unveil true comets, often unseen from the human eye and standard computer vision methodology. Conclusions: This work contributes to the biomedical informatics field by the introduction of a novel approach based on established object detection Deep Learning technique for evaluating the DNA damage. The main contribution is the application of Faster R-CNN for the detection and quantification of DNA damage in comet assay images, by fully automatizing the detection/classification DNA damage task. The experimental results extracted in two real use-case datasets demonstrated (i) the higher robustness of the proposed methodology against other state-of-the-art Deep Learning competitors, (ii) the speeding up of the comet analysis procedure and (iii) the minimization of the intra/inter-operator variability. © 2020 Elsevier Ltd","Comet assay; Deep learning; DNA damage classification; Faster R-CNN; Pattern recognition","Convolutional neural networks; Deep learning; Diagnosis; DNA; Learning systems; Object detection; DNA; Biomedical informatics; Comet assays; Damage quantification; Detection and quantifications; Environmental influences; Learning techniques; State of the art; State-of-the-art approach; accuracy; algorithm; Article; automation; biologist; comet assay; computer vision; controlled study; deep learning; discriminant analysis; DNA damage; human; human cell; male; methodology; newborn; pattern recognition; prepuce; primary cell culture; priority journal; skin fibroblast; standard; Damage detection","Università Politecnica delle Marche, UNIVPM","","Elsevier Ltd","32658777"
"Kim M.-G.; Ko H.; Pan S.B.","Kim, Min-Gu (56123033400); Ko, Hoon (24512238000); Pan, Sung Bum (7402713421)","56123033400; 24512238000; 7402713421","A study on user recognition using 2D ECG based on ensemble of deep convolutional neural networks","2020","11","5","","1859","1867","8","10.1007/s12652-019-01195-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060062632&doi=10.1007%2fs12652-019-01195-4&partnerID=40&md5=3f7682d473e3618fc9ac92140cf5a382","The risk of tampering exists for conventional user recognition methods based on biometrics such as face and fingerprint. Recently, research on user recognition using biometric signals such as electrocardiogram (ECG), electroencephalogram (EEG), and electromyogram (EMG) has been actively performed to overcome this issue. We herein propose a user recognition method applying a deep learning technique based on ensemble networks after transforming ECG signals into two-dimensional (2D) images. A preprocessing process for one-dimensional ECG signals is performed to remove noise or distortion; subsequently, they are projected onto a 2D image space and transformed into image data. For the proposed algorithm, we designed deep learning-based ensemble networks to improve the degraded performance arising from overfitting in a single network. Our experimental results demonstrate that the proposed ensemble networks exhibit an accuracy that is 1.7% higher than that of the single network. In particular, the performance of the ensemble networks is up to 13% higher compared to the single network that degrades the recognition rate by displaying similar features between classes. © 2019, The Author(s).","Biometrics; CNNs; Electrocardiogram; Ensemble networks; User recognition","Biometrics; Deep neural networks; Electrocardiography; Electroencephalography; Neural networks; CNNs; Convolutional neural network; Degraded performance; Electro-encephalogram (EEG); Ensemble networks; Learning techniques; Two dimensional (2D) image; User recognition; Biomedical signal processing","Ministry of Education, MOE, (2017R1A6A1A03015496); Ministry of Science, ICT and Future Planning, MSIP, (NRF-2018R1A2B6001984); National Research Foundation of Korea, NRF","","Springer",""
"Wodzinski M.; Banzato T.; Atzori M.; Andrearczyk V.; Cid Y.D.; Muller H.","Wodzinski, Marek (57195258893); Banzato, Tommaso (26323554400); Atzori, Manfredo (55388259600); Andrearczyk, Vincent (57190974414); Cid, Yashin DIcente (56732880800); Muller, Henning (8501863000)","57195258893; 26323554400; 55388259600; 57190974414; 56732880800; 8501863000","Training Deep Neural Networks for Small and Highly Heterogeneous MRI Datasets for Cancer Grading","2020","2020-July","","9175634","1758","1761","3","10.1109/EMBC44109.2020.9175634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091026443&doi=10.1109%2fEMBC44109.2020.9175634&partnerID=40&md5=0fb8be8eb5a251404b2225078cbaa353","Using medical images recorded in clinical practice has the potential to be a game-changer in the application of machine learning for medical decision support. Thousands of medical images are produced in daily clinical activity. The diagnosis of medical doctors on these images represents a source of knowledge to train machine learning algorithms for scientific research or computer-aided diagnosis. However, the requirement of manual data annotations and the heterogeneity of images and annotations make it difficult to develop algorithms that are effective on images from different centers or sources (scanner manufacturers, protocols, etc.). The objective of this article is to explore the opportunities and the limits of highly heterogeneous biomedical data, since many medical data sets are small and entail a challenge for machine learning techniques. Particularly, we focus on a small data set targeting meningioma grading. Meningioma grading is crucial for patient treatment and prognosis. It is normally performed by histological examination but recent articles showed that it is possible to do it also on magnetic resonance images (MRI), so non-invasive. Our data set consists of 174 T1-weighted MRI images of patients with meningioma, divided into 126 benign and 48 atypical/anaplastic cases, acquired using 26 different MRI scanners and 125 acquisition protocols, which shows the enormous variability in the data set. The performed preprocessing steps include tumor segmentation, spatial image normalization and data augmentation based on color and affine transformations. The preprocessed cases are passed to a carefully trained 2-D convolutional neural network. Accuracy above 74% was obtained, with the high-grade tumor recall above 74%. The results are encouraging considering the limited size and high heterogeneity of the data set. The proposed methodology can be useful for other problems involving classification of small and highly heterogeneous data sets. © 2020 IEEE.","classification; deep learning; grading; meningioma; small data set","Classification (of information); Computer aided diagnosis; Computer aided instruction; Convolutional neural networks; Decision support systems; Deep learning; Deep neural networks; Grading; Image segmentation; Learning systems; Magnetic resonance; Magnetic resonance imaging; Medical imaging; Patient treatment; Scanning; Tumors; Acquisition protocols; Affine transformations; Histological examination; Machine learning techniques; Magnetic resonance images (MRI); Medical decision supports; Scanner manufacturers; Scientific researches; Learning algorithms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Anderson O.; Kidd A.C.; Goatman K.A.; Weir A.J.; Voisey J.; Dilys V.; Siebert J.P.; Blyth K.G.","Anderson, Owen (57212452913); Kidd, Andrew C. (56042549600); Goatman, Keith A. (6602561233); Weir, Alexander J. (24726294600); Voisey, Jeremy (57216504252); Dilys, Vismantas (57194786256); Siebert, Jan P. (7102263104); Blyth, Kevin G. (8921989700)","57212452913; 56042549600; 6602561233; 24726294600; 57216504252; 57194786256; 7102263104; 8921989700","Fully automated volumetric measurement of malignant pleural mesothelioma from computed tomography images by deep learning: Preliminary results of an internal validation","2020","","","","64","73","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083730129&partnerID=40&md5=f3301597b5be86ce6607dcc963c87533","Malignant Pleural Mesothelioma (MPM) is a cancer associated with prior exposure to asbestos fibres. Unlike most tumours, which are roughly spherical, MPM grows like a rind surrounding the lung. This irregular shape poses significant clinical and technical challenges. Accurate tumour measurements are necessary to determine treatment efficacy, but manual segmentation is tedious, time-consuming and associated with high intra- and inter-observer variation. In addition, uncertainty is compounded by poor differentiation in the computed tomography (CT) image between MPM and other common features. We describe herein an internal validation of a fully automatic tool to generate volumetric segmentations of MPM tumours using a convolutional neural network (CNN). The system was trained using the first 123 CT volumetric datasets from a planned total of 403 scans. Each scan was manually segmented to provide the expert ground truth. Evaluation was by seven-fold cross validation on a subset of 80/123 datasets that have full volumetric segmentations. The mean volume of MPM tumour in these datasets is 405.1 cm3 (standard deviation 271.5 cm3). Following three-dimensional binary closing of the manual annotations to improve inter-slice consistency, the mean volume difference between the manual and automatic measurements is 27.2 cm3, which is not significantly different from zero difference (p = 0.225). The 95% limits of agreement between the manual and automated measurements are between-417 and +363 cm3. The mean Dice overlap coefficient was 0.64, which is comparable with inter-observer measurements reported elsewhere. To our knowledge, this is the first algorithm of its kind that fully automates and evaluates measurement of the MPM tumour volume. The next step will be to evaluate the method on the remaining unseen multi-centre evaluation set. Such an algorithm has possible future application to pharmaceutical trials (where it offers a repeatable study end point) and to routine care (where it allows tumour progression to be assessed rapidly to enhance therapeutic clinical decision making). Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Computed Tomography (CT); Convolutional Neural Network (CNN); Deep Learning (DL); Image Segmentation; Malignant Pleural Mesothelioma (MPM)","Asbestos; Biomedical engineering; Computerized tomography; Convolutional neural networks; Decision making; Tumors; Automated measurement; Automatic measurements; Clinical decision making; Computed tomography images; Malignant pleural mesotheliomas; Technical challenges; Volumetric measurement; Volumetric segmentations; Deep learning","Cancer Innovation Challenge; Scottish Health Council","Soares F.; Fred A.; Gamboa H.","SciTePress",""
"Seo H.; Badiei Khuzani M.; Vasudevan V.; Huang C.; Ren H.; Xiao R.; Jia X.; Xing L.","Seo, Hyunseok (56125023000); Badiei Khuzani, Masoud (55390716200); Vasudevan, Varun (57209329840); Huang, Charles (55890598500); Ren, Hongyi (57215971063); Xiao, Ruoxiu (57212428138); Jia, Xiao (57192916619); Xing, Lei (7103349003)","56125023000; 55390716200; 57209329840; 55890598500; 57215971063; 57212428138; 57192916619; 7103349003","Machine learning techniques for biomedical image segmentation: An overview of technical aspects and introduction to state-of-art applications","2020","47","5","","e148","e167","19","10.1002/mp.13649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084860873&doi=10.1002%2fmp.13649&partnerID=40&md5=349f96d644e266fdafe4e9e0a0995596","In recent years, significant progress has been made in developing more accurate and efficient machine learning algorithms for segmentation of medical and natural images. In this review article, we highlight the imperative role of machine learning algorithms in enabling efficient and accurate segmentation in the field of medical imaging. We specifically focus on several key studies pertaining to the application of machine learning methods to biomedical image segmentation. We review classical machine learning algorithms such as Markov random fields, k-means clustering, random forest, etc. Although such classical learning models are often less accurate compared to the deep-learning techniques, they are often more sample efficient and have a less complex structure. We also review different deep-learning architectures, such as the artificial neural networks (ANNs), the convolutional neural networks (CNNs), and the recurrent neural networks (RNNs), and present the segmentation results attained by those learning models that were published in the past 3 yr. We highlight the successes and limitations of each machine learning paradigm. In addition, we discuss several challenges related to the training of different machine learning models, and we present some heuristics to address those challenges. © 2019 American Association of Physicists in Medicine","deep learning; machine learning; medical Image; overview; segmentation","Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Decision trees; Image segmentation; K-means clustering; Learning algorithms; Markov processes; Medical imaging; Biomedical image segmentation; Deep learning; Learning models; Machine learning algorithms; Machine learning techniques; Machine-learning; Medical image; Overview; Segmentation; Technical aspects; conference paper; controlled study; convolutional neural network; deep learning; diagnostic imaging; heuristics; image segmentation; k means clustering; Markov random field; random forest; recurrent neural network; diagnostic imaging; human; image processing; machine learning; procedures; Recurrent neural networks","National Institutes of Health, NIH; National Cancer Institute, NCI, (R01CA176553); National Cancer Institute, NCI; Google; Varian Medical Systems","","John Wiley and Sons Ltd","32418337"
"Guo L.; Xie G.; Xu X.; Ren J.","Guo, Lei (58381663700); Xie, Gang (7202981334); Xu, Xinying (8853613200); Ren, Jinchang (23398632100)","58381663700; 7202981334; 8853613200; 23398632100","Effective melanoma recognition using deep convolutional neural network with covariance discriminant loss","2020","20","20","5786","1","14","13","10.3390/s20205786","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093705772&doi=10.3390%2fs20205786&partnerID=40&md5=68832c7c00ff23a45b2466a1bee179f7","Melanoma recognition is challenging due to data imbalance and high intra-class variations and large inter-class similarity. Aiming at the issues, we propose a melanoma recognition method using deep convolutional neural network with covariance discriminant loss in dermoscopy images. Deep convolutional neural network is trained under the joint supervision of cross entropy loss and covariance discriminant loss, rectifying the model outputs and the extracted features simultaneously. Specifically, we design an embedding loss, namely covariance discriminant loss, which takes the first and second distance into account simultaneously for providing more constraints. By constraining the distance between hard samples and minority class center, the deep features of melanoma and non-melanoma can be separated effectively. To mine the hard samples, we also design the corresponding algorithm. Further, we analyze the relationship between the proposed loss and other losses. On the International Symposium on Biomedical Imaging (ISBI) 2018 Skin Lesion Analysis dataset, the two schemes in the proposed method can yield a sensitivity of 0.942 and 0.917, respectively. The comprehensive results have demonstrated the efficacy of the designed embedding loss and the proposed methodology. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Covariance discriminant loss; Deep convolutional neural network; Dermoscopy image; Embedding loss; Melanoma recognition","Algorithms; Deep Learning; Dermoscopy; Humans; Melanoma; Neural Networks, Computer; Skin Neoplasms; Convolution; Deep neural networks; Dermatology; Diagnosis; Embeddings; Medical imaging; Oncology; Biomedical imaging; Class Centers; Cross entropy; Data imbalance; Dermoscopy images; Intra-class variation; Model outputs; Recognition methods; algorithm; diagnostic imaging; epiluminescence microscopy; human; melanoma; skin tumor; Convolutional neural networks","Hundred Talents Programme of Shanxi; Shanxi International Cooperation Project; Ecumenical Project for International Cooperation, EPIC, (201803D421039); Natural Science Foundation of Shanxi Province, (201801D121144); Shanxi Provincial Key Research and Development Project, (201703D111023, 201703D111027)","","MDPI AG","33066123"
"Xu J.; Zheng H.; Wang J.; Li D.; Fang X.","Xu, Jiacan (57210253570); Zheng, Hao (56984835800); Wang, Jianhui (55904629000); Li, Donglin (57215351417); Fang, Xiaoke (9747613400)","57210253570; 56984835800; 55904629000; 57215351417; 9747613400","Recognition of eeg signal motor imagery intention based on deep multi-view feature learning","2020","20","12","3496","1","16","15","10.3390/s20123496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086759677&doi=10.3390%2fs20123496&partnerID=40&md5=9f80f963947434c53c15a1f00224efe0","Recognition of motor imagery intention is one of the hot current research focuses of brain-computer interface (BCI) studies. It can help patients with physical dyskinesia to convey their movement intentions. In recent years, breakthroughs have been made in the research on recognition of motor imagery task using deep learning, but if the important features related to motor imagery are ignored, it may lead to a decline in the recognition performance of the algorithm. This paper proposes a new deep multi-view feature learning method for the classification task of motor imagery electroencephalogram (EEG) signals. In order to obtain more representative motor imagery features in EEG signals, we introduced a multi-view feature representation based on the characteristics of EEG signals and the differences between different features. Different feature extraction methods were used to respectively extract the time domain, frequency domain, time-frequency domain and spatial features of EEG signals, so as to made them cooperate and complement. Then, the deep restricted Boltzmann machine (RBM) network improved by t-distributed stochastic neighbor embedding (t-SNE) was adopted to learn the multi-view features of EEG signals, so that the algorithm removed the feature redundancy while took into account the global characteristics in the multi-view feature sequence, reduced the dimension of the multi-visual features and enhanced the recognizability of the features. Finally, support vector machine (SVM) was chosen to classify deep multi-view features. Applying our proposed method to the BCI competition IV 2a dataset we obtained excellent classification results. The results show that the deep multi-view feature learning method further improved the classification accuracy of motor imagery tasks. © 2020 by the authors.","Brain-computer interface (BCI); Deep neural network; Electroencephalography (EEG); Multi-view learning; Parametric t-distributed stochastic neighbor embedding (p.t-SNE)","Algorithms; Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Intention; Brain computer interface; Classification (of information); Deep learning; Electroencephalography; Frequency domain analysis; Image classification; Image enhancement; Learning systems; Stochastic systems; Support vector machines; Time domain analysis; Classification accuracy; Classification results; Electroencephalogram signals; Feature extraction methods; Feature representation; Restricted boltzmann machine; Stochastic neighbor embedding; Time frequency domain; algorithm; behavior; brain computer interface; electroencephalography; human; imagination; Biomedical signal processing","","","MDPI AG","32575798"
"Calhas D.; Romero E.; Henriques R.","Calhas, David (57216750828); Romero, Enrique (57220652850); Henriques, Rui (35334051400)","57216750828; 57220652850; 35334051400","On the use of pairwise distance learning for brain signal classification with limited observations","2020","105","","101852","","","","10.1016/j.artmed.2020.101852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084428684&doi=10.1016%2fj.artmed.2020.101852&partnerID=40&md5=0119debe6fce142d1c91a15e7574c3fe","The increasing access to brain signal data using electroencephalography creates new opportunities to study electrophysiological brain activity and perform ambulatory diagnoses of neurological disorders. This work proposes a pairwise distance learning approach for schizophrenia classification relying on the spectral properties of the signal. To be able to handle clinical trials with a limited number of observations (i.e. case and/or control individuals), we propose a Siamese neural network architecture to learn a discriminative feature space from pairwise combinations of observations per channel. In this way, the multivariate order of the signal is used as a form of data augmentation, further supporting the network generalization ability. Convolutional layers with parameters learned under a cosine contrastive loss are proposed to adequately explore spectral images derived from the brain signal. The proposed approach for schizophrenia diagnostic was tested on reference clinical trial data under resting-state protocol, achieving 0.95 ± 0.05 accuracy, 0.98 ± 0.02 sensitivity and 0.92 ± 0.07 specificity. Results show that the features extracted using the proposed neural network are remarkably superior than baselines to diagnose schizophrenia (+20pp in accuracy and sensitivity), suggesting the existence of non-trivial electrophysiological brain patterns able to capture discriminative neuroplasticity profiles among individuals. The code is available on Github: https://github.com/DCalhas/siamese_schizophrenia_eeg. © 2020 Elsevier B.V.","Classification; Electroencephalography; Pairwise learning; Schizophrenia","Algorithms; Brain; Education, Distance; Electroencephalography; Humans; Neural Networks, Computer; Brain; Diseases; Distance education; Electroencephalography; Electrophysiology; Medical applications; Network architecture; Neurophysiology; Spectroscopy; Data augmentation; Discriminative features; Generalization ability; Limited observations; Neurological disorders; Pair-wise combinations; Pairwise distances; Spectral properties; Article; brain; case control study; clinical assessment; clinical trial (topic); deep learning; diagnostic accuracy; disease classification; electroencephalography; feature extraction; human; image analysis; nerve cell network; nerve cell plasticity; neurofeedback; priority journal; resting state network; schizophrenia; sensitivity and specificity; signal transduction; algorithm; brain; diagnostic imaging; education; electroencephalography; Biomedical signal processing","","","Elsevier B.V.","32505420"
"Nisha S.S.; Meeral M.N.","Nisha, S. Shajun (57192830023); Meeral, M. Nagoor (57481255400)","57192830023; 57481255400","Applications of deep learning in biomedical engineering","2020","","","","245","270","25","10.1016/B978-0-12-823014-5.00008-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120713067&doi=10.1016%2fB978-0-12-823014-5.00008-9&partnerID=40&md5=b24d4e75b3def99a7012627998e90c55","Biomedical engineering is the concept of applying fundamental theories and analytical practices to medicine and biology. It can be profitable in the field of healthcare from implementation of medical devices to diagnostic expert systems. These devices and expert systems produce high-dimensional and irregular data. Employing deep learning (DL) algorithms in these devices will be effective for signal analyzing and identification of diseases. DL is a subset of machine learning that employs multiple levels of neural network. It is capable of learning features automatically. The applications of DL in biomedical engineering can be categorized into four fields. They are bio and medical images analysis, brain, body, and machine interface, genomic sequencing and gene expression analysis, and public and medical health management system. This chapter discusses fundamentals of biomedical engineering and DL. It also explores applications of DL in various problems of biomedical field. © 2021 Elsevier Inc. All rights reserved.","And machine interface; Biomedical engineering; Body; Brain; Deep learning; Gene expression analysis; Genomic sequencing; Medical images; Public and medical health management system","","","","Elsevier",""
"Li H.; Yin Z.","Li, Haohan (56352698800); Yin, Zhaozheng (36351279000)","56352698800; 36351279000","Attention, suggestion and annotation: A deep active learning framework for biomedical image segmentation","2020","12261 LNCS","","","3","13","10","10.1007/978-3-030-59710-8_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093106221&doi=10.1007%2f978-3-030-59710-8_1&partnerID=40&md5=7ee6b521db4ef10095a9b800a9f75f32","Despite the great success, deep learning based segmentation methods still face a critical obstacle: the difficulty in acquiring sufficient training data due to high annotation costs. In this paper, we propose a deep active learning framework that combines the attention gated fully convolutional network (ag-FCN) and the distribution discrepancy based active learning algorithm (dd-AL) to significantly reduce the annotation effort by iteratively annotating the most informative samples to train the ag-FCN for the better segmentation performance. Our framework is evaluated on 2015 MICCAI Gland Segmentaion dataset and 2017 MICCAI 6-month infant brain MRI Segmentation dataset. Experiment results show that our framework can achieve state-of-the-art segmentation performance by using only a portion of the training data. © Springer Nature Switzerland AG 2020.","","Convolutional neural networks; Deep learning; Image annotation; Image segmentation; Iterative methods; Magnetic resonance imaging; Medical computing; Medical imaging; Active Learning; Active-learning algorithm; Biomedical image segmentation; Convolutional networks; Learning-based segmentation; Segmentation performance; State of the art; Training data; Learning algorithms","","Martel A.L.; Abolmaesumi P.; Stoyanov D.; Mateus D.; Zuluaga M.A.; Zhou S.K.; Racoceanu D.; Joskowicz L.","Springer Science and Business Media Deutschland GmbH",""
"Zeimarani B.; Costa M.G.F.; Nurani N.Z.; Bianco S.R.; De Albuquerque Pereira W.C.; Filho C.F.F.C.","Zeimarani, Bashir (57218119296); Costa, Marly Guimaraes Fernandes (55252953100); Nurani, Nilufar Zeimarani (57218120253); Bianco, Sabrina Ramos (57218489317); De Albuquerque Pereira, Wagner Coelho (57221938197); Filho, Cicero Ferreira Fernandes Costa (6506784770)","57218119296; 55252953100; 57218120253; 57218489317; 57221938197; 6506784770","Breast Lesion Classification in Ultrasound Images Using Deep Convolutional Neural Network","2020","8","","9145538","133349","133359","10","10.1109/ACCESS.2020.3010863","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089303302&doi=10.1109%2fACCESS.2020.3010863&partnerID=40&md5=aa833c81111ae08b353019ac580c983d","In recent years, convolutional neural networks (CNNs) have found many applications in medical image analysis. Having enough labeled data, CNNs could be trained to learn image features and used for object localization, classification, and segmentation. Although there are many interests in building and improving automated systems for medical image analysis, lack of reliable and publicly available biomedical datasets makes such a task difficult. In this work, the effectiveness of CNNs for the classification of breast lesions in ultrasound (US) images will be studied. First, due to a limited number of training data, we use a custom-built CNN with a few hidden layers and apply regularization techniques to improve the performance. Second, we use transfer learning and adapt some pre-trained models for our dataset. The dataset used in this work consists of a limited number of cases, 641 in total, histopathologically categorized (413 benign and 228 malignant lesions). To assess how the results of our classifier generalize on our data set, a 5-fold cross-validation were employed, where in each fold 80% of data were used for training and the 20% for testing. Accuracy and the area under the ROC curve (AUC) were used as the main performance metrics. Before applying any regularizations techniques, we achieved an overall accuracy of 85.98% for tumor classification, and the AUC equal to 0.94. After applying image augmentation and regularization, the accuracy and the AUC increased to 92.05% and 0.97, respectively. Using a pre-trained model, we achieved an overall accuracy of 87.07% and an AUC equal to 0.96. The obtained results demonstrated the effectiveness of our custom architecture for classification of tumors in this small US imaging dataset, surpassing some traditional learning algorithm based on manual feature selection. © 2013 IEEE.","Breast tumor; convolutional neural network; transfer learning; ultrasound images","Automation; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Image analysis; Image classification; Image enhancement; Image segmentation; Learning algorithms; Statistical tests; Transfer learning; Tumors; Ultrasonics; Area under the ROC curve; Automated systems; Object localization; Overall accuracies; Performance metrics; Regularization technique; Traditional learning; Tumor classification; Medical imaging","Federal University of Amazonas-CETELI; Samsung Electronics of Amazonia Ltd., (8.387/1991); UFAM; Coordenação de Aperfeiçoamento de Pessoal de Nível Superior, CAPES","","Institute of Electrical and Electronics Engineers Inc.",""
"Toğaçar M.; Ergen B.; Cömert Z.","Toğaçar, Mesut (57205581917); Ergen, Burhan (6508022484); Cömert, Zafer (36543652400)","57205581917; 6508022484; 36543652400","Application of breast cancer diagnosis based on a combination of convolutional neural networks, ridge regression and linear discriminant analysis using invasive breast cancer images processed with autoencoders","2020","135","","109503","","","","10.1016/j.mehy.2019.109503","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075195028&doi=10.1016%2fj.mehy.2019.109503&partnerID=40&md5=58e8df55c2b555f9f2e258a668d99ec8","Invasive ductal carcinoma cancer, which invades the breast tissues by destroying the milk channels, is the most common type of breast cancer in women. Approximately, 80% of breast cancer patients have invasive ductal carcinoma and roughly 66.6% of these patients are older than 55 years. This situation points out a powerful relationship between the type of breast cancer and progressed woman age. In this study, the classification of invasive ductal carcinoma breast cancer is performed by using deep learning models, which is the sub-branch of artificial intelligence. In this scope, convolutional neural network models and the autoencoder network model are combined. In the experiment, the dataset was reconstructed by processing with the autoencoder model. The discriminative features obtained from convolutional neural network models were utilized. As a result, the most efficient features were determined by using the ridge regression method, and classification was performed using linear discriminant analysis. The best success rate of classification was achieved as 98.59%. Consequently, the proposed approach can be admitted as a successful model in the classification. © 2019 Elsevier Ltd","Autoencoder network; Biomedical image processing; Decision support; Deep learning; Feature selection; Invasive breast cancer","Algorithms; Artificial Intelligence; Breast Neoplasms; Carcinoma, Ductal, Breast; Diagnosis, Computer-Assisted; Discriminant Analysis; Female; Humans; Image Processing, Computer-Assisted; Linear Models; Machine Learning; Neoplasm Invasiveness; Neural Networks, Computer; Programming Languages; Reproducibility of Results; Sensitivity and Specificity; Software; adult; Article; artificial intelligence; autoencoder; breast carcinoma; cancer diagnosis; controlled study; convolutional neural network; deep learning; discriminant analysis; feature selection; female; human; human tissue; image processing; information processing; major clinical study; middle aged; tumor classification; algorithm; breast tumor; computer assisted diagnosis; computer language; discriminant analysis; image processing; machine learning; Paget nipple disease; procedures; reproducibility; sensitivity and specificity; software; statistical model; tumor invasion","","","Churchill Livingstone","31760247"
"Habiba A.A.; Raghu B.","Habiba, A. Afreen (57217868697); Raghu, B. (57193133682)","57217868697; 57193133682","Computer aided diagnosis of brain tumour deep learning convolution neutral network for medical image recognition; [Компютърна диагностика на мозъчен тумор Дълбоко обучение Неволюлна мрежа за медицинско разпознаване на образи]","2020","59","S1","","344","360","16","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112126464&partnerID=40&md5=9dd5e66f7aa34dfbc29f330f35c3f8d3","In the recent past, biomedical domain has become popular due to digital image processing of accurate and efficient diagnosis of clinical patients using Computer-Aided Diagnosis (CAD). Appropriate and punctual disease identification and treatment arrangement directs to enhance superiority of life and improved life hope in brain tumour Disease patients. The cutting-edge approaches that believe multimodal analysis have been shown to be efficient and accurate are improved compared with manual analysis. Many tools have been introduced for detection of brain tumour but still it is a financially high costly diagnosis system gives detection of disease with low accuracy and efficient due to performance of Magnetic Resonance Imaging (MRI) scanning devices. A novel methodology is proposed in this research as CAD process using various algorithms for predicting brain tumour. The MRI images from scanning device are a highly noisy image due to thermal activities of hardware involved in scanning device. The image restoration technique is applied using 2D Adaptive Bilateral Filter (2D-ABF) algorithm. The quality of image in terms of brightness and contrast are improved using image enhancement techniques based on Adaptive Histogram Adjustment (AHA) algorithm. The Region of Interest of brain tumour disease is segmented using U-net algorithm. The various features are calculated using convolution neural network. Based on selection of features, the Deep Learning (DL) approach is used to classify the disease images and its stages. The Deep Convolutional Neural Network (DCNN) is the classification technique implemented to classify disease for proper diagnostic decision making. The experimental results prove that the proposed methodology provides better accuracy and efficiency than existing system. © 2020 Izdatelstvo Medicina i Fizkultura. All rights reserved.","2D-ABF; AHA; CAD; Deep learning neural network classifier; MRI; U-Net segmentation","","","","Izdatelstvo Medicina i Fizkultura",""
"Dobratulin K.; Gaidel A.; Kapishnikov A.; Ivleva A.; Aupova I.; Zelter P.","Dobratulin, Konstantin (57219685346); Gaidel, Andrey (55652819400); Kapishnikov, Aleksandr (6507900025); Ivleva, Anna (57216846125); Aupova, Irina (57241900300); Zelter, Pavel (56512149200)","57219685346; 55652819400; 6507900025; 57216846125; 57241900300; 56512149200","The efficiency of deep learning algorithms for detecting anatomical reference points on radiological images of the head profile","2020","","","9253067","","","","10.1109/ITNT49337.2020.9253067","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097611242&doi=10.1109%2fITNT49337.2020.9253067&partnerID=40&md5=e7b6e0cbb37d2c59bbf5d8be4b76d6f9","In this article we investigate the efficiency of deep learning algorithms in solving the task of detecting anatomical reference points on radiological images of the head in lateral projection using a fully convolutional neural network and a fully convolutional neural network with an extended architecture for biomedical image segmentation - U-Net. A comparison is made for the results of detection anatomical reference points for each of the selected neural network architectures and their comparison with the results obtained when orthodontists detected anatomical reference points. Based on the obtained results, it was concluded that a U-Net neural network allows performing the detection of anatomical reference points more accurately than a fully convolutional neural network. The results of the detection of anatomical reference points by the U-Net neural network are closer to the average results of the detection of reference points by agroupoforthodontists. © 2020 IEEE.","biomedical imagery; convolution neural networks; deep learning; image processing; localization; orthodontic; radiological images; radiology; u-net","Bioinformatics; Convolution; Convolutional neural networks; Deep learning; Efficiency; Image segmentation; Nanotechnology; Network architecture; Biomedical image segmentation; Radiological images; Reference points; Learning algorithms","RF Ministry of Science and Higher Education, (007-GZ/Ch3363/26); Russian Foundation for Basic Research, РФФИ, (18-07-01390, 19-29-01135, 19-29-01235)","","Institute of Electrical and Electronics Engineers Inc.",""
"Ashraf R.; Habib M.A.; Akram M.; Latif M.A.; Malik M.S.A.; Awais M.; Dar S.H.; Mahmood T.; Yasir M.; Abbas Z.","Ashraf, Rehan (56704783800); Habib, Muhammad Asif (35772504100); Akram, Muhammad (57217541926); Latif, Muhammad Ahsan (58583401200); Malik, Muhammad Sheraz Arshad (57505246800); Awais, Muhammad (57224215215); Dar, Saadat Hanif (57203841811); Mahmood, Toqeer (56081146500); Yasir, Muhammad (57215783658); Abbas, Zahoor (57217381928)","56704783800; 35772504100; 57217541926; 58583401200; 57505246800; 57224215215; 57203841811; 56081146500; 57215783658; 57217381928","Deep Convolution Neural Network for Big Data Medical Image Classification","2020","8","","9104735","105659","105670","11","10.1109/ACCESS.2020.2998808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087166459&doi=10.1109%2fACCESS.2020.2998808&partnerID=40&md5=c58fd8faf01b060649a0a0b898d1a6dc","Deep learning is one of the most unexpected machine learning techniques which is being used in many applications like image classification, image analysis, clinical archives and object recognition. With an extensive utilization of digital images as information in the hospitals, the archives of medical images are growing exponentially. Digital images play a vigorous role in predicting the patient disease intensity and there are vast applications of medical images in diagnosis and investigation. Due to recent developments in imaging technology, classifying medical images in an automatic way is an open research problem for researchers of computer vision. For classifying the medical images according to their relevant classes a most suitable classifier is most important. Image classification is beneficial to predict the appropriate class or category of unknown images. The less discriminating ability and domain-specific categorization are the main drawbacks of low-level features. A semantic gap that exists between features of low-level as machine understanding and features of human understanding as high-level perception. In this research, a novel image representation method is proposed where the algorithm is trained for classifying medical images by deep learning technique. A pre-trained deep convolution neural network method with the fine-tuned approach is applied to the last three layers of deep neural network. The results of the experiment exhibit that our method is best suited to classify various medical images for various body organs. In this manner, data can sum up to other medical classification applications which supports radiologist's efforts for improving diagnosis. © 2013 IEEE.","big data; biomedical image processing; convolution neural network; deep learning; image analysis; image enhancement; Medical image classification; pre-trained DCNN","Big data; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Learning algorithms; Learning systems; Medical imaging; Multilayer neural networks; Object recognition; Semantics; Convolution neural network; Discriminating abilities; Human understanding; Image representations; Learning techniques; Machine learning techniques; Machine understanding; Medical classification; Image classification","","","Institute of Electrical and Electronics Engineers Inc.",""
"Cullell-Dalmau M.; Otero-Viñas M.; Manzo C.","Cullell-Dalmau, Marta (57214215459); Otero-Viñas, Marta (6507474893); Manzo, Carlo (7003878225)","57214215459; 6507474893; 7003878225","Research Techniques Made Simple: Deep Learning for the Classification of Dermatological Images","2020","140","3","","507","514.e1","","10.1016/j.jid.2019.12.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079639482&doi=10.1016%2fj.jid.2019.12.029&partnerID=40&md5=b2421190091a0630cc1dcfda78399743","Deep learning is a branch of artificial intelligence that uses computational networks inspired by the human brain to extract patterns from raw data. Development and application of deep learning methods for image analysis, including classification, segmentation, and restoration, have accelerated in the last decade. These tools have been progressively incorporated into several research fields, opening new avenues in the analysis of biomedical imaging. Recently, the application of deep learning to dermatological images has shown great potential. Deep learning algorithms have shown performance comparable with humans in classifying skin lesion images into different skin cancer categories. The potential relevance of deep learning to the clinical realm created the need for researchers in disciplines other than computer science to understand its fundamentals. In this paper, we introduce the basics of a deep learning architecture for image classification, the convolutional neural network, in a manner accessible to nonexperts. We explain its fundamental operation, the convolution, and describe the metrics for the evaluation of its performance. These concepts are important to interpret and evaluate scientific publications involving these tools. We also present examples of recent applications for dermatology. We further discuss the capabilities and limitations of these artificial intelligence-based methods. © 2020 The Authors","","Deep Learning; Humans; Image Processing, Computer-Assisted; Research Design; Skin; Skin Diseases; artificial intelligence; classification; convolutional neural network; deep learning; dermatology; human; machine learning; priority journal; Short Survey; diagnostic imaging; image processing; methodology; procedures; skin; skin disease","Nvidia; Ministerio de Ciencia, Innovación y Universidades, MCIU; Generalitat de Catalunya; Agència de Gestió d'Ajuts Universitaris i de Recerca, AGAUR, (2017SGR940); Instituto de Salud Carlos III, ISCIII, (FIS PI19/01379); European Regional Development Fund, ERDF, (001-P-000382); Agencia Estatal de Investigación, AEI, (BFU2017-85693-R, RYC-2015-17896)","","Elsevier B.V.","32087827"
"Butola A.; Prasad D.K.; Ahmad A.; Dubey V.; Qaiser D.; Srivastava A.; Senthilkumaran P.; Ahluwalia B.S.; Mehta D.S.","Butola, Ankit (57196217761); Prasad, Dilip K. (35746873900); Ahmad, Azeem (56535839400); Dubey, Vishesh (56536194500); Qaiser, Darakhshan (36155647900); Srivastava, Anurag (57211371519); Senthilkumaran, Paramasivam (6701795186); Ahluwalia, Balpreet Singh (55398869000); Mehta, Dalip Singh (55666465200)","57196217761; 35746873900; 56535839400; 56536194500; 36155647900; 57211371519; 6701795186; 55398869000; 55666465200","Deep learning architecture “LightOCT” for diagnostic decision support using optical coherence tomography images of biological samples","2020","11","9","","5017","5031","14","10.1364/BOE.395487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096203655&doi=10.1364%2fBOE.395487&partnerID=40&md5=776a9e6aaa06f6922356edbb5fd1e6f3","Optical coherence tomography (OCT) is being increasingly adopted as a label-free and non-invasive technique for biomedical applications such as cancer and ocular disease diagnosis. Diagnostic information for these tissues is manifest in textural and geometric features of the OCT images, which are used by human expertise to interpret and triage. However, it suffers delays due to the long process of the conventional diagnostic procedure and shortage of human expertise. Here, a custom deep learning architecture, LightOCT, is proposed for the classification of OCT images into diagnostically relevant classes. LightOCT is a convolutional neural network with only two convolutional layers and a fully connected layer, but it is shown to provide excellent training and test results for diverse OCT image datasets. We show that LightOCT provides 98.9% accuracy in classifying 44 normal and 44 malignant (invasive ductal carcinoma) breast tissue volumetric OCT images. Also, >96% accuracy in classifying public datasets of ocular OCT images as normal, age-related macular degeneration and diabetic macular edema. Additionally, we show ∼96% test accuracy for classifying retinal images as belonging to choroidal neovascularization, diabetic macular edema, drusen, and normal samples on a large public dataset of more than 100,000 images. The performance of the architecture is compared with transfer learning based deep neural networks. Through this, we show that LightOCT can provide significant diagnostic support for a variety of OCT images with sufficient training and minimal hyper-parameter tuning. The trained LightOCT networks for the three-classification problem will be released online to support transfer learning on other datasets. © 2020 Optical Society of America under the terms of the OSA Open Access Publishing Agreement","","Classification (of information); Convolution; Convolutional neural networks; Decision support systems; Deep neural networks; Diagnosis; Image classification; Large dataset; Medical applications; Medical imaging; Multilayer neural networks; Network architecture; Ophthalmology; Optical tomography; Statistical tests; Tissue; Tomography; Transfer learning; Age-related macular degeneration; Biomedical applications; Choroidal neovascularization; Diagnostic decisions; Diagnostic procedure; Invasive ductal carcinomata; Learning architectures; Noninvasive technique; age related macular degeneration; algorithm; Article; choroidal neovascularization; computer model; controlled study; convolutional neural network; decision support system; deep learning; diabetic macular edema; diagnostic test accuracy study; drusen; human; human tissue; image analysis; learning algorithm; measurement accuracy; neovascularization (pathology); optical coherence tomography; receiver operating characteristic; refraction index; retina image; sensitivity and specificity; support vector machine; training; Deep learning","Direktoratet for internasjonalisering og kvalitetsutvikling i høgare utdanning, DIKU, (INCP- 2014/10024)","","The Optical Society",""
"Marchetti M.A.; Liopyris K.; Dusza S.W.; Codella N.C.F.; Gutman D.A.; Helba B.; Kalloo A.; Halpern A.C.; Soyer H.P.; Curiel-Lewandrowski C.; Caffery L.; Malvehy J.","Marchetti, Michael A. (57211010760); Liopyris, Konstantinos (57195290437); Dusza, Stephen W. (6602264879); Codella, Noel C.F. (57221190506); Gutman, David A. (26640342900); Helba, Brian (56110034900); Kalloo, Aadi (57213031962); Halpern, Allan C. (7103054781); Soyer, H. Peter (7102788402); Curiel-Lewandrowski, Clara (7801359609); Caffery, Liam (24342871500); Malvehy, Josep (6701867255)","57211010760; 57195290437; 6602264879; 57221190506; 26640342900; 56110034900; 57213031962; 7103054781; 7102788402; 7801359609; 24342871500; 6701867255","Computer algorithms show potential for improving dermatologists' accuracy to diagnose cutaneous melanoma: Results of the International Skin Imaging Collaboration 2017","2020","82","3","","622","627","5","10.1016/j.jaad.2019.07.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077930214&doi=10.1016%2fj.jaad.2019.07.016&partnerID=40&md5=69d0110b319c45687ab825a638b1d437","Background: Computer vision has promise in image-based cutaneous melanoma diagnosis but clinical utility is uncertain. Objective: To determine if computer algorithms from an international melanoma detection challenge can improve dermatologists' accuracy in diagnosing melanoma. Methods: In this cross-sectional study, we used 150 dermoscopy images (50 melanomas, 50 nevi, 50 seborrheic keratoses) from the test dataset of a melanoma detection challenge, along with algorithm results from 23 teams. Eight dermatologists and 9 dermatology residents classified dermoscopic lesion images in an online reader study and provided their confidence level. Results: The top-ranked computer algorithm had an area under the receiver operating characteristic curve of 0.87, which was higher than that of the dermatologists (0.74) and residents (0.66) (P <. 001 for all comparisons). At the dermatologists' overall sensitivity in classification of 76.0%, the algorithm had a superior specificity (85.0% vs. 72.6%, P = .001). Imputation of computer algorithm classifications into dermatologist evaluations with low confidence ratings (26.6% of evaluations) increased dermatologist sensitivity from 76.0% to 80.8% and specificity from 72.6% to 72.8%. Limitations: Artificial study setting lacking the full spectrum of skin lesions as well as clinical metadata. Conclusion: Accumulating evidence suggests that deep neural networks can classify skin images of melanoma and its benign mimickers with high accuracy and potentially improve human performance. © 2019 American Academy of Dermatology, Inc.","automated melanoma diagnosis; computer algorithm; computer vision; deep learning; dermatologist; International Skin Imaging Collaboration; International Symposium on Biomedical Imaging; machine learning; melanoma; reader study; skin cancer","Colombia; Cross-Sectional Studies; Deep Learning; Dermatologists; Dermoscopy; Diagnosis, Differential; Humans; Image Interpretation, Computer-Assisted; International Cooperation; Internship and Residency; Israel; Keratosis, Seborrheic; Melanoma; Nevus; ROC Curve; Skin; Skin Neoplasms; Spain; United States; Article; cancer diagnosis; cross-sectional study; cutaneous melanoma; dermatologist; diagnostic accuracy; diagnostic test accuracy study; epiluminescence microscopy; human; image analysis; major clinical study; physician attitude; pigmented nevus; priority journal; resident; seborrheic keratosis; sensitivity and specificity; Colombia; computer assisted diagnosis; dermatologist; diagnostic imaging; differential diagnosis; international cooperation; Israel; medical education; melanoma; nevus; pathology; procedures; receiver operating characteristic; skin; skin tumor; Spain; United States","National Institutes of Health, NIH; National Cancer Institute, NCI, (P30CA008748); National Cancer Institute, NCI; International Business Machines Corporation, IBM","","Mosby Inc.","31306724"
"Mojabi P.; Khoshdel V.; Lovetri J.","Mojabi, Pedram (57224835984); Khoshdel, Vahab (56602901200); Lovetri, Joe (57204246122)","57224835984; 56602901200; 57204246122","Tissue-type classification with uncertainty quantification of microwave and ultrasound breast imaging: A deep learning approach","2020","8","","","182092","182104","12","10.1109/ACCESS.2020.3027805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102342808&doi=10.1109%2fACCESS.2020.3027805&partnerID=40&md5=3db50d325fd679b283ab7e9a23f261b1","A deep learning approach is proposed for performing tissue-type classification of tomographic microwave and ultrasound property images of the breast. The approach is based on a convolutional neural network (CNN) utilizing the U-net architecture that also quantifies the uncertainty in the classification of each pixel. Quantitative tomographic reconstructions of dielectric properties (complex-valued permittivity), ultrasonic properties (compressibility and attenuation), as well as their combination, with the corresponding actual tissue-type classification constitute the training set. The CNN learns to map the quantitative property reconstructions to a single tissue-type image. The level of confidence in predicting a tissue-type at each pixel is determined. This uncertainty quantification is diagnostically critical for biomedical applications, especially when attempting to distinguish between cancerous and healthy tissues. The Gauss-Newton Inversion algorithm is used for the quantitative reconstruction of both dielectric and ultrasonic properties. Electromagnetic and ultrasound scattered-field data is obtained from MRI-derived numerical breast phan- toms. Several numerical breast phantoms types, from fatty to dense, are considered. The proposed classi- fication and uncertainty quantification approach is shown to outperform a previously studied tissue-type classification method based on a Bayesian approach. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Breast imaging; Convolutional neural network; Deep learning method; Inverse scattering; Microwave tomography; Multi-physics imaging; Tissue classification; Ultrasound tomography; Uncertainty quantification","Bayesian networks; Classification (of information); Convolutional neural networks; Deep learning; Dielectric materials; Dielectric properties; Image reconstruction; Medical applications; Medical imaging; Pixels; Tomography; Ultrasonics; Uncertainty analysis; Bayesian approaches; Biomedical applications; Inversion algorithm; Scattered field data; Tissue-type images; Tomographic reconstruction; Ultrasonic properties; Uncertainty quantifications; Tissue","Mitacs; Natural Sciences and Engineering Research Council of Canada, NSERC","","Institute of Electrical and Electronics Engineers Inc.",""
"Listyalina L.; Mustiadi I.; Dharmawan D.A.","Listyalina, Latifah (57188828027); Mustiadi, Ikhwan (57215409735); Dharmawan, Dhimas Arief (56516931400)","57188828027; 57215409735; 56516931400","Joint dice and intersection over union losses for deep optical disc segmentation","2020","","","9487620","49","54","5","10.1109/IBIOMED50285.2020.9487620","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112654091&doi=10.1109%2fIBIOMED50285.2020.9487620&partnerID=40&md5=ff6f0da3f9fd594a3466f44f58a7183a","Optic disc segmentation on retinal images is essential for the diagnosis of various eye-related diseases, such as diabetic retinopathy, glaucoma, and macular edema. However, manual segmentation of optic discs from fundus images by ophthalmologists is time-consuming, tedious, and labor-extensive. In the literature, various optic disc segmentation algorithms have been proposed. In general, the existing methods are evaluated in terms of the Dice coefficient and Area of Overlap. These two metrics indicates the capability of the existing methods in preserving the accurate optic disc contour and size. However, most available segmentation methods do not attempt to reduce the two measures directly. In this paper, we present a new deep optical disc framework that can tackle the drawbacks of the methods in the literature. The proposed framework performs segmentation by taking the advantages of the U-shaped convolutional neural network (U-Net); U-Net could be trained using a limited number of data. Unlike most other methods in the literature, we use a joint dice and intersection over union losses for training the deep network. We train and evaluate the proposed framework on retinal images from the DRIVE and DRISHTI-GS datasets. In the experimental parts, the proposed framework is capable of outperforming competing methods in terms of the Dice coefficient and Area of Overlap. Therefore, our framework is suitable for broad applications of automated retinal diseases diagnosis. © 2020 IEEE.","Deep learning; Dice loss; IoU loss; Optical disc; Retinal image; Segmentation","Biomedical engineering; Compact disks; Convolutional neural networks; Diagnosis; Disks (machine components); Disks (structural components); Eye protection; Ophthalmology; Optical disk storage; Broad application; Diabetic retinopathy; Dice coefficient; Manual segmentation; Number of datum; Retinal disease; Segmentation algorithms; Segmentation methods; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Konnova N.; Basarab M.; Khaperskaya V.","Konnova, Natalia (57193195003); Basarab, Mikhail (15069132900); Khaperskaya, Vera (57220183736)","57193195003; 15069132900; 57220183736","Application of machine learning algorithms for SCG signal classification","2020","11584","","115841L","","","","10.1117/12.2579578","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097198284&doi=10.1117%2f12.2579578&partnerID=40&md5=6e1a77340434c64259d4a7e7a7057865","Recent studies demonstrated the clinical utility of seismocardiography (hereinafter SCG) signals for the detection and monitoring of cardiovascular conditions. Renewed interest in investigating the utility of SCG has been accelerated recently and benefited from new advances in low-cost lightweight sensors and machine learning methods. This article compares various machine learning algorithms (the method of nearest neighbors, the method of support vectors, decision trees, the ensemble of models) and neural networks: based on the architecture of long short-Term memory and convolutional ones. An original numerical experiment was carried out using the developed mathematical software, where all of the mentioned methods and algorithms were implemented. During this study, much attention was paid to the preparation and preliminary processing of data. In particular, signal filtering is carried out using the Butterworth filter, and the issues of extracting features from the signal, which will become an input vector for machine learning algorithms, are also discussed. To compare the effectiveness of the considered models for solving the problem of diagnosing diseases, Accuracy, Recall, Sensitivity, Specificity, Precision, F1-measure, etc. are given. For each algorithm and data set, confusion matrices and ROC curves were constructed. Results of this research show that convolutional neural networks are very effective at diagnosing the states of the human cardiovascular system and supporting decision-making in cardiology and cardiac surgery.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","CNN; decision support system; deep learning; digital signal processing; KNN; LSTM; machine learning; neural networks; SVM","Biomedical signal processing; Butterworth filters; Cardiovascular surgery; Cardiovascular system; Convolution; Convolutional neural networks; Data handling; Decision making; Decision trees; Diagnosis; Image processing; Machine learning; Numerical methods; Video signal processing; Extracting features; Human cardiovascular systems; Lightweight sensors; Machine learning methods; Mathematical software; Numerical experiments; Preliminary processing; Signal classification; Learning algorithms","Russian Foundation for Basic Research, РФФИ, (18-29-02019)","Su R.","SPIE",""
"Chen T.; Lu T.; Song S.; Miao S.; Gao F.; Li J.","Chen, Tingting (57094298900); Lu, Tong (55769063400); Song, Shaoze (57202157179); Miao, Shichao (57215812528); Gao, Feng (57218975020); Li, Jiao (35770953200)","57094298900; 55769063400; 57202157179; 57215812528; 57218975020; 35770953200","A deep learning method based on U-Net for quantitative photoacoustic imaging","2020","11240","","112403V","","","","10.1117/12.2543173","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082686976&doi=10.1117%2f12.2543173&partnerID=40&md5=12fc08db0a2d438f995037758dfebcf9","Quantitative photoacoustic imaging (QPAI) is a hybrid imaging technique aimed at reconstructing optical parameters from photoacoustic signals detected around the biological tissues. The recovery of optical parameters is a nonlinear, ill-posed inverse problem which is usually solved by iterative optimization methods based on the error minimization strategy. Most of the iterative algorithms are empirical and computationally expensive, leading to inadequate performance in practical application. In this work, we propose a deep learning-based QPAI approach to efficiently recover the optical absorption coefficient of biological tissues from the reconstructed result of initial pressure. The method involves a U-Net architecture based on the fully convolutional neural network. The Monte Carlo simulation with the wide-field illumination has been used to generate simulation data for the network training. The feasibility of the proposed method was demonstrated through numerical simulations, and its applicability to quantitatively reconstruct the distribution of optical absorption in the practical situation is further verified in phantom experiments. High image performance of this method in accuracy, efficiency and fidelity from both simulated and experimental results, suggests the enormous potential in biomedical applications in the future. © 2020 SPIE.","Deep learning; Experimental validation; Optical inverse problem; Quantitative photoacoustic imaging; U-Net","Convolutional neural networks; Histology; Imaging techniques; Intelligent systems; Inverse problems; Iterative methods; Learning systems; Light absorption; Medical applications; Monte Carlo methods; Numerical methods; Optical variables control; Photoacoustic effect; Photons; Tissue; Ultrasonic applications; Biomedical applications; Experimental validations; ILL-posed inverse problem; Iterative algorithm; Iterative Optimization; Optical absorption coefficients; Photo-acoustic imaging; Photoacoustic signals; Deep learning","National Natural Science Foundation, (81671728, 81971656); Tianjin Municipal Education Commission, (17JCZDJC32700, 18JCYBJC29400, 19JCQNJC12800, 19JCY01BJC28600)","Oraevsky A.A.; Wang L.V.","SPIE",""
"Ke J.; Liu C.; Lu Y.; Jing N.; Liang X.; Jiang F.","Ke, Jing (57193131816); Liu, Changchang (59287406600); Lu, Yizhou (57200809307); Jing, Naifeng (35100372900); Liang, Xiaoyao (7401735951); Jiang, Fusong (56178389400)","57193131816; 59287406600; 57200809307; 35100372900; 7401735951; 56178389400","FIMIL: A high-throughput deep learning model for abnormality detection with weak annotation in microscopy images","2020","","","a34","","","","10.1145/3373017.3373051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079848157&doi=10.1145%2f3373017.3373051&partnerID=40&md5=c3874c01d4cd33cc8e165d2d245df7af","Automatic computer-aided detection plays an important role in biomedical image analysis. Many studies have focused on weak supervised learning as annotation tasks are time-consuming and tedious. Compared with pixel-wise annotation by particular software on the scanned digital high-resolution images, an alternative method of marking out of suspicious regions on microscopy slides is significantly more convenient for pathologists. Additionally, with a focus on dysplasias in the central area, there is a high likelihood of the similar tissues to be found around in clusters. In this paper, for weak annotation on microscopy images, we propose an efficient Foveated Imaging based Multiple Instance Learning (FIMIL) framework to classify weakly-labeled microscopy images. The model also provides multi-scale algorithm for arbitrary image size, in which the patches with highest possibility to contain dysplasia are considered as ""fixation points"" in the image. The developed model combines deep convolutional neural networks (CNNs) with multiple instance learning (MIL) for dysplasias detection with only image-level labeling. The benchmark tests are carried out on the marked regions of 40x magnified whole-slide cytology images and the normal/abnormal label and their corresponding possibilities are predicted. Evaluated on the real-life clinical data, our proposed model shows high accuracy and efficiency by weakly-supervised learning. 1 © 2020 ACM.","foveated imaging; microscopy image; multiple instance learning; performance acceleration","Benchmarking; Computer aided analysis; Convolutional neural networks; Cytology; Deep neural networks; Image annotation; Learning systems; Supervised learning; Biomedical image analysis; Computer aided detection; Foveated imaging; High resolution image; Microscopy images; Multiple instance learning; Performance acceleration; Weakly supervised learning; Deep learning","Science and Technology and Economic Commission of Shanghai Pudong","","Association for Computing Machinery",""
"Gayathri S.; Gopi V.P.; Palanisamy P.","Gayathri, S. (58688571000); Gopi, Varun P. (36537070400); Palanisamy, P. (57212368594)","58688571000; 36537070400; 57212368594","A lightweight CNN for Diabetic Retinopathy classification from fundus images","2020","62","","102115","","","","10.1016/j.bspc.2020.102115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089221799&doi=10.1016%2fj.bspc.2020.102115&partnerID=40&md5=04cbb7b6e6279e82e536253bf8bc741f","Diabetic Retinopathy (DR) is a complication of diabetes mellitus that damages blood vessel networks in the retina. This is a serious vision-threatening issue in most diabetic subjects. The DR diagnosis by color fundus images involves skilled clinicians to recognize the presence of lesions in the image that can be used to detect the disease properly, making it a time-consuming process. Effective automated detection of DR is a challenging task. The feature extraction plays an excellent role in effective automated disease detection. Convolutional Neural Networks (CNN) have superior image classification efficiency in the present scenario compared to earlier handcrafted feature-based image classification techniques. This work presents a novel CNN model to extract features from retinal fundus images for better classification performance. The CNN output features are used as input for different machine learning classifiers in the suggested system. The model is evaluated through various classifiers (Support Vector Machine, AdaBoost, Naive Bayes, Random Forest, and J48) by using images from generic IDRiD, MESSIDOR, and KAGGLE datasets. The efficacy of the classifier is evaluated by comparing the specificity, precision, recall, False Positive Rate (FPR), Kappa-score, and accuracy values for each classifier. The evaluation results indicate that the proposed feature extraction technique along with the J48 classifier outperforms all the other classifiers for MESSIDOR, IDRiD, and KAGGLE datasets with an average accuracy of 99.89% for binary classification and 99.59% for multiclass classification. Furthermore, for the J48 classifier, the average Kappa-score (K-score) is 0.994 for binary classification and 0.994 for multi-class classification. © 2020 Elsevier Ltd","10-fold cross-validation; Classifiers; CNN feature extraction; DR binary and multi class classification; Retinal fundus images","Adaptive boosting; Biomedical signal processing; Blood vessels; Classifiers; Convolutional neural networks; Decision trees; Diagnosis; Extraction; Eye protection; Feature extraction; Image classification; Learning systems; Support vector machines; Binary classification; Classification efficiency; Classification performance; Classification technique; Diabetic retinopathy; Feature extraction techniques; Multi-class classification; Retinal fundus images; Article; artificial neural network; Bayesian learning; binary classification; controlled study; convolutional neural network; deep neural network; diabetic retinopathy; eye fundus; feature extraction; genetic algorithm; kappa statistics; machine learning; multiclass classification; multilayer perceptron; priority journal; random forest; support vector machine; Classification (of information)","","","Elsevier Ltd",""
"Wang T.; Jin Y.","Wang, Tongyue (57221615615); Jin, Yanhua (24776129500)","57221615615; 24776129500","Modulation Recognition Based on Lightweight Neural Networks","2020","","","9263501","468","472","4","10.1109/CISP-BMEI51763.2020.9263501","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099559947&doi=10.1109%2fCISP-BMEI51763.2020.9263501&partnerID=40&md5=096c0df08bd6dcb0e4dd23df31fa4d23","In order to solve the problems of complex networks, large amount of calculation and high equipment requirements in the current deep learning method to complete the modulation recognition process, this paper proposes a modulation recognition algorithm based on lightweight neural networks. First, map the common 8 kinds of modulated signals to constellation diagrams to make image data sets. In the process of retaining the original signals, make full use of the performance of the neural network, build a representative the MobileNet neural network in the neural network to complete the training of the data set, use the test samples Verify the effectiveness of the lightweight neural networks used. Simulation experiment results show that the overall recognition rate of modulation reaches 98% when the SNR is greater than 2dB, but the training speed is greatly improved. © 2020 IEEE.","constellation; deep learning; lightweight neural network; MobileNet; modulation recognition","Biomedical engineering; Biomedical signal processing; Complex networks; Deep learning; Image processing; Learning systems; Modulation; Statistical tests; Constellation diagrams; Equipment requirements; Image datasets; Learning methods; Modulated signal; Modulation recognition; Original signal; Training speed; Neural networks","","Zheng Q.; Zheng X.; Zhao X.; Yan W.; Zhang N.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"Miao M.; Hu W.; Yin H.; Zhang K.","Miao, Minmin (57192816170); Hu, Wenjun (41661532200); Yin, Hongwei (57192423801); Zhang, Ke (57204393952)","57192816170; 41661532200; 57192423801; 57204393952","Spatial-Frequency Feature Learning and Classification of Motor Imagery EEG Based on Deep Convolution Neural Network","2020","2020","","1981728","","","","10.1155/2020/1981728","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089301429&doi=10.1155%2f2020%2f1981728&partnerID=40&md5=91c80d94d0452d36f662325b21867c11","EEG pattern recognition is an important part of motor imagery- (MI-) based brain computer interface (BCI) system. Traditional EEG pattern recognition algorithm usually includes two steps, namely, feature extraction and feature classification. In feature extraction, common spatial pattern (CSP) is one of the most frequently used algorithms. However, in order to extract the optimal CSP features, prior knowledge and complex parameter adjustment are often required. Convolutional neural network (CNN) is one of the most popular deep learning models at present. Within CNN, feature learning and pattern classification are carried out simultaneously during the procedure of iterative updating of network parameters; thus, it can remove the complicated manual feature engineering. In this paper, we propose a novel deep learning methodology which can be used for spatial-frequency feature learning and classification of motor imagery EEG. Specifically, a multilayer CNN model is designed according to the spatial-frequency characteristics of MI EEG signals. An experimental study is carried out on two MI EEG datasets (BCI competition III dataset IVa and a self-collected right index finger MI dataset) to validate the effectiveness of our algorithm in comparison with several closely related competing methods. Superior classification performance indicates that our proposed method is a promising pattern recognition algorithm for MI-based BCI system. © 2020 Minmin Miao et al.","","Algorithms; Brain-Computer Interfaces; Databases, Factual; Deep Learning; Electroencephalography; Humans; Imagination; Mathematical Concepts; Models, Neurological; Motor Cortex; Neural Networks, Computer; Pattern Recognition, Automated; Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Extraction; Feature extraction; Image classification; Iterative methods; Learning systems; Pattern recognition systems; Classification performance; Common spatial patterns; Convolution neural network; EEG pattern recognition; Feature classification; Feature engineerings; Network parameters; Pattern recognition algorithms; Article; automated pattern recognition; classification algorithm; controlled study; convolutional neural network; electroencephalogram; experimental study; feature learning (machine learning); human; index finger; motor imagery; signal processing; spatial frequency feature learning; algorithm; automated pattern recognition; biological model; brain computer interface; electroencephalography; factual database; imagination; mathematical phenomena; motor cortex; physiology; Deep learning","National Natural Science Foundation of China, NSFC, (61772198, 61772198 61772199, 61772199); Zhejiang Province Public Welfare Technology Application Research Project, (LGN18F020002)","","Hindawi Limited","32765639"
"Ongie G.; Sidky E.Y.; Reiser I.S.; Pan X.","Ongie, Gregory (56156713300); Sidky, Emil Y. (7003283807); Reiser, Ingrid S. (7004761259); Pan, Xiaochuan (7401930983)","56156713300; 7003283807; 7004761259; 7401930983","Supervised learning of model observers for assessment of CT image reconstruction algorithms","2020","11316","","113160B","","","","10.1117/12.2549817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085248552&doi=10.1117%2f12.2549817&partnerID=40&md5=f05b2057f2380b3d32c54b1acc63756f","Given the wide variety of CT reconstruction algorithms currently available { from filtered back projection, to non- linear iterative algorithms, and now even deep learning approaches { there is a pressing need for reconstruction quality metrics that correlate well with task-specific goals. For detection tasks, metrics based on a model observer framework are an attractive option. In this framework, a reconstruction algorithm is assessed based on how well a statistically optimal ""model observer"" performs on a signal present/signal absent detection task. However, computing exact model observers requires a detailed description of the statistics of the reconstructed images, which are often unknown or computationally intractable to obtain, especially in the case of non-linear reconstruction algorithms. Instead, we study the feasibility of using supervised machine learning approaches to approximate model observers in a CT reconstruction setting. In particular, we show that we can well-approximate the Hotelling observer, i.e., the optimal linear classifier, for a signal-known-exactly/background-known-exactly task by training from labeled training images in the case of FBP reconstruction. We also investigate the feasibility of training multi-layer neural networks to approximate the ideal observer in the case of total variation constrained iterative reconstruction. Our results demonstrate that supervised machine learning methods achieve close to ideal performance in both cases. © 2020 SPIE.","","Biomedical signal processing; Deep learning; Image reconstruction; Iterative methods; Learning algorithms; Learning systems; Medical imaging; Multilayer neural networks; Network layers; Supervised learning; Ct image reconstruction; Filtered back projection; Iterative algorithm; Iterative reconstruction; Non linear reconstruction; Reconstruction algorithms; Reconstruction quality; Supervised machine learning; Computerized tomography","National Institutes of Health, NIH, (OD025081-01, P30 CA14599, R01-EB023968, R01-EB026282, S10 RR021039)","Samuelson F.W.; Taylor-Phillips S.","SPIE",""
"Atila Ü.; Baydilli Y.Y.; Sehirli E.; Turan M.K.","Atila, Ümit (37074174900); Baydilli, Yusuf Yargı (57201117007); Sehirli, Eftal (56940693000); Turan, Muhammed Kamil (56460945700)","37074174900; 57201117007; 56940693000; 56460945700","Classification of DNA damages on segmented comet assay images using convolutional neural network","2020","186","","105192","","","","10.1016/j.cmpb.2019.105192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074768788&doi=10.1016%2fj.cmpb.2019.105192&partnerID=40&md5=20f12c6a4e7c61ad1c08a0b78ccfdd33","Background and Objective: Identification and quantification of DNA damage is a very significant subject in biomedical research area which still needs more robust and effective methods. One of the cheapest, easy to use and most successful method for DNA damage analyses is comet assay. In this study, performance of Convolutional Neural Network was examined on quantification of DNA damage using comet assay images and was compared to other methods in the literature. Methods: 796 single comet grayscale images with 170 x 170 resolution labeled by an expert and classified into 4 classes each having approximately 200 samples as G0 (healthy), G1 (poorly defective), G2 (defective) and G3 (very defective) were utilized. 120 samples were used as test dataset and the rest were used in data augmentation process to achieve better performance with training of Convolutional Neural Network. The augmented data having a total of 9995 images belonging to four classes were used as network training data set. Results: The proposed model, which was not dependent to pre-processing parameters of image processing for DNA damage classification, was able to classify comet images into 4 classes with an overall accuracy rate of 96.1%. Conclusions: This paper primarily focuses on features and usage of Convolutional Neural Network as a novel method to classify comet objects on segmented comet assay images. © 2019","Comet assay; Convolutional neural Network; Deep learning; DNA damage","Algorithms; Comet Assay; DNA Damage; Humans; Image Processing, Computer-Assisted; Lymphocytes; Neural Networks, Computer; Reproducibility of Results; Convolution; Deep learning; Deep neural networks; Defects; DNA; Image classification; Neural networks; Statistical tests; Biomedical research; Comet assays; Convolutional neural network; Data augmentation; DNA damages; Gray-scale images; Overall accuracies; Quantification of dnas; article; cell cycle G0 phase; cell cycle G1 phase; comet assay; convolutional neural network; deep learning; diagnostic test accuracy study; DNA damage; human; human experiment; image processing; major clinical study; algorithm; lymphocyte; procedures; reproducibility; ultrastructure; Damage detection","Karab?k University, (BAP-16/2-DR-102); Karabük Üniversitesi, (KBÜ-BAP-16/2-DR-102)","","Elsevier Ireland Ltd","31733518"
"Lam F.; Li Y.; Peng X.","Lam, Fan (35782118100); Li, Yahang (57216685567); Peng, Xi (36718260000)","35782118100; 57216685567; 36718260000","Constrained Magnetic Resonance Spectroscopic Imaging by Learning Nonlinear Low-Dimensional Models","2020","39","3","8770102","545","555","10","10.1109/TMI.2019.2930586","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081909350&doi=10.1109%2fTMI.2019.2930586&partnerID=40&md5=14353a7f0c1984bbd93013ef2c2a7674","Magnetic resonance spectroscopic imaging (MRSI) is a powerful molecular imaging modality but has very limited speed, resolution, and SNR tradeoffs. Construction of a low-dimensional model to effectively reduce the dimensionality of the imaging problem has recently shown great promise in improving these tradeoffs. This paper presents a new approach to model and reconstruct the spectroscopic signals by learning a nonlinear low-dimensional representation of the general MR spectra. Specifically, we trained a deep neural network to capture the low-dimensional manifold, where the high-dimensional spectroscopic signals reside. A regularization formulation is proposed to effectively integrate the learned model and physics-based data acquisition model for MRSI reconstruction with the capability to incorporate additional spatiospectral constraints. An efficient numerical algorithm was developed to solve the associated optimization problem involving back-propagating the trained network. Simulation and experimental results were obtained to demonstrate the representation power of the learned model and the ability of the proposed formulation in producing SNR-enhancing reconstruction from the practical MRSI data. © 1982-2012 IEEE.","low-dimensionalmodels; manifold learning; MR spectroscopic imaging; neural network; spatiospectral constraint; spectroscopy","Algorithms; Computer Simulation; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Magnetic Resonance Spectroscopy; Neural Networks, Computer; Nonlinear Dynamics; Biomedical signal processing; Commerce; Data acquisition; Deep learning; Deep neural networks; Magnetic resonance; Magnetic resonance spectroscopy; Molecular imaging; Neural networks; Spectroscopy; Low-dimensional manifolds; Low-dimensional modeling; Low-dimensional representation; low-dimensionalmodels; Magnetic resonance spectroscopic imaging; Manifold learning; Mr spectroscopic imaging; spatiospectral constraint; algorithm; article; deep neural network; manifold learning; nuclear magnetic resonance; physics; simulation; spectroscopy; algorithm; computer simulation; human; image processing; machine learning; nonlinear system; nuclear magnetic resonance imaging; nuclear magnetic resonance spectroscopy; procedures; Learning systems","","","Institute of Electrical and Electronics Engineers Inc.","31352337"
"","","","5th International Conference on Computing in Engineering and Technology,ICCET 2020","2020","1155","","","","","432","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089544581&partnerID=40&md5=daec5cb9e78de76842f3ad5dfd245937","The proceedings contain 43 papers. The special focus in this conference is on Computing in Engineering and Technology. The topics include: Machine learning techniques for homomorphically encrypted data; improving leaf disease detection and localization accuracy using bio-inspired machine learning; identification of medicinal plant using image processing and machine learning; Human gait analysis based on decision tree, random forest and KNN algorithms; adaptive mean filter technique for removal of high density salt and pepper (impulse) noise; a novel approach of image processing to identify type and name of snake; robust and secure lucas sequence-based video watermarking; creating video summary using speeded up robust features; fingerprint-based gender classification by using neural network model; segmentation of characters from degraded Brahmi script images; sentiment analysis of democratic presidential primaries debate tweets using machine learning models; a computational linguistics approach to preserving and promoting natural languages; Comparative analysis of geometric transformation effects for image annotation using various CNN models; prominent feature selection for sequential input by using high dimensional biomedical data set; an enhanced stochastic gradient descent variance reduced ascension optimization algorithm for deep neural networks; threat detection with facial expression and suspicious weapon; IMEXT text summarizer using deep learning; Integrated YOLO based object detection for semantic outdoor natural scene classification; customer feedback through facial expression recognition using deep neural network; implementation of e-health record with biometric authentication; modeling groundwater spring potential of selected geographical area using machine learning algorithms; lane detection and collision prevention system for automated vehicles; preface; singleton wavelet packet matrix.","","","","Iyer B.; Rajurkar A.M.; Gudivada V.","Springer",""
"Behura A.","Behura, Aradhana (57216374591)","57216374591","Congruence of deep learning in biomedical engineering: Future prospects and challenges","2020","","","","1","24","23","10.1016/B978-0-12-823014-5.00003-X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120533343&doi=10.1016%2fB978-0-12-823014-5.00003-X&partnerID=40&md5=cd6cccaedb7efa110557dcb904ca376b","Deep learning models have opened up many prospects in medical images for achieving unprecedented performance, for example, classification of tissues and division or segmentation are a few medical outcomes. This chapter evaluates and describes the convolutional neural network (CNN) intended for characterization of tissue in clinical imaging, which is applied for segregating essential metastatic liver tumors from diffusion-weighted magnetic resonance imaging information. Advancement in the field of deep learning for normal pictures has provoked a surge of enthusiasm for applying comparative strategies to clinical images. Most of the initial attempts replaced the input of a deep CNN with medical images, which does not consider the basic contrasts between these two kinds of pictures. In particular, fine details are fundamental in clinical pictures, unlike regular images where coarse structures are very important. This distinction makes it difficult to utilize the current organized models created for common pictures, because they chip away at downscaled medical images to decrease the memory prerequisites. These subtleties are important to provide accurate detection. Furthermore, a medical test in clinical imaging regularly accompanies many perspectives, which must be intertwined to arrive at the right conclusion. A survey of deep learning is used for image classification, carotid ultrasound data investigations, cardiotocography, intravascular ultrasound reports, lung computed tomography reports, brain tumor prediction, coronavirus prediction (COVID-19) object detection, segmentation, breast cancer prediction, electrocardiogram signals, electroencephalograms, photoplethysmographic signal registration, psoriasis skin disease, as well as cancer detection. Concise summaries are delivered of trainings per application zone: pulmonary, musculoskeletal neuro, digital pathology, abdominal, retinal, breast, and cardiac. There are various types of deep learning techniques present to improve the accuracy of the medical dataset. Deep reinforcement learning, recursive neural network, multilayer perceptron, recurrent neural network, Boltzmann machine, and CNN are different types of deep learning techniques used to train the image and signal dataset. Generative adversarial network (GAN), autoencoder, and deep belief neural network are subcategories of unsupervised pretrained neural network. Some well-known architectural models of CNNs are ResNet (2015), VGGNet (2014), SqueezeNet (2016), GoogLeNet (2014), and ZFNet (2013) and are the visualization concept of the deconvolutional network; AlexNet (2012) and LeNet (Peng et al., 2009; Mitchell; Bengio, 2012; Dutkowski et al., 2015; Han et al., 2020 [16-20]) are basically used to train image datasets; the long short-term memory technique is used to train signalized datasets; and RHSBoost and genetically optimized neural network are used for efficient multiple classification of datasets. Dimensionality reduction, feature extraction, overfitting, underfitting, and normalization problems can be solved using various types of optimization algorithm. Image security is another important part, and by using an autoencoder, GAN network, and CNN we can prevent alteration in the medical image. Minor alteration of the medical image is very dangerous to patient life. By using deep learning and steganography, we can first compress as well as train the dataset, then security can be preserved after embedding of watermarks (which is a secret image visible to the human eye that cannot be altered; this steganography concept is called watermarking). © 2021 Elsevier Inc. All rights reserved.","Biomedical image and signal processing; Breast cancer; Deep learning; Image segmentation; Unsupervised feature learning","","","","Elsevier",""
"Wang R.; Fan J.; Li Y.","Wang, Ruxin (57204721884); Fan, Jianping (14015509700); Li, Ye (57192879224)","57204721884; 14015509700; 57192879224","Deep Multi-Scale Fusion Neural Network for Multi-Class Arrhythmia Detection","2020","24","9","9064540","2461","2472","11","10.1109/JBHI.2020.2981526","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090491674&doi=10.1109%2fJBHI.2020.2981526&partnerID=40&md5=a1d407bb291220a212f0a0124f65c00c","Automated electrocardiogram (ECG) analysis for arrhythmia detection plays a critical role in early prevention and diagnosis of cardiovascular diseases. Extracting powerful features from raw ECG signals for fine-grained diseases classification is still a challenging problem today due to variable abnormal rhythms and noise distribution. For ECG analysis, the previous research works depend mostly on heartbeat or single scale signal segments, which ignores underlying complementary information of different scales. In this paper, we formulate a novel end-to-end Deep Multi-Scale Fusion convolutional neural network (DMSFNet) architecture for multi-class arrhythmia detection. Our proposed approach can effectively capture abnormal patterns of diseases and suppress noise interference by multi-scale feature extraction and cross-scale information complementarity of ECG signals. The proposed method implements feature extraction for signal segments with different sizes by integrating multiple convolution kernels with different receptive fields. Meanwhile, joint optimization strategy with multiple losses of different scales is designed, which not only learns scale-specific features, but also realizes cumulatively multi-scale complementary feature learning during the learning process. In our work, we demonstrate our DMSFNet on two open datasets (CPSC_2018 and PhysioNet/CinC_2017) and deliver the state-of-art performance on them. Among them, CPSC_2018 is a 12-lead ECG dataset and CinC_2017 is a single-lead dataset. For these two datasets, we achieve the F1 score \text{82.8}\% and \text{84.1}\% which are higher than previous state-of-art approaches respectively. The results demonstrate that our end-to-end DMSFNet has outstanding performance for feature extraction from a broad range of distinct arrhythmias and elegant generalization ability for effectively handling ECG signals with different leads. © 2013 IEEE.","convolutional neural network; Deep learning; ECG; multi-scale fusion","Algorithms; Arrhythmias, Cardiac; Electrocardiography; Heart Rate; Humans; Neural Networks, Computer; Arts computing; Convolution; Convolutional neural networks; Diseases; Electrocardiography; Extraction; Feature extraction; Arrhythmia detection; Cardio-vascular disease; Complementary features; Generalization ability; Multi-scale features; Multiple convolution; Noise distribution; State-of-art performance; acute heart infarction; Article; bundle brunch block; cardiovascular disease; clinical effectiveness; convolutional neural network; deep neural network; electrocardiography; electronic health record; feature classification; feature extraction; feature learning (machine learning); first degree atrioventricular block; heart arrhythmia; heart rhythm; heart ventricle contraction; hidden Markov model; human; image processing; learning algorithm; mathematical analysis; nerve cell network; noise distribution; principal component analysis; ST segment depression; support vector machine; algorithm; heart arrhythmia; heart rate; Biomedical signal processing","Major Special Project of Guangdong Province, (2017B030308007); Shen-zhen Basic Research Projects, (JCYJ20180703145202065); Special Fund Project for Innovation of High-level Overseas Talents, (KQJSCX20170731165939298); Strategic Priority CAS, (XDB38000000); National Natural Science Foundation of China, NSFC, (61771465, U1913210); General Logistics Department, People's Liberation Army, GLD, (AWS13C008); Shenzhen Science and Technology Innovation Program, (JSGG20170823144843046)","","Institute of Electrical and Electronics Engineers Inc.","32287022"
"Lu Y.; Cai J.; Zheng H.; Zeng Y.","Lu, Yihong (57221607553); Cai, Jianyong (8529435800); Zheng, Hua (57709394000); Zeng, Yuanqiang (57221603010)","57221607553; 8529435800; 57709394000; 57221603010","A Deep Meta-Learning Neural Network for Single Image Rain Removal","2020","","","9263524","231","237","6","10.1109/CISP-BMEI51763.2020.9263524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099538719&doi=10.1109%2fCISP-BMEI51763.2020.9263524&partnerID=40&md5=66a037d395b5d0d1ee73ae6d0546068f","Due to various interference factors, image degradation seriously retards the precision and efficiency of target tracking and recognition. Consequently, image restoration becomes a significant issue in the field of computer vision. In this paper, a novel de-rain network, called Meta-DerainNet was proposed to remove rain streaks in various conditions. With the strongly generation ability, Model-Agnostic Meta-Learning (MAML) has been proven to be able to accomplish the task of removing rain streaks from single image. However, in order to combine the MAML algorithm with rain removal tasks, there are many parts need to be improved. The datasets with specific sample methods were designed to train the generalization ability of the network, and the network structured of MAML was improved for more efficiently extract feature map. The modified network was successfully applied to remove rain streaks under various conditions. Experimental results on real-world data show that the method proposed in this paper performs better than other advanced methods on PSNR and SSIM. Furthermore, our method can also be applied to process other image interference removal factors, such as medical image recognition, self-driving and other fields. © 2020 IEEE.","convolution neural network; deep learning; meta-learning; rain removal","Biomedical engineering; Deep neural networks; Image recognition; Image reconstruction; Medical imaging; Neural networks; Rain; Target tracking; Generalization ability; Image degradation; Interference factor; Interference removal; Metalearning; Rain removals; Self drivings; Single images; Deep learning","Fujian Provincial Engineering Technology Research Center of Photoelectric Sensing Application; Natural Science Foundation of Fujian Province, (2017J01744)","Zheng Q.; Zheng X.; Zhao X.; Yan W.; Zhang N.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"Somnath; Negi S.; Negi P.C.B.S.; Sharma N.","Somnath (57220747033); Negi, Sachin (57220753158); Negi, Pranshu Cbs (57220750785); Sharma, Neeraj (57199924854)","57220747033; 57220753158; 57220750785; 57199924854","Tumor Segmentation in Brain MRI using Fully Convolutional Network","2020","","","9213036","158","161","3","10.1109/ICACCM50413.2020.9213036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097551987&doi=10.1109%2fICACCM50413.2020.9213036&partnerID=40&md5=7c9711fed680b86ffa1e930fce1f6058","In biomedical image processing and cancer studies tumor segmentation is one of the most indispensable tasks. Early diagnosis of tumorous cells aids substantially in early treatment planning and enhances the chance of survival of the patient. Manual segmentation of tumor cells in Brain MRI is difficult and time-consuming and also requires expertise in this field. In this paper, we have presented a deep Fully Convolutional Network designed using the TensorFlow library, which can successfully perform segmentation tasks in medical images. Brain MRI images of 225 patients are used as a training data set and a separate set from 20 patients is used to test the performance of the network. Two different loss functions: dice loss and weighted cross-entropy are used in the learning algorithm. We obtained a 0.76 Dice Score coefficient (i.e., 76% of the overlapping between the predicted image and ground truth) for a training of 100 epochs. © 2020 IEEE.","Brain tumor; fully convolutional network; magnetic resonance imaging; segmentation","Convolution; Diagnosis; Image segmentation; Learning algorithms; Magnetic resonance imaging; Medical imaging; Patient treatment; Statistical tests; Tumors; Brain mri images; Convolutional networks; Early diagnosis; Loss functions; Manual segmentation; Training data sets; Treatment planning; Tumor segmentation; Convolutional neural networks","","Semwal S.; Dhuliya P.","Institute of Electrical and Electronics Engineers Inc.",""
"Das H.; Pradhan C.; Dey N.","Das, Himansu (56151748100); Pradhan, Chittaranjan (57216004996); Dey, Nilanjan (55356190900)","56151748100; 57216004996; 55356190900","Deep Learning for Data Analytics: Foundations, Biomedical Applications, and Challenges","2020","","","","1","204","203","10.1016/C2019-0-00626-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118014098&doi=10.1016%2fC2019-0-00626-7&partnerID=40&md5=bb208b04d90fa511b587f1bdb084a4bf","Deep learning, a branch of Artificial Intelligence and machine learning, has led to new approaches to solving problems in a variety of domains including data science, data analytics and biomedical engineering. Deep Learning for Data Analytics: Foundations, Biomedical Applications and Challenges provides readers with a focused approach for the design and implementation of deep learning concepts using data analytics techniques in large scale environments. Deep learning algorithms are based on artificial neural network models to cascade multiple layers of nonlinear processing, which aids in feature extraction and learning in supervised and unsupervised ways, including classification and pattern analysis. Deep learning transforms data through a cascade of layers, helping systems analyze and process complex data sets. Deep learning algorithms extract high level complex data and process these complex sets to relatively simpler ideas formulated in the preceding level of the hierarchy. The authors of this book focus on suitable data analytics methods to solve complex real world problems such as medical image recognition, biomedical engineering, and object tracking using deep learning methodologies. The book provides a pragmatic direction for researchers who wish to analyze large volumes of data for business, engineering, and biomedical applications. Deep learning architectures including deep neural networks, recurrent neural networks, and deep belief networks can be used to help resolve problems in applications such as natural language processing, speech recognition, computer vision, bioinoformatics, audio recognition, drug design, and medical image analysis. © 2020 Elsevier Inc. All rights reserved.","","","","","Elsevier",""
"Ma J.; Deng Y.; Ma Z.","Ma, Jinlin (54407151300); Deng, Yuanyuan (57219573621); Ma, Ziping (54385612200)","54407151300; 57219573621; 54385612200","Review of deep learning segmentation methods for CT images of liver tumors; [肝脏肿瘤CT图像深度学习分割方法综述]","2020","25","10","","2024","2046","22","10.11834/jig.200234","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093940281&doi=10.11834%2fjig.200234&partnerID=40&md5=0e19db7dc61857e6ec31e67a12117bbb","Hepatocellular carcinoma is one of the most common malignant tumors of the digestive system in clinic. It ranks third after gastric cancer and lung cancer in the death ranking of malignant tumors. Computed tomography (CT) can well display the organs composed of soft tissue and show the lesions in the abdominal image. It has become a typical method for the diagnosis and treatment of liver diseases. It produces high-quality liver imaging that can provide comprehensive information for the diagnosis and treatment of liver tumors, alleviate the heavy workload of doctors, and have an important value for subsequent diagnosis and treatment. Segmentation of CT images of liver tumors is a crucial step in the diagnosis of liver cancer. In accordance with the maximum diameter, volume, and number of liver lesions, medical workers can give patients accurate diagnosis results and treatment plans conveniently and rapidly. However, the manual three-dimensional segmentation of liver tumors is time consuming and requires substantial work. Therefore, a method for automatically segmenting liver tumors is urgently needed. Many challenges occur in the segmentation of liver tumors. First, the CT image of a liver tumor shows the cross section of the human body, and the contrast of the liver and liver tumor tissue is inconsiderably different from that of the surrounding adjacent tissues (such as the stomach, pancreas, and heart). The segmentation by using grayscale differences is difficult. Second, the individual differences of patients result in diverse sizes and shapes of liver tumors. Third, CT images are susceptible to various external factors, such as noise, partial volume effects, and magnetic field bias. The interference of the shift makes the image blurry. Dealing with the effects of these factors in a timely manner is a great challenge for medical imaging researchers. Accurate segmentation can ensure that clinicians can make wise surgical treatment plans. With the rise of big data and artificial intelligence in recent years, assisted diagnosis of liver cancer based on deep learning has gradually become a popular research topic. Its combination with medicine can realize and predict the condition and assist diagnosis, which has great clinical significance. Segmentation methods for liver tumor CT images based on deep learning have also attracted wide attention in the past few years. From relevant literature in the field of liver tumor image segmentation, this paper mainly summarizes several commonly used segmentation methods for current liver tumor CT images based on deep learning, aiming to provide convenience to related researchers. We comprehensively summarize and analyze the deep learning methods for liver tumor CT images from three aspects: datasets, evaluation indicators and algorithms. First, we introduce common databases of liver tumors and analyze and compare them in terms of year, resolution, number of cases, slice thickness, pixel size, and voxel size to compare the segmentation methods for emerging liver tumors objectively. Second, several important evaluation indicators, such as Dice, relative volume difference, and volumetric overlap error, are also briefly introduced, analyzed, and compared to evaluate the effectiveness of each algorithm in the accuracy of liver tumor segmentation. On the basis of the previous work, we divide the deep learning segmentation methods for CT images of liver tumors into three categories, namely, liver tumor segmentation methods based on fully convolutional network (FCN), U-Net, and generative adversarial network (GAN). The segmentation methods based on FCN can be further divided into two- and three-dimensional methods in accordance with the dimension of the convolution kernel. The segmentation methods based on U-Net are divided into three subcategories, which are methods based on single network, methods based on multinetwork, and methods combined with traditional methods. Similarly, the segmentation methods based on GAN are divided into three subcategories, which are based on network architecture improvements, generator-based improvements, and other methods. The basic ideas, network architecture forms, improvement schemes, advantages, and disadvantages of various methods are emphasized, and the performance of these methods on typical datasets is compared. Lastly, the advantages, disadvantages, and application scope of the three methods are summarized and compared. The future research trends of liver tumor deep learning segmentation methods are analyzed. 1) The use of three-dimensional neural networks and network deepening is a future research direction in this field. 2) The use of multimodal liver images for segmentation and the combination of multiple different deep neural networks to extract deep information of images for improving the accuracy of liver tumor segmentation are also main research directions in this field. 3) To overcome the problem of lack or unavailability of data, some researchers have shifted the supervised field to a semi-supervised or unsupervised field. For example, GAN is combined with other higher-performance networks. This situation can be further studied in the future. In summary, accurate segmentation of liver tumors is a necessary step in liver disease diagnosis, surgical planning, and postoperative evaluation. Deep learning is superior to traditional segmentation methods when segmenting liver tumors, and the obtained images have higher sensitivity and specificity. This study hopes that clinicians can intuitively and clearly observe the anatomical structure of normal and diseased tissues through the increasingly mature liver tumor segmentation technologies. It provides a scientific basis for clinical diagnosis, surgical procedures, and biomedical research. The research and development of medical image segmentation technologies play an important role in the reform of the medical field and have great research value and significance. © 2020, Editorial and Publishing Board of Journal of Image and Graphics. All right reserved.","Computed tomography(CT); Deep learning; Fully convolutional network(FCN); Generative adversarial network(GAN); Liver tumor; Medical image segmentation; U-Net","","National Natural Science Foundation of China, NSFC, (61462002, 61762003)","","Editorial and Publishing Board of JIG",""
"Baum Z.M.C.; Hu Y.; Barratt D.C.","Baum, Zachary M. C. (6506021565); Hu, Yipeng (24512208500); Barratt, Dean C. (7005201740)","6506021565; 24512208500; 7005201740","Multimodality Biomedical Image Registration Using Free Point Transformer Networks","2020","12437 LNCS","","","116","125","9","10.1007/978-3-030-60334-2_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092739402&doi=10.1007%2f978-3-030-60334-2_12&partnerID=40&md5=8afaf86e10aa2821ae3b2c6801e94a7c","We describe a point-set registration algorithm based on a novel free point transformer (FPT) network, designed for points extracted from multimodal biomedical images for registration tasks, such as those frequently encountered in ultrasound-guided interventional procedures. FPT is constructed with a global feature extractor which accepts unordered source and target point-sets of variable size. The extracted features are conditioned by a shared multilayer perceptron point transformer module to predict a displacement vector for each source point, transforming it into the target space. The point transformer module assumes no vicinity or smoothness in predicting spatial transformation and, together with the global feature extractor, is trained in a data-driven fashion with an unsupervised loss function. In a multimodal registration task using prostate MR and sparsely acquired ultrasound images, FPT yields comparable or improved results over other rigid and non-rigid registration methods. This demonstrates the versatility of FPT to learn registration directly from real, clinical training data and to generalize to a challenging task, such as the interventional application presented. © 2020, Springer Nature Switzerland AG.","Deep-learning; Point-set registration; Prostate cancer","Bioinformatics; Computer aided analysis; Geometry; Image enhancement; Medical imaging; Metadata; Multilayer neural networks; Pediatrics; Ultrasonics; Vector spaces; Biomedical image registration; Clinical training; Displacement vectors; Interventional procedures; Multimodal registration; Nonrigid registration method; Point-set registrations; Spatial transformation; Image analysis","Centre for Interventional and Surgical Sciences, (203145Z/16/Z); Natural Sciences and Engineering Research Council of Canada, NSERC; University College London, UCL","Hu Y.; Licandro R.; Noble J.A.; Hutter J.; Melbourne A.; Aylward S.; Abaci Turk E.; Torrents Barrena J.; Torrents Barrena J.","Springer Science and Business Media Deutschland GmbH",""
"Sova I.; Sidenko I.; Kondratenko Y.","Sova, Ivan (57221292558); Sidenko, Ievgen (55991342900); Kondratenko, Yuriy (6602324472)","57221292558; 55991342900; 6602324472","Machine learning technology for neoplasm segmentation on brain mri scans","2020","2791","","","50","59","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098727632&partnerID=40&md5=ae35f8ea3b44f0271e020d4f20d5e138","In this paper, machine learning technology for neoplasm segmentation on brain MRI scans is analyzed. This analysis allows to choose the most appropriate machine learning architecture and various preprocessing techniques to increase the precision of tumor instance segmentation. Understanding the image and extracting information from it to accomplish some result is an important area of application in digital image technology. Image segmentation has quickly found its use in medicine and specifically oncology. Precise segmentation masks may not be critical in other cases, but marginal segmentation errors in medical images may render the results unreliable for clinical use. Therefore, biomedical problems require much higher boundary detection precision to improve further analysis. Comparison of different machine learning algorithms, neural network architectures will achieve the highest accuracy of recognition and segmentation. During the comparison, a system of the U-Net architecture with additional processing methods was selected as the final model. Its accuracy reached 94%, which is a significant result compared to manual image segmentation.  Copyright © 2020 for this paper by its authors.","Biomedicine; Deep Learning; Instance Segmentation; Machine Learning; Magnetic Resonance Imaging; Neoplasm; Neural Network","Industrial research; Learning algorithms; Machine learning; Magnetic resonance imaging; Medical image processing; Network architecture; Tumors; Biomedical problems; Boundary detection; Digital image technology; Extracting information; Machine learning technology; Preprocessing techniques; Segmentation error; Segmentation masks; Image segmentation","","Nikitchenko M.; Taras Shevchenko National University of Kyiv, 64/13, Volodymyrska Street, Kyiv; Bogomolov S.","CEUR-WS",""
"Zeng C.; Nan Y.; Xu F.; Lei Q.; Li F.; Chen T.; Liang S.; Hou X.; Lv B.; Liang D.; Luo W.; Lv C.; Li X.; Xie G.; Liu Z.","Zeng, Caihong (57202571023); Nan, Yang (57217028826); Xu, Feng (56527573800); Lei, Qunjuan (57215660069); Li, Fengyi (57217029448); Chen, Tingyu (57208481340); Liang, Shaoshan (55173691300); Hou, Xiaoshuai (56982264100); Lv, Bin (58717185000); Liang, Dandan (57188857554); Luo, WeiLi (57217735405); Lv, Chuanfeng (57216090925); Li, Xiang (56044095900); Xie, Guotong (14042931500); Liu, Zhihong (56118017700)","57202571023; 57217028826; 56527573800; 57215660069; 57217029448; 57208481340; 55173691300; 56982264100; 58717185000; 57188857554; 57217735405; 57216090925; 56044095900; 14042931500; 56118017700","Identification of glomerular lesions and intrinsic glomerular cell types in kidney diseases via deep learning","2020","252","1","","53","64","11","10.1002/path.5491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087566915&doi=10.1002%2fpath.5491&partnerID=40&md5=1a9dfe409d8733da80f37831df2f0886","Identification of glomerular lesions and structures is a key point for pathological diagnosis, treatment instructions, and prognosis evaluation in kidney diseases. These time-consuming tasks require a more accurate and reproducible quantitative analysis method. We established derivation and validation cohorts composed of 400 Chinese patients with immunoglobulin A nephropathy (IgAN) retrospectively. Deep convolutional neural networks and biomedical image processing algorithms were implemented to locate glomeruli, identify glomerular lesions (global and segmental glomerular sclerosis, crescent, and none of the above), identify and quantify different intrinsic glomerular cells, and assess a network-based mesangial hypercellularity score in periodic acid–Schiff (PAS)-stained slides. Our framework achieved 93.1% average precision and 94.9% average recall for location of glomeruli, and a total Cohen's kappa of 0.912 [95% confidence interval (CI), 0.892–0.932] for glomerular lesion classification. The evaluation of global, segmental glomerular sclerosis, and crescents achieved Cohen's kappa values of 1.0, 0.776, 0.861, and 95% CI of (1.0, 1.0), (0.727, 0.825), (0.824, 0.898), respectively. The well-designed neural network can identify three kinds of intrinsic glomerular cells with 92.2% accuracy, surpassing the about 5–11% average accuracy of junior pathologists. Statistical interpretation shows that there was a significant difference (P value < 0.0001) between this analytic renal pathology system (ARPS) and four junior pathologists for identifying mesangial and endothelial cells, while that for podocytes was similar, with P value = 0.0602. In addition, this study indicated that the ratio of mesangial cells, endothelial cells, and podocytes within glomeruli from IgAN was 0.41:0.36:0.23, and the performance of mesangial score assessment reached a Cohen's kappa of 0.42 and 95% CI (0.18, 0.69). The proposed computer-aided diagnosis system has feasibility for quantitative analysis and auxiliary recognition of glomerular pathological features. © 2020 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of Pathological Society of Great Britain and Ireland. © 2020 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of Pathological Society of Great Britain and Ireland.","computational pathology; glomerular lesion classification; IgAN; intrinsic glomerular cells identification; mesangial hypercellularity score assessment","Adult; Deep Learning; Diagnosis, Computer-Assisted; Female; Glomerulonephritis, IGA; Humans; Kidney Diseases; Kidney Glomerulus; Male; Mesangial Cells; Neural Networks, Computer; Podocytes; adult; Article; cellular distribution; Chinese; cohort analysis; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; feasibility study; female; focal glomerulosclerosis; glomerular structure; glomerulopathy; glomerulus epithelium cell; histopathology; human; human tissue; imaging algorithm; immunoglobulin A nephropathy; major clinical study; male; mesangium cell; pathologist; periodic acid Schiff stain; podocyte; priority journal; quantitative analysis; rapidly progressive glomerulonephritis; retrospective study; sensitivity and specificity; validation study; computer assisted diagnosis; glomerulus; immunoglobulin A nephropathy; kidney disease; mesangium cell; pathology; podocyte","Science, Technology and Education of Jiangsu Province Medical Key Talent, (ZDRCA2016098); National Natural Science Foundation of China, NSFC, (81570644); National Natural Science Foundation of China, NSFC; National Key Research and Development Program of China, NKRDPC, (2016YFC0901202); National Key Research and Development Program of China, NKRDPC","","John Wiley and Sons Ltd","32542677"
"Shah M.A.; Nour A.; Ngom A.; Rueda L.","Shah, Mohammad Anas (57216898213); Nour, Abdala (57201747273); Ngom, Alioune (7003729382); Rueda, Luis (7004107964)","57216898213; 57201747273; 7003729382; 7004107964","Cancer Detection Based on Image Classification by Using Convolution Neural Network","2020","12108 LNBI","","","275","286","11","10.1007/978-3-030-45385-5_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085163717&doi=10.1007%2f978-3-030-45385-5_25&partnerID=40&md5=de4cc711d2ad75c213a1bd875f74d694","Breast cancer starts when cells in the breast begin to grow out of control. These cells usually form a tumor that can often be seen on an x-ray or felt as a lump. The tumor is malignant (cancer) if the cells can grow into (invade) surrounding tissues or spread (metastasize) to distant areas of the body. The challenge of this project was to build an algorithm by using a neural network to automatically identify whether a patient is suffering from breast cancer by looking at biopsy images. The algorithm must be accurate because the lives of people are at stake. © Springer Nature Switzerland AG 2020.","Algorithms; Benign; Convolutional neural network; Deep learning; Image breast cancer; Malignant; Prediction","Bioinformatics; Biomedical engineering; Diseases; Image classification; Tumors; Biopsy images; Breast Cancer; Cancer detection; Convolution neural network; Out-of-control; Medical imaging","Office of Research and Innovation Services; University of Windsor; Natural Sciences and Engineering Research Council of Canada, NSERC","Rojas I.; Valenzuela O.; Rojas F.; Herrera L.J.; Ortuño F.","Springer",""
"Toğaçar M.; Ergen B.; Cömert Z.; Özyurt F.","Toğaçar, M. (57205581917); Ergen, B. (6508022484); Cömert, Z. (36543652400); Özyurt, F. (56780136900)","57205581917; 6508022484; 36543652400; 56780136900","A Deep Feature Learning Model for Pneumonia Detection Applying a Combination of mRMR Feature Selection and Machine Learning Models","2020","41","4","","212","222","10","10.1016/j.irbm.2019.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075211045&doi=10.1016%2fj.irbm.2019.10.006&partnerID=40&md5=e04d70a55f3485dd94a95bac08309be7","Pneumonia is one of the diseases that people may encounter in any period of their lives. Approximately 18% of infectious diseases are caused by pneumonia. This disease may result in death in the following stages. In order to diagnose pneumonia as a medical condition, lung X-ray images are routinely examined by the field experts in the clinical practice. In this study, lung X-ray images that are available for the diagnosis of pneumonia were used. The convolutional neural network was employed as feature extractor, and some of existing convolutional neural network models that are AlexNet, VGG-16 and VGG-19 were utilized so as to realize this specific task. Then, the number of deep features was reduced from 1000 to 100 by using the minimum redundancy maximum relevance algorithm for each deep model. Accordingly, we achieved 100 deep features from each deep model, and we combined these features so as to provide an efficient feature set consisting of totally 300 deep features. In this step of the experiment, this feature set was given as an input to the decision tree, k-nearest neighbors, linear discriminant analysis, linear regression, and support vector machine learning models. Finally, all models ensured promising results, especially linear discriminant analysis yielded the most efficient results with an accuracy of 99.41%. Consequently, the results point out that the deep features provided robust and consistent features for pneumonia detection, and minimum redundancy maximum relevance method was found a beneficial tool to reduce the dimension of the feature set. © 2019 AGBM","Biomedical image processing; Convolutional neural network; Diagnosis system; Feature selection; Pneumonia","Article; convolutional neural network; decision tree; discriminant analysis; feature learning (machine learning); information processing; k nearest neighbor; linear regression analysis; pneumonia; support vector machine; X ray","","","Elsevier Masson SAS",""
"Andreini P.; Bonechi S.; Bianchini M.; Mecocci A.; Scarselli F.","Andreini, Paolo (56906861600); Bonechi, Simone (54398271600); Bianchini, Monica (7004830222); Mecocci, Alessandro (7005623421); Scarselli, Franco (6603295429)","56906861600; 54398271600; 7004830222; 7005623421; 6603295429","Image generation by GAN and style transfer for agar plate image segmentation","2020","184","","105268","","","","10.1016/j.cmpb.2019.105268","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076971687&doi=10.1016%2fj.cmpb.2019.105268&partnerID=40&md5=037e2afedbc8bca9b4b1b3df52833f56","Background and objectives. Deep learning models and specifically Convolutional Neural Networks (CNNs) are becoming the leading approach in many computer vision tasks, including medical image analysis. Nevertheless, the CNN training usually requires large sets of supervised data, which are often difficult and expensive to obtain in the medical field. To address the lack of annotated images, image generation is a promising method, which is becoming increasingly popular in the computer vision community. In this paper, we present a new approach to the semantic segmentation of bacterial colonies in agar plate images, based on deep learning and synthetic image generation, to increase the training set size. Indeed, semantic segmentation of bacterial colony is the basis for infection recognition and bacterial counting in Petri plate analysis. Methods. A convolutional neural network (CNN) is used to separate the bacterial colonies from the background. To face the lack of annotated images, a novel engine is designed — which exploits a generative adversarial network to capture the typical distribution of the bacterial colonies on agar plates — to generate synthetic data. Then, bacterial colony patches are superimposed on existing background images, taking into account both the local appearance of the background and the intrinsic opacity of the bacterial colonies, and a style transfer algorithm is used for further improve visual realism. Results. The proposed deep learning approach has been tested on the only public dataset available with pixel–level annotations for bacterial colony semantic segmentation in agar plates. The role of including synthetic data in the training of a segmentation CNN has been evaluated, showing how comparable performances can be obtained with respect to the use of real images. Qualitative results are also reported for a second public dataset in which the segmentation annotations are not provided. Conclusions. The use of a small set of real data, together with synthetic images, allows obtaining comparable results with respect to using a complete set of real images. Therefore, the proposed synthetic data generator is able to address the scarcity of biomedical data and provides a scalable and cheap alternative to human ground–truth supervision. © 2019","Agar plate image; Bacterial culture; Deep learning; Generative adversarial network; Semantic segmentation; Synthetic image generation","Agar; Algorithms; Bacteria; Deep Learning; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Algae; Computer vision; Convolution; Deep learning; Image enhancement; Medical imaging; Neural networks; Polysaccharides; Semantics; agar; Adversarial networks; Agar plates; Bacterial cultures; Semantic segmentation; Synthetic image generation; algorithm; article; bacterial count; bacterium colony; bacterium culture; computer vision; convolutional neural network; deep learning; human; image segmentation; bacterium; growth, development and aging; image processing; procedures; Image segmentation","","","Elsevier Ireland Ltd","31891902"
"Lyu Q.; Niu T.; Ruan D.; Sheng K.","Lyu, Qihui (57189849074); Niu, Tianye (36466788900); Ruan, Dan (35265014200); Sheng, Ke (13613228700)","57189849074; 36466788900; 35265014200; 13613228700","Iterative reconstruction of cone-beam breast CT using plug-and-play projected gradient descent","2020","11312","","113124J","","","","10.1117/12.2549787","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086734604&doi=10.1117%2f12.2549787&partnerID=40&md5=8813c471659ff07b5f281cc1598fb744","Concerns on the risks of radiation dose in the cone-beam breast CT (CBBCT) motivated the development of low dose CBBCT (LdCBBCT). Due to the noisy and inadequate data acquisition in LdCBBCT, the conventional analytical Filtered Back Projection (FBP) algorithm tends to result in severe image artifacts and overwhelming noise. Model-based iterative reconstruction methods managed to reduce artifacts and enhance the signal-to-noise ratio but were unable to recover many fine structures and low contrast objects pertinent to diagnosis and treatment. To maintain the strengths of the model-based optimization framework and overcome its limitations in signal recovery, we adapted a CNN-based iterative reconstruction framework, termed Plug- and-Play (PnP) proximal gradient descent (PGD) framework, that incorporated state-of-the-art deep-learning-based denoising algorithms with model-based image reconstruction. The PnP-PGD framework is achieved by combining a least-square data fidelity term for data consistency with a non-local regularization for image smoothness, which was solved via PGD. A deep convolutional neural network (DCNN) was plugged in to substitute the proximal operator of the regularization term. The PnP-PGD was evaluated on LdCBBCT scans of a breast phantom and was compared with Filtered Back Projection (FBP), Total Variation (TV), the Block-Matching 3D-transform shrinkage (BM3D), and the DCNN based post-processing method. Compared with FBP, iterative reconstruction, and BM3D, the proposed PnP-PGD substantially reduced image noise and artifacts. Compared with the DCNN based post-processing method, the PnP-PGD improved image contrast-to-noise ratio (CNR). The proposed PnP-PGD takes advantage of both model-based reconstruction and deep-learning-based denoisers, showing improved image quality. © 2020 SPIE","Compressed Sensing (CS); Deep convolutional neural network (DCNN); Iterative reconstruction; Low dose cone-beam breast CT (LdCBBCT); Plug-and-Play (PnP); Proximal gradient descent (PGD)","Biomedical signal processing; Convolutional neural networks; Data acquisition; Deep learning; Deep neural networks; Diagnosis; Gradient methods; Image enhancement; Image reconstruction; Learning systems; Medical imaging; Processing; Signal to noise ratio; De-noising algorithm; Filtered back projection; Iterative reconstruction; Model based iterative reconstruction; Model based optimization; Model based reconstruction; Non-local regularization; Postprocessing methods; Computerized tomography","","Chen G.-H.; Bosmans H.","SPIE",""
"Zhang K.; Xu G.; Chen L.; Tian P.; Han C.; Zhang S.; Duan N.; Huang C.","Zhang, Kai (56611003500); Xu, Guanghua (55632209100); Chen, Longtin (57037203400); Tian, Peiyuan (57218932029); Han, ChengCheng (56166400100); Zhang, Sicong (15754711700); Duan, Nan (57215333827); Huang, Chenxi (57196056436)","56611003500; 55632209100; 57037203400; 57218932029; 56166400100; 15754711700; 57215333827; 57196056436","Instance Transfer Subject-Dependent Strategy for Motor Imagery Signal Classification Using Deep Convolutional Neural Networks","2020","2020","","1683013","","","","10.1155/2020/1683013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090816995&doi=10.1155%2f2020%2f1683013&partnerID=40&md5=bbabd382e526eacae6cf9fba00a71e4d","In the process of brain-computer interface (BCI), variations across sessions/subjects result in differences in the properties of potential of the brain. This issue may lead to variations in feature distribution of electroencephalogram (EEG) across subjects, which greatly reduces the generalization ability of a classifier. Although subject-dependent (SD) strategy provides a promising way to solve the problem of personalized classification, it cannot achieve expected performance due to the limitation of the amount of data especially for a deep neural network (DNN) classification model. Herein, we propose an instance transfer subject-independent (ITSD) framework combined with a convolutional neural network (CNN) to improve the classification accuracy of the model during motor imagery (MI) task. The proposed framework consists of the following steps. Firstly, an instance transfer learning based on the perceptive Hash algorithm is proposed to measure similarity of spectrogram EEG signals between different subjects. Then, we develop a CNN to decode these signals after instance transfer learning. Next, the performance of classifications by different training strategies (subject-independent-(SI-) CNN, SD-CNN, and ITSD-CNN) are compared. To verify the effectiveness of the algorithm, we evaluate it on the dataset of BCI competition IV-2b. Experiments show that the instance transfer learning can achieve positive instance transfer using a CNN classification model. Among the three different training strategies, the average classification accuracy of ITSD-CNN can achieve 94.7±2.6 and obtain obvious improvement compared with a contrast model p<0.01. Compared with other methods proposed in previous research, the framework of ITSD-CNN outperforms the state-of-the-art classification methods with a mean kappa value of 0.664. © 2020 Kai Zhang et al.","","Algorithms; Brain-Computer Interfaces; Computational Biology; Deep Learning; Electroencephalography; Humans; Imagination; Mathematical Concepts; Neural Networks, Computer; Photic Stimulation; Visual Perception; Brain computer interface; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Electroencephalography; Hash functions; Image classification; Image enhancement; Transfer learning; Classification accuracy; Classification methods; Classification models; Electro-encephalogram (EEG); Feature distribution; Generalization ability; Positive instances; Signal classification; algorithm; Article; classification algorithm; classifier; convolutional neural network; discrete cosine transform; dual tree complex wavelet transform; electroencephalogram; evaluation study; instance transfer subject dependent strategy; intermethod comparison; measurement accuracy; mental function; motor imagery; perceptive hash algorithm; short time Fourier transform; signal processing; task performance; twin support vector machine; variational autoencoder; biology; brain computer interface; classification; electroencephalography; human; imagination; mathematical phenomena; photostimulation; physiology; vision; Biomedical signal processing","","","Hindawi Limited","32908576"
"Onofrey J.A.; Staib L.H.; Huang X.; Zhang F.; Papademetris X.; Metaxas D.; Rueckert D.; Duncan J.S.","Onofrey, John A. (55823011300); Staib, Lawrence H. (7005557159); Huang, Xiaojie (55500290600); Zhang, Fan (57199243418); Papademetris, Xenophon (6602197282); Metaxas, Dimitris (7006359060); Rueckert, Daniel (7004895812); Duncan, James S. (57203363835)","55823011300; 7005557159; 55500290600; 57199243418; 6602197282; 7006359060; 7004895812; 57203363835","Sparse Data-Driven Learning for Effective and Efficient Biomedical Image Segmentation","2020","22","","","127","153","26","10.1146/annurev-bioeng-060418-052147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086052462&doi=10.1146%2fannurev-bioeng-060418-052147&partnerID=40&md5=3b2a39eb9a6e2673471e12f4a78eb877","Sparsity is a powerful concept to exploit for high-dimensional machine learning and associated representational and computational efficiency. Sparsity is well suited for medical image segmentation. We present a selection of techniques that incorporate sparsity, including strategies based on dictionary learning and deep learning, that are aimed at medical image segmentation and related quantification. © 2020 by Annual Reviews. All rights reserved.","dictionary learning; image representation; image segmentation; machine learning; medical image analysis; Sparsity","Algorithms; Animals; Brain; Deep Learning; Dogs; Echocardiography; Heart Ventricles; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Models, Theoretical; Neural Networks, Computer; Tomography, X-Ray Computed; Computational efficiency; Deep learning; Medical image processing; Biomedical image segmentation; Dictionary learning; High-dimensional; Sparse data; deep learning; image analysis; image segmentation; review; algorithm; animal; brain; diagnostic imaging; dog; echocardiography; heart ventricle; human; image processing; machine learning; procedures; theoretical model; three-dimensional imaging; x-ray computed tomography; Image segmentation","National Institutes of Health, NIH, (R01CA206180, R41CA224888); National Institutes of Health, NIH; National Heart, Lung, and Blood Institute, NHLBI, (R01HL121226); National Heart, Lung, and Blood Institute, NHLBI","","Annual Reviews Inc.","32169002"
"Farah Malik A.E.; Barin S.; Yuksel M.E.","Farah Malik, Afrah Elfatih (57221816033); Barin, Sezin (57221814808); Yuksel, Mehmet Emin (7006176095)","57221816033; 57221814808; 7006176095","Accurate Classification of Heart Sound Signals for Cardiovascular Disease Diagnosis by Wavelet Analysis and Convolutional Neural Network: Preliminary Results","2020","","","9302491","","","","10.1109/SIU49456.2020.9302491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100315724&doi=10.1109%2fSIU49456.2020.9302491&partnerID=40&md5=d99edf6c2757e9abb4654a04e1945e59","Heart sound (HS) signals contain valuable diagnostic information for detection of heart abnormalities. The early detection of heart abnormalities plays an important role in reducing the mortality rate caused by heart diseases. Auscultation, the process of listening to heart sounds, is the first diagnostic method of heart diseases. This process is highly dependent on the physician expertise, making the diagnosis more of a subjective issue. There is ongoing research to automate heart sound diagnosis. Advances in machine learning have provided an easier, cheaper and objective diagnosis of diseases. Algorithms developed for heart sound classifications rely on several features and the accuracy of a model depends on the feature vector. The advent of deep learning (DL) provides a possible solution to overcome the overwhelming and time-consuming step of feature extraction. Convolutional neural networks (CNN), popular deep network architectures, offer high classification accuracies for 2D images and 1D time series. This study proposes an efficient and highly accurate method for heart sound signal classification. The continuous wavelet transform method is employed to obtain scalogram images. The 2D scalogram images are fed to a deep CNN classifier. Using the heart sound dataset consisting of 4 abnormal and 1 normal heart sound subsets, this study investigates both binary classification and multi-class classification. The proposed classification method outperformed the state-of-the-art methods in the literature.  © 2020 IEEE.","Continuous wavelet transform; Convolutional neural networks; Deep learning; Scalogram","Cardiology; Classification (of information); Computer aided diagnosis; Convolution; Convolutional neural networks; Deep learning; Diseases; Heart; Learning systems; Network architecture; Wavelet analysis; Wavelet transforms; Binary classification; Cardio-vascular disease; Classification accuracy; Classification methods; Classification of heart sounds; Continuous Wavelet Transform; Multi-class classification; State-of-the-art methods; Biomedical signal processing","","","Institute of Electrical and Electronics Engineers Inc.",""
"Vedanarayanan V.; Aranganathan A.; Gomathi T.; Poonguzhali S.; Megalan Leo L.","Vedanarayanan, V. (55811603200); Aranganathan, A. (37066942700); Gomathi, T. (57190791994); Poonguzhali, S. (57194104665); Megalan Leo, L. (57201149852)","55811603200; 37066942700; 57190791994; 57194104665; 57201149852","Blood Vessel Segmentation on Retinal Images Using Robust Random Walks (RRW) and Cardiovascular Disease Classification Using Deep Learning","2020","11","4","","36","47","11","10.31838/jcdr.2020.11.04.07","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098950293&doi=10.31838%2fjcdr.2020.11.04.07&partnerID=40&md5=56be74ffc9c4cb93d854968acec699b9","In the recent past, retinal image processing has become a popular biomedical modern computer aided diagnosis (CAD) system development technology for the detection and identification of eye related disease such as diabetic retinopathy, exudates, cardiovascular disease, glaucoma, etc. In present ophthalmology, the arrangement of retinal image with appropriate disease segmentation has attained greater attention for disease identification. Examining diameters of blood vessel inside vessels of retinal image during cardiac cycle (ECG gating) can assist cardiologists in the forecast of cardiovascular disease. Manual process of blood vessels on retinal image is a complex process due to risk handling of physician, noise occurrence on image and various types of acquisition execution. In this paper, we have proposed automatic diagnosis of cardiovascular disease using improved image processing methodologies using various CAD algorithms. The preprocessing steps are useful to improve the retinal image quality. The 2-Dimentional Adaptive Improved Bilateral Filter (2D-AIBF) is applied to remove noise interference on retinal image such as speckle noise, impulse noise and Gaussian noise. The contrast and brightness of retinal image is improved by applying Edge Preservation – Contrast Limited Adaptive Histogram Equalization (EP-CLAHE) algorithm. The blood vessel pixels are clustered by applying Arbitrary Robust Random Walks (ARRW) cluster algorithm. The Adaptive Otsu Threshold (AO) methodology is used to segment only Region Of Interest (ROI) blood vessels pixels and suppress other pixels. The Gray Level Co-Occurrence Matrix (GLCM) algorithm is used to extract the features on segmented image. The Deep Learning (DL) methodology is used to classify cardiovascular disease occurred or not. The Deep Convolutional Neural Network (CNN) is the type of DL technique that is applied for classification of cardiovascular disease. The experimental results are evaluated by comparing other conventional methods of retinal blood vessel segmentation with respect to accuracy, sensitivity and specificity using Confusion Matrix (CM) algorithm and the proposed methodology is proved to be more efficient and accurate in classification of cardiovascular disease classification. © 2020 EManuscript Technologies. All rights reserved.","2D-AIBF; AO; ARRW; DCNN; EP-CLAHE; GLCM","algorithm; Article; blood vessel; brightness; cardiovascular disease; computer assisted diagnosis; confusion matrix algorithm; convolutional neural network; deep learning; diagnostic accuracy; disease classification; evolutionary algorithm; feature extraction algorithm; fuzzy c means clustering; genetic algorithm; histogram; human; image enhancement; image processing; image quality; image reconstruction; image segmentation; mathematical variable; methodology; noise; priority journal; random walk; retina image; robust random walk; sensitivity and specificity; simulated annealing; Tabu search","","","EManuscript Technologies",""
"Zhang D.; Chen K.; Jian D.; Yao L.","Zhang, Dalin (57202792363); Chen, Kaixuan (57202790744); Jian, Debao (57214682630); Yao, Lina (54406102800)","57202792363; 57202790744; 57214682630; 54406102800","Motor Imagery Classification via Temporal Attention Cues of Graph Embedded EEG Signals","2020","24","9","8961150","2570","2579","9","10.1109/JBHI.2020.2967128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087546227&doi=10.1109%2fJBHI.2020.2967128&partnerID=40&md5=d8236445102de51528748a3e585f6f64","Motor imagery classification from EEG signals is essential for motor rehabilitation with a Brain-Computer Interface (BCI). Most current works on this issue require a subject-specific adaptation step before applied to a new user. Thus the research of directly extending a pre-trained model to new users is particularly desired and indispensable. As brain dynamics fluctuate considerably across different subjects, it is challenging to design practical hand-crafted features based on prior knowledge. Regarding this gap, this paper proposes a Graph-based Convolutional Recurrent Attention Model (G-CRAM) to explore EEG features across different subjects for motor imagery classification. A graph structure is first developed to represent the positioning information of EEG nodes. Then a convolutional recurrent attention model learns EEG features from both spatial and temporal dimensions and emphasizes on the most distinguishable temporal periods. We evaluate the proposed approach on two benchmark EEG datasets of motor imagery classification on the subject-independent testing. The results show that the G-CRAM achieves superior performance to state-of-the-art methods regarding recognition accuracy and ROC-AUC. Furthermore, model interpretation studies reveal the learning process of different neural network components and demonstrate that the proposed model can extract detailed features efficiently. © 2013 IEEE.","Deep Learning; EEG; Motor Imagery","Algorithms; Brain-Computer Interfaces; Cues; Electroencephalography; Humans; Imagination; Neural Networks, Computer; Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Graph structures; Graphic methods; Learning systems; Recurrent neural networks; Model interpretations; Motor imagery classification; Motor rehabilitation; Positioning information; Recognition accuracy; State-of-the-art methods; Subject-specific; Temporal dimensions; adult; article; attention; deep learning; electroencephalogram; female; human; human experiment; imagery; male; algorithm; association; brain computer interface; electroencephalography; imagination; Image classification","","","Institute of Electrical and Electronics Engineers Inc.","31976916"
"Banerjee S.; Singh S.K.; Chakraborty A.; Das A.; Bag R.","Banerjee, Shubhendu (57193737728); Singh, Sumit Kumar (57211858675); Chakraborty, Avishek (57209847244); Das, Atanu (56506075800); Bag, Rajib (14824524500)","57193737728; 57211858675; 57209847244; 56506075800; 14824524500","Melanoma diagnosis using deep learning and fuzzy logic","2020","10","8","577","","","","10.3390/diagnostics10080577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090249765&doi=10.3390%2fdiagnostics10080577&partnerID=40&md5=47b4251a52baaeaf3b5e73c667b0159e","Melanoma or malignant melanoma is a type of skin cancer that develops when melanocyte cells, damaged by excessive exposure to harmful UV radiations, start to grow out of control. Though less common than some other kinds of skin cancers, it is more dangerous because it rapidly metastasizes if not diagnosed and treated at an early stage. The distinction between benign and melanocytic lesions could at times be perplexing, but the manifestations of the disease could fairly be distinguished by a skilled study of its histopathological and clinical features. In recent years, deep convolutional neural networks (DCNNs) have succeeded in achieving more encouraging results yet faster and computationally effective systems for detection of the fatal disease are the need of the hour. This paper presents a deep learning-based 'You Only Look Once (YOLO)' algorithm, which is based on the application of DCNNs to detect melanoma from dermoscopic and digital images and offer faster and more precise output as compared to conventional CNNs. In terms with the location of the identified object in the cell, this network predicts the bounding box of the detected object and the class confidence score. The highlight of the paper, however, lies in its infusion of certain resourceful concepts like two phase segmentation done by a combination of the graph theory using minimal spanning tree concept and L-type fuzzy number based approximations and mathematical extraction of the actual affected area of the lesion region during feature extraction process. Experimented on a total of 20250 images from three publicly accessible datasets-PH2, International Symposium on Biomedical Imaging (ISBI) 2017 and The International Skin Imaging Collaboration (ISIC) 2019, encouraging results have been obtained. It achieved a Jac score of 79.84% on ISIC 2019 dataset and 86.99% and 88.64% on ISBI 2017 and PH2 datasets, respectively. Upon comparison of the pre-defined parameters with recent works in this area yielded comparatively superior output in most cases. © 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).","Deep learning; Melanoma; Skin cancer; Skin lesion segmentation; YOLO","algorithm; Article; cancer diagnosis; classifier; constants and coefficients; convolutional neural network; deep learning; diagnostic accuracy; diagnostic error; diagnostic test accuracy study; dice coefficient; digital imaging; epiluminescence microscopy; false negative result; false positive result; feature extraction; fuzzy logic; human; image processing; image segmentation; intermethod comparison; jaccard index; k nearest neighbor; mathematical parameters; melanoma; methodology; preliminary data; sensitivity and specificity; support vector machine; true negative result; true positive result; you only look once algorithm","","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Fadel W.; Kollod C.; Wahdow M.; Ibrahim Y.; Ulbert I.","Fadel, Ward (57216612890); Kollod, Csaba (57216622594); Wahdow, Moutz (57216623012); Ibrahim, Yahya (57210808514); Ulbert, Istvan (6602096329)","57216612890; 57216622594; 57216623012; 57210808514; 6602096329","Multi-Class Classification of Motor Imagery EEG Signals Using Image-Based Deep Recurrent Convolutional Neural Network","2020","","","9061622","","","","10.1109/BCI48061.2020.9061622","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084065551&doi=10.1109%2fBCI48061.2020.9061622&partnerID=40&md5=9dfa957a29e06174e7b29b807318dcf8","Classification of EEG signals is a cornerstone of building the motor-imagery (MI) based Brain-computer interface (BCI) systems. EEG signals differ from one subject to another and even for the same subject among different trials, and this is why designing a general classification model is still debated. Deep learning is dominant in so many fields like computer vision and natural language processing but it is still under investigation for EEG signals classification. We followed a new trend in EEG signals classification in which these signals are transformed into images, and so classifying such signals become an image classification problem where Deep learning can work well. The Physionet dataset for EEG motor movement/imagery tasks was used which consists of 109 subjects and the motor imagery EEG signals for three frequency bands (Delta [0.5-4 Hz], Mu [8-13 Hz], and Beta [13-30 Hz]) was transformed into 3-channel images (one channel for each band) using the Azimuthal equidistant projection and Clough-Tocher algorithm for interpolation. These 2-D images represent the input data to our model which consists of Deep Convolutional Neural Network (DCNN) to extract the spatial and frequency features followed by Long Short Term Memory (LSTM) to extract temporal features and then finally to be classified into 5 different classes (4 motor imagery tasks and one rest). Our results were promising (70.64% average accuracy) and 5% better than the results of Support Vector Machine (SVM) method over the same dataset. We noticed that taking Delta band into account increases the classification accuracy by 2.51%. © 2020 IEEE.","Brain-Computer Interface (BCI); Classification; Convolutional Neural Networks (CNN); Long Short Term Memory (LSTM); Motor Imagery","Brain computer interface; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Image classification; Learning systems; Long short-term memory; Natural language processing systems; Support vector machines; Classification accuracy; Classification models; EEG signals classification; Frequency features; Motor imagery eeg signals; Motor imagery tasks; Multi-class classification; NAtural language processing; Biomedical signal processing","Hungarian National Research Development and Innovation Office; National Bionics Program, (ED-17-1-2017-0009); National Bionics Program ED_17-1-2017-0009; National Research, Development and Innovation Office, (2017-1.2.1-NKP-2017-00002)","","Institute of Electrical and Electronics Engineers Inc.",""
"Li Y.; Xie D.; Cember A.; Nanga R.P.R.; Yang H.; Kumar D.; Hariharan H.; Bai L.; Detre J.A.; Reddy R.; Wang Z.","Li, Yiran (57202651118); Xie, Danfeng (57189350400); Cember, Abigail (56770079400); Nanga, Ravi Prakash Reddy (15058121000); Yang, Hanlu (57724946700); Kumar, Dushyant (57209150204); Hariharan, Hari (7003744606); Bai, Li (55521756900); Detre, John A. (7006351633); Reddy, Ravinder (7202835344); Wang, Ze (57207118006)","57202651118; 57189350400; 56770079400; 15058121000; 57724946700; 57209150204; 7003744606; 55521756900; 7006351633; 7202835344; 57207118006","Accelerating GluCEST imaging using deep learning for B0 correction","2020","84","4","","1724","1733","9","10.1002/mrm.28289","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083498020&doi=10.1002%2fmrm.28289&partnerID=40&md5=40162fd07b0d5e6c31c90d60bc22ceb4","Purpose: Glutamate weighted Chemical Exchange Saturation Transfer (GluCEST) MRI is a noninvasive technique for mapping parenchymal glutamate in the brain. Because of the sensitivity to field (B0) inhomogeneity, the total acquisition time is prolonged due to the repeated image acquisitions at several saturation offset frequencies, which can cause practical issues such as increased sensitivity to patient motions. Because GluCEST signal is derived from the small z-spectrum difference, it often has a low signal-to-noise-ratio (SNR). We proposed a novel deep learning (DL)-based algorithm armed with wide activation neural network blocks to address both issues. Methods: B0 correction based on reduced saturation offset acquisitions was performed for the positive and negative sides of the z-spectrum separately. For each side, a separate deep residual network was trained to learn the nonlinear mapping from few CEST-weighted images acquired at different ppm values to the one at 3 ppm (where GluCEST peaks) in the same side of the z-spectrum. Results: All DL-based methods outperformed the “traditional” method visually and quantitatively. The wide activation blocks-based method showed the highest performance in terms of Structural Similarity Index (SSIM) and peak signal-to-noise ratio (PSNR), which were 0.84 and 25dB respectively. SNR increases in regions of interest were over 8dB. Conclusion: We demonstrated that the new DL-based method can reduce the entire GluCEST imaging time by ˜50% and yield higher SNR than current state-of-the-art. © 2020 International Society for Magnetic Resonance in Medicine","deep learning; deep residual network; GluCEST; wide activation","Brain; Brain Mapping; Deep Learning; Glutamic Acid; Humans; Magnetic Resonance Imaging; Biomedical signal processing; Brain mapping; Chemical activation; Deep learning; Image acquisition; Mapping; glutamic acid; Chemical exchange saturation transfer; Low signal-to-noise ratio; Noninvasive technique; Nonlinear mappings; Offset frequencies; Peak signal to noise ratio; Regions of interest; Structural similarity indices (SSIM); adult; aged; algorithm; Article; clinical article; controlled study; deep learning; deep neural network; diagnostic imaging; female; GluCEST nuclear magnetic resonance imaging; human; male; motion; non invasive procedure; nonlinear system; nuclear magnetic resonance imaging; quantitative analysis; sensitivity analysis; signal noise ratio; brain; brain mapping; nuclear magnetic resonance imaging; Signal to noise ratio","National Institute of Drug Abuse of NIHunder; National Institutes of Health, NIH; National Institute on Drug Abuse, NIDA, (R01DA037289); National Institute on Aging, NIA, (R01AG060054); National Institute of Biomedical Imaging and Bioengineering, NIBIB, (p41EB015893)","","John Wiley and Sons Inc","32301185"
"Singh R.K.; Gorantla R.","Singh, Rajeev Kumar (57213969919); Gorantla, Rohan (57213834541)","57213969919; 57213834541","DMenet: Diabetic Macular Edema diagnosis using Hierarchical Ensemble of CNNs","2020","15","2","e0220677","","","","10.1371/journal.pone.0220677","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079244524&doi=10.1371%2fjournal.pone.0220677&partnerID=40&md5=6bf75f0481bf3aedcb827d2d8c6f712d","Diabetic Macular Edema (DME) is an advanced stage of Diabetic Retinopathy (DR) and can lead to permanent vision loss. Currently, it affects 26.7 million people globally and on account of such a huge number of DME cases and the limited number of ophthalmologists, it is desirable to automate the diagnosis process. Computer-assisted, deep learning based diagnosis could help in early detection, following which precision medication can help to mitigate the vision loss. Method: In order to automate the screening of DME, we propose a novel DMENet Algorithm which is built on the pillars of Convolutional Neural Networks (CNNs). DMENet analyses the preprocessed color fundus images and passes it through a two-stage pipeline. The first stage detects the presence or absence of DME whereas the second stage takes only the positive cases and grades the images based on severity. In both the stages, we use a novel Hierarchical Ensemble of CNNs (HE-CNN). This paper uses two of the popular publicly available datasets IDRiD and MESSIDOR for classification. Preprocessing on the images is performed using morphological opening and gaussian kernel. The dataset is augmented to solve the class imbalance problem for better performance of the proposed model. Results: The proposed methodology achieved an average Accuracy of 96.12%, Sensitivity of 96.32%, Specificity of 95.84%, and F−1 score of 0.9609 on MESSIDOR and IDRiD datasets. Conclusion: These excellent results establish the validity of the proposed methodology for use in DME screening and solidifies the applicability of the HE-CNN classification technique in the domain of biomedical imaging. © 2020 Singh, Gorantla. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Algorithms; Datasets as Topic; Deep Learning; Diabetic Retinopathy; Diagnosis, Computer-Assisted; Early Diagnosis; Humans; Macular Edema; Neural Networks, Computer; Sensitivity and Specificity; algorithm; Article; automation; color vision; computer assisted diagnosis; convolutional neural network; deep learning; diabetic macular edema; diagnostic procedure; diagnostic test accuracy study; disease classification; disease severity assessment; early diagnosis; eye fundus; sensitivity and specificity; validation process; visual impairment; computer assisted diagnosis; diabetic retinopathy; diagnostic imaging; human; information processing; macular edema; procedures","","","Public Library of Science","32040475"
"Prommakhot A.; Srinonchat J.","Prommakhot, Anuruk (57216864857); Srinonchat, Jakkree (25634588700)","57216864857; 25634588700","Exploiting Convolutional Neural Network for Automatic Fungus Detection in Microscope Images","2020","","","9077417","","","","10.1109/iEECON48109.2020.229532","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084969742&doi=10.1109%2fiEECON48109.2020.229532&partnerID=40&md5=c4b81c8620dca45573c0164b1d335f52","The fungus detection system is a part of biomedical technology which is used to classify fungus species for investigate mycoses. Recently, fungus are mostly effect to human health, food, and plant. The previous works were used computer vision techniques to detect the fungus, however, the previous researches are shown that the detection quality were depended on the image processing algorithm. The deep learning which one of the artificial intelligent method, is now applied to biomedical technology. This article presents the exploiting convolutional neural network (C-NN) for automatic fungus detection in microscope images. This experiment focuses on chaetomium and aspergillus fungus which exists in the air, food and human body using convolutional neural network. The results shown that adjusting technique in C-NN can provide results with an achieved 98.03% accuracy. © 2020 IEEE.","convolutional neural network; deep leaning; fungus detection","Convolution; Deep learning; Image processing; Artificial intelligent; Aspergillus fungi; Biomedical technologies; Computer vision techniques; Detection system; Human bodies; Image processing algorithm; Microscope images; Convolutional neural networks","Department of Electronics and Telecommunication engineering; Signal Processing Research Laboratory; Rajamangala University of Technology Thanyaburi, RMUTT","","Institute of Electrical and Electronics Engineers Inc.",""
"Li Z.; Yu Y.","Li, Zheng (57220180627); Yu, Yang (55731519100)","57220180627; 55731519100","Improving EEG-based motor imagery classification with conditional Wasserstein GAN","2020","11584","","115841U","","","","10.1117/12.2581328","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097128742&doi=10.1117%2f12.2581328&partnerID=40&md5=184eb841d9b80de41da95b2a551c6100","Deep learning based algorithms have made huge progress in the field of image classification and speech recognition. There is an increasing number of researchers beginning to use deep learning to process electroencephalographic(EEG) brain signals. However, at the same time, due to the complexity of the experimental device and the expensive collection cost, we cannot train a powerful deep learning model without enough satisfactory EEG data. Data augmentation has been considered as an effective method to eliminate this issue. We propose the Conditional Wasserstein Generative Adversarial Network with gradient penalty (CWGAN-GP) to synthesize EEG data for data augmentation. We use two public neural networks for a motor imagery task and combine the synthesized data with real EEG data to test the generated samples' data enhancement effect. The results indicate that our model can generate high-quality artificial EEG data, which can effectively learn the features from the original EEG data. Both neural networks have gained improved classification performance, and the more complex one has obtained more significant performance improvement. The experiment provides us with new ideas for improving the performance of EEG signal processing.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Brain-computer interface (BCI); Data augment.; Deep learning; EEG; Generative Adversarial Network(GAN)","Biomedical signal processing; Complex networks; Deep learning; Electroencephalography; Image classification; Learning algorithms; Neural networks; Speech recognition; Video signal processing; Adversarial networks; Classification performance; EEG signal processing; Electroencephalographic (EEG); Experimental devices; Learning-based algorithms; Motor imagery classification; Motor imagery tasks; Image enhancement","","Su R.","SPIE",""
"Ali M.; Gilani S.O.; Waris A.; Zafar K.; Jamil M.","Ali, Mahnoor (57221004265); Gilani, Syed Omer (57194679489); Waris, Asim (54894010500); Zafar, Kashan (57215656557); Jamil, Mohsin (57616931600)","57221004265; 57194679489; 54894010500; 57215656557; 57616931600","Brain Tumour Image Segmentation Using Deep Networks","2020","8","","9171998","153589","153598","9","10.1109/ACCESS.2020.3018160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090585705&doi=10.1109%2fACCESS.2020.3018160&partnerID=40&md5=5d761bd6584806739c5d451e25b10e58","Automated segmentation of brain tumour from multimodal MR images is pivotal for the analysis and monitoring of disease progression. As gliomas are malignant and heterogeneous, efficient and accurate segmentation techniques are used for the successful delineation of tumours into intra-tumoural classes. Deep learning algorithms outperform on tasks of semantic segmentation as opposed to the more conventional, context-based computer vision approaches. Extensively used for biomedical image segmentation, Convolutional Neural Networks have significantly improved the state-of-the-art accuracy on the task of brain tumour segmentation. In this paper, we propose an ensemble of two segmentation networks: a 3D CNN and a U-Net, in a significant yet straightforward combinative technique that results in better and accurate predictions. Both models were trained separately on the BraTS-19 challenge dataset and evaluated to yield segmentation maps which considerably differed from each other in terms of segmented tumour sub-regions and were ensembled variably to achieve the final prediction. The suggested ensemble achieved dice scores of 0.750, 0.906 and 0.846 for enhancing tumour, whole tumour, and tumour core, respectively, on the validation set, performing favourably in comparison to the state-of-the-art architectures currently available. © 2013 IEEE.","BraTS; CNN; Deep learning; ensembling; medical imaging; segmentation; U-Net","Brain; Convolutional neural networks; Deep learning; Image enhancement; Learning algorithms; Magnetic resonance imaging; Predictive analytics; Semantics; Tumors; Accurate prediction; Automated segmentation; Biomedical image segmentation; Disease progression; Segmentation map; Segmentation techniques; Semantic segmentation; State of the art; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Wang Y.; He Z.; Xie P.; Yang C.; Zhang Y.; Li F.; Chen X.; Lu K.; Li T.; Zhou J.; Zuo K.","Wang, Yuan (57219774374); He, Zhiyou (57191858920); Xie, Peizhen (57218281149); Yang, Canqun (13408914200); Zhang, Yu (59072202600); Li, Fangfang (56039980600); Chen, Xiang (57212086254); Lu, Kai (8685091500); Li, Tao (56965840800); Zhou, Jiao (57218285366); Zuo, Ke (24588344100)","57219774374; 57191858920; 57218281149; 13408914200; 59072202600; 56039980600; 57212086254; 8685091500; 56965840800; 57218285366; 24588344100","Segment Medical Image Using U-Net Combining Recurrent Residuals and Attention","2020","633 LNEE","","","77","86","9","10.1007/978-981-15-5199-4_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088573030&doi=10.1007%2f978-981-15-5199-4_8&partnerID=40&md5=1e6a6402f1c7e5647e76b659c5f9b5eb","Medical image segmentation is the key to decide the issue of medical images in clinical practice that can provide a reliable basis. The development of medical image segmentation technology not only affects the development of other related technologies in medical image processing, such as visualization 3D reconstruction, but in the analysis of biomedical images also occupies an extremely important position. With the application of deep learning algorithms in medical image segmentation, medical image segmentation technology has made significant progress. In this paper, we discuss the segmentation method of 2D medical images about U-net variant network. Use the U-net combing recurrent residual model and attention model to segmented the image can get better result. © 2020, Springer Nature Singapore Pte Ltd.","Attention; Medical image; Residual; Segmentation; U-net","Computer aided diagnosis; Engineering education; Image segmentation; Learning algorithms; Recurrent neural networks; Three dimensional computer graphics; 3D reconstruction; Attention model; Biomedical images; Clinical practices; Residual model; Segmentation methods; Medical image processing","","Su R.; Liu H.","Springer",""
"Piuri V.; Raj S.; Genovese A.; Srivastava R.","Piuri, Vincenzo (35426171300); Raj, Sandeep (56797593800); Genovese, Angelo (36650547700); Srivastava, Rajshree (57212475441)","35426171300; 56797593800; 36650547700; 57212475441","Trends in Deep Learning Methodologies: Algorithms, Applications, and Systems","2020","","","","1","288","287","10.1016/B978-0-12-822226-3.01001-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126409994&doi=10.1016%2fB978-0-12-822226-3.01001-1&partnerID=40&md5=cd27f3b4453a7b0c240985366d5c7240","Trends in Deep Learning Methodologies: Algorithms, Applications, and Systems covers deep learning approaches such as neural networks, deep belief networks, recurrent neural networks, convolutional neural networks, deep auto-encoder, and deep generative networks, which have emerged as powerful computational models. Chapters elaborate on these models which have shown significant success in dealing with massive data for a large number of applications, given their capacity to extract complex hidden features and learn efficient representation in unsupervised settings. Chapters investigate deep learning-based algorithms in a variety of application, including biomedical and health informatics, computer vision, image processing, and more. In recent years, many powerful algorithms have been developed for matching patterns in data and making predictions about future events. The major advantage of deep learning is to process big data analytics for better analysis and self-adaptive algorithms to handle more data. Deep learning methods can deal with multiple levels of representation in which the system learns to abstract higher level representations of raw data. Earlier, it was a common requirement to have a domain expert to develop a specific model for each specific application, however, recent advancements in representation learning algorithms allow researchers across various subject domains to automatically learn the patterns and representation of the given data for the development of specific models. © 2021 Elsevier Inc. All rights reserved.","","","","","Elsevier",""
"Tang X.; Spaink H.A.J.; Wijk R.C.V.; Verbeek F.J.","Tang, Xiaoqin (58836185400); Spaink, Hermes A. J. (57761041300); Wijk, Rob C. Van (57194397640); Verbeek, Fons J. (6701677480)","58836185400; 57761041300; 57194397640; 6701677480","Segmentation-Driven Optimization for Iterative Reconstruction in Optical Projection Tomography: An Exploration","2020","6","","9262061","1537","1547","10","10.1109/TCI.2020.3038489","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097195004&doi=10.1109%2fTCI.2020.3038489&partnerID=40&md5=62b1094292dfb8fbb83d2e8175c03a5b","Three-dimensional reconstruction of tomograms from optical projection microscopy is confronted with several drawbacks. In this paper we employ iterative reconstruction algorithms to avoid streak artefacts in the reconstruction and explore possible ways to optimize two parameters of the algorithms, i.e., iteration number and initialization, in order to improve the reconstruction performance. As benchmarks for direct reconstruction evaluation in optical projection tomography are absent, we consider the assessment through the performance of the segmentation on the 3D reconstruction. In our explorative experiments we use the zebrafish model system which is a typical specimen for use in optical projection tomography system; and as such frequently used. In this manner data can be easily obtained from which a benchmark set can be built. For the segmentation approach we apply a two-dimensional U-net convolutional neural network because it is recognized to have a good performance in biomedical image segmentation. In order to prevent the training from getting stuck in local minima, a novel learning rate schema is proposed. This optimization achieves a lower training loss during the training process, as compared to an optimal constant learning rate. Our experiments demonstrate that the approach to the benchmarking of iterative reconstruction via results of segmentation is very useful. It contributes an important tool to the development of computational tools for optical projection tomography.  © 2015 IEEE.","Convolutional neural network; Deep learning; Image reconstruction; Image segmentation; OPT","Benchmarking; Computerized tomography; Convolutional neural networks; Image segmentation; Iterative methods; Optical projectors; Biomedical image segmentation; Computational tools; Iteration numbers; Iterative reconstruction; Iterative reconstruction algorithms; Optical projection tomography; Optical projections; Three-dimensional reconstruction; Image reconstruction","China Scholarship Council, CSC","","Institute of Electrical and Electronics Engineers Inc.",""
"Tan X.; Yu Y.; Duan K.; Zhang J.; Sun P.; Sun H.","Tan, Xian (57214414200); Yu, Yang (57216704120); Duan, Kaiwen (57218541092); Zhang, Jingbo (24559758100); Sun, Pingping (55856731100); Sun, Hui (57306461400)","57214414200; 57216704120; 57218541092; 24559758100; 55856731100; 57306461400","Current advances and limitations of deep learning in anticancer drug sensitivity prediction","2020","20","21","","1858","1867","9","10.2174/1568026620666200710101307","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089531401&doi=10.2174%2f1568026620666200710101307&partnerID=40&md5=9fef72a13e8fee218326dc6f913a5467","Anticancer drug screening can accelerate drug discovery to save the lives of cancer patients, but cancer heterogeneity makes this screening challenging. The prediction of anticancer drug sensitivity is useful for anticancer drug development and the identification of biomarkers of drug sensitivity. Deep learning, as a branch of machine learning, is an important aspect of in silico research. Its outstanding computational performance means that it has been used for many biomedical purposes, such as medical image interpretation, biological sequence analysis, and drug discovery. Several studies have predicted anticancer drug sensitivity based on deep learning algorithms. The field of deep learning has made progress regarding model performance and multi-omics data integration. However, deep learning is limited by the number of studies performed and data sources available, so it is not perfect as a pre-clinical approach for use in the anticancer drug screening process. Improving the performance of deep learning models is a pressing issue for researchers. In this review, we introduce the research of anticancer drug sensitivity prediction and the use of deep learning in this research area. To provide a reference for future research, we also review some common data sources and machine learning methods. Lastly, we discuss the advantages and disadvantages of deep learning, as well as the limitations and future perspectives regarding this approach. © 2020 Bentham Science Publishers.","Anticancer drug screening; Bioinformatics; Cancer; Cancer cell lines; Computational biology; Deep learning","Antineoplastic Agents; Cell Proliferation; Computational Biology; Deep Learning; Drug Discovery; Drug Evaluation, Preclinical; Humans; antineoplastic agent; antineoplastic agent; artificial neural network; computer model; computer prediction; deep learning; drug identification; drug screening; drug sensitivity; high throughput screening; human; Review; sensitivity analysis; biology; cell proliferation; chemistry; drug development; drug effect; preclinical study","Science and Technology Development Plan of Jilin province, (20180414006GH); Natural Science Foundation of Jilin Province, (20200201158JC); National Natural Science Foundation of China, NSFC, (41671379, 61502093, 61802057); National Key Research and Development Program of China, NKRDPC, (2017YFC0909200); Jilin Scientific and Technological Development Program, (20180520028JH); science and technology research project of ""13th Five-Year Plan"" of the Education Department of Jilin province, (JJKH20190290KJ)","","Bentham Science Publishers","32648840"
"Aldayel M.S.; Ykhlef M.; Al-Nafjan A.N.","Aldayel, Mashael S. (55608201500); Ykhlef, Mourad (26647882500); Al-Nafjan, Abeer N. (36940908700)","55608201500; 26647882500; 36940908700","Electroencephalogram-based preference prediction using deep transfer learning","2020","8","","","176818","176829","11","10.1109/ACCESS.2020.3027429","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102744053&doi=10.1109%2fACCESS.2020.3027429&partnerID=40&md5=4db0dd199f7d9fdc93dbfffb61aefcc8","Transfer learning is an approach in machine learning where a model that was built and trained on one task is re-purposed on a second task. The success of transfer learning in computer vision has motivated its use in neuroscience. Although common in image recognition, the use of transfer learning in EEG classification remains unexplored. Most EEG-based neuroscience studies depend on using traditional machine learning algorithms to answer a question, rather than on improving the algorithms. Developing algorithms for transfer learning for EEG can also assist with problems of low data availability in EEG classification. The primary objective of this study is to investigate EEG-based transfer learning and propose deep transfer learning models to transfer knowledge from emotion recognition to preference recognition to enhance the classification prediction accuracy. To the best of our knowledge, this is the first study demonstrating the effect of applying deep transfer learning between EEG-based emotion recognition and EEG-based preference detection. We propose different approaches for deep transfer learning models to detect preferences from EEG signals using the preprocessed DEAP dataset. Two types of features were extracted from EEG signals, namely the power spectral density and valence. We built three models of deep neural networks: basic without transfer learning, fine-tuning of deep transfer learning, and retraining of deep transfer learning. We compared the performance of deep transfer learning with those of deep neural networks and other conventional classification algorithms such as support vector machine, random forest, and k-nearest neighbor. Although the deep neural network classifiers achieved a high accuracy of greater than 87%, deep transfer learning achieved the highest accuracy result of 93%. The results demonstrate that although the proposed deep transfer learning approaches exhibit higher accuracy than the support vector machine and k-nearest neighbor classifiers, random forest achieves results similar to those of deep transfer learning. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Artificial neural networks; Brain-computer interfaces; Consumer behavior; Data mining; Emotion recognition; Signal processing; Supervised learning","Biomedical signal processing; Decision trees; Deep neural networks; Electroencephalography; Image recognition; Learning systems; Motion compensation; Nearest neighbor search; Neural networks; Neurology; Random forests; Spectral density; Speech recognition; Support vector machines; Transfer learning; Classification algorithm; Classification prediction; EEG classification; Emotion recognition; K-nearest neighbor classifier; K-nearest neighbors; Learning approach; Neural network classifier; Deep learning","King Saud University, KSU; Deanship of Scientific Research, King Saud University; Department of Sport and Recreation, Government of Western Australia, DSR; King Saud University, KSU; Deanship of Scientific Research, King Saud University","","Institute of Electrical and Electronics Engineers Inc.",""
"Samreen A.; Taha A.M.; Reddy Y.V.; Sathish P.","Samreen, Ayesha (57214725737); Taha, Amtul Mohimin (57220201297); Reddy, Yasa Vishwanath (57220200007); Sathish, P. (57211526539)","57214725737; 57220201297; 57220200007; 57211526539","Brain Tumor Detection by Using Convolution Neural Network","2020","16","13","","58","69","11","10.3991/ijoe.v16i13.18545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097247751&doi=10.3991%2fijoe.v16i13.18545&partnerID=40&md5=f9fb8fc11e47f2fb97727c842d3023b1","Nowadays, Biomedical technology plays a vital role in diagnosis and treatment of small to dangerous life-threatening diseases and one of the most life-threatening disease is Brain Tumor, which is the mass growth of abnormal cells in brain. Early detection and treatment of it can save the human life by preventing the further growth of abnormal cells. Detection of it can be done by analysing the Magnetic Resonance Imaging (MRI) Scans. Accurate analysis of MRI Scans needs to be done to detect the brain tumor and it can be achieved by using the algorithms of artificial neural networks, although human can detect manually but possibility to human errors is more and is time consuming. This paper proposes an effective algorithm model to predict brain tumor probability by using convolution neural networks. The algorithm includes image pre-processing in which noise is reduced using Gaussian filter and morphological operations. After that, images are normalized to scale fit. Batch normalization is added to the network to speed up the training. BRATS and Kaggle image dataset are used to train and evaluate the model to get maximised accuracy. Confusion matrix is used to evaluate the performance of the maximised model. © 2020, International journal of online and biomedical engineering. All rights reserved.","Brain tumor detection; Convolution Neural Network (CNN); Deep learning; Keras; Magnetic Resonance imaging (MRI); TensorFlow","","","","Kassel University Press GmbH",""
"Wang J.; Peng K.","Wang, Jiabin (38562168000); Peng, Kai (55366580600)","38562168000; 55366580600","A multi-view gait recognition method using deep convolutional neural network and channel attention mechanism","2020","125","1","","245","263","18","10.32604/cmes.2020.011046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091395942&doi=10.32604%2fcmes.2020.011046&partnerID=40&md5=05ad972482010321283c951ed4e64e35","In many existing multi-view gait recognition methods based on images or video sequences, gait sequences are usually used to superimpose and synthesize images and construct energy-like template. However, information may be lost during the process of compositing image and capture EMG signals. Errors and the recognition accuracy may be introduced and affected respectively by some factors such as period detection. To better solve the problems, a multi-view gait recognition method using deep convolutional neural network and channel attention mechanism is proposed. Firstly, the sliding time window method is used to capture EMG signals. Then, the back-propagation learning algorithm is used to train each layer of convolution, which improves the learning ability of the convolutional neural network. Finally, the channel attention mechanism is integrated into the neural network, which will improve the ability of expressing gait features. And a classifier is used to classify gait. As can be shown from experimental results on two public datasets, OULP and CASIA-B, the recognition rate of the proposed method can be achieved at 88.44% and 97.25% respectively. As can be shown from the comparative experimental results, the proposed method has better recognition effect than several other newer convolutional neural network methods. Therefore, the combination of convolutional neural network and channel attention mechanism is of great value for gait recognition. © 2020 Tech Science Press. All rights reserved.","Back-propagation; Channel attention mechanism; Convolutional neural network; EMG signal capture; Gait characteristics; Gait recognition; Multi-view","Backpropagation; Biomedical signal processing; Convolution; Deep neural networks; Gait analysis; Image processing; Multilayer neural networks; Pattern recognition; Attention mechanisms; Backpropagation learning algorithm; Gait recognition; Learning abilities; Period detections; Recognition accuracy; Sliding time windows; Video sequences; Convolutional neural networks","Fujian natural science foundation project, (2018J05106, 3502Z20173046); National Natural Science Foundation of China, NSFC, (61902133)","","Tech Science Press",""
"de Pinho Pinheiro C.A.; Nedjah N.; de Macedo Mourelle L.","de Pinho Pinheiro, Cesar Affonso (57207830460); Nedjah, Nadia (6701673657); de Macedo Mourelle, Luiza (6602182066)","57207830460; 6701673657; 6602182066","Detection and classification of pulmonary nodules using deep learning and swarm intelligence","2020","79","21-22","","15437","15465","28","10.1007/s11042-019-7473-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062995200&doi=10.1007%2fs11042-019-7473-z&partnerID=40&md5=dc2efe422c1efa76ab5db998fd632447","Cancer diagnosis is usually an arduous task in medicine, especially when it comes to pulmonary cancer, which is one of the most deadly and hard to treat types of that disease. Early detecting pulmonary cancerous nodules drastically increases surviving chances but also makes it an even harder problem to solve, as it mostly depends on a visual inspection of tomography scans. In order to help improving cancer detection and surviving rates, engineers and scientists have been developing computer-aided diagnosis systems, similar to the one presented in this paper. These systems are used as second opinions, to help health professionals during the diagnosis of numerous diseases. This work uses computational intelligence techniques to propose a new approach towards solving the problem of detecting pulmonary carcinogenic nodules in computed tomography scans. The applied technology consists of using Deep Learning and Swarm Intelligence to develop different nodule detection and classification models. We exploit seven different swarm intelligence algorithms and convolutional neural networks, prepared for biomedical image segmentation, to find and classify cancerous pulmonary nodules in the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) databases. The aim of this work is to use swarm intelligence to train convolutional neural networks and verify whether this approach brings more efficiency than the classic training algorithms, such as back-propagation and gradient descent methods. As main contribution, this work confirms the superiority of swarm-trained models over the back-propagation-based model for this application, as three out of the seven algorithms are proved to be superior regarding all four performance metrics, which are accuracy, precision, sensitivity, and specificity, as well as training time, where the best swarm-trained model operates 25% faster than the back-propagation model. The performed experiments show that the developed models can achieve up to 93.71% accuracy, 93.53% precision, 92.96% sensitivity, and 98.52% specificity. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Convolutional neural networks; Deep learning; Nodule detection; Swarm intelligence","Backpropagation algorithms; Bioinformatics; Classification (of information); Computer aided diagnosis; Computerized tomography; Convolution; Database systems; Deep learning; Deep neural networks; Diseases; Gradient methods; Image segmentation; Neural networks; Biomedical image segmentation; Computational intelligence techniques; Computed tomography scan; Computer aided diagnosis systems; Convolutional neural network; Gradient Descent method; Nodule detection; Swarm intelligence algorithms; Swarm intelligence","","","Springer",""
"Shahraki F.F.; Saadatifard L.; Berisha S.; Lotfollahi M.; Mayerich D.; Prasad S.","Shahraki, Farideh Foroozandeh (57033991400); Saadatifard, Leila (57202704612); Berisha, Sebastian (56642641000); Lotfollahi, Mahsa (57195399716); Mayerich, David (7801383946); Prasad, Saurabh (14018500100)","57033991400; 57202704612; 56642641000; 57195399716; 7801383946; 14018500100","Deep learning for hyperspectral image analysis, part II: Applications to remote sensing and biomedicine","2020","","","","69","115","46","10.1007/978-3-030-38617-7_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085170932&doi=10.1007%2f978-3-030-38617-7_4&partnerID=40&md5=aa38ad3027ef17466d28e97cfee68daf","Deep neural networks are emerging as a popular choice for hyperspectral image analysis—compared with other machine learning approaches, they are more effective for a variety of applications in hyperspectral imaging. Part I (Chap. 3) introduces the fundamentals of deep learning algorithms and techniques deployed with hyperspectral images. In this chapter (Part II), we focus on application-specific nuances and design choices with respect to deploying such networks for robust analysis of hyperspectral images. We provide quantitative and qualitative results with a variety of deep learning architectures, and compare their performance to baseline state-of-the-art methods for both remote sensing and biomedical image analysis tasks. In addition to surveying recent developments in these areas, our goal in these two chapters is to provide guidance on how to utilize such algorithms for multichannel optical imagery. With that goal, we also provide code and example datasets used in this chapter. © 2020, Springer Nature Switzerland AG.","","","","","Springer",""
"Ferreira J.; Domingues I.; Sousa O.; Sampaio I.L.; Santos J.A.M.","Ferreira, Jorge (57188819415); Domingues, Ines (57183994300); Sousa, Olga (19637155400); Sampaio, Ines Lucena (57192209957); Santos, Joao A. M. (55984028200)","57188819415; 57183994300; 19637155400; 57192209957; 55984028200","Classification of oesophagic early-stage cancers: Deep learning versus traditional learning approaches","2020","","","9288025","746","751","5","10.1109/BIBE50027.2020.00127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099568885&doi=10.1109%2fBIBE50027.2020.00127&partnerID=40&md5=368fe001854642ad542e44b0f6f6db89","Esophageal cancer is a disease with a high prevalence which can be evaluated by a variety of imaging modalities. Computer vision techniques could provide a valuable help in the analysis of these images, for it would allow an enhancement in diagnostic and staging accuracies, a decrease in medical workflow time and preventing patients' loss of quality of life.Traditional learning techniques are frequently used in the biomedical imaging field, and deep learning algorithms are starting to see their rise in usage in this field as well. In this paper, both traditional and deep learning algorithms are applied on a dataset provided by Instituto Portugues de Oncologia (IPO) consisting of CT and three PET scans acquired at different treatment phases of 14 patients with oesophageal cancer.The main goal is to distinguish patients that need surgery from the ones that do not. The traditional learning method consisted of manually extracting the features and applying feature selection algorithms for further classification. Feature level and decision level fusion were also conducted. The deep learning method consisted of using convolutional neural networks to extract and classify the image features. Moreover, traditional and deep learning techniques were used simultaneously, where the features were extracted and selected by a pretrained network and classified using the traditional learning classifiers.Traditional Learning methods achieved 92.86% accuracy, while for feature extraction with deep learning followed by classification with a traditional classifier was able to reach 100% accuracy. The difference has, however, proven not to be statistically significant. In this way, for this particular problem and conditions, it can be said that traditional techniques are capable of achieving results as good as with deep learning. © 2020 IEEE.","Classification; CT; Deep Learning; Oesophagic cancer; PET; Traditional Learning","Bioinformatics; Classification (of information); Computerized tomography; Convolutional neural networks; Deep learning; Diagnosis; Diseases; Feature extraction; Image enhancement; Learning systems; Medical computing; Medical imaging; Patient treatment; Quality control; Biomedical imaging; Computer vision techniques; Decision level fusion; Different treatments; Feature selection algorithm; Learning techniques; Traditional learning; Traditional techniques; Learning algorithms","Fundac¸ão para a Ciência Tecnologia, (NORTE-01-0145-FEDER-000027, UIDP/00776/2020); Norte Portugal Regional Operational Programme; Fundação para a Ciência e a Tecnologia, FCT; European Regional Development Fund, ERDF","","Institute of Electrical and Electronics Engineers Inc.",""
"Zhao H.; Ke Z.; Chen N.; Wang S.; Li K.; Wang L.; Gong X.; Zheng W.; Song L.; Liu Z.; Liang D.; Liu C.","Zhao, Huangxuan (57207451578); Ke, Ziwen (57210896130); Chen, Ningbo (57202057692); Wang, Songjian (57213591786); Li, Ke (57213221239); Wang, Lidai (36864572900); Gong, Xiaojing (56677170300); Zheng, Wei (56518738400); Song, Liang (55587150600); Liu, Zhicheng (7406672820); Liang, Dong (58761554900); Liu, Chengbo (56024357900)","57207451578; 57210896130; 57202057692; 57213591786; 57213221239; 36864572900; 56677170300; 56518738400; 55587150600; 7406672820; 58761554900; 56024357900","A new deep learning method for image deblurring in optical microscopic systems","2020","13","3","e201960147","","","","10.1002/jbio.201960147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077885591&doi=10.1002%2fjbio.201960147&partnerID=40&md5=07ad7ab8858edc8fb59144f76bb72da5","Deconvolution is the most commonly used image processing method in optical imaging systems to remove the blur caused by the point-spread function (PSF). While this method has been successful in deblurring, it suffers from several disadvantages, such as slow processing time due to multiple iterations required to deblur and suboptimal in cases where the experimental operator chosen to represent PSF is not optimal. In this paper, we present a deep-learning-based deblurring method that is fast and applicable to optical microscopic imaging systems. We tested the robustness of proposed deblurring method on the publicly available data, simulated data and experimental data (including 2D optical microscopic data and 3D photoacoustic microscopic data), which all showed much improved deblurred results compared to deconvolution. We compared our results against several existing deconvolution methods. Our results are better than conventional techniques and do not require multiple iterations or pre-determined experimental operator. Our method has several advantages including simple operation, short time to compute, good deblur results and wide application in all types of optical microscopic imaging systems. The deep learning approach opens up a new path for deblurring and can be applied in various biomedical imaging fields. © 2019 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","convolutional neural network; deblur method; deep learning; optical microscopic imaging systems; photoaoustic image","Algorithms; Deep Learning; Image Processing, Computer-Assisted; Deep learning; Deep neural networks; Imaging systems; Medical imaging; Microscopic examination; Neural networks; Optical data processing; Optical transfer function; Processing; Conventional techniques; Convolutional neural network; deblur method; Deconvolution method; Image processing - methods; Microscopic imaging; Optical imaging system; photoaoustic image; algorithm; image processing; Image enhancement","National Natural Science Foundation of China, NSFC, (31570952, 91739117)","","Wiley-VCH Verlag","31845537"
"Hammam A.A.; Elmousalami H.H.; Hassanien A.E.","Hammam, Ahmed A. (57212442079); Elmousalami, Haytham H. (57196150503); Hassanien, Aboul Ella (57192178208)","57212442079; 57196150503; 57192178208","Stacking Deep Learning for Early COVID-19 Vision Diagnosis","2020","78","","","297","307","10","10.1007/978-3-030-55258-9_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105991222&doi=10.1007%2f978-3-030-55258-9_18&partnerID=40&md5=ffadd5964b78e7837d9856add11198a1","early and accurate COVID-19 diagnosis prediction plays a crucial role for helping radiologists and health care workers to take reliable corrective actions for classify patients and detecting the COVID 19 confirmed cases. Prediction and classification accuracy are critical for COVID-19 diagnosis application. Current practices for COVID-19 images classification are mostly built upon convolutional neural network (CNNs) where CNN is a single algorithm. On the other hand, ensemble machine learning models produce higher accuracy than a single machine leaning. Therefore, this study conducts stacking deep learning methodology to produce the highest results of COVID-19 classification. The stacked ensemble deep learning model accuracy has produced 98.6% test accuracy. Accordingly, the stacked ensemble deep learning model produced superior performance than any single model. Accordingly, ensemble machine learning evolves as a future trend due to its high scalability, stability, and prediction accuracy. © 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.","Biomedical image processing; Classification; COVID-19; Deep learning; Ensemble learning; Stacking","Computer aided diagnosis; Convolutional neural networks; Deep learning; Forecasting; Image classification; Learning systems; Classification accuracy; Convolutional neural network; Corrective actions; Current practices; Deep learning; Ensemble learning; Health care workers; Learning models; Prediction accuracy; Stackings; COVID-19","","","Springer Science and Business Media Deutschland GmbH",""
"","","","24th Annual Conference on Medical Image Understanding and Analysis, MIUA 2020","2020","1248 CCIS","","","","","445","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088585919&partnerID=40&md5=c7ee66ec8dd6cd5c16a575abaea4bac8","The proceedings contain 34 papers. The special focus in this conference is on Medical Image Understanding and Analysis. The topics include: Pancreas Segmentation-Derived Biomarkers: Volume and Shape Metrics in the UK Biobank Imaging Study; Localization and Identification of Lumbar Intervertebral Discs on Spine MR Images with Faster RCNN Based Shortest Path Algorithm; deepSplit: Segmentation of Microscopy Images Using Multi-task Convolutional Networks; a Framework for Jointly Assessing and Reducing Imaging Artefacts Automatically Using Texture Analysis and Total Variation Optimisation for Improving Perivascular Spaces Quantification in Brain Magnetic Resonance Imaging; groupwise Multimodal Image Registration Using Joint Total Variation; CT Scan Registration with 3D Dense Motion Field Estimation Using LSGAN; A Supervised Image Registration Approach for Late Gadolinium Enhanced MRI and Cine Cardiac MRI Using Convolutional Neural Networks; unsupervised Deep Learning for Stain Separation and Artifact Detection in Histopathology Images; asymmetric Point Spread Function Estimation and Deconvolution for Serial-Sectioning Block-Face Imaging; Unlearning Scanner Bias for MRI Harmonisation in Medical Image Segmentation; automatic and Objective Facial Palsy Grading Index Prediction Using Deep Feature Regression; prediction of Thrombectomy Functional Outcomes Using Multimodal Data; radiomics: A New Biomedical Workflow to Create a Predictive Model; going Deeper into Cardiac Motion Analysis to Model Fine Spatio-Temporal Features; ridge Detection and Analysis of Susceptibility-Weighted Magnetic Resonance Imaging in Neonatal Hypoxic-Ischaemic Encephalopathy; a Machine Learning Approach for Colles’ Fracture Treatment Diagnosis; A Lightweight CNN and Joint Shape-Joint Space ($$JS^2$$ ) Descriptor for Radiological Osteoarthritis Detection; discovering Unknown Diseases with Explainable Automated Medical Imaging; Segmenting Hepatocellular Carcinoma in Multi-phase CT.","","","","Papiez B.W.; Namburete A.I.L.; Yaqub M.; Noble J.A.; Yaqub M.","Springer",""
"Shen Y.; Ji Z.; Gao M.","Shen, Yan (57204107888); Ji, Zhanghexuan (57212001918); Gao, Mingchen (55424598500)","57204107888; 57212001918; 55424598500","An End-to-End Learnable Flow Regularized Model for Brain Tumor Segmentation","2020","12436 LNCS","","","532","541","9","10.1007/978-3-030-59861-7_54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092733086&doi=10.1007%2f978-3-030-59861-7_54&partnerID=40&md5=1fd84a4d1a8470ff684418218d80cfa8","Many segmentation tasks for biomedical images can be modeled as the minimization of an energy function and solved by a class of max-flow and min-cut optimization algorithms. However, the segmentation accuracy is sensitive to the contrasting of semantic features of different segmenting objects, as the traditional energy function usually uses hand-crafted features in their energy functions. To address these limitations, we propose to incorporate end-to-end trainable neural network features into the energy functions. Our deep neural network features are extracted from the down-sampling and up-sampling layers with skip-connections of a U-net. In the inference stage, the learned features are fed into the energy functions. And the segmentations are solved in a primal-dual form by ADMM solvers. In the training stage, we train our neural networks by optimizing the energy function in the primal form with regularizations on the min-cut and flow-conservation functions, which are derived from the optimal conditions in the dual form. We evaluate our methods, both qualitatively and quantitatively, in a brain tumor segmentation task. As the energy minimization model achieves a balance on sensitivity and smooth boundaries, we would show how our segmentation contours evolve actively through iterations as ensemble references for doctor diagnosis. © 2020, Springer Nature Switzerland AG.","","Bioinformatics; Brain; Computer aided instruction; Deep learning; Deep neural networks; Diagnosis; Image segmentation; Medical imaging; Multilayer neural networks; Semantics; Signal sampling; Tumors; Brain tumor segmentation; Down sampling and up samplings; Energy minimization; Neural network features; Optimal conditions; Optimization algorithms; Segmentation accuracy; Semantic features; Learning systems","National Science Foundation, NSF, (1910492)","Liu M.; Lian C.; Yan P.; Cao X.","Springer Science and Business Media Deutschland GmbH",""
"Gadosey P.K.; Li Y.; Agyekum E.A.; Zhang T.; Liu Z.; Yamak P.T.; Essaf F.","Gadosey, Pius Kwao (57201334954); Li, Yujian (26642995500); Agyekum, Enock Adjei (57215589307); Zhang, Ting (57198705645); Liu, Zhaoying (55672356900); Yamak, Peter T. (57208780170); Essaf, Firdaous (57212878980)","57201334954; 26642995500; 57215589307; 57198705645; 55672356900; 57208780170; 57212878980","SD-UNET: Stripping down U-net for segmentation of biomedical images on platforms with low computational budgets","2020","10","2","110","","","","10.3390/diagnostics10020110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081253571&doi=10.3390%2fdiagnostics10020110&partnerID=40&md5=a971286937330d8ec35aa6a56c47e524","During image segmentation tasks in computer vision, achieving high accuracy performance while requiring fewer computations and faster inference is a big challenge. This is especially important in medical imaging tasks but one metric is usually compromised for the other. To address this problem, this paper presents an extremely fast, small and computationally effective deep neural network called Stripped-Down UNet (SD-UNet), designed for the segmentation of biomedical data on devices with limited computational resources. By making use of depthwise separable convolutions in the entire network, we design a lightweight deep convolutional neural network architecture inspired by the widely adapted U-Net model. In order to recover the expected performance degradation in the process, we introduce a weight standardization algorithm with the group normalization method. We demonstrate that SD-UNet has three major advantages including: (i) smaller model size (23x smaller than U-Net); (ii) 8x fewer parameters; and (iii) faster inference time with a computational complexity lower than 8M floating point operations (FLOPs). Experiments on the benchmark dataset of the Internatioanl Symposium on Biomedical Imaging (ISBI) challenge for segmentation of neuronal structures in electron microscopic (EM) stacks and the Medical Segmentation Decathlon (MSD) challenge brain tumor segmentation (BRATs) dataset show that the proposed model achieves comparable and sometimes better results compared to the current state-of-the-art. © 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).","Biomedical image segmentation; Computer vision; Depthwise separable convolutions; Group normalization; Weight standardization","algorithm; Article; brain tumor; computer vision; convolutional neural network; deep learning; deep neural network; diagnostic imaging; electron microscopy; image analysis; image segmentation; nerve cell; stripped down unet; structure analysis; u net; weight","Chaoyang Postdoctoral Foundation of Beijing, (2019zz-35); National Natural Science Foundation of China, NSFC, (61806013, 61876010, 61906005)","","Multidisciplinary Digital Publishing Institute (MDPI)",""
"Cui R.; Liu M.","Cui, Ruoxuan (57191681172); Liu, Manhua (8611675100)","57191681172; 8611675100","RNN-based longitudinal analysis for diagnosis of Alzheimer's disease","2019","73","","","1","10","9","10.1016/j.compmedimag.2019.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061290878&doi=10.1016%2fj.compmedimag.2019.01.005&partnerID=40&md5=7a45bfbbd6697b0fbefa4a0f0e86cbbf","Alzheimer's disease (AD) is an irreversible neurodegenerative disorder with progressive impairment of memory and other mental functions. Magnetic resonance images (MRI) have been widely used as an important imaging modality of brain for AD diagnosis and monitoring the disease progression. The longitudinal analysis of sequential MRIs is important to model and measure the progression of the disease along the time axis for more accurate diagnosis. Most existing methods extracted the features capturing the morphological abnormalities of brain and their longitudinal changes using MRIs and then designed a classifier to discriminate different groups. However, these methods have several limitations. First, since the feature extraction and classifier model are independent, the extracted features may not capture the full characteristics of brain abnormalities related to AD. Second, longitudinal MR images may be missing at some time points for some subjects, which results in difficulties for extraction of consistent features for longitudinal analysis. In this paper, we present a classification framework based on combination of convolutional and recurrent neural networks for longitudinal analysis of structural MR images in AD diagnosis. First, Convolutional Neural Networks (CNN) is constructed to learn the spatial features of MR images for the classification task. After that, recurrent Neural Networks (RNN) with cascaded three bidirectional gated recurrent units (BGRU) layers is constructed on the outputs of CNN at multiple time points for extracting the longitudinal features for AD classification. Instead of independently performing feature extraction and classifier training, the proposed method jointly learns the spatial and longitudinal features and disease classifier, which can achieve optimal performance. In addition, the proposed method can model the longitudinal analysis using RNN from the imaging data at various time points. Our method is evaluated with the longitudinal T1-weighted MR images of 830 participants including 198 AD, 403 mild cognitive impairment (MCI), and 229 normal controls (NC) subjects from Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Experimental results show that the proposed method achieves classification accuracy of 91.33% for AD vs. NC and 71.71% for pMCI vs. sMCI, demonstrating the promising performance for longitudinal MR image analysis. © 2019 Elsevier Ltd","Alzheimer's disease diagnosis; Convolutional neural networks (CNNs); Longitudinal analysis; Magnetic resonance images; Recurrent neural network","Algorithms; Alzheimer Disease; Databases, Factual; Humans; Longitudinal Studies; Magnetic Resonance Imaging; Neural Networks, Computer; Neuroimaging; Aluminum compounds; Biomedical signal processing; Classification (of information); Computer aided diagnosis; Convolution; Extraction; Feature extraction; Image analysis; Magnetic resonance; Magnetic resonance imaging; Neuroimaging; Recurrent neural networks; Alzheimer's disease; Classification framework; Convolutional neural network; Longitudinal analysis; Magnetic resonance images (MRI); Mild cognitive impairments (MCI); Neurodegenerative disorders; Recurrent neural network (RNN); aged; Alzheimer disease; Article; artificial neural network; cerebrospinal fluid; classification algorithm; classifier; controlled study; deep learning; disease classification; feature extraction; female; gray matter; human; major clinical study; male; mild cognitive impairment; neuroimaging; nuclear magnetic resonance imaging; priority journal; recurrent neural network; sensitivity and specificity; white matter; algorithm; Alzheimer disease; factual database; longitudinal study; Neurodegenerative diseases","National Natural Science Foundation of China, NSFC, (61375112, 61773263, 6181101049); Shanghai Jiao Tong University, SJTU; National Key Research and Development Program of China, NKRDPC, (2015CB931802, 2016YFC0100903)","","Elsevier Ltd","30763637"
"Kim K.-J.; Tagkopoulos I.","Kim, Ki-Jo (25031739600); Tagkopoulos, Ilias (14025920800)","25031739600; 14025920800","Application of machine learning in rheumatic disease research","2019","34","4","","708","722","14","10.3904/kjim.2018.349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069267590&doi=10.3904%2fkjim.2018.349&partnerID=40&md5=5fdf9c7c747b4e4b678a1d35112a7eca","Over the past decade, there has been a paradigm shift in how clinical data are collected, processed and utilized. Machine learning and artificial intelligence, fueled by breakthroughs in high-performance computing, data availability and algorithmic innovations, are paving the way to effective analyses of large, multi-dimensional collections of patient histories, laboratory results, treatments, and outcomes. In the new era of machine learning and predictive analytics, the impact on clinical decision-making in all clinical areas, including rheumatology, will be unprecedented. Here we provide a critical review of the machine-learning methods currently used in the analysis of clinical data, the advantages and limitations of these methods, and how they can be leveraged within the field of rheumatology. © 2019 The Korean Association of Internal Medicine.","Machine learning; Prediction; Rheumatology","Biomedical Research; Data Accuracy; Data Mining; Humans; Machine Learning; Rheumatic Diseases; Rheumatology; autoantibody; C reactive protein; antibody titer; area under the curve; arthralgia; Article; artificial intelligence; artificial neural network; automated pattern recognition; bias variance overfitting; bias variance trade off; big data; bootstrapping; chi square test; classification algorithm; clinical decision support system; clinical feature; clinical practice; clinical research; convolutional neural network; cross validation; data accuracy; data analysis; data cleaning; data comparability; data completeness; data control; data mining; data preprocessing; data quality; data quantity; decision making; decision tree; deep learning; diagnostic accuracy; diagnostic test accuracy study; differential diagnosis; disease activity score; disease classification; electronic medical record; embedded method; erythrocyte sedimentation rate; feature engineering; feature selection; filter method; game; gene expression; genomics; histopathology; hospital admission; human; image analysis; information processing; information storage; joint swelling; k cluster; kernel method; learning algorithm; least absolute shrinkage and selection operator; lung tuberculosis; machine learning; mortality risk; multidisciplinary team; myositis; nonhuman; null hypothesis; online system; osteoarthritis; personalized medicine; prediction; principal component analysis; privacy; probability; problem solving; prognosis; proportional hazards model; quality control; random forest; random survival forest; randomization; reinforcement learning (machine learning); reliability; reproducibility; reward; rheumatic disease; rheumatoid arthritis; rheumatology; risk assessment; sample size; standardization; statistical bias; statistical model; statistical parameters; statistical significance; supervised machine learning; support vector machine; systemic lupus erythematosus; test dataset; thorax radiography; training; training dataset; transfer machine learning; treatment response; unsupervised machine learning; validation dataset; validation study; wrapper method; measurement accuracy; medical research; pathophysiology; procedures; rheumatic disease","","","Korean Association of Internal Medicine","30616329"
"Hazratov S.; Bilgin G.","Hazratov, Sardor (57211989728); Bilgin, Gokhan (8362224100)","57211989728; 8362224100","Mitosis detection in multispectral histopathological images with deep learning","2019","","","8894914","","","","10.1109/TIPTEKNO.2019.8894914","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075602130&doi=10.1109%2fTIPTEKNO.2019.8894914&partnerID=40&md5=e7ae13390ea8a46c8a51e18b3d021e09","In this study, segmentation of cellular structures in the multispectral histopathological images and possibility of the discrimination within normal and mitotic cells have been investigated. In histopathological images, it is very challenging task to extract the mitotic cells from the histopathological image. In the first stage of the study, 'discriminative images' are obtained using linear discriminant analysis. The discriminative images found are used to screen mitotic cell candidates and train them with deep learning networks. Since mitotic cells are usually dark pixels, the discriminating images are first filtered to obtain dark areas. Then, two-clustered k-means algorithm was used to differentiate background and mitotic candidates. With the help of convolutional neural networks, it is aimed to find the mitotic and non-mitotic areas with the classification approach. In experimental studies, ICPR-2012 dataset is used in both training and prediction stages and the training of deep artificial neural network architecture is carried out with samples of mitotic and non-mitotic regions. As a result, the F-measure for the data set is found as 0.760, the recall is 0.723 and the sensitivity is 0.802. © 2019 IEEE.","Classification; Histopathological images; Mitosis detection; Multispectral; Segmentation","Biomedical engineering; Cells; Classification (of information); Cytology; Discriminant analysis; Image segmentation; K-means clustering; Network architecture; Neural networks; Cellular structure; Classification approach; Convolutional neural network; Histopathological images; Learning network; Linear discriminant analysis; Mitosis detections; Multi-spectral; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Swati Z.N.K.; Zhao Q.; Kabir M.; Ali F.; Ali Z.; Ahmed S.; Lu J.","Swati, Zar Nawab Khan (57204147436); Zhao, Qinghua (56903363200); Kabir, Muhammad (56740196100); Ali, Farman (57224837156); Ali, Zakir (54920849000); Ahmed, Saeed (57213511614); Lu, Jianfeng (55547138819)","57204147436; 56903363200; 56740196100; 57224837156; 54920849000; 57213511614; 55547138819","Brain tumor classification for MR images using transfer learning and fine-tuning","2019","75","","","34","46","12","10.1016/j.compmedimag.2019.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066294296&doi=10.1016%2fj.compmedimag.2019.05.001&partnerID=40&md5=c4849f6c1ebcc2c8968310ce517633a0","Accurate and precise brain tumor MR images classification plays important role in clinical diagnosis and decision making for patient treatment. The key challenge in MR images classification is the semantic gap between the low-level visual information captured by the MRI machine and the high-level information perceived by the human evaluator. The traditional machine learning techniques for classification focus only on low-level or high-level features, use some handcrafted features to reduce this gap and require good feature extraction and classification methods. Recent development on deep learning has shown great progress and deep convolution neural networks (CNNs)have succeeded in the images classification task. Deep learning is very powerful for feature representation that can depict low-level and high-level information completely and embed the phase of feature extraction and classification into self-learning but require large training dataset in general. For most of the medical imaging scenario, the training datasets are small, therefore, it is a challenging task to apply the deep learning and train CNN from scratch on the small dataset. Aiming this problem, we use pre-trained deep CNN model and propose a block-wise fine-tuning strategy based on transfer learning. The proposed method is evaluated on T1-weighted contrast-enhanced magnetic resonance images (CE-MRI)benchmark dataset. Our method is more generic as it does not use any handcrafted features, requires minimal preprocessing and can achieve average accuracy of 94.82% under five-fold cross-validation. We compare our results not only with the traditional machine learning but also with deep learning methods using CNNs. Experimental results show that our proposed method outperforms state-of-the-art classification on the CE-MRI dataset. © 2019 Elsevier Ltd","Block-wise fine-tuning; Brain tumor classification; Convolutional neural networks; Deep learning; Magnetic resonance images; Transfer learning","Algorithms; Brain Neoplasms; Deep Learning; Humans; Magnetic Resonance Imaging; Neural Networks, Computer; Biomedical signal processing; Brain; Computer aided diagnosis; Convolution; Decision making; Deep learning; Extraction; Feature extraction; Image classification; Image enhancement; Large dataset; Machine learning; Magnetic resonance; Magnetic resonance imaging; Medical imaging; Neural networks; Patient treatment; Semantics; Tumors; Brain tumor classifications; Convolution neural network; Convolutional neural network; Feature extraction and classification; Feature representation; Fine tuning; Machine learning techniques; Transfer learning; Article; artificial neural network; convolution neural network; deep learning; diagnostic accuracy; diagnostic imaging; diagnostic test accuracy study; dynamic contrast-enhanced magnetic resonance imaging; feature extraction; fine tuning; glioma; human; hypophysis tumor; information processing; machine learning; major clinical study; meningioma; priority journal; sensitivity and specificity; transfer of learning; tumor classification; validation study; algorithm; brain tumor; classification; diagnostic imaging; nuclear magnetic resonance imaging; Classification (of information)","Natural Science Foundation of Jiangsu Province, (20131351); National Basic Research Program of China (973 Program), (2018YFB1004); Higher Education Discipline Innovation Project, (B13022)","","Elsevier Ltd","31150950"
"Pang S.; Du A.; He X.; Díez J.; Orgun M.A.","Pang, Shuchao (55639762100); Du, Anan (56167972000); He, Xiaoli (57218575078); Díez, Jorge (7201552665); Orgun, Mehmet A. (6603681610)","55639762100; 56167972000; 57218575078; 7201552665; 6603681610","Fast and accurate lung tumor spotting and segmentation for boundary delineation on CT slices in a coarse-to-fine framework","2019","1142 CCIS","","","589","597","8","10.1007/978-3-030-36808-1_64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083005148&doi=10.1007%2f978-3-030-36808-1_64&partnerID=40&md5=93f0717bb39997a65cf80cd949d02c2d","Label noise and class imbalance are two of the critical challenges when training image-based deep neural networks, especially in the biomedical image processing domain. Our work focuses on how to address the two challenges effectively and accurately in the task of lesion segmentation from biomedical/medical images. To address the pixel-level label noise problem, we propose an advanced transfer training and learning approach with a detailed DICOM pre-processing method. To address the tumor/non-tumor class imbalance problem, we exploit a self-adaptive fully convolutional neural network with an automated weight distribution mechanism to spot the Radiomics lung tumor regions accurately. Furthermore, an improved conditional random field method is employed to obtain sophisticated lung tumor contour delineation and segmentation. Finally, our approach has been evaluated using several well-known evaluation metrics on the Lung Tumor segmentation dataset used in the 2018 IEEE VIP-CUP Challenge. Experimental results show that our weakly supervised learning algorithm outperforms other deep models and state-of-the-art approaches. © Springer Nature Switzerland AG 2019.","Boundary delineation; Fully convolutional neural networks; Lung tumor segmentation","Biological organs; Computerized tomography; Convolutional neural networks; Deep learning; Deep neural networks; Image segmentation; Learning systems; Noise pollution; Petroleum reservoir evaluation; Processing; Transfer learning; Tumors; Boundary delineation; Class imbalance problems; Conditional random field; Critical challenges; Lesion segmentations; Pre-processing method; State-of-the-art approach; Weight distributions; Learning algorithms","","Gedeon T.; Wong K.W.; Lee M.","Springer",""
"Ha K.-W.; Jeong J.-W.","Ha, Kwon-Woo (57208403999); Jeong, Jin-Woo (57205722835)","57208403999; 57205722835","Motor imagery EEG classification using capsule networks","2019","19","13","2854","","","","10.3390/s19132854","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068623465&doi=10.3390%2fs19132854&partnerID=40&md5=c0f99a39fb4ec9bfcbaadb9449902ba8","Various convolutional neural network (CNN)-based approaches have been recently proposed to improve the performance of motor imagery based-brain-computer interfaces (BCIs). However, the classification accuracy of CNNs is compromised when target data are distorted. Specifically for motor imagery electroencephalogram (EEG), the measured signals, even from the same person, are not consistent and can be significantly distorted. To overcome these limitations, we propose to apply a capsule network (CapsNet) for learning various properties of EEG signals, thereby achieving better and more robust performance than previous CNN methods. The proposed CapsNet-based framework classifies the two-class motor imagery, namely right-hand and left-hand movements. The motor imagery EEG signals are first transformed into 2D images using the short-time Fourier transform (STFT) algorithm and then used for training and testing the capsule network. The performance of the proposed framework was evaluated on the BCI competition IV 2b dataset. The proposed framework outperformed state-of-the-art CNN-based methods and various conventional machine learning approaches. The experimental results demonstrate the feasibility of the proposed approach for classification of motor imagery EEG signals. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","Brain-computer interface (BCI); Capsule network; Deep learning; Electroencephalogram (EEG); Motor imagery classification","Algorithms; Brain-Computer Interfaces; Electroencephalography; Fourier Analysis; Hand; Humans; Imagination; Machine Learning; Movement; Neural Networks, Computer; Biomedical signal processing; Computer networks; Deep learning; Electroencephalography; Image classification; Image enhancement; Neural networks; Brain computer interfaces (BCIs); Classification accuracy; Conventional machines; Convolutional neural network; Electro-encephalogram (EEG); Motor imagery classification; Motor imagery eeg signals; Short time Fourier transforms; algorithm; brain computer interface; diagnostic imaging; electroencephalography; Fourier analysis; hand; human; imagination; machine learning; movement (physiology); physiology; procedures; Brain computer interface","National Research Foundation of Korea, NRF; Ministry of Science ICT and Future Planning, MSIP, (2019R1F1A1045329); Ministry of Science and ICT, South Korea, MSIT","","MDPI AG","31252557"
"Alah R.S.A.; Bilgin G.; Albayrak A.","Alah, Roaa Safi Abed (57208424088); Bilgin, Gokhan (8362224100); Albayrak, Abdulkadir (55807331600)","57208424088; 8362224100; 55807331600","Automatic nuclei detection in histopathological images based on convolutional neural networks","2019","","","","193","200","7","10.5220/0007484301930200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064757045&doi=10.5220%2f0007484301930200&partnerID=40&md5=f625dedecd807a409cdded50173bc228","Analysis of cells in histopathological images with conventional manual methods is relatively expensive and time-consuming work for pathologists. Recently, computer aided and facilitated researches for the diagnostic algorithms have obtained a high significance to assist the pathologists to extract cellular structures. In this paper, we are compering the conventional fuzzy c-means (FCM) clustering method with the proposed automated detection system based on Tiny-Convolutional Neural Network (Tiny-CNN) to detect center of nucleus in histopathological images, Also, in this study, we are tried to find center of nucleus by combined unsupervised method (FCM) with supervised method (Tiny-CNN). Briefly, First step, nuclei centers are detected with FCM algorithm which is applied as a clustering-segmentation method to perform segmentation of nucleus cellular and nucleus non-cellular structure to find the correct center of nuclei. Second step, the deep learning method is used to detect center of nucleus based automated method. Afterward, combined each of these individual methods to evaluate our model for extracting the center of nucleus on two different data set the University of California Santa Barbara's UCSB-58 data set and data set University of Warwick's CRC-100 data set. Copyright © 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Convolution neural networks; Deep learning; FCM algorithm; Histopathological images; Nuclei detection","Biomedical engineering; Biomimetics; Cellular automata; Clustering algorithms; Convolution; Deep learning; Deep neural networks; Signal processing; Clustering segmentation; Convolution neural network; Convolutional neural network; FCM algorithm; Fuzzy C means clustering; Histopathological images; Nuclei detections; University of California; Fuzzy neural networks","","Putze F.; Fred A.; Gamboa H.","SciTePress",""
"Hart S.N.; Flotte W.; Norgan A.P.; Shah K.K.; Buchan Z.R.; Mounajjed T.; Flotte T.J.","Hart, Steven N. (57195606308); Flotte, William (57208133204); Norgan, Andrew P. (35311789400); Shah, Kabeer K. (57192066872); Buchan, Zachary R. (57208123260); Mounajjed, Taofic (8836176400); Flotte, Thomas J. (7103314284)","57195606308; 57208133204; 35311789400; 57192066872; 57208123260; 8836176400; 7103314284","Classification of melanocytic lesions in selected and whole-slide images via convolutional neural networks","2019","10","1","5","","","","10.4103/jpi.jpi_32_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063861699&doi=10.4103%2fjpi.jpi_32_18&partnerID=40&md5=f2ce8243f55a4d5aade45c483eb20ed8","Whole-slide images (WSIs) are a rich new source of biomedical imaging data. The use of automated systems to classify and segment WSIs has recently come to forefront of the pathology research community. While digital slides have obvious educational and clinical uses, their most exciting potential lies in the application of quantitative computational tools to automate search tasks, assist in classic diagnostic classification tasks, and improve prognosis and theranostics. An essential step in enabling these advancements is to apply advances in machine learning and artificial intelligence from other fields to previously inaccessible pathology datasets, thereby enabling the application of new technologies to solve persistent diagnostic challenges in pathology. Here, we applied convolutional neural networks to differentiate between two forms of melanocytic lesions (Spitz and conventional). Classification accuracy at the patch level was 99.0%-2% when applied to WSI. Importantly, when the model was trained without careful image curation by a pathologist, the training took significantly longer and had lower overall performance. These results highlight the utility of augmented human intelligence in digital pathology applications, and the critical role pathologists will play in the evolution of computational pathology algorithms. © 2019 Journal of Pathology Informatics | Published by Wolters Kluwer - Medknow.","Bioinformatics; deep learning; dermatology; image analysis","","Mayo Clinic","","Wolters Kluwer Medknow Publications",""
"Kagiyama N.; Shrestha S.; Farjo P.D.; Sengupta P.P.","Kagiyama, Nobuyuki (56032730000); Shrestha, Sirish (57201688823); Farjo, Peter D. (57191347348); Sengupta, Partho P. (7103155438)","56032730000; 57201688823; 57191347348; 7103155438","Artificial intelligence: practical primer for clinical research in cardiovascular disease","2019","8","17","e012788","","","","10.1161/JAHA.119.012788","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071651581&doi=10.1161%2fJAHA.119.012788&partnerID=40&md5=6fbab9a8513c35a783a91546997b03ba","[No abstract available]","Artificial intelligence; Deep learning; Machine learning; Risk model; Risk prediction; Statistics; Telemedicine","Artificial Intelligence; Biomedical Research; Cardiovascular Diseases; Diagnosis, Computer-Assisted; Diffusion of Innovation; Humans; Precision Medicine; Telemedicine; Therapy, Computer-Assisted; accuracy; algorithm; aortic stenosis; aortic valve replacement; artificial intelligence; artificial neural network; cardiovascular disease; clinical decision making; clinical practice; clinical research; clinician; computer assisted tomography; convolutional neural network; data quality; decision tree; deep learning; diagnostic imaging; disease course; disease severity; echocardiography; electronic health record; feature selection; heart amyloidosis; heart failure; heart left ventricle ejection fraction; hierarchical clustering; hospital readmission; human; hypertrophic cardiomyopathy; image recognition; image segmentation; k nearest neighbor; knowledge; learning; logistic regression analysis; machine learning; medical research; mortality; natural language processing; noise; Note; nuclear magnetic resonance imaging; oscillometry; outcome variable; personal experience; phonocardiography; play; practice guideline; prediction; principal component analysis; problem solving; prognosis; pulmonary hypertension; reinforcement learning; risk factor; scientist; sensitivity analysis; short term memory; software; statistics; supervised machine learning; support vector machine; voice recognition; artificial intelligence; cardiovascular disease; computer assisted diagnosis; computer assisted therapy; mass communication; pathophysiology; personalized medicine; telemedicine","National Institute of General Medical Sciences, NIGMS, (U54GM104942)","","American Heart Association Inc.","31450991"
"Ryoo J.; Fan M.; Tang X.; Jiang H.; Arunachalam M.; Naveen S.; Kandemir M.T.","Ryoo, Jihyun (57159124500); Fan, Mengran (57215213163); Tang, Xulong (57013793800); Jiang, Huaipan (56451943700); Arunachalam, Meena (57188576053); Naveen, Sharada (57215213244); Kandemir, Mahmut T. (35549787100)","57159124500; 57215213163; 57013793800; 56451943700; 57188576053; 57215213244; 35549787100","Architecture-Centric Bottleneck Analysis for Deep Neural Network Applications","2019","","","8990516","205","214","9","10.1109/HiPC.2019.00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080144759&doi=10.1109%2fHiPC.2019.00034&partnerID=40&md5=bcd37f22c8fbea225ae24f3089f81cdd","The ever-growing complexity and popularity of machine learning and deep learning applications have motivated an urgent need of effective and efficient support for these applications on contemporary computing systems. In this paper, we thoroughly analyze the various DNN algorithms on three widely used architectures (CPU, GPU, and Xeon Phi). The DNN algorithms we choose for evaluation include i) Unet-for biomedical image segmentation, based on Convolutional Neural Network (CNN), ii) NMT-for neural machine translation based on Recurrent Neural Network (RNN), iii) ResNet-50, and iv) DenseNet-both for image processing based on CNNs. The ultimate goal of this paper is to answer four fundamental questions: i) whether the different DNN networks exhibit similar behavior on a given execution platform? ii) whether, across different platforms, a given DNN network exhibits different behaviors? iii) for the same execution platform and the same DNN network, whether different execution phases have different behaviors? and iv) are the current major general-purpose platforms tuned sufficiently well for different DNN algorithms? Motivated by these questions, we conduct an in-depth investigation of running DNN applications on modern systems. Specifically, we first identify the most time-consuming functions (hotspot functions) across different networks and platforms. Next, we characterize performance bottlenecks and discuss them in detail. Finally, we port selected hotspot functions to a cycle-accurate simulator, and use the results to direct architectural optimizations to better support DNN applications. © 2019 IEEE.","Characterization; CPU; DNN; GPU; Xeon Phi","Bioinformatics; Convolutional neural networks; Graphics processing unit; Image segmentation; Network architecture; Program processors; Recurrent neural networks; Architecture-centric; Biomedical image segmentation; Cycle-accurate simulators; Machine translations; Neural network application; Performance bottlenecks; Recurrent neural network (RNN); Xeon Phi; Deep neural networks","National Science Foundation, NSF, (1439057, 1526750, 1629129, 1629915, 1763681, 1822923, 1908793, 1931531); Intel Corporation","","Institute of Electrical and Electronics Engineers Inc.",""
"Ge Y.; Li B.; Zhao Y.; Yan W.","Ge, Yunhao (57195494229); Li, Bin (57199787081); Zhao, Yanzheng (36017835600); Yan, Weixin (24367497900)","57195494229; 57199787081; 36017835600; 24367497900","HH-Net: Image driven microscope fast auto-focus with deep neural network","2019","","","","180","185","5","10.1145/3326172.3326225","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069223888&doi=10.1145%2f3326172.3326225&partnerID=40&md5=32f9450d2aeb94d8598fce046d5d9e0c","Computer aid auto-focus system is necessary for accurate microscope diagnosis, especially for the high precision microscope, which leaves little physical distance for focus adjusting manually. We proposed an image-driven microscope fast auto-focus system with a deep neural network. There are two main contributions. First, combining the high-level feature learning ability advantages of convolution neural network (CNN) and the handcraft feature selection ability of statistical learning, we proposed a High-level-Handcraft Neural Network (HH-Net) to accurately determine the distance index between microscope lens and cell smear by evaluating the image focus quality. It deployed 13 layers CNN for the high-level feature extraction from image patches. While the handcraft features which provide global information from the raw image were extracted by statistical algorithms and merged into CNN features. Finally, the combined features are utilized by the fully connected layers in the network to obtain the final distance index by classifying the biomedical image focus quality. Second, cooperated with the HH-Net, we propose an end to end image driven microscope fast auto-focus system, which can learn auto-focus policies from visual input and finish at a clear spot automatically. The accuracy of our patch level focus quality prediction is 92.4% with HH-Net, while the real-time image level focus quality predication can be 99.99% with 0.025s cost time by certainty voting strategy. Our auto-focus system can also cooperate with the X-Y Micro platform to automatically scan the whole cell smear and get the real-time best-in-focus image of a microscope with fast response, accuracy, and robustness. © 2019 Association for Computing Machinery.","Convolutional neural network; Deep neural network; Fast auto-focus; Handcraft features; High-level features; Image focus quality; Microscope","Biomedical engineering; Convolution; Convolutional neural networks; Deep learning; Feature extraction; Image quality; Microscopes; Network layers; Auto focus; Convolution neural network; Handcraft features; High-level feature extractions; High-level features; Image focus; Statistical algorithm; Statistical learning; Deep neural networks","","","Association for Computing Machinery",""
"Brinker T.J.; Hekler A.; Enk A.H.; von Kalle C.","Brinker, Titus J. (56286969000); Hekler, Achim (57204272697); Enk, Alexander H. (57217521840); von Kalle, Christof (7004127481)","56286969000; 57204272697; 57217521840; 7004127481","Enhanced classifier training to improve precision of a convolutional neural network to identify images of skin lesions","2019","14","6","e0218713","","","","10.1371/journal.pone.0218713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067629922&doi=10.1371%2fjournal.pone.0218713&partnerID=40&md5=eb149bc3e7cc98de8c161f8c189c2571","Background In recent months, multiple publications have demonstrated the use of convolutional neural networks (CNN) to classify images of skin cancer as precisely as dermatologists. However, these CNNs failed to outperform the International Symposium on Biomedical Imaging (ISBI) 2016 challenge which ranked the average precision for classification of dermoscopic melanoma images. Accordingly, the technical progress represented by these studies is limited. In addition, the available reports are impossible to reproduce, due to incomplete descriptions of training procedures and the use of proprietary image databases or non-disclosure of used images. These factors prevent the comparison of various CNN classifiers in equal terms. Objective To demonstrate the training of an image-classifier CNN that outperforms the winner of the ISBI 2016 CNNs challenge by using open source images exclusively. Methods A detailed description of the training procedure is reported while the used images and test sets are disclosed fully, to insure the reproducibility of our work. Results Our CNN classifier outperforms all recent attempts to classify the original ISBI 2016 challenge test data (full set of 379 test images), with an average precision of 0.709 (vs. 0.637 of the ISBI winner) and with an area under the receiver operating curve of 0.85. Conclusion This work illustrates the potential for improving skin cancer classification with enhanced training procedures for CNNs, while avoiding the use of costly equipment or proprietary image data. © 2019 Brinker et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Algorithms; Databases, Factual; Deep Learning; Dermatologists; Dermoscopy; Humans; Image Interpretation, Computer-Assisted; Melanoma; Neural Networks, Computer; Reproducibility of Results; Skin; Skin Neoplasms; Article; artificial neural network; classifier; controlled study; convolutional neural network; diagnostic accuracy; epiluminescence microscopy; imaging; International Symposium on Biomedical Imaging; skin defect; training; algorithm; classification; computer assisted diagnosis; dermatologist; diagnostic imaging; factual database; human; melanoma; procedures; reproducibility; skin; skin tumor","","","Public Library of Science","31233565"
"Anderson R.; Li H.; Ji Y.; Liu P.; Giger M.L.","Anderson, Rachel (57199166049); Li, Hui (56986807700); Ji, Yu (57190743032); Liu, Peifang (37861611800); Giger, Maryellen L. (7103040897)","57199166049; 56986807700; 57190743032; 37861611800; 7103040897","Evaluating deep learning techniques for dynamic contrast-enhanced MRI in the diagnosis of breast cancer","2019","10950","","1095006","","","","10.1117/12.2512667","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068107190&doi=10.1117%2f12.2512667&partnerID=40&md5=9f35cc82ab1f819d00e8c702db5a81e8","Deep learning has shown promise in the field of computer vision for image recognition. We evaluated two deep transfer learning techniques (feature extraction and fine-tuning) in the diagnosis of breast cancer compared to a lesion-based radiomics computer-aided diagnosis (CAD) method. The dataset included a total of 2006 breast lesions (1506 malignant and 500 benign) that were imaged with dynamic contrast-enhanced MRI. Pre-contrast, first post-contrast, and second post-contrast timepoint images for each lesion were combined to form an RGB image, which subsequently served as input to a VGG19 convolutional neural network (CNN) pre-trained on the ImageNet database. The first transfer learning technique was feature extraction conducted by extracting feature output from each of the five max-pooling layers in the trained CNN, average-pooling the features, performing feature reduction, and merging the CNN-features with a support vector machine in the classification of malignant and benign lesions. The second transfer learning method used a 64% training, 16% validation, and 20% testing dataset split in the fine-tuning of the final fully connected layers of the pretrained VGG19 to classify the images as malignant or benign. The performance of each of the three CAD methods were evaluated using receiver operating characteristic (ROC) analysis with area under the ROC curve (AUC) as the performance metric in the task of distinguishing between malignant and benign lesions. The performance of the radiomics CAD (AUC = 0.90) was significantly better than that of the CNN-feature-extraction (AUC = 0.84; p<0.0001), however, we failed to show a significant difference with the fine-tuning method (AUC = 0.86; p=0.1251), and thus, we conclude that transfer learning shows potential as a comparable computer-aided diagnosis technique. © 2019 SPIE.","Breast cancer; Computer-aided diagnosis; Convolutional neural network; DCE-MRI; Deep learning; Transfer learning","Biomedical signal processing; Classification (of information); Computer aided instruction; Convolution; Deep learning; Deep neural networks; Diseases; Extraction; Feature extraction; Image enhancement; Image recognition; Learning algorithms; Magnetic resonance imaging; Mammography; Medical imaging; Neural networks; Statistical tests; Support vector machines; Breast Cancer; Computer Aided Diagnosis(CAD); Convolutional neural network; DCE-MRI; Dynamic contrast enhanced MRI; Receiver operating characteristic analysis; Transfer learning; Transfer learning methods; Computer aided diagnosis","University of Chicago Medicine Comprehensive Cancer Center; National Institutes of Health, NIH, (U01CA195564); National Cancer Institute, NCI","Mori K.; Hahn H.K.","SPIE",""
"Gao F.; Gao L.; Gao J.Y.","Gao, Feng (57225898808); Gao, Liwei (57201446449); Gao, JingYang (55995325700)","57225898808; 57201446449; 55995325700","Integrated Detection of Copy Number Variation Based on the Assembly of NGS and 3GS Data","2019","11465 LNBI","","","251","260","9","10.1007/978-3-030-17938-0_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065821599&doi=10.1007%2f978-3-030-17938-0_23&partnerID=40&md5=8d0198b728a13e14e65b7c4a6fbc7fb5","The genomic coverage of copy number variations (CNVs) ranges from 5% to 10%, which is one of the essential pathogenic factors of human diseases. The detection of large CNVs is still defective. However, the read length of the third-generation sequencing (3GS) data is longer than that of the next-generation sequencing (NGS) data, which can theoretically solve the defect that the long variation can’t be detected. However, due to the low accuracy of the 3GS data, it is difficult to apply in practice. To a large extent, it is a supplement to the NGS data research. To solve these problems, we developed a new mutation detection tool named AssCNV23 in this paper. Firstly, this tool corrects the 3GS data to solve the problem of high error rate, and then combines the results of a variety of mutation detection tools to improve the accuracy of the initial mutation set and to solve the detection bias of a single detection tool. At the same time, the high-quality 3GS data was introduced by AssCNV23 to guide the NGS data to assemble, and then detects the CNV after getting enough length data. Finally, to improve the detection efficiency, the tool generates images containing the sequence depth information based on the read depth strategy and uses the convolutional neural network to detect the existing CNVs. The experimental results show that AssCNV23 guarantees a high level of breakpoint accuracy and performs well in identifying large variation. Compared with other tools, the deep learning model has advantages in accuracy and sensitivity, and Matthew correlation coefficient (MCC) performs well in various experiments. This algorithm is relatively reliable. © 2019, Springer Nature Switzerland AG.","3GS; AssCNV23; Assembly; Integrated detection; NGS","Assembly; Bioinformatics; Biomedical engineering; Deep learning; Defects; Inspection equipment; Neural networks; AssCNV23; Convolutional neural network; Copy number variations; Correlation coefficient; Detection efficiency; Integrated detection; Mutation detection; Next-generation sequencing; Image enhancement","Natural Science Foundation of Beijing Municipality, (5182018); China-Japan Friendship Hospital, CJFH, (PYBZ1834); Fundamental Research Funds for the Central Universities","Rojas F.; Rojas I.; Valenzuela O.; Ortuño F.; Ortuño F.","Springer Verlag",""
"Zemouri R.; Devalland C.; Valmary-Degano S.; Zerhouni N.","Zemouri, Ryad (6602649063); Devalland, Christine (55302491800); Valmary-Degano, Séverine (54396229200); Zerhouni, Noureddine (7003536461)","6602649063; 55302491800; 54396229200; 7003536461","Neural network: A future in pathology?; [Intelligence artificielle: quel avenir en anatomie pathologique ?]","2019","39","2","","119","129","10","10.1016/j.annpat.2019.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062234993&doi=10.1016%2fj.annpat.2019.01.004&partnerID=40&md5=78cd937d48ca9510017efb58a86f9b82","Artificial Intelligence, in particular deep neural networks are the most used machine learning technics in the biomedical field. Artificial neural networks are inspired by the biological neurons; they are interconnected and follow mathematical models. Two phases are required: a learning and a using phase. The two main applications are classification and regression Computer tools such as GPU computational accelerators or some development tools such as MATLAB libraries are used. Their application field is vast and allows the management of big data in genomics and molecular biology as well as the automated analysis of histological slides. The Whole Slide Image scanner can acquire and store slides in the form of digital images. This scanning associated with deep learning algorithms allows automatic recognition of lesions through the automatic recognition of regions of interest previously validated by the pathologist. These computer aided diagnosis techniques are tested in particular in mammary pathology and dermatopathology. They will allow an efficient and a more comprehensive vision, and will provide diagnosis assistance in pathology by correlating several biomedical data such as clinical, radiological and molecular biology data. © 2019 Elsevier Masson SAS","Artificial network; Artificial neural networks; Computer-assisted diagnosis; Digital pathology","Artificial Intelligence; Forecasting; Humans; Neural Networks, Computer; Pathology; algorithm; artificial intelligence; artificial neural network; big data; computer assisted diagnosis; data analysis software; deep learning; human; mathematical model; molecular biology; nerve cell network; pathologist; Short Survey; skin disease; forecasting; pathology; procedures","","","Elsevier Masson SAS","30773224"
"Shea C.; Mohsenin T.","Shea, Colin (55388937300); Mohsenin, Tinoosh (23668732400)","55388937300; 23668732400","Heterogeneous scheduling of deep neural networks for low-power real-time designs","2019","15","4","36","","","","10.1145/3358699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077797445&doi=10.1145%2f3358699&partnerID=40&md5=4d04d5032e7007c54b724cda2019693b","Deep neural networks have become the readiest answer to a range of application challenges including image recognition, stock analysis, natural language processing, and biomedical applications such as seizure detection. All while outperforming prior leading solutions that relied heavily on hand-engineered techniques. However, deployment of these neural networks often requires high-computational and memory-intensive solutions. These requirements make it challenging to deploy Deep Neural Networks (DNNs) in embedded, real-time low-power applications where classic architectures, GPUs and CPUs, still impose significant power burden. Systems-on-Chip (SoC) with Field-programmable Gate Arrays (FPGAs) can be used to improve performance and allow more fine-grain control of resources than CPUs or GPUs, but it is difficult to find the optimal balance between hardware and software to improve DNN efficiency. In the current research literature there have been few proposed solutions to address optimizing hardware and software deployments of DNNs in embedded low-power systems. To address the computation resource restriction and low-power needs for deploying these networks, we describe and implement a domain-specific metric model for optimizing task deployment on differing platforms, hardware and software. Next, we propose a DNN hardware accelerator called Scalable Low-power Accelerator for real-time deep neural Networks (SCALENet) that includes multithreaded software workers. Finally, we propose a heterogeneous aware scheduler that uses the DNN-specific metric models and the SCALENet accelerator to allocate a task to a resource based on solving a numerical cost for a series of domain objectives. To demonstrate the applicability of our contribution, we deploy nine modern deep network architectures, each containing a different number of parameters within the context of two different neural network applications: image processing and biomedical seizure detection. Utilizing the metric modeling techniques integrated into the heterogeneous aware scheduler and the SCALENet accelerator, we demonstrate the ability to meet computational requirements, adapt to multiple architectures, and lower power by providing an optimized task to resource allocation. Our heterogeneous aware scheduler improves power saving by decreasing power consumption by 10% of the total system power, does not affect the accuracy of the networks, and still meets the real-time deadlines. We demonstrate the ability to achieve parity with or exceed the energy efficiency of NVIDIA GPUs when evaluated against Jetson TK1 with embedded GPU SoC and with a 4× power savings in a power envelope of 2.0W. When compared to existing FPGA-based accelerators, SCALENet’s accelerator and heterogeneous aware scheduler achieves a 4.8× improvement in energy efficiency. © 2019 Copyright held by the owner/author(s).","Co-design; FPGA; Hardware; Machine learning; Real-time; Scheduling; Software","Acceleration; Computer hardware; Computer software; Embedded systems; Energy efficiency; Field programmable gate arrays (FPGA); Image processing; Image recognition; Learning algorithms; Learning systems; Low power electronics; Medical applications; Natural language processing systems; Network architecture; Program processors; Programmable logic controllers; Scheduling; System-on-chip; Biomedical applications; Co-designs; Computational requirements; Heterogeneous Scheduling; Multithreaded softwares; NAtural language processing; Neural network application; Real time; Deep neural networks","","","Association for Computing Machinery",""
"Liu Q.; Yang Q.; Cheng H.; Wang S.; Zhang M.; Liang D.","Liu, Qiegen (35339592100); Yang, Qingxin (57210568371); Cheng, Huitao (57210554391); Wang, Shanshan (36761739900); Zhang, Minghui (55704419000); Liang, Dong (58761554900)","35339592100; 57210568371; 57210554391; 36761739900; 55704419000; 58761554900","Highly undersampled magnetic resonance imaging reconstruction using autoencoding priors","2020","83","1","","322","336","14","10.1002/mrm.27921","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070862686&doi=10.1002%2fmrm.27921&partnerID=40&md5=eccd2b2921fdc006d38656efd1f229ec","Purpose: Although recent deep learning methodologies have shown promising results in fast MR imaging, how to explore it to learn an explicit prior and leverage it into the observation constraint is still desired. Methods: A denoising autoencoder (DAE) network is leveraged as an explicit prior to address the highly undersampling MR image reconstruction problem. First, inspired by the observation that the prior information learned from high-dimension signals is more effective than that from the low-dimension counterpart in image restoration tasks, we train the network in a multichannel scenario and apply the learned network to single-channel image reconstruction by a variables augmentation technique. Second, because of the fact that multiple implementations of artificial noise generation in DAE favors a better underlying result, we introduce a 2-sigma rule to complement each other for improving the final reconstruction. The whole algorithm is tackled by proximal gradient descent. Results: Experimental results under varying sampling trajectories and acceleration factors consistently demonstrate the superiority of the enhanced autoencoding priors, in terms of peak signal-to-noise ratio, structural similarity, and high-frequency error norm. Conclusion: A simple and effective way to incorporate the DAE prior into highly undersampling MR reconstruction is proposed. Once the DAE prior is obtained, it can be applied to the reconstruction tasks with different sampling trajectories and acceleration factors, and achieves superior performance in comparison with state-of-the-art methods. © 2019 International Society for Magnetic Resonance in Medicine","autoencoding priors; image reconstruction; magnetic resonance imaging; multichannel prior; proximal gradient descent","Algorithms; Brain; Computer Systems; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Signal-To-Noise Ratio; Software; Biomedical signal processing; Deep learning; Gradient methods; Learning systems; Magnetic resonance imaging; Signal to noise ratio; Augmentation techniques; autoencoding priors; Gradient descent; Multichannel; Observation constraints; Peak signal to noise ratio; State-of-the-art methods; Structural similarity; acceleration; article; image reconstruction; nuclear magnetic resonance imaging; sampling; signal noise ratio; algorithm; brain; computer system; diagnostic imaging; human; image processing; procedures; software; Image reconstruction","Basic Research Program of Shenzhen, (JCYJ20150831154213680); National Natural Science Foundation of China, NSFC, (61661031, 61871206); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Jiangxi Province, (20181BAB202003); Natural Science Foundation of Jiangxi Province","","John Wiley and Sons Inc","31429993"
"Xiong Y.; Kim H.J.; Tangirala B.; Mehta R.; Johnson S.C.; Singh V.","Xiong, Yunyang (57201315887); Kim, Hyunwoo J. (56336378000); Tangirala, Bhargav (57208928285); Mehta, Ronak (57208052169); Johnson, Sterling C. (57201598532); Singh, Vikas (58948051900)","57201315887; 56336378000; 57208928285; 57208052169; 57201598532; 58948051900","On Training Deep 3D CNN Models with Dependent Samples in Neuroimaging","2019","11492 LNCS","","","99","111","12","10.1007/978-3-030-20351-1_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066152007&doi=10.1007%2f978-3-030-20351-1_8&partnerID=40&md5=0fddc80f3f4a993499d7f0e9f72e0596","There is much interest in developing algorithms based on 3D convolutional neural networks (CNNs) for performing regression and classification with brain imaging data and more generally, with biomedical imaging data. A standard assumption in learning is that the training samples are independently drawn from the underlying distribution. In computer vision, where we have millions of training examples, this assumption is violated but the empirical performance may remain satisfactory. But in many biomedical studies with just a few hundred training examples, one often has multiple samples per participant and/or data may be curated by pooling datasets from a few different institutions. Here, the violation of the independent samples assumption turns out to be more significant, especially in small-to-medium sized datasets. Motivated by this need, we show how 3D CNNs can be modified to deal with dependent samples. We show that even with standard 3D CNNs, there is value in augmenting the network to exploit information regarding dependent samples. We present empirical results for predicting cognitive trajectories (slope and intercept) from morphometric change images derived from multiple time points. With terms which encode dependency between samples in the model, we get consistent improvements over a strong baseline which ignores such knowledge. © 2019, Springer Nature Switzerland AG.","","Brain mapping; Neural networks; Biomedical imaging; Cognitive trajectory; Convolutional neural network; Empirical performance; Independent samples; Morphometric changes; Standard assumptions; Underlying distribution; Bioinformatics","UW CPCP, (AI117924, R01 AG021155, R01 AG040396, R01 AG062336, R01 EB022883); National Science Foundation, NSF, (RI 1252725); National Science Foundation, NSF; Institute for Clinical and Translational Research, University of Wisconsin, Madison, UW ICTR, (1UL1RR025011); Institute for Clinical and Translational Research, University of Wisconsin, Madison, UW ICTR; Alzheimer’s Disease Research Center, University of Washington, ADRC, UW, (AG033514); Alzheimer’s Disease Research Center, University of Washington, ADRC, UW","Bao S.; Chung A.C.S.; Gee J.C.; Yushkevich P.A.","Springer Verlag",""
"Hao C.; Wibowo S.; Majmudar M.; Rajput K.S.","Hao, Chen (57203185920); Wibowo, Sandi (57213609704); Majmudar, Maulik (24528723200); Rajput, Kuldeep Singh (57203180099)","57203185920; 57213609704; 24528723200; 57203180099","Spectro-Temporal Feature Based Multi-Channel Convolutional Neural Network for ECG Beat Classification","2019","","","8857554","5642","5645","3","10.1109/EMBC.2019.8857554","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077896145&doi=10.1109%2fEMBC.2019.8857554&partnerID=40&md5=c3f753a7afaca27ef52dde77a33a6377","Automatic classification of abnormal beats in ECG signals is crucial for monitoring cardiac conditions and the performance of the classification will improve the success rate of the treatment. However, under certain circumstances, traditional classifiers cannot be adapted well to the variation of ECG morphologies or variation of different patients due to fixed hand-crafted features selection. Additionally, existing deep learning related solutions reach their limitation because they fail to use the beat-to-beat information together with single-beat morphologies. This paper applies a novel solution which converts one-dimensional ECG signal into spectro-temporal images and use multiple dense convolutional neural network to capture both beat-to-beat and single-beat information for analysis. The results of simulation on the MIT-BIH arrhythmias database demonstrate the effectiveness of the proposed methodology by showing an outstanding detection performance compared to other existing methods. © 2019 IEEE.","","Algorithms; Arrhythmias, Cardiac; Electrocardiography; Humans; Neural Networks, Computer; Signal Processing, Computer-Assisted; Convolution; Convolutional neural networks; Deep learning; Electrocardiography; Automatic classification; Detection performance; Ecg beat classifications; ECG morphologies; Features selection; Mit-bih arrhythmias database; Temporal features; Temporal images; algorithm; electrocardiography; heart arrhythmia; human; signal processing; Biomedical signal processing","","","Institute of Electrical and Electronics Engineers Inc.","31947133"
"Ozdemir M.A.; Degirmenci M.; Guren O.; Akan A.","Ozdemir, Mehmet Akif (57206479576); Degirmenci, Murside (57206472130); Guren, Onan (56364720900); Akan, Aydin (35617283100)","57206479576; 57206472130; 56364720900; 35617283100","EEG based emotional state estimation using 2-D deep learning technique","2019","","","8895158","","","","10.1109/TIPTEKNO.2019.8895158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075593961&doi=10.1109%2fTIPTEKNO.2019.8895158&partnerID=40&md5=2223d58d7b7a2e00509891bd95011c27","Emotion detection is very crucial role on diagnosis of brain disorders and psychological disorders. Electroencephalogram (EEG) is useful tool that obtain complex physiological brain signals from human. In this paper, we proposed a novel approach for emotional state estimation using convolutional neural network (CNN) based deep learning technique from EEG signals. Firstly, we convert 32 lead EEG signals to 2D EEG images with Azimuthal Equidistant Projection (AEP) technique. Then, 2D images that represented measurements of EEG signals sent to CNN based deep neural network for classification. In this study, we have achieved accuracy of 95.96% two classes as negative and positive valence, 96.09% two classes as high and low arousal and 95.90% two classes as high and low arousal dominance. © 2019 IEEE.","Convolutional Neural Network; EEG Images; Electroencephalogram; Emotion Detection Topographic EEG Maps","Biomedical engineering; Convolution; Deep neural networks; Learning algorithms; Neural networks; State estimation; Brain disorders; Brain signals; Convolutional neural network; Electro-encephalogram (EEG); Emotion detection; Learning techniques; Measurements of; Psychological disorders; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Le N.Q.K.; Huynh T.-T.; Yapp E.K.Y.; Yeh H.-Y.","Le, Nguyen Quoc Khanh (57208281644); Huynh, Tuan-Tu (57196947407); Yapp, Edward Kien Yee (55696875500); Yeh, Hui-Yuan (57207112031)","57208281644; 57196947407; 55696875500; 57207112031","Identification of clathrin proteins by incorporating hyperparameter optimization in deep learning and PSSM profiles","2019","177","","","81","88","7","10.1016/j.cmpb.2019.05.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065903133&doi=10.1016%2fj.cmpb.2019.05.016&partnerID=40&md5=a60b108a40a53d49c3094d1d591a362c","Background and Objectives: Clathrin is an adaptor protein that serves as the principal element of the vesicle-coating complex and is important for the membrane cleavage to dispense the invaginated vesicle from the plasma membrane. The functional loss of clathrins has been tied to a lot of human diseases, i.e., neurodegenerative disorders, cancer, Alzheimer's diseases, and so on. Therefore, creating a precise model to identify its functions is a crucial step towards understanding human diseases and designing drug targets. Methods: We present a deep learning model using a two-dimensional convolutional neural network (CNN) and position-specific scoring matrix (PSSM) profiles to identify clathrin proteins from high throughput sequences. Traditionally, the 2D CNNs take images as an input so we treated the PSSM profile with a 20 × 20 matrix as an image of 20 × 20 pixels. The input PSSM profile was then connected to our 2D CNN in which we set a variety of parameters to improve the performance of the model. Based on the 10-fold cross-validation results, hyper-parameter optimization process was employed to find the best model for our dataset. Finally, an independent dataset was used to assess the predictive ability of the current model. Results: Our model could identify clathrin proteins with sensitivity of 92.2%, specificity of 91.2%, accuracy of 91.8%, and MCC of 0.83 in the independent dataset. Compared to state-of-the-art traditional neural networks, our method achieved a significant improvement in all typical measurement metrics. Conclusions: Throughout the proposed study, we provide an effective tool for investigating clathrin proteins and our achievement could promote the use of deep learning in biomedical research. We also provide source codes and dataset freely at https://www.github.com/khanhlee/deep-clathrin/. © 2019 Elsevier B.V.","Adaptor protein complex; Clathrin coated pits; Convolutional neural network; Molecular function; Position specific scoring matrix; Vesicular transport","Algorithms; Cell Membrane; Clathrin; Deep Learning; Humans; Neural Networks, Computer; Position-Specific Scoring Matrices; Reproducibility of Results; Sensitivity and Specificity; Software; Cell membranes; Complex networks; Convolution; Neural networks; Neurodegenerative diseases; Proteins; clathrin; clathrin; Adaptor proteins; Clathrins; Convolutional neural network; Molecular function; Position specific scoring matrix; Vesicular transport; accuracy; Article; artificial neural network; controlled study; deep learning; high throughput sequencing; human; jackknife test; position weight matrix; process optimization; protein analysis; two-dimensional imaging; algorithm; cell membrane; chemistry; reproducibility; sensitivity and specificity; software; Deep learning","Nvidia; Nanyang Technological University, NTU","","Elsevier Ireland Ltd","31319963"
"Serener A.; Serte S.","Serener, Ali (6507058092); Serte, Sertan (57209738143)","6507058092; 57209738143","Transfer learning for early and advanced glaucoma detection with convolutional neural networks","2019","","","8894965","","","","10.1109/TIPTEKNO.2019.8894965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075605491&doi=10.1109%2fTIPTEKNO.2019.8894965&partnerID=40&md5=c2c8fa22d827cd5c3235dc403e26c58b","Glaucoma affects millions of people worldwide and is an eye disease that can lead to vision loss if left untreated. Open-angle glaucoma is the most common type and gradually leads to vision deterioration without many early warning signs or painful symptoms. Clinical diagnosis of glaucoma by specialists is possible but the methods used are either expensive or takes a lot of time. This paper presents automatic detection of early and advanced glaucoma using fundus images. ResNet-50 and GoogLeNet deep convolutional neural network algorithms are trained and fine-tuned using transfer learning for classification. It is shown that GoogLeNet model outperforms ResNet-50 for the detection of early as well as advanced glaucoma detection. © 2019 IEEE.","Deep learning; Fundus images; Glaucoma; Histogram equalization; Transfer learning","Biomedical engineering; Convolution; Deep learning; Deep neural networks; Deterioration; Diagnosis; Neural networks; Automatic Detection; Convolutional neural network; Early warning signs; Fundus image; Glaucoma; Histogram equalizations; Open-angle glaucoma; Transfer learning; Ophthalmology","","","Institute of Electrical and Electronics Engineers Inc.",""
"Fang Z.; Wang W.; Hou Z.-G.","Fang, Zhijie (57218573647); Wang, Weiqun (55904592500); Hou, Zeng-Guang (57218664616)","57218573647; 55904592500; 57218664616","Convolutional LSTM: A deep learning method for motion intention recognition based on spatiotemporal EEG data","2019","1142 CCIS","","","216","224","8","10.1007/978-3-030-36808-1_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089617708&doi=10.1007%2f978-3-030-36808-1_24&partnerID=40&md5=5104931306a3e6fb710881beeb53d827","Brain-Computer Interface (BCI) is a powerful technology that allows human beings to communicate with computers or to control devices. Owing to their convenient collection, non-invasive Electroencephalography (EEG) signals play an important role in BCI systems. Design of high-performance motion intention recognition algorithm based on EEG data under cross-subject and multi-category circumstances is a crucial challenge. Towards this purpose, a convolutional recurrent neural network is proposed. The raw EEG streaming is transformed into image sequence according to its location of the primary sensorimotor area to preserve its spatiotemporal features. A Convolutional Long Short-Term Memory (ConvLSTM) network is used to encode spatiotemporal information and generate a better representation from the obtained image sequence. The spatial features are then extracted from the output of ConvLSTM network by convolutional layer. The convolutional layer along with ConvLSTM network is capable of capturing the spatiotemporal features which enables the recognition of motion intention from the raw EEG signals. Experiments are carried out on the PhysioNet EEG motor imagery dataset to test the performance of the proposed method. It is shown that the proposed method can achieve high accuracy of 95.15%, which outperforms previous methods. Meanwhile, the proposed method can be used to design high-performance BCI systems, such as mind-controlled exoskeletons, prosthetic hands and rehabilitation robotics. © Springer Nature Switzerland AG 2019.","Brain-Computer Interface; Convolutional LSTM EEG; Motion intention recognition","Biomedical signal processing; Brain computer interface; Convolution; Convolutional neural networks; Deep learning; Electroencephalography; Electrophysiology; Exoskeleton (Robotics); Learning systems; Motion estimation; Network layers; Statistical tests; Learning methods; Motion intention; Motion intention recognition; Prosthetic hands; Rehabilitation robotics; Spatial features; Spatio temporal features; Spatiotemporal information; Long short-term memory","Chinese Academy of Science, (XDB32000000); National Key R&D Program of China, (2018YFC2001700); Natural Science Foundation of Beijing Municipality, (3171001, L172050)","Gedeon T.; Wong K.W.; Lee M.","Springer",""
"Ozer H.S.; Demir C.; Bilgin G.","Ozer, Hatice Sumeyye (57211992787); Demir, Ceyda (57211989675); Bilgin, Gokhan (8362224100)","57211992787; 57211989675; 8362224100","Classification of cell types on histopathological images using local binary patterns; [Histopatoloji görüntülerinde hücre tiplerinin yerel ikili örüntüler kullanilarak siniflandirmasi]","2019","","","8895252","","","","10.1109/TIPTEKNO.2019.8895252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075594535&doi=10.1109%2fTIPTEKNO.2019.8895252&partnerID=40&md5=8c54b3b9cfe9927cde5d93d7d02efdd4","In recent years, the use of computer aided diagnostic (CAD) systems has been increasing with a high acceleration in the field of digital pathology. Application and study areas are expanding over time include the detection, classification and segmentation of nuclei. In this study, various traditional machine learning methods (k-closest neighborhood, random forests and support vector machines) and deep learning (convolutional neural network) were used comparatively on CRC colorectal adenocarcinomas dataset. Since conventional machine learning algorithms do not receive a two-dimensional input such as convolutional neural network, local binary images are utilized. As a result, when the feature extraction for machine learning algorithms is performed, KNN and RF algorithms provide very successful results, whereas CNN algorithm gave better results without making any feature extraction. © 2019 IEEE.","Classification; Convolutional neural network; Hisopathological images; Local binary patterns","Binary images; Biomedical engineering; Classification (of information); Computer aided design; Convolution; Decision trees; Deep learning; Diagnosis; Extraction; Feature extraction; Image classification; Image segmentation; Machine learning; Nearest neighbor search; Neural networks; Support vector machines; Colorectal adenocarcinoma; Computer aided diagnostics; Conventional machines; Convolutional neural network; Hisopathological images; Histopathological images; Local binary patterns; Machine learning methods; Learning algorithms","","","Institute of Electrical and Electronics Engineers Inc.",""
"Mathews S.M.","Mathews, Sherin Mary (56640862000)","56640862000","Explainable Artificial Intelligence Applications in NLP, Biomedical, and Malware Classification: A Literature Review","2019","998","","","1269","1292","23","10.1007/978-3-030-22868-2_90","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069530134&doi=10.1007%2f978-3-030-22868-2_90&partnerID=40&md5=e04f92522743429e9f991d16a38f60a9","Deep learning algorithms have achieved high performance accuracy in complex domains such as image classification, face recognition sentiment analysis, text classification, and speech understanding. Due to the nested non-linear structure of deep learning algorithms, these highly successful models are usually applied in a black-box manner, i.e., no information is provided about what exactly causes them to arrive at their predictions. The effectiveness of these systems is thus limited by the machine’s current inability to explain its decisions and actions to human users. Such a lack of transparency can be a major drawback. For instance, in medical applications the development of methods for visualizing, explaining, and interpreting deep learning models has recently attracted increasing attention. Explainable Machine Learning (XAI) or Interpretable Machine Learning (IML) programs aim to create a suite of machine learning techniques that produce more explainable models while maintaining the high level of accuracy. It also enables human users to understand, appropriately trust, and effectively manage the emerging generation of artificially intelligent partners. Our work summarizes recent developments in this field, and we present three classification tasks wherein we make use of LIME (Local Interpretable Model-Agnostic Explanations) to explain predictions of deep learning models. LIME attempts to make these complex models at least partly understandable by evaluating using three classification tasks. Our first evaluation is performed on natural language processing application for tweet data classification and our second evaluation is on biomedical signal classification cancer detection. Our third evaluation is on Windows PC malware classification in a cybersecurity domain. In all three case studies, the interpreted results are presented in terms of visualization. © 2019, Springer Nature Switzerland AG.","Biomedical signal classification; Black-box models; Deep neural networks; Explainability; Explainable artificial intelligence; Explainable machine learning; Interpretability; Interpretable machine learning; Natural language processing; Sensitivity analysis; Tumor classification; Tweet classification; Windows PC malware classification","Character recognition; Classification (of information); Complex networks; Deep neural networks; Face recognition; Intelligent computing; Lime; Machine learning; Malware; Medical applications; Sensitivity analysis; Sentiment analysis; Speech recognition; Biomedical signal; Black-box model; Explainability; Interpretability; Malware classifications; NAtural language processing; Tumor classification; Learning algorithms","","Arai K.; Bhatia R.; Kapoor S.","Springer Verlag",""
"Liu C.; Wu S.; Wu S.; Wang Z.; Xiao K.","Liu, Chang (57157480800); Wu, Shaozhi (35172143800); Wu, Su (57208176651); Wang, Ziheng (57208178955); Xiao, Kai (55129739300)","57157480800; 35172143800; 57208176651; 57208178955; 55129739300","Reliable Automatic Organ Segmentation from CT Images using Deep CNN","2019","","","8859477","368","374","6","10.1109/QRS-C.2019.00075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073881185&doi=10.1109%2fQRS-C.2019.00075&partnerID=40&md5=70cd0096e99cb72ccc03fbec851b9a78","In the field of biomedical image analysis, segmentation is critical for disease diagnosis and treatment planning. While manual segmentation is tedious, time consuming and subjective due to the large shape and appearance variance among different subject, accurate and reliable segmentation is very challenging for automatic segmentation methods at the same time. In this paper, we present our recent effort on developing a reliable segmentation algorithm in the form of a convolutional neural network. Our network architecture is inspired by the popular U-Net and its variation (3D U-Net) and has been carefully modified to maximize bladder and rectum segmentation performance. We transfer our data to four channels to augment the data and prevent overfitting. The Dice similarity coefficient (DSC) is used to evaluate the network's performance. The outcome of experiments demonstrates the superiority of the proposed method. © 2019 IEEE.","CNN; CT; deep learning; Dice similarity coefficient; segmentation","C (programming language); Computer software selection and evaluation; Computerized tomography; Deep learning; Diagnosis; Network architecture; Neural networks; Software reliability; Automatic segmentations; Biomedical image analysis; Convolutional neural network; Manual segmentation; Organ segmentation; Segmentation algorithms; Segmentation performance; Similarity coefficients; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Fu J.; Dong J.; Zhao F.","Fu, Jian (57072848300); Dong, Jianbing (57211537226); Zhao, Feng (57217563254)","57072848300; 57211537226; 57217563254","A Deep Learning Reconstruction Framework for Differential Phase-Contrast Computed Tomography with Incomplete Data","2020","29","1","8879671","2190","2202","12","10.1109/TIP.2019.2947790","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077738137&doi=10.1109%2fTIP.2019.2947790&partnerID=40&md5=a06f08a84c648e176189dc69a43e4d6f","Differential phase-contrast computed tomography (DPC-CT) is a powerful analysis tool for soft-tissue and low-atomic-number samples. Limited by the implementation conditions, DPC-CT with incomplete projections happens quite often. Conventional reconstruction algorithms face difficulty when given incomplete data. They usually involve complicated parameter selection operations, which are also sensitive to noise and are time-consuming. In this paper, we report a new deep learning reconstruction framework for incomplete data DPC-CT. It involves the tight coupling of the deep learning neural network and DPC-CT reconstruction algorithm in the domain of DPC projection sinograms. The estimated result is not an artifact caused by the incomplete data, but a complete phase-contrast projection sinogram. After training, this framework is determined and can be used to reconstruct the final DPC-CT images for a given incomplete projection sinogram. Taking the sparse-view, limited-view and missing-view DPC-CT as examples, this framework is validated and demonstrated with synthetic and experimental data sets. Compared with other methods, our framework can achieve the best imaging quality at a faster speed and with fewer parameters. This work supports the application of the state-of-the-art deep learning theory in the field of DPC-CT. © 2019 IEEE.","biomedical imaging; biomedical signal processing; computed tomography (CT); Image reconstruction; reconstruction algorithms; tomography","Atoms; Bioinformatics; Biomedical signal processing; Computerized tomography; Genetic algorithms; Image reconstruction; Medical imaging; Tomography; Biomedical imaging; CT reconstruction; Differential phase contrast; Learning neural networks; Parameter selection; Reconstruction algorithms; Reconstruction frameworks; State of the art; article; artifact; artificial neural network; computer assisted tomography; controlled study; deep learning; learning theory; noise; reconstruction algorithm; velocity; Deep learning","Cancer Imaging Program; Chinese Academy of Science; TCIA; National Cancer Institute, NCI; National Natural Science Foundation of China, NSFC, (11574023, 51975026); National Natural Science Foundation of China, NSFC; Chinese Academy of Sciences, CAS, (U1432101, U1932111); Chinese Academy of Sciences, CAS; National Major Science and Technology Projects of China, (2018ZX04018001-006); National Major Science and Technology Projects of China","","Institute of Electrical and Electronics Engineers Inc.","31647435"
"Ortiz A.; Martínez Murcia F.J.; Munilla J.; Górriz J.M.; Ramírez J.","Ortiz, Andrés (18434650900); Martínez Murcia, Francisco J. (55062058300); Munilla, Jorge (25634311500); Górriz, Juan M. (7004736801); Ramírez, Javier (57191694395)","18434650900; 55062058300; 25634311500; 7004736801; 57191694395","Label aided deep ranking for the automatic diagnosis of Parkinsonian syndromes","2019","330","","","162","171","9","10.1016/j.neucom.2018.10.074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056824600&doi=10.1016%2fj.neucom.2018.10.074&partnerID=40&md5=e9f307d2e7ef41d8bc772440c9d38599","Parkinsonism is the second most common neurodegenerative disease in the world. Its diagnosis usually relies on visual analysis of Emission Computed Tomography (SPECT) images acquired using 123I−ioflupane radiotracer. This aims to detect a deficit of dopamine transporters at the striatum. The use of Computer Aided tools for diagnosis based on statistical data processing and machine learning methods have significantly improved the diagnosis accuracy. In this paper we propose a classification method based on Deep Ranking which learns an embedding function that projects the source images into a new space in which samples belonging to the same class are closer to each other, while samples from different classes are moved apart. Moreover, the proposed approach introduces a new cost-sensitive loss function to avoid overfitting due to class imbalance (an usual issue in practical biomedical applications), along with label information to produce sparser embedding spaces. The experiments carried out in this work demonstrate the superiority of the proposed method, improving the diagnosis accuracy achieved by previous methodologies and validate our approach as an efficient way to construct linear classifiers. © 2018 Elsevier B.V.","Class imbalance; Computer aided diagnosis; Cost-sensitive learning; Deep ranking; Label aided classifier; Parkinsonian syndromes","Amines; Computer aided instruction; Data handling; Learning systems; Medical applications; Neurodegenerative diseases; Single photon emission computed tomography; dopamine transporter; Biomedical applications; Class imbalance; Cost-sensitive learning; Deep ranking; Emission Computed Tomography; Machine learning methods; Parkinsonian syndromes; Statistical data processing; adult; algorithm; Article; artificial neural network; automation; computer analysis; controlled study; corpus striatum; cost benefit analysis; diagnostic test accuracy study; diagnostic value; human; machine learning; parkinsonism; priority journal; sensitivity and specificity; Computer aided diagnosis","F. Hoffman-La Roche Ltd.; MINECO/FEDER; PPMI; Abbott Laboratories; Pfizer; Genentech; Biogen Idec; GE Healthcare; F. Hoffmann-La Roche; Nvidia; Ministerio de Economía y Competitividad, MINECO; European Regional Development Fund, FEDER, (PSI2015-65848-R, TEC2015-64718-R)","","Elsevier B.V.",""
"Qayyum A.; Meriaudeau F.; Chan G.C.Y.","Qayyum, Abdul (57211138712); Meriaudeau, Fabrice (7004591575); Chan, Genevieve C Y (57200505199)","57211138712; 7004591575; 57200505199","Classification of atrial fibrillation with pretrained convolutional neural network models","2019","","","8626624","594","599","5","10.1109/IECBES.2018.8626624","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062798021&doi=10.1109%2fIECBES.2018.8626624&partnerID=40&md5=2690246934319c896f1a609ca447f2bc","Atrial Fibrillation (AF) is the most common chronic arrhythmia. Effective detection of the AF would avoid serious consequences like stroke. Conventional AF detection methods need heuristic or hand-crafted features extraction. Recently, deep learning (DL) techniques with massive data have been used on image, voice and other field widely with impressive results. The ECG rhythms such as AF, normal, Noisy and other rhythms have been segmented into 3 segments per rhythm, converted into 2D images using short time Fourier transform (STFT) and fed into pretrained models. The pre-trained CNN models are used for transfer learning or are fine tuned for the detection and classification of the AF rhythm. The features extracted from the last layer of the pre-trained models are used as input to classical classification algorithms such as Ensemble classifier and support vector machine (SVM) for AF detection. The proposed approach would be have great potential on real-time monitoring of atrial fibrillation signal in electrocardiogram. Overall, our approaches achieved accuracy, sensitivity and specificity as of 97.89%, 97.12% and 96.99% similar to the latest state of the art techniques but with more flexibility. © 2018 IEEE","AF detction; CNN models; Deep learning; ECG; Feature extraction","Biomedical engineering; Deep learning; Diseases; Electrocardiography; Extraction; Heuristic methods; Neural networks; Support vector machines; AF detction; Classification algorithm; CNN models; Convolutional neural network; Ensemble classifiers; Sensitivity and specificity; Short time Fourier transforms; State-of-the-art techniques; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.",""
"Angermann C.; Haltmeier M.","Angermann, Christoph (57212020372); Haltmeier, Markus (9839336500)","57212020372; 9839336500","Random 2.5D U-net for Fully 3D Segmentation","2019","11794 LNCS","","","158","166","8","10.1007/978-3-030-33327-0_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075715518&doi=10.1007%2f978-3-030-33327-0_19&partnerID=40&md5=1744b2daccd31a571904e1d99f5babf0","Convolutional neural networks are state-of-the-art for various segmentation tasks. While for 2D images these networks are also computationally efficient, 3D convolutions have huge storage requirements and therefore, end-to-end training is limited by GPU memory and data size. To overcome this issue, we introduce a network structure for volumetric data without 3D convolution layers. The main idea is to include projections from different directions to transform the volumetric data to a sequence of images, where each image contains information of the full data. We then apply 2D convolutions to these projection images and lift them again to volumetric data using a trainable reconstruction algorithm. The proposed architecture can be applied end-to-end to very large data volumes without cropping or sliding-window techniques. For a tested sparse binary segmentation task, it outperforms already known standard approaches and is more resistant to generation of artefacts. © 2019, Springer Nature Switzerland AG.","Biomedical imaging; Deep learning; Magnetic resonance angiography; U-net; Volumetric segmentation","Biomedical engineering; Computer aided instruction; Convolution; Deep learning; Digital storage; Machine learning; Magnetic resonance; Medical computing; Neural networks; Stents; Volumetric analysis; Biomedical imaging; Computationally efficient; Convolutional neural network; Magnetic resonance Angiography; Proposed architectures; Reconstruction algorithms; Sliding window techniques; Volumetric segmentations; Medical imaging","","Liao H.; Wang G.; Liu Y.; Ding Z.; Balocco S.; Zhang F.; Duong L.; Phellan R.; Zahnd G.; Albarqouni S.; Demirci S.; Breininger K.; Moriconi S.; Lee S.-L.","Springer",""
"Xie Q.; Tu S.; Wang G.; Lian Y.; Xu L.","Xie, Qingsong (57193491792); Tu, Shikui (26023910500); Wang, Guoxing (36515882700); Lian, Yong (7005050885); Xu, Lei (55998341800)","57193491792; 26023910500; 36515882700; 7005050885; 55998341800","Feature enrichment based convolutional neural network for heartbeat classification from electrocardiogram","2019","7","","8879514","153751","153760","9","10.1109/ACCESS.2019.2948857","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077967674&doi=10.1109%2fACCESS.2019.2948857&partnerID=40&md5=6587f09fc6863bde92d03eff0fb3aaea","Correct heartbeat classification from electrocardiogram (ECG) signals is fundamental to the diagnosis of arrhythmia. The recent advancement in deep convolutional neural network (CNN) has renewed the interest in applying deep learning techniques to improve the accuracy of heartbeat classification. So far, the results are not very exciting. Most of the existing methods are based on ECG morphological information, which makes deep learning difficult to extract discriminative features for classification. Towards an opposite direction of feature extraction or selection, this paper proceeds along a recent proposed direction named feature enrichment (FE). To exploit the advantage of deep learning, we develop a FE-CNN classifier by enriching the ECG signals into time-frequency images by discrete short-time Fourier transform and then using the images as the input to CNN. Experiments on MIT-BIH arrhythmia database show FE-CNN obtains sensitivity (Sen) of 75.6%, positive predictive rate (Ppr) of 90.1%, and F1 score of 0.82 for the detection of supraventricular ectopic (S) beats. Sen, Ppr, and F1 score are 92.8%, 94.5%, and 0.94, respectively, for ventricular ectopic (V) beat detection. The result demonstrates our method outperforms state-of-theart algorithms including other CNN based methods, without any hand-crafted features, especially F1 score for S beat detection from 0.75 to 0.82. This FE-CNN classifier is simple, effective, and easy to be applied to other types of vital signs. © 2013 IEEE.","convolutional neural network; Electrocardiogram; feature enrichment; short-time Fourier transform","Classification (of information); Computer aided diagnosis; Convolution; Deep neural networks; Diseases; Electrocardiography; Feature extraction; Neural networks; Convolutional neural network; Discrete short time fourier transforms; Discriminative features; Electrocardiogram signal; Heartbeat classifications; Morphological information; Short time Fourier transforms; Time-frequency images; Biomedical signal processing","National Natural Science Foundation of China, NSFC, (61874171); Shanghai Jiao Tong University, SJTU, (WF220103010); National Major Science and Technology Projects of China, (2018AAA0100700)","","Institute of Electrical and Electronics Engineers Inc.",""
"Halicek M.; Fabelo H.; Ortega S.; Callico G.M.; Fei B.","Halicek, Martin (56285163800); Fabelo, Himar (56405568500); Ortega, Samuel (57189334144); Callico, Gustavo M. (56006321500); Fei, Baowei (7005499116)","56285163800; 56405568500; 57189334144; 56006321500; 7005499116","In-vivo and ex-vivo tissue analysis through hyperspectral imaging techniques: Revealing the invisible features of cancer","2019","11","6","756","","","","10.3390/cancers11060756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069509747&doi=10.3390%2fcancers11060756&partnerID=40&md5=de930c3774d0c85f3c810b6b1113abf7","In contrast to conventional optical imaging modalities, hyperspectral imaging (HSI) is able to capture much more information from a certain scene, both within and beyond the visual spectral range (from 400 to 700 nm). This imaging modality is based on the principle that each material provides different responses to light reflection, absorption, and scattering across the electromagnetic spectrum. Due to these properties, it is possible to differentiate and identify the different materials/substances presented in a certain scene by their spectral signature. Over the last two decades, HSI has demonstrated potential to become a powerful tool to study and identify several diseases in the medical field, being a non-contact, non-ionizing, and a label-free imaging modality. In this review, the use of HSI as an imaging tool for the analysis and detection of cancer is presented. The basic concepts related to this technology are detailed. The most relevant, state-of-the-art studies that can be found in the literature using HSI for cancer analysis are presented and summarized, both in-vivo and ex-vivo. Lastly, we discuss the current limitations of this technology in the field of cancer detection, together with some insights into possible future steps in the improvement of this technology. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; Biomedical optical imaging; Cancer; Clinical diagnosis; Hyperspectral imaging; Machine learning; Medical diagnostic imaging","algorithm; artificial neural network; brain cancer; breast cancer; cancer diagnosis; cancer tissue; clinical feature; colon cancer; deep learning; digestive system cancer; electromagnetism; ex vivo study; head and neck cancer; human; hyperspectral imaging technique; image processing; imaging and display; in vivo study; larynx cancer; light absorption; light scattering; malignant neoplasm; nonhuman; optical spectroscopy; Review; stomach cancer; support vector machine; three dimensional imaging; tongue cancer","Conserjería de Economía, Industria, Comercio y Conocimiento; ITHACA, (ProID2017010164); National Institutes of Health, NIH, (R01CA204254, R01HL140325, R21CA176684); National Institutes of Health, NIH; National Cancer Institute, NCI, (R01CA156775); National Cancer Institute, NCI; Faculty of Science and Engineering, University of Manchester, FSE; European Social Fund, ESF; Universidad de Las Palmas de Gran Canaria, ULPGC; Agencia Canaria de Investigación, Innovación y Sociedad de la Información, ACIISI","","MDPI AG",""
"Luo Z.; Yurt A.; Stahl R.; Lambrechts A.; Reumers V.; Braeken D.; Lagae L.","Luo, Zhenxiang (57188875156); Yurt, Abdulkadir (36660203700); Stahl, Richard (56243368400); Lambrechts, Andy (23091208500); Reumers, Veerle (14060912400); Braeken, Dries (8504529000); Lagae, Liesbet (7004978233)","57188875156; 36660203700; 56243368400; 23091208500; 14060912400; 8504529000; 7004978233","Pixel super-resolution for lens-free holographic microscopy using deep learning neural networks","2019","27","10","","13581","13595","14","10.1364/OE.27.013581","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065813542&doi=10.1364%2fOE.27.013581&partnerID=40&md5=7530b67fcd915e970bc0de493b47bad7","Lens-free holographic microscopy (LFHM) provides a cost-effective tool for large field-of-view imaging in various biomedical applications. However, due to the unit optical magnification, its spatial resolution is limited by the pixel size of the imager. Pixel super-resolution (PSR) technique tackles this problem by using a series of sub-pixel shifted low-resolution (LR) lens-free holograms to form the high-resolution (HR) hologram. Conventional iterative PSR methods require a large number of measurements and a time-consuming reconstruction process, limiting the throughput of LFHM in practice. Here we report a deep learning-based PSR approach to enhance the resolution of LFHM. Compared with the existing PSR methods, our neural network-based approach outputs the HR hologram in an end-to-end fashion and maintains consistency in resolution improvement with a reduced number of LR holograms. Moreover, by exploiting the resolution degradation model in the imaging process, the network can be trained with a data set synthesized from the LR hologram itself without resorting to the HR ground truth. We validated the effectiveness and the robustness of our method by imaging various types of samples using a single network trained on an entirely different data set. This deep learning-based PSR approach can significantly accelerate both the data acquisition and the HR hologram reconstruction processes, therefore providing a practical solution to fast, lens-free, super-resolution imaging. © 2019 Optical Society of America.","","Algorithms; Holography; Image Enhancement; Machine Learning; Microscopy; Neural Networks (Computer); Cost effectiveness; Data acquisition; Deep neural networks; Electron holography; Iterative methods; Lithography; Medical applications; Optical resolving power; Pixels; Biomedical applications; Hologram reconstruction; Holographic microscopy; Learning neural networks; Network-based approach; Pixel super resolutions; Reconstruction process; Super resolution imaging; algorithm; artificial neural network; holography; image enhancement; machine learning; microscopy; procedures; Holograms","H2020 European Research Council, ERC, (617312); Agentschap Innoveren en Ondernemen, VLAIO, (IWT.150031)","","OSA - The Optical Society","31163820"
"Aubreville M.; Goncalves M.; Knipfer C.; Oetter N.; Würfl T.; Neumann H.; Stelzle F.; Bohr C.; Maier A.","Aubreville, Marc (56940880900); Goncalves, Miguel (57194557921); Knipfer, Christian (35090081500); Oetter, Nicolai (55892022000); Würfl, Tobias (57191574553); Neumann, Helmut (23100999100); Stelzle, Florian (32267673500); Bohr, Christopher (8549789900); Maier, Andreas (23392966100)","56940880900; 57194557921; 35090081500; 55892022000; 57191574553; 23100999100; 32267673500; 8549789900; 23392966100","Transferability of Deep Learning Algorithms for Malignancy Detection in Confocal Laser Endomicroscopy Images from Different Anatomical Locations of the Upper Gastrointestinal Tract","2019","1024","","","67","85","18","10.1007/978-3-030-29196-9_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071680875&doi=10.1007%2f978-3-030-29196-9_4&partnerID=40&md5=6e42cf8ead196fca62d6f17e75f31d08","Squamous Cell Carcinoma (SCC) is the most common cancer type of the epithelium and is often detected at a late stage. Besides invasive diagnosis of SCC by means of biopsy and histo-pathologic assessment, Confocal Laser Endomicroscopy (CLE) has emerged as noninvasive method that was successfully used to diagnose SCC in vivo. For interpretation of CLE images, however, extensive training is required, which limits its applicability and use in clinical practice of the method. To aid diagnosis of SCC in a broader scope, automatic detection methods have been proposed. This work compares two methods with regard to their applicability in a transfer learning sense, i.e. training on one tissue type (from one clinical team) and applying the learnt classification system to another entity (different anatomy, different clinical team). Besides a previously proposed, patch-based method based on convolutional neural networks, a novel classification method on image level (based on a pre-trained Inception V.3 network with dedicated preprocessing and interpretation of class activation maps) is proposed and evaluated. The newly presented approach improves recognition performance, yielding accuracies of 91.63% on the first data set (oral cavity) and 92.63% on a joint data set. The generalization from oral cavity to the second data set (vocal folds) lead to similar area-under-the-ROC curve values than a direct training on the vocal folds data set, indicating good generalization. © 2019, Springer Nature Switzerland AG.","Confocal Laser Endomicroscopy; Head and neck squamous cell carcinoma; Transfer learning","Biomedical engineering; Learning algorithms; Neural networks; Noninvasive medical procedures; Speech; Area under the ROC curve; Automatic detection method; Confocal laser endomicroscopy; Convolutional neural network; Head-and-neck squamous cell carcinoma; Squamous cell carcinoma; Transfer learning; Upper gastrointestinal; Deep learning","","Bermúdez i Badia S.; Cliquet A.; Wiebe S.; Zwiggelaar R.; Anderson P.; Fred A.; Gamboa H.; Saggio G.","Springer Verlag",""
"Mohseni Salehi S.S.; Khan S.; Erdogmus D.; Gholipour A.","Mohseni Salehi, Seyed Sadegh (57190744602); Khan, Shadab (57203719239); Erdogmus, Deniz (7004584113); Gholipour, Ali (57192251309)","57190744602; 57203719239; 7004584113; 57192251309","Real-Time Deep Pose Estimation With Geodesic Loss for Image-to-Template Rigid Registration","2019","38","2","8443391","470","481","11","10.1109/TMI.2018.2866442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061041708&doi=10.1109%2fTMI.2018.2866442&partnerID=40&md5=88ee12976dfbec083aaa0d4fe47e6c55","With an aim to increase the capture range and accelerate the performance of state-of-the-art inter-subject and subject-to-template 3-D rigid registration, we propose deep learning-based methods that are trained to find the 3-D position of arbitrarily-oriented subjects or anatomy in a canonical space based on slices or volumes of medical images. For this, we propose regression convolutional neural networks (CNNs) that learn to predict the angle-axis representation of 3-D rotations and translations using image features. We use and compare mean square error and geodesic loss to train regression CNNs for 3-D pose estimation used in two different scenarios: slice-to-volume registration and volume-to-volume registration. As an exemplary application, we applied the proposed methods to register arbitrarily oriented reconstructed images of fetuses scanned in-utero at a wide gestational age range to a standard atlas space. Our results show that in such registration applications that are amendable to learning, the proposed deep learning methods with geodesic loss minimization achieved 3-D pose estimation with a wide capture range in real-time (<100ms). We also tested the generalization capability of the trained CNNs on an expanded age range and on images of newborn subjects with similar and different MR image contrasts. We trained our models on T2-weighted fetal brain MRI scans and used them to predict the 3-D pose of newborn brains based on T1-weighted MRI scans. We showed that the trained models generalized well for the new domain when we performed image contrast transfer through a conditional generative adversarial network. This indicates that the domain of application of the trained deep regression CNNs can be further expanded to image modalities and contrasts other than those used in training. A combination of our proposed methods with accelerated optimization-based registration algorithms can dramatically enhance the performance of automatic imaging devices and image processing methods of the future. © 2018 IEEE.","CNN; convolutional neural network; deep learning; fetal MRI; Image registration; MRI; pose estimation","Algorithms; Brain; Databases, Factual; Deep Learning; Female; Fetus; Humans; Image Processing, Computer-Assisted; Infant, Newborn; Magnetic Resonance Imaging; Pregnancy; Convolution; Deep learning; Geodesy; Image enhancement; Image registration; Interactive computer systems; Mean square error; Medical imaging; Neural networks; Real time systems; Regression analysis; Three dimensional displays; Biomedical imaging; Convolutional neural network; Fetal MRI; Pose estimation; Predictive models; Solid model; Article; contrast enhancement; deep learning; electroencephalography; fetus; fetus brain; gestational age; human; image processing; image reconstruction; image registration; neuroimaging; nuclear magnetic resonance imaging; register; three dimensional imaging; algorithm; brain; diagnostic imaging; factual database; female; image processing; newborn; pregnancy; procedures; Magnetic resonance imaging","National Institutes of Health, NIH, (R01 EB018988); National Institute of Neurological Disorders and Stroke, NINDS, (R01NS106030); National Institute of Biomedical Imaging and Bioengineering, NIBIB; McKnight Foundation","","Institute of Electrical and Electronics Engineers Inc.","30138909"
"Mhaske D.; Rajeswari K.; Tekade R.","Mhaske, Diksha (57218177686); Rajeswari, Kannan (6601981341); Tekade, Ruchita (57193733809)","57218177686; 6601981341; 57193733809","Deep learning algorithm for classification and prediction of lung cancer using CT scan images","2019","","","9128479","","","","10.1109/ICCUBEA47591.2019.9128479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088161449&doi=10.1109%2fICCUBEA47591.2019.9128479&partnerID=40&md5=d39fb87ac5f6f9f9a0b12c33cf9fbc0b","Cancer is the second leading cause of death globally and among all the cancers, Lung cancer is considered to be the major reason for all cancer-related deaths. Detecting lung cancer at early stages can improve the survival rate, but it is a difficult task as lung cancer shows very few symptoms. To diagnose lung cancers at an earlier stage, Computed Tomography (CT) images are used. Nowadays medical decision-making is performed using only CT scan images and an automatic assessment of Computer-Aided Diagnosis (CAD) system. Computer Aided Diagnosis (CAD) system is a medical diagnosis tool that is very useful for today's medical imaging practicality. The primary aim of this work is to develop an advanced computer-aided diagnosis (CAD) system using deep learning algorithms that will efficiently extract data from CT scan images and provide precise and timely diagnosis of lung cancer. The work is divided into three phases -segmentation, feature extraction and classification. The CT scan images are segmented using (OTSU) Thresholding. This work focuses on utilizing the deep learning techniques, namely Convolutional Neural Network (CNN) for feature extraction and recurrent neural network (RNN-LSTM) for lung cancer classification and obtain high accuracy. © 2019 IEEE.","Convolutional Neural Network; CT Scan Images; Deep Learning; Lung Cancer Diagnosis; Recurrent Neural Network and Long Short Term Memory","Biological organs; Biomedical signal processing; Computer aided diagnosis; Computer aided instruction; Convolutional neural networks; Decision making; Deep learning; Diseases; Extraction; Feature extraction; Image classification; Learning algorithms; Learning systems; Long short-term memory; Medical imaging; Automatic assessment; Computer Aided Diagnosis(CAD); CT-scan images; Diagnosis of lung cancer; Feature extraction and classification; Learning techniques; Medical decision making; Survival rate; Computerized tomography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Zreik M.; Van Hamersvelt R.W.; Wolterink J.M.; Leiner T.; Viergever M.A.; Išgum I.","Zreik, Majd (45861597300); Van Hamersvelt, Robbert W. (56182844700); Wolterink, Jelmer M. (56198388700); Leiner, Tim (7004171845); Viergever, Max A. (57203030739); Išgum, Ivana (6507874503)","45861597300; 56182844700; 56198388700; 7004171845; 57203030739; 6507874503","A Recurrent CNN for Automatic Detection and Classification of Coronary Artery Plaque and Stenosis in Coronary CT Angiography","2019","38","7","8550784","1588","1598","10","10.1109/TMI.2018.2883807","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057852969&doi=10.1109%2fTMI.2018.2883807&partnerID=40&md5=caa9c053a15aaeeb296be1536745f5de","Various types of atherosclerotic plaque and varying grades of stenosis could lead to different management of patients with a coronary artery disease. Therefore, it is crucial to detect and classify the type of coronary artery plaque, as well as to detect and determine the degree of coronary artery stenosis. This paper includes retrospectively collected clinically obtained coronary CT angiography (CCTA) scans of 163 patients. In these, the centerlines of the coronary arteries were extracted and used to reconstruct multi-planar reformatted (MPR) images for the coronary arteries. To define the reference standard, the presence and the type of plaque in the coronary arteries (no plaque, non-calcified, mixed, calcified), as well as the presence and the anatomical significance of coronary stenosis (no stenosis, non-significant, i.e., <50% luminal narrowing, and significant, i.e., ≥50% luminal narrowing) were manually annotated in the MPR images by identifying the start- and end-points of the segment of the artery affected by the plaque. To perform an automatic analysis, a multi-task recurrent convolutional neural network is applied on coronary artery MPR images. First, a 3D convolutional neural network is utilized to extract features along the coronary artery. Subsequently, the extracted features are aggregated by a recurrent neural network that performs two simultaneous multi-class classification tasks. In the first task, the network detects and characterizes the type of the coronary artery plaque. In the second task, the network detects and determines the anatomical significance of the coronary artery stenosis. The network was trained and tested using the CCTA images of 98 and 65 patients, respectively. For detection and characterization of coronary plaque, the method was achieved an accuracy of 0.77. For detection of stenosis and determination of its anatomical significance, the method was achieved an accuracy of 0.80. The results demonstrate that automatic detection and classification of coronary artery plaque and stenosis are feasible. This may enable automated triage of patients to those without coronary plaque and those with coronary plaque and stenosis in need for further cardiovascular workup. © 1982-2012 IEEE.","automatic classification; coronary artery plaque; Coronary artery stenosis; coronary CT angiography; deep learning; recurrent convolutional neural network","Algorithms; Computed Tomography Angiography; Coronary Angiography; Coronary Stenosis; Coronary Vessels; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Plaque, Atherosclerotic; Angiography; Computerized tomography; Convolution; Deep learning; Diseases; Feature extraction; Flow visualization; Image segmentation; Job analysis; Medical imaging; Patient monitoring; Recurrent neural networks; iopromide; Arteries; Atherosclerosis; Automatic classification; Biomedical imaging; Convolutional neural network; Coronary arteries; Coronary artery stenosis; Coronary ct angiographies; Task analysis; adult; Article; atherosclerotic plaque; autoanalysis; computed tomographic angiography; computer assisted diagnosis; controlled study; convolutional neural network; coronary angiography; coronary artery atherosclerosis; coronary artery calcification; coronary artery circumflex branch; coronary artery obstruction; deep learning; diagnostic accuracy; disease classification; feature extraction; female; human; image analysis; image reconstruction; image segmentation; intermethod comparison; left anterior descending coronary artery; machine learning; major clinical study; male; middle aged; predictive value; retrospective study; right coronary artery; algorithm; atherosclerotic plaque; computed tomographic angiography; coronary angiography; coronary artery obstruction; coronary blood vessel; diagnostic imaging; image processing; procedures; Heart","IMDI, (104003009); Netherlands Organization for Health Research and Development; ZonMw","","Institute of Electrical and Electronics Engineers Inc.","30507498"
"Wang L.; Wang S.; Chen R.; Qu X.; Chen Y.; Huang S.; Liu C.","Wang, Liansheng (36740418500); Wang, Shuxin (57208402040); Chen, Rongzhen (57189524400); Qu, Xiaobo (22958150800); Chen, Yiping (56233739200); Huang, Shaohui (55851000700); Liu, Changhua (57092307400)","36740418500; 57208402040; 57189524400; 22958150800; 56233739200; 55851000700; 57092307400","Nested dilation networks for brain tumor segmentation based on magnetic resonance imaging","2019","13","APR","285","","","","10.3389/fnins.2019.00285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068225715&doi=10.3389%2ffnins.2019.00285&partnerID=40&md5=d457c3b5142be4b8c5426545da71ad93","Aim: Brain tumors are among the most fatal cancers worldwide. Diagnosing and manually segmenting tumors are time-consuming clinical tasks, and success strongly depends on the doctor's experience. Automatic quantitative analysis and accurate segmentation of brain tumors are greatly needed for cancer diagnosis. Methods:This paper presents an advanced three-dimensional multimodal segmentation algorithm called nested dilation networks (NDNs). It is inspired by the U-Net architecture, a convolutional neural network (CNN) developed for biomedical image segmentation and is modified to achieve better performance for brain tumor segmentation. Thus, we propose residual blocks nested with dilations (RnD) in the encoding part to enrich the low-level features and use squeeze-and-excitation (SE) blocks in both the encoding and decoding parts to boost significant features. To prove the reliability of the network structure, we compare our results with those of the standard U-Net and its transmutation networks. Different loss functions are considered to cope with class imbalance problems to maximize the brain tumor segmentation results. A cascade training strategy is employed to run NDNs for coarse-to-fine tumor segmentation. This strategy decomposes the multiclass segmentation problem into three binary segmentation problems and trains each task sequentially. Various augmentation techniques are utilized to increase the diversity of the data to avoid overfitting. Results: This approach achieves Dice similarity scores of 0.6652, 0.5880, and 0.6682 for edema, non-enhancing tumors, and enhancing tumors, respectively, in which the Dice loss is used for single-pass training. After cascade training, the Dice similarity scores rise to 0.7043, 0.5889, and 0.7206, respectively. Conclusion: Experiments show that the proposed deep learning algorithm outperforms other U-Net transmutation networks for brain tumor segmentation. Moreover, applying cascade training to NDNs facilitates better performance than other methods. The findings of this study provide considerable insight into the automatic and accurate segmentation of brain tumors. Copyright © 2019 Wang, Wang, Chen, Qu, Chen, Huang and Liu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.","Brain tumor segmentation; Coarse-to-fine; Nested dilation networks; Residual blocks nested with dilations; Squeeze-and-excitation blocks","Article; artificial neural network; brain edema; brain tumor; deep learning; diagnostic accuracy; diagnostic value; glioma; human; image processing; image segmentation; information processing; intermethod comparison; learning algorithm; multimodal imaging; nested dilation network; neuroimaging; nuclear magnetic resonance imaging; three dimensional imaging; tumor diagnosis","Dominant Disciplines’ Talent Team Development Scheme of Higher Education of Shandong Province; Scientific Research Foundation of Binzhou Medical University, (BY2016KYQD01); Taishan Scholars Construction Engineering of Shandong Province; Yantai High-End Talent Introduction Plan; National Natural Science Foundation of China, NSFC, (31870338, 61571380, 61601392, 61671399, 81602556, 81872162); Natural Science Foundation of Shandong Province, (ZR2017JL030); National Basic Research Program of China (973 Program), (2017YFC0108703); Fundamental Research Funds for the Central Universities, (20720180056)","","Frontiers Media S.A.",""
"Topiwala A.; Al-Zogbi L.; Fleiter T.; Krieger A.","Topiwala, Anirudh (57215272056); Al-Zogbi, Lidia (57209216829); Fleiter, Thorsten (6701460715); Krieger, Axel (57201238593)","57215272056; 57209216829; 6701460715; 57201238593","Adaptation and evaluation of deep learning techniques for skin segmentation on novel abdominal dataset","2019","","","8941944","752","759","7","10.1109/BIBE.2019.00141","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078574668&doi=10.1109%2fBIBE.2019.00141&partnerID=40&md5=7bc1b5319e4fee368fb934229d6ef1ce","Skin segmentation plays an important role in a wide variety of biomedical image processing applications, such as skin cancer identification, skin lesion detection, and wound isolation. However, contemporary research has been mainly based on facial and hand skin datasets, with no other body regions considered for skin pixels sampling. Segmenting skin specifically in the abdominal region can aid in robotic abdominal surgeries and treatment procedures, such as robot-assisted laparoscopic surgeries and abdominal ultrasounds. A robust and highly accurate abdominal skin detection technique thus becomes imperative. To this end, we compiled a novel dataset of 1,400 segmented abdominal pictures and adapted and compared four abdominal skin segmentation techniques: one based on thresholding and three deep learning techniques, namely a fully connected neural network for pixel-level classification, and two convolution-based networks, U-Net and Mask-RCNN. We show that the U-Net model outperforms the other segmentation techniques, resulting in a pixel-to-pixel mean cross-validation accuracy of 95.51% on our Abdominal dataset. The incorporation of the Abdominal dataset in the training helped improve the abdominal skin segmentation accuracy by 10.19%. The U-Net model proved to be computationally the fastest, enabling real time skin segmentation with a processing rate of 37 frames per second. © 2019 IEEE.","Deep Learning; Semantic Skin Dataset; Semantic Skin Segmentation","Bioinformatics; Classification (of information); Dermatology; Image segmentation; Learning algorithms; Object recognition; Pixels; Robotic surgery; Semantics; Surgery; Abdominal surgery; Biomedical images; Frames per seconds; Fully connected neural network; Laparoscopic surgery; Learning techniques; Segmentation techniques; Skin segmentation; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Saber H.; Somai M.; Rajah G.B.; Scalzo F.; Liebeskind D.S.","Saber, Hamidreza (54794505100); Somai, Melek (57208811899); Rajah, Gary B. (37079569100); Scalzo, Fabien (8935537800); Liebeskind, David S. (7004045734)","54794505100; 57208811899; 37079569100; 8935537800; 7004045734","Predictive analytics and machine learning in stroke and neurovascular medicine","2019","41","8","","681","690","9","10.1080/01616412.2019.1609159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069656854&doi=10.1080%2f01616412.2019.1609159&partnerID=40&md5=fad6c76cb15df7f12a6a5f8b94691aa0","Advances in predictive analytics and machine learning supported by an ever-increasing wealth of data and processing power are transforming almost every industry. Accuracy and precision of predictive analytics have significantly increased over the past few years and are evolving at an exponential pace. There have been significant breakthroughs in using Predictive Analytics in healthcare where it is held as the foundation of precision medicine. Yet, although the research in the field is expanding with the profuse volume of papers applying machine learning algorithms to medical data, very few have contributed meaningfully to clinical care. This lack of impact stands in stark contrast to the enormous relevance of machine learning to many other industries. Regardless of the status of its current contribution, the field of predictive analytics is expected to fundamentally change the way we diagnose and treat diseases, as well as the conduct of biomedical science research. In this review, we describe the main tools and techniques in predictive analytics and will analyze the trends in application of these techniques over the recent years. We will also provide examples of its application in medicine and more specifically in stroke and neurovascular research and outline current limitations. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","deep learning; Machine learning; neurovascular; predictive analysis","Algorithms; Cerebrovascular Disorders; Diagnosis, Computer-Assisted; Humans; Machine Learning; Neural Networks, Computer; Stroke; arteriovenous malformation; artificial intelligence; artificial neural network; brain artery aneurysm; cerebrovascular accident; cerebrovascular malformation; clinical medicine; deep learning; diagnostic accuracy; diffusion weighted imaging; health care personnel; high throughput sequencing; human; image processing; learning algorithm; machine learning; personalized medicine; positron emission tomography; principal component analysis; reinforcement; Review; semi supervised machine learning; supervised machine learning; unsupervised machine learning; whole exome sequencing; algorithm; cerebrovascular accident; cerebrovascular disease; computer assisted diagnosis; procedures","","","Taylor and Francis Ltd.","31038007"
"Jun Y.; Eo T.; Shin H.; Kim T.; Lee H.-J.; Hwang D.","Jun, Yohan (57191201833); Eo, Taejoon (56415046300); Shin, Hyungseob (57202641438); Kim, Taeseong (57218356679); Lee, Ho-Joon (36652691800); Hwang, Dosik (10039447700)","57191201833; 56415046300; 57202641438; 57218356679; 36652691800; 10039447700","Parallel imaging in time-of-flight magnetic resonance angiography using deep multistream convolutional neural networks","2019","81","6","","3840","3853","13","10.1002/mrm.27656","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060332050&doi=10.1002%2fmrm.27656&partnerID=40&md5=7890fe115382e98170e6cf061271d119","Purpose: To develop and evaluate a method of parallel imaging time-of-flight (TOF) MRA using deep multistream convolutional neural networks (CNNs). Methods: A deep parallel imaging network (“DPI-net”) was developed to reconstruct 3D multichannel MRA from undersampled data. It comprises 2 deep-learning networks: a network of multistream CNNs for extracting feature maps of multichannel images and a network of reconstruction CNNs for reconstructing images from the multistream network output feature maps. The images were evaluated using normalized root mean square error (NRMSE), peak signal-to-noise ratio (PSNR), and structural similarity (SSIM) values, and the visibility of blood vessels was assessed by measuring the vessel sharpness of middle and posterior cerebral arteries on axial maximum intensity projection (MIP) images. Vessel sharpness was compared using paired t tests, between DPI-net, 2 conventional parallel imaging methods (SAKE and ESPIRiT), and a deep-learning method (U-net). Results: DPI-net showed superior performance in reconstructing vessel signals in both axial slices and MIP images for all reduction factors. This was supported by the quantitative metrics, with DPI-net showing the lowest NRMSE, the highest PSNR and SSIM (except R = 3.8 on sagittal MIP images, and R = 5.7 on axial slices and sagittal MIP images), and significantly higher vessel sharpness values than the other methods. Conclusion: DPI-net was effective in reconstructing 3D TOF MRA from highly undersampled multichannel MR data, achieving superior performance, both quantitatively and qualitatively, over conventional parallel imaging and other deep-learning methods. © 2019 International Society for Magnetic Resonance in Medicine","deep-learning; magnetic resonance angiography; multistream network; parallel imaging; time-of-flight","Algorithms; Brain; Cerebral Angiography; Deep Learning; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Angiography; Angiography; Biomedical signal processing; Blood vessels; Convolution; Deep learning; Deep neural networks; Image reconstruction; Learning systems; Magnetic resonance; Mean square error; Signal to noise ratio; Magnetic resonance Angiography; Maximum intensity projection; Multi-stream; Parallel imaging; Parallel imaging method; Peak signal to noise ratio; Root mean square errors; Time of flight; article; controlled study; deep learning; image analysis; magnetic resonance angiography; posterior cerebral artery; quantitative analysis; signal noise ratio; visibility; algorithm; brain; brain angiography; diagnostic imaging; human; image processing; magnetic resonance angiography; procedures; vascularization; Convolutional neural networks","Ministry of Science, ICT and Future Planning, MSIP, (2016R1A2B4015016); National Research Foundation of Korea, NRF; Ministry of Science and ICT, South Korea, MSIT, (2018M3C7A1024734)","","John Wiley and Sons Inc","30666723"
"","","","3rd Conference on Information Technology, Systems Research and Computational Physics, ITSRCP 2018","2020","945","","","","","381","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065391092&partnerID=40&md5=68b8c42ac1d60fb764b344c4de8ebb27","The proceedings contain 30 papers. The special focus in this conference is on Information Technology, Systems Research and Computational Physics. The topics include: Metaheuristics in physical processes optimization; crisp vs fuzzy decision support systems for the forex market; a hybrid cascade neural network with ensembles of extended neo-fuzzy neurons and its deep learning; Recurrent neural networks with grid data quantization for modeling LHC superconducting magnets behavior; two approaches for the computational model for software usability in practice; graph cutting in image processing handling with biological data analysis; a methodology for trabecular bone microstructure modelling agreed with three-dimensional bone properties; RMID: A novel and efficient image descriptor for mammogram mass classification; instrumentals/songs separation for background music removal; fault propagation models generation in mobile telecommunications networks based on bayesian networks with principal component analysis filtering; content-based recommendations in an E-commerce platform; Generative models for fast cluster simulations in the TPC for the ALICE experiment; 2d-raman correlation spectroscopy recognizes the interaction at the carbon coating and albumin interface; effect of elastic and inelastic scattering on electronic transport in open systems; phase-space approach to time evolution of quantum states in confined systems. The spectral split-operator method; probability measures and projections on quantum logics; statistical analysis of models’ reliability for punching resistance assessment; on persistence of convergence of kernel density estimates in particle filtering; multidimensional copula models of dependencies between selected international financial market indexes; new types of decomposition integrals and computational algorithms; optimizing clustering with cuttlefish algorithm; image enhancement with applications in biomedical processing.","","","","Kóczy L.T.; Mesiar R.; Kóczy L.T.; Kulczycki P.; Kulczycki P.; Kacprzyk J.; Wisniewski R.","Springer Verlag",""
"Guzel K.; Bilgin G.","Guzel, Kadir (56780135600); Bilgin, Gokhan (8362224100)","56780135600; 8362224100","Classification of nuclei in colon cancer images using ensemble of deep learned features; [Derin öǧrenilen özellikler topluluǧu kullanarak kolon kanser görüntülerinde çekirdeklerin siniflandirilmasi]","2019","","","8895224","","","","10.1109/TIPTEKNO.2019.8895224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075620295&doi=10.1109%2fTIPTEKNO.2019.8895224&partnerID=40&md5=0133138ae0ea78f9daebf2f636106670","The classification of the cell nuclei in histopathological cancerous tissue images is a difficult problem due to the inhomogeneity of the cellular structures. In this study, ensemble learning and deep learning methods are used to reduce the difficulty of this problem. On the deep learning side, the features of histopathological images were extracted using convolution layers of convolutional neural networks. It has been suggested that these extracted features will be reduced with feature reduction methods and modeled with conventional machine learning algorithms. In order to get better results, the decisions of the learners were combined and a second proposition was made with ensemble learning. The proposed method in this study showed more robust results compared to the results of other studies in the literature. With this proposed approach, it is aimed to make more accurate analysis of cancer cell types and histopathological images. © 2019 IEEE.","Decision fusion; Deep learning; Ensemble learning; Histopathological images; Nuclei classification","Biomedical engineering; Convolution; Diseases; Image classification; Learning algorithms; Machine learning; Multilayer neural networks; Accurate analysis; Cancerous tissues; Cellular structure; Conventional machines; Convolutional neural network; Decision fusion; Ensemble learning; Histopathological images; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Nguyen T.H.","Nguyen, Thanh Hai (57209166507)","57209166507","Metagenome-Based Disease Classification with Deep Learning and Visualizations Based on Self-organizing Maps","2019","11814 LNCS","","","307","319","12","10.1007/978-3-030-35653-8_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077027605&doi=10.1007%2f978-3-030-35653-8_20&partnerID=40&md5=ed67ada433257e943c5475554e2175c6","Machine learning algorithms have recently revealed impressive results across a variety of biology and medicine domains. The applications of machine learning in bioinformatics include predicting of biological processes (for example, prediction tasks on gene function), prevention of diseases and personalized treatment. In the last decade, deep learning has gained an impressive success on a variety of problems such as speech recognition, image classification, and natural language processing. Among various methodological variants of deep learning networks, the Convolutional Neural Networks (CNN) have been extensively studied, especially in the field of image processing. Moreover, Data visualization is considered as an indispensable technique for the exploratory data analysis and becomes a key for discoveries. In this paper, a novel approach based on visualization capabilities of Self-Organizing Maps and deep learning is proposed to not only visualize metagenomic data but also leverage advances in deep learning to improve the disease prediction. Several solutions are also introduced to reduce negative affects of overlapped points to enhance the performance. The proposed approach is evaluated on six metagenomic datasets using species abundance. The results reveal that the proposed visualization not only shows improvements in the performance but also allows to visualize biomedical signatures. © 2019, Springer Nature Switzerland AG.","Convolutional Neural Network; Deep learning; Overlapped issue; Self-organizing maps; Visualization for metagenomics","Conformal mapping; Convolution; Data visualization; Deep learning; Deep neural networks; Forecasting; Image processing; Learning algorithms; Machine learning; Natural language processing systems; Network security; Security systems; Speech recognition; Visualization; Biological process; Biology and medicine; Convolutional neural network; Disease classification; Exploratory data analysis; Metagenomics; NAtural language processing; Overlapped issue; Self organizing maps","","Dang T.K.; Küng J.; Takizawa M.; Bui S.H.","Springer",""
"Basaran E.; Comert Z.; Sengur A.; Budak U.; Celik Y.; Togacar M.","Basaran, Erdal (57211453705); Comert, Zafer (36543652400); Sengur, Abdulkadir (12545159900); Budak, Umit (57189511236); Celik, Yuksel (55220314800); Togacar, Mesut (57205581917)","57211453705; 36543652400; 12545159900; 57189511236; 55220314800; 57205581917","Chronic Tympanic Membrane Diagnosis based on Deep Convolutional Neural Network","2019","","","8907070","635","638","3","10.1109/UBMK.2019.8907070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076204552&doi=10.1109%2fUBMK.2019.8907070&partnerID=40&md5=9c0b807340127fc5e09ff5ca0c09007f","Chronic Otitis Media (COM) causes deformation of the middle ear ossicles with perforation as a result of long-lasting inflammation of the middle ear and it is one of the basic reasons for hearing loss. The middle ear images are examined by otolaryngologists in the diagnosis of the disease in clinical practice. The observers make a decision considering the status of the tympanic membrane images. Decision support systems using image processing techniques and machine learning algorithms are quite useful in the diagnosis process, however, the usage of such systems in this field is limited. In this study, we propose a diagnostic model using a pretrained deep convolutional neural network (DCNN) called AlexNet. The experiments were carried out on a private dataset consisting of totally 598 tympanic membrane images collected from patients admitted to Özel Van Akdamar Hospital. Firstly, a set of preprocessing procedures were applied to the eardrum images. Then, the tympanic membrane images were used to feed the DCNN model. The proposed model was trained using transfer learning approach. To evaluate and validate the success of the proposed model, the 10-fold cross-validation method was used. As a result, the model provided satisfactory results with an accuracy of 98.77%. Consequently, the proposed DCNN model was determined as a robust tool in separating chronic and normal tympanic membrane images. © 2019 IEEE.","Biomedical signal processing; deep convolutional neural network; diagnosis system; otitis media","Audition; Biomedical signal processing; Convolution; Decision support systems; Diagnosis; Image processing; Learning algorithms; Machine learning; Membranes; Neural networks; 10-fold cross-validation; Clinical practices; Convolutional neural network; Diagnosis systems; Image processing technique; Otitis media; Transfer learning; Tympanic membranes; Deep neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Valliani A.A.-A.; Ranti D.; Oermann E.K.","Valliani, Aly Al-Amyn (57194874392); Ranti, Daniel (57210725289); Oermann, Eric Karl (23973230500)","57194874392; 57210725289; 23973230500","Deep Learning and Neurology: A Systematic Review","2019","8","2","","351","365","14","10.1007/s40120-019-00153-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071332504&doi=10.1007%2fs40120-019-00153-8&partnerID=40&md5=f67b8a7d2b124df6988fc5d0edd6968b","Deciphering the massive volume of complex electronic data that has been compiled by hospital systems over the past decades has the potential to revolutionize modern medicine, as well as present significant challenges. Deep learning is uniquely suited to address these challenges, and recent advances in techniques and hardware have poised the field of medical machine learning for transformational growth. The clinical neurosciences are particularly well positioned to benefit from these advances given the subtle presentation of symptoms typical of neurologic disease. Here we review the various domains in which deep learning algorithms have already provided impetus for change—areas such as medical image analysis for the improved diagnosis of Alzheimer’s disease and the early detection of acute neurologic events; medical image segmentation for quantitative evaluation of neuroanatomy and vasculature; connectome mapping for the diagnosis of Alzheimer’s, autism spectrum disorder, and attention deficit hyperactivity disorder; and mining of microscopic electroencephalogram signals and granular genetic signatures. We additionally note important challenges in the integration of deep learning tools in the clinical setting and discuss the barriers to tackling the challenges that currently exist. © 2019, The Author(s).","Artificial intelligence; Biomedical informatics; Computer vision; Connectome mapping; Deep learning; Genomics; Machine learning; Neurology; Neuroscience","fluorodeoxyglucose f 18; algorithm; Alzheimer disease; artificial intelligence; attention deficit disorder; autism; brain hemorrhage; computer assisted tomography; computer model; connectome; convolutional neural network; deep learning; electroencephalography; functional connectivity; functional magnetic resonance imaging; human; image analysis; image segmentation; mild cognitive impairment; neuroanatomy; neurology; perivascular space; positron emission tomography; priority journal; Review; seizure; systematic review; white matter","meet","","Adis",""
"Zuluaga-Gomez J.; Zerhouni N.; Al Masry Z.; Devalland C.; Varnier C.","Zuluaga-Gomez, J. (57211262590); Zerhouni, N. (7003536461); Al Masry, Z. (56989876800); Devalland, C. (55302491800); Varnier, C. (6602100261)","57211262590; 7003536461; 56989876800; 55302491800; 6602100261","A survey of breast cancer screening techniques: thermography and electrical impedance tomography","2019","43","5","","305","322","17","10.1080/03091902.2019.1664672","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073182556&doi=10.1080%2f03091902.2019.1664672&partnerID=40&md5=99feb090e4db6b6f0472b85361e99cdc","Breast cancer is a disease that threat many women’s life, thus, the early and accurate detection play a key role in reducing the mortality rate. Mammography stands as the reference technique for breast cancer screening; nevertheless, many countries still lack access to mammograms due to economic, social and cultural issues. Last advances in computational tools, infra-red cameras and devices for bio-impedance quantification allowed the development of parallel techniques like, thermography, infra-red imaging and electrical impedance tomography, these being faster, reliable and cheaper. In the last decades, these have been considered as complement procedures for breast cancer diagnosis, where many studies concluded that false positive and false negative rates are greatly reduced. This work aims to review the last breakthroughs about the three above-mentioned techniques describing the benefits of mixing several computational skills to obtain a better global performance. In addition, we provide a comparison between several machine learning techniques applied to breast cancer diagnosis going from logistic regression, decision trees and random forest to artificial, deep and convolutional neural networks. Finally, it is mentioned several recommendations for 3D breast simulations, pre-processing techniques, biomedical devices in the research field, prediction of tumour location and size. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Breast cancer; computer aided diagnosis; electrical impedance tomography; machine learning techniques; thermography","Breast Neoplasms; Early Detection of Cancer; Electric Impedance; Female; Humans; Thermography; Tomography; Bioinformatics; Computer aided diagnosis; Computer aided instruction; Decision trees; Diagnostic radiography; Diseases; Electric impedance; Electric impedance measurement; Electric impedance tomography; Learning algorithms; Machine learning; Neural networks; Thermography (temperature measurement); Breast Cancer; Breast cancer diagnosis; Breast cancer screening; Convolutional neural network; Electrical impedance tomography; False positive and false negatives; Logistic regressions; Machine learning techniques; artificial neural network; breast cancer; cancer screening; clinical protocol; computer assisted diagnosis; computer assisted impedance tomography; computer simulation; convolutional neural network; decision tree; diagnostic accuracy; early cancer diagnosis; health care access; human; image processing; machine learning; predictive value; priority journal; random forest; receiver operating characteristic; Review; sensitivity and specificity; thermography; three dimensional imaging; tumor localization; tumor volume; breast tumor; female; impedance; procedures; thermography; tomography; Thermography (imaging)","","","Taylor and Francis Ltd","31545114"
"Vizitiu A.; Puiu A.; Reaungamornrat S.; Itu L.M.","Vizitiu, Anamaria (56544506000); Puiu, Andrei (57210861398); Reaungamornrat, Sureerat (35074959000); Itu, Lucian Mihai (36349647600)","56544506000; 57210861398; 35074959000; 36349647600","Data-driven adversarial learning for sinogram-based iterative low-dose CT image reconstruction","2019","","","8885947","668","674","6","10.1109/ICSTCC.2019.8885947","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075085305&doi=10.1109%2fICSTCC.2019.8885947&partnerID=40&md5=3177ac02624d65a6fe29e41995786431","One of the most active research areas in computed tomography (CT) is to devise a strategy to reduce radiation exposure, while maintaining high image quality, required for accurate diagnosis. The recent advancements offered by deep learning based data-driven approaches for solving inverse problems in biomedical imaging have led to the development of an alternative method for producing high-quality reconstructed images from low-dose CT data. While most of the reconstruction approaches tackle the problem from a post-processing perspective, in this paper, inspired by the idea of unfolding a proximal gradient descent optimization algorithm to finite iterations, and replacing the proximal terms with trainable deep artificial neural networks, we propose an end-to-end solution for reconstructing full-dose tomographic images directly from low-dose measurements. The framework is designed to encapsulate the knowledge of the physical model of CT image formation, and to produce high-quality images that account for human perception through a Generative Adversarial Network with Wasserstein distance and a contextual loss. The proposed method was validated on a clinical dataset, and promising results have been obtained compared to the state-of-the-art mean-squared-error (MSE) based learned iterative reconstruction approach, while also maintaining a runtime suitable for a routine clinical setting. © 2019 IEEE.","CT imaging; Deep learning; Reconstruction","Computation theory; Computerized tomography; Deep learning; Gradient methods; Inverse problems; Mean square error; Medical imaging; Neural networks; System theory; Adversarial learning; Adversarial networks; CT imaging; Data-driven approach; End-to-end solutions; Gradient descent optimization; Iterative reconstruction; Wasserstein distance; Image reconstruction","Ministery of Research and Innovation; Corporation for National and Community Service, CNCS; Unitatea Executiva pentru Finantarea Invatamantului Superior, a Cercetarii, Dezvoltarii si Inovarii, UEFISCDI, (PN-III-P1-1.1-PD-2016-0320)","Precup R.-E.","Institute of Electrical and Electronics Engineers Inc.",""
"von Chamier L.; Laine R.F.; Henriques R.","von Chamier, Lucas (57188593653); Laine, Romain F. (56545241500); Henriques, Ricardo (30067763700)","57188593653; 56545241500; 30067763700","Artificial intelligence for microscopy: What you should know","2019","47","4","","1029","1040","11","10.1042/BST20180391","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071710951&doi=10.1042%2fBST20180391&partnerID=40&md5=b5e342348a1cc791b8fdc65ee6c575ca","Artificial Intelligence based on Deep Learning (DL) is opening new horizons in biomedical research and promises to revolutionize the microscopy field. It is now transitioning from the hands of experts in computer sciences to biomedical researchers. Here, we introduce recent developments in DL applied to microscopy, in a manner accessible to non-experts. We give an overview of its concepts, capabilities and limitations, presenting applications in image segmentation, classification and restoration. We discuss how DL shows an outstanding potential to push the limits of microscopy, enhancing resolution, signal and information content in acquired data. Its pitfalls are discussed, along with the future directions expected in this field. © 2019 The Author(s).","","Algorithms; Artificial Intelligence; Microscopy; Neural Networks, Computer; article; artificial intelligence; deep learning; human; image segmentation; microscopy; algorithm; microscopy; procedures","UK Medical Research Council, (MR/K015826/1); Wellcome Trust, WT, (203276/Z/16/Z); Wellcome Trust, WT; Medical Research Council, MRC; Biotechnology and Biological Sciences Research Council, BBSRC, (BB/ M022374/1, BB/P027431/1, BB/R000697/1, BB/S507532/1); Biotechnology and Biological Sciences Research Council, BBSRC; University College London, UCL, (MC_UU12018/7); University College London, UCL; University of Toronto, UofT","","Portland Press Ltd","31366471"
"Costa A.C.; Oliveira H.C.R.; Catani J.H.; de Barros N.; Melo C.F.E.; Vieira M.A.C.","Costa, Arthur C. (57209657897); Oliveira, Helder C. R. (56902289200); Catani, Juliana H. (57194471302); de Barros, Nestor (57212628459); Melo, Carlos F. E. (57194469544); Vieira, Marcelo A. C. (57209584734)","57209657897; 56902289200; 57194471302; 57212628459; 57194469544; 57209584734","Detection of Architectural Distortion with Deep Convolutional Neural Network and Data Augmentation of Limited Dataset","2019","70","","","155","159","4","10.1007/978-981-13-2517-5_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086145703&doi=10.1007%2f978-981-13-2517-5_24&partnerID=40&md5=91735a3e5705c9818e913d0025eaa62d","Early detection of breast cancer can increase treatment efficiency. One of the earliest signs of breast cancer is the Architectural Distortion (AD), which is a subtle contraction of the breast tissue, most of the time unnoticeable. A lot of techniques have been proposed over the years to aid the detection of AD in digital mammography but only a few using a deep learning approach. One of the most successful algorithms of deep neural architecture are the Convolutional Neural Networks (CNNs). However, to assure better CNN performance, the training step requires a large volume of data. This paper presents a deep CNN architecture designed for the automatic detection of AD in digital mammography images. For the training step, we considered the data augmentation approach, to overcome the limitation of clinical dataset. CNN performance was evaluated in terms of Receiver Operating Characteristic (ROC). The measured area under the ROC curve (AUC) was 0.87 for the proposed CNN in the task of AD detection in digital mammography. © 2019, Springer Nature Singapore Pte Ltd.","Architectural distortion; Breast cancer; Convolutional neural network; Deep learning; Digital mammography","Biomedical engineering; Convolution; Deep learning; Deep neural networks; Diseases; Mammography; Network architecture; Architectural distortions; Area under the ROC curve; Automatic Detection; Digital mammography; Early detection of breast cancer; Neural architectures; Receiver operating characteristics; Treatment efficiency; Convolutional neural networks","Nvidia; Fundação de Amparo à Pesquisa do Estado de São Paulo, FAPESP, (2015=20812 5); Coordenação de Aperfeiçoamento de Pessoal de Nível Superior, CAPES; Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq","Costa-Felix R.; Alvarenga A.V.; Machado J.C.","Springer",""
"Ma Y.; Xu T.; Huang X.; Wang X.; Li C.; Jerwick J.; Ning Y.; Zeng X.; Wang B.; Wang Y.; Zhang Z.; Zhang X.; Zhou C.","Ma, Yutao (55687210800); Xu, Tao (56465290800); Huang, Xiaolei (57218604182); Wang, Xiaofang (55736852800); Li, Canyu (57201985369); Jerwick, Jason (57189310283); Ning, Yuan (57201985499); Zeng, Xianxu (55674979900); Wang, Baojin (57193131530); Wang, Yihong (57199651474); Zhang, Zhan (9039114500); Zhang, Xiaoan (57218444961); Zhou, Chao (8352448200)","55687210800; 56465290800; 57218604182; 55736852800; 57201985369; 57189310283; 57201985499; 55674979900; 57193131530; 57199651474; 9039114500; 57218444961; 8352448200","Computer-Aided Diagnosis of Label-Free 3-D Optical Coherence Microscopy Images of Human Cervical Tissue","2019","66","9","","2447","2456","9","10.1109/TBME.2018.2890167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059619299&doi=10.1109%2fTBME.2018.2890167&partnerID=40&md5=986a44f2c65d95dfff7a6b5b8fd4cf5e","Objective: Ultrahigh-resolution optical coherence microscopy (OCM) has recently demonstrated its potential for accurate diagnosis of human cervical diseases. One major challenge for clinical adoption, however, is the steep learning curve clinicians need to overcome to interpret OCM images. Developing an intelligent technique for computer-aided diagnosis (CADx) to accurately interpret OCM images will facilitate clinical adoption of the technology and improve patient care. Methods: 497 high-resolution three-dimensional (3-D) OCM volumes (600 cross-sectional images each) were collected from 159 ex vivo specimens of 92 female patients. OCM image features were extracted using a convolutional neural network (CNN) model, concatenated with patient information [e.g., age and human papillomavirus (HPV) results], and classified using a support vector machine classifier. Ten-fold cross-validations were utilized to test the performance of the CADx method in a five-class classification task and a binary classification task. Results: An 88.3 ± 4.9% classification accuracy was achieved for five fine-grained classes of cervical tissue, namely normal, ectropion, low-grade and high-grade squamous intraepithelial lesions (LSIL and HSIL), and cancer. In the binary classification task [low-risk (normal, ectropion, and LSIL) versus high-risk (HSIL and cancer)], the CADx method achieved an area-under-the-curve value of 0.959 with an 86.7 ± 11.4% sensitivity and 93.5 ± 3.8% specificity. Conclusion: The proposed deep-learning-based CADx method outperformed four human experts. It was also able to identify morphological characteristics in OCM images that were consistent with histopathological interpretations. Significance: Label-free OCM imaging, combined with deep-learning-based CADx methods, holds a great promise to be used in clinical settings for the effective screening and diagnosis of cervical diseases. © 2019 IEEE Computer Society. All rights reserved.","Cervical cancer; computer-aided diagnosis; deep learning; optical coherence microscopy; optical coherence tomography","Algorithms; Cervix Uteri; Deep Learning; Female; Humans; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Microscopy; Tomography, Optical Coherence; Uterine Cervical Diseases; Classification (of information); Computer aided instruction; Deep learning; Diseases; Image enhancement; Medical imaging; Neural networks; Optical tomography; Tissue; Biomedical imaging; Cervical cancers; Classification tasks; Deep learning; Features extraction; Label free; Lesion; Microscopy images; Optical coherence microscopy; algorithm; computer assisted diagnosis; diagnostic imaging; female; human; microscopy; optical coherence tomography; procedures; three-dimensional imaging; uterine cervix; uterine cervix disease; Computer aided diagnosis","Henan Province Medical Technology Challenger Program, (SBGJ2018050); Medical Science and Technology projects of China, (161100311100, 201503117); National Science Foundation, NSF, (DBI-1455613); National Science Foundation, NSF; National Institutes of Health, NIH, (R01-EB025209); National Institutes of Health, NIH; National Institute of Biomedical Imaging and Bioengineering, NIBIB, (K99EB010071); National Institute of Biomedical Imaging and Bioengineering, NIBIB; Lehigh University; National Key Research and Development Program of China, NKRDPC, (2014CB340404); National Key Research and Development Program of China, NKRDPC","","IEEE Computer Society","30605087"
"Serener A.; Serte S.","Serener, Ali (6507058092); Serte, Sertan (57209738143)","6507058092; 57209738143","Dry and wet age-related macular degeneration classification using OCT images and deep learning","2019","","","8741768","","","","10.1109/EBBT.2019.8741768","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068574197&doi=10.1109%2fEBBT.2019.8741768&partnerID=40&md5=06e739975e7518237b1ca4e37c0184a9","Diabetic retinopathy (DR) and age-related macular degeneration (AMD) are diseases that can have adverse effects on the eyes of the elderly. They affect the central part of the retina, called macula. Depending on the severity, they might require urgent eye care and the treatment varies according to the specific case. In this paper, automated and fast classification of dry and wet AMD using deep convolutional neural networks is proposed. It is important that both dry and wet types are accurately detected for timely treatment. It is shown here through the performance results of the deep neural networks that dry vision impairment can be detected more accurately than wet. It is further shown that eighteen layer ResNet model outperforms AlexNet model in classifications. The area under the receiver operating characteristic curve of the ResNet model for each AMD stage is 94% and 63%, respectively. © 2019 IEEE.","Age-Related Macular Degeneration; Convolutional Neural Network; Deep Learning; Machine Learning; OCT images","Biomedical engineering; Convolution; Deep learning; Electronic medical equipment; Eye protection; Image classification; Learning algorithms; Learning systems; Neural networks; Ophthalmology; Adverse effect; Age-related macular degeneration; Convolutional neural network; Diabetic retinopathy; Fast classification; OCT images; Receiver operating characteristic curves; Vision impairments; Deep neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Tang W.; Wu G.; Shen G.","Tang, Wei (57214796497); Wu, Gang (56150085000); Shen, Gang (54386029200)","57214796497; 56150085000; 54386029200","Improved Automatic Radiographic Bone Age Prediction with Deep Transfer Learning","2019","","","8965906","","","","10.1109/CISP-BMEI48845.2019.8965906","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079145875&doi=10.1109%2fCISP-BMEI48845.2019.8965906&partnerID=40&md5=cc0e8fbd5c28c85c2418483dc6788e9d","Radiograph based pediatric bone age assessment plays a key role in many medical and judiciary tasks. The traditional bone age identification techniques, such as GP method and TW scoring, rely on human experts to compare X-ray image of the hand skeleton with the standard atlas and visually examine the similarities, thus impacted by an individual's experience and judgment. The recent advances of deep neural networks (DNN) have made possible more accurate bone age estimation with the help of computer vision representation and understanding. DNNs usually demands large scale annotated image datasets for training, but this is not guaranteed for bone age estimation because of the incurred cost and the concerns of privacy protection. In this paper, we report our work of developing a convolutional neural network (CNN) based bone age classifier and transferring the low level hand radiograph features learned from the Radiological Society of North America (RSNA) dataset to the small dataset collected from a local hospital. The first few layers of the proposed network are treated as the feature extractors while the remaining parts are further fine-tuned to improve the transfer performance. The experiment results show that the proposed transfer learning framework achieves a mean absolute difference (MAD) of 0.16 years, outperforming other state-of-the-art algorithms. © 2019 IEEE.","Bone age; Deep neural networks; Transfer learning","Biomedical engineering; Classification (of information); Convolutional neural networks; Deep neural networks; Large dataset; Transfer learning; X ray radiography; Bone age; Bone age assessment; Identification techniques; Learning frameworks; Mean absolute differences; Privacy protection; State-of-the-art algorithms; Transfer performance; Deep learning","","Li Q.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"Long Z.; Feng P.; He P.; Wu X.; Guo X.; Ren X.; Chen M.; Gao J.; Wei B.; Cong W.","Long, Zourong (57202959235); Feng, Peng (8903298300); He, Peng (55226397500); Wu, Xiaochuan (57207327085); Guo, Xiaodong (57209254578); Ren, Xuezhi (57209741047); Chen, Mianyi (55960472400); Gao, Jingxuan (57213164851); Wei, Biao (7202263625); Cong, Wenxiang (7005402309)","57202959235; 8903298300; 55226397500; 57207327085; 57209254578; 57209741047; 55960472400; 57213164851; 7202263625; 7005402309","Fully Convolutional Pyramidal Residual Network for Material Discrimination of Spectral CT","2019","7","","8903314","167187","167194","7","10.1109/ACCESS.2019.2953942","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077619517&doi=10.1109%2fACCESS.2019.2953942&partnerID=40&md5=be9d4523ef17145bae5f7a21e957f9e9","The spectral computed tomography (CT) based on photon-counting detector performs energy-dependent image reconstruction of material attenuation coefficients, allowing for effective medical diagnosis and material discrimination. However, the spectral CT image quality is degraded in narrow energy bins as a consequence of low photon counts. Thus the edge information of some materials with similar attenuation cannot be well identified. To improve the accuracy of material discrimination of spectral CT, we proposed a deep-learning-based material discrimination method based on Fully Convolutional Pyramidal Residual Network (FC-PRNet). The FC-PRNet model can predict each pixel of spectral CT images and extract more edge information for different material components. We evaluated our method using mouse spectral CT data set, and experimental results demonstrated that the proposed method could efficiently discriminate different materials compared with traditional method based on post-reconstruction. Moreover, our algorithm has fewer parameters, faster convergent speed and higher accuracy, and achieves better quality of material discrimination than SegNet, FCN-8s and U-Net. © 2013 IEEE.","artificial neural networks; Biomedical computing; image segmentation; multispectral imaging","Convolution; Deep learning; Diagnosis; Discriminators; Image reconstruction; Image segmentation; Medical imaging; Neural networks; Photons; Attenuation coefficient; Biomedical computing; Material components; Material discrimination; Multispectral imaging; Photon counting detectors; Quality of materials; Spectral computed tomographies; Computerized tomography","ICT NDT Engineering Research Center Fund of Chongqing University; Scientific Project of Chongqing Technology and Business Institute, (NDZD2019-02); Nvidia; National Natural Science Foundation of China, NSFC, (11605017, 61401049); National Natural Science Foundation of China, NSFC; Chongqing Municipal Education Commission, CQMEC, (KJQN201904007); Chongqing Municipal Education Commission, CQMEC; National Basic Research Program of China (973 Program), (2016YFC0104609, 2019YFC0605203); National Basic Research Program of China (973 Program); Fundamental Research Funds for the Central Universities, (2018CDGFGD0008, 2019CDYGYB019); Fundamental Research Funds for the Central Universities; Jilin Scientific and Technological Development Program","","Institute of Electrical and Electronics Engineers Inc.",""
"Thanati H.; Chalakkal R.J.; Abdulla W.H.","Thanati, Haneesha (57208821488); Chalakkal, Renoh Johnson (57204427329); Abdulla, Waleed H. (7005050351)","57208821488; 57204427329; 7005050351","On deep learning based algorithms for detection of diabetic retinopathy","2019","","","8706431","","","","10.23919/ELINFOCOM.2019.8706431","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065886983&doi=10.23919%2fELINFOCOM.2019.8706431&partnerID=40&md5=475bfa57e32236ccf5f3584577f6f1d6","Diabetic retinopathy (DR) is one of the leading causes of avertible blindness worldwide. Early detection of the disease can help to save the vision of diabetic patients. Presence of exudates, hemorrhages, and microaneurysms indicate an unhealthy eye image. Deep learning models have triumphed in image recognition, object detection and biomedical signal classification. Convolution neural network based DR detection techniques are fast evolving and can identify complex features and thus can accurately classify even severe cases. The presented paper investigates the recent work done in diabetic retinopathy detection using deep learning and collating the milestones achieved to guide researchers working in this domain to the future trend. © 2019 Institute of Electronics and Information Engineers (IEIE).","Convolutional neural networks; Deep learning; Diabetic retinopathy; Machine learning; Review","Convolution; Eye protection; Image recognition; Learning systems; Neural networks; Object detection; Reviews; Biomedical signal; Convolution neural network; Convolutional neural network; Diabetic patient; Diabetic retinopathy; Learning models; Learning-based algorithms; Microaneurysms; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Ragab D.A.; Sharkas M.; Marshall S.; Ren J.","Ragab, Dina A. (54984568000); Sharkas, Maha (11539610200); Marshall, Stephen (7401823400); Ren, Jinchang (23398632100)","54984568000; 11539610200; 7401823400; 23398632100","Breast cancer detection using deep convolutional neural networks and support vector machines","2019","2019","1","e6201","","","","10.7717/peerj.6201","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061392228&doi=10.7717%2fpeerj.6201&partnerID=40&md5=cbd7b7f1db91e40f19deea5182c31373","It is important to detect breast cancer as early as possible. In this manuscript, a new methodology for classifying breast cancer using deep learning and some segmentation techniques are introduced. A new computer aided detection (CAD) system is proposed for classifying benign and malignant mass tumors in breast mammography images. In this CAD system, two segmentation approaches are used. The first approach involves determining the region of interest (ROI) manually, while the second approach uses the technique of threshold and region based. The deep convolutional neural network (DCNN) is used for feature extraction. A well-known DCNN architecture named AlexNet is used and is fine-tuned to classify two classes instead of 1,000 classes. The last fully connected (fc) layer is connected to the support vector machine (SVM) classifier to obtain better accuracy. The results are obtained using the following publicly available datasets (1) the digital database for screening mammography (DDSM); and (2) the Curated Breast Imaging Subset of DDSM (CBIS-DDSM). Training on a large number of data gives high accuracy rate. Nevertheless, the biomedical datasets contain a relatively small number of samples due to limited patient volume. Accordingly, data augmentation is a method for increasing the size of the input data by generating new data from the original input data. There are many forms for the data augmentation; the one used here is the rotation. The accuracy of the new-trained DCNN architecture is 71.01% when cropping the ROI manually from the mammogram. The highest area under the curve (AUC) achieved was 0.88 (88%) for the samples obtained from both segmentation techniques. Moreover, when using the samples obtained from the CBIS- DDSM, the accuracy of the DCNN is increased to 73.6%. Consequently, the SVM accuracy becomes 87.2% with an AUC equaling to 0.94 (94%). This is the highest AUC value compared to previous work using the same conditions. © 2019 Ragab et al.","The computer aided detection; The deep convolutional neural network; The support vector machine","algorithm; area under the curve; Article; artificial neural network; breast cancer; cancer diagnosis; cancer screening; curated breast imaging subset; deep convolutional neural network; diagnostic accuracy; diagnostic test accuracy study; digital breast tomosynthesis; disease classification; human; image segmentation; imaging; receiver operating characteristic; sensitivity and specificity; support vector machine; training; transfer of learning","","","PeerJ Inc.",""
"Panganiban E.B.; Chung W.-Y.; Tai W.-C.; Paglinawan A.C.; Lai J.-S.; Cheng R.-W.; Chang M.-K.; Chang P.-H.","Panganiban, Edward B. (57201298762); Chung, Wen-Yaw (56675168200); Tai, Wei-Chieh (55364741400); Paglinawan, Arnold C. (24172624800); Lai, Jheng-Siang (57212048649); Cheng, Ren-Wei (57212048842); Chang, Ming-Kai (57212048608); Chang, Po-Hsuan (57224563954)","57201298762; 56675168200; 55364741400; 24172624800; 57212048649; 57212048842; 57212048608; 57224563954","Real-Time Intelligent Healthcare Monitoring and Diagnosis System Through Deep Learning and Segmented Analysis","2020","74","","","15","25","10","10.1007/978-3-030-30636-6_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075811102&doi=10.1007%2f978-3-030-30636-6_3&partnerID=40&md5=f7fcd3aa8194706fad59194fe170cbfa","Medical facilities and technologies have been greatly improved through the application of biosensors, healthcare systems, health diagnosis and disease prevention technologies. However, wireless transmission and deep learning neural network are essential applications and new methods in biomedical engineering nowadays. Hence, authors established a new real-time and intelligent healthcare system that will help the physician’s diagnosis over the patient’s condition and will have a great contribution to medical research. Physiological conditions can be monitored and primary diagnosis will be determined which will help people primarily for personal health care. This paper focused on the collection, transmission, and analysis of physiological signals captured from biosensors with the application of deep learning and segmented analysis for the prediction of heart diseases. Biosensors employed were non-invasive composed of infrared body temperature sensor (MLX90614), heart rate and blood oxygen sensor (MAX30100) and ECG sensor (AD8232). This research used these biosensors to collect signals integrated with Arduino UNO as a central module to process and analyze those signals. ESP8266 Wi-Fi microchip was used to transmit digitized result signals to the database for deep learning analysis. The first segment of deep learning analysis is the Long-Short Term Memory (LSTM) network applied for the temperature, heart rate and arterial oxygen saturation prediction. A rolled training technique was used to provide accurate predictions in this segment. The second segment used was the Convolutional Neural Network (CNN), which comprises three hidden layers to analyze the ECG signals from the image datasets. Deep learning tools used were the powerful python language, python based Anaconda, Google’s TensorFlow and open source neural network library Keras. The algorithm was used for evaluation using the available MIT-BIH ECG database from Physionet databases which attained 99.05% accuracy and arrived at only 4.96% loss rate after 30 training steps. The implementation of the system is comprised of physiological parameter sensing system, the wireless transmission system and the deep neural network prediction system. User interfaces were also developed such as the LCD display which shows values of body temperature, heart rate and arterial oxygen saturation level. Web page and app were created to allow users or doctors for visual presentations of the results of analysis. The webpage contains information about the system, deep learning networks used, biosensors and the historical graph of about the patient’s body temperature, heart rate and oxygen saturation. It also indicates the normal ranges of the physiological parameters. © 2020, Springer Nature Switzerland AG.","Biosensors; CNN; Deep learning; LSTM; Physiological signals","Biomedical engineering; Biosensors; Convolutional neural networks; Database systems; Deep neural networks; Electrocardiography; Engineering education; Forecasting; Health care; Heart; High level languages; Image segmentation; Learning systems; Liquid crystal displays; Long short-term memory; Medical informatics; Multilayer neural networks; Physiological models; Security of data; Signal analysis; User interfaces; Websites; Disease prevention technologies; Learning neural networks; LSTM; Neural network predictions; Oxygen saturation levels; Physiological signals; Prediction of heart disease; Wireless transmission systems; Deep learning","Chung Yuan Christian University, CYCU","Lin K.-P.; Magjarevic R.; de Carvalho P.","Springer Science and Business Media Deutschland GmbH",""
"Jangra M.; Dhull S.K.; Singh K.K.","Jangra, Manisha (57204953949); Dhull, Sanjeev Kr. (54962357600); Singh, Krishna Kant (55265360800)","57204953949; 54962357600; 55265360800","ECG arrhythmia classification using modified visual geometry group network (mVGGNet)","2020","38","3","","3151","3165","14","10.3233/JIFS-191135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081601166&doi=10.3233%2fJIFS-191135&partnerID=40&md5=fec1a7afc944084d4c11ecccdd6f4b46","In this paper, the authors propose an improved convolutional neural network for automatic arrhythmia classification using Electro-Cardio-Gram (ECG) signal. It is essential to periodically monitor the heart beat arrhythmia to reduce the risk of death due to cardiovascular disease (CVD). The Visual Geometry Group network (VGGNet) is being widely used in computer vision problems. However, the same network cannot be used for classification of ECG beats as ECG signal is different from image signal in terms of dimensionality and inherent features. Thus, the authors investigated the effect of decreasing depth and width of a convolutional neural network in context of cardiac arrhythmia classification. In this paper, six configurations differing in depth and width are evaluated using benchmark MIT-BIH database. A deep network having thirteen convolution layers but with a smaller number of filters (reduced width) showed outstanding performance for the given problem. Based on the findings, the work is further extended to propose an improved convolutional neural network named as modified VGGNet (mVGGNet) for the task of ECG arrhythmia classification into four classes which are normal (N), ventricular ectopic beat (VEB), supraventricular ectopic beat (SVEB) and fusion beat (F). The hyper-parameters of the proposed architecture were optimized using sequential model based global optimization (SMBO) algorithm. The proposed architecture is evaluated using subjected-oriented patient-independent evaluation protocol. The performance is evaluated using five-fold cross-validation. The proposed mVGGNet achieved 98.79% and 99.16% accuracy for ventricular ectopic beats (VEB) and supraventricular ectopic beats (SVEB) classification respectively. The proposed method resulted in higher specificity and precision as compared to other state-of-the-art algorithms. Thus, it can be effectively used for ECG arrhythmia classification. © 2020-IOS Press and the authors. All rights reserved.","arrhythmia; convolutional neural network; Deep learning; ECG; VGGNet","Biomedical signal processing; Convolution; Deep learning; Deep neural networks; Diseases; Electrocardiography; Global optimization; Network architecture; arrhythmia; Arrhythmia classification; Cardiovascular disease; Computer vision problems; Proposed architectures; State-of-the-art algorithms; Ventricular ectopic beats; VGGNet; Convolutional neural networks","","","IOS Press",""
"Ali U.; Li H.; Yao R.; Wang Q.; Hussain W.; ud Duja S.B.; Amjad M.; Ahmed B.","Ali, Usman (57214298634); Li, Haifang (59157712100); Yao, Rong (57209716707); Wang, Qianshan (57215217743); Hussain, Waqar (35177640300); ud Duja, Syed Badar (57215211555); Amjad, Muhammad (58431764100); Ahmed, Bilal (58255275900)","57214298634; 59157712100; 57209716707; 57215217743; 35177640300; 57215211555; 58431764100; 58255275900","EEG emotion signal of artificial neural network by using capsule network","2020","11","1","","434","443","9","10.14569/ijacsa.2020.0110154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080110030&doi=10.14569%2fijacsa.2020.0110154&partnerID=40&md5=1dceb3a575676bbd1bd083c08f2a394a","Human emotion recognition through electroencephalographic (EEG) signals is becoming attractive. Several evolutions used for our research mechanism technology to describe two different primaries: one used for combining the vital attribute, frequency sphere, and physical element of the EEG signals, and the architecture describes the two-dimensional image. Emotion realization is imposing effort in the computer brain interface field, which is mostly used to understand the field of education, medical military, and many others. The allocation issue arises in the required area of emotion recognition. In this paper, the allocation structure based on Caps Net neural network is described. The heder factor shows that the best point to classified the original EEG signals scarce group to using many of the algorithms like Lasso for a better function to used and other than occupy the heights. Furthermore, essential features like tiny subset take by input for the computer network attain for many ultimate emotional classifications. Many of the results show to alternate the best parameters model use and other network formats to making the Caps Net and another neural network act as the emotional valuation on EEG signals. It attains almost 80.22% and 85.41% average allocation efficiency under demeanor and view of the emotion pathway as compared to the Support Vector Machine (SVM) and convolutional neural network(CNN or ConvNet). A significant allocation edge attains the best conclusion and automatically enhances the performance of the EEG emotional classification. Deep learning access, such as CNN has widely used to improve primary allocation performance of motor symbolism-based brain-computer interfaces (BCI). As we know that CNN's limited allocation achievement degraded when an essential point data is distorted. Basically, in the electroencephalography (EEG) case, the signals consist of the same user are not measure. So we implement the Capsule networks (CapsNet), which is essential to extract many features. By that, it attains a much more powerful and positive performance than the old CNN approaches. © 2013 The Science and Information (SAI) Organization.","Caps net; CNN; Deep learning; EEG signal; Emotion recognition; Granger; Hybrid neural networks; Motor imagery classification; Multidimensional feature","Biomedical signal processing; Computerized tomography; Deep learning; Electroencephalography; Electrophysiology; Image classification; Interfaces (computer); Neural networks; Regression analysis; Speech recognition; Support vector machines; Cap net; CNN; Deep learning; Electroencephalographic signals; Emotion recognition; Granger; Hybrid neural networks; Motor imagery classification; Multidimensional feature; Performance; Brain computer interface","","","Science and Information Organization",""
"Wang E.K.; Zhang X.; Pan L.; Cheng C.; Dimitrakopoulou-Strauss A.; Li Y.; Zhe N.","Wang, Eric Ke (57222049054); Zhang, Xun (57192510910); Pan, Leyun (16316794000); Cheng, Caixia (56309714300); Dimitrakopoulou-Strauss, Antonia (7003424339); Li, Yueping (23397496300); Zhe, Nie (25927435000)","57222049054; 57192510910; 16316794000; 56309714300; 7003424339; 23397496300; 25927435000","Multi-path dilated residual network for nuclei segmentation and detection","2019","8","5","499","","","","10.3390/cells8050499","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075361086&doi=10.3390%2fcells8050499&partnerID=40&md5=5d758ef04a30b6d979a549ef3b29eb9f","As a typical biomedical detection task, nuclei detection has been widely used in human health management, disease diagnosis and other fields. However, the task of cell detection in microscopic images is still challenging because the nuclei are commonly small and dense with many overlapping nuclei in the images. In order to detect nuclei, the most important key step is to segment the cell targets accurately. Based on Mask RCNN model, we designed a multi-path dilated residual network, and realized a network structure to segment and detect dense small objects, and effectively solved the problem of information loss of small objects in deep neural network. The experimental results on two typical nuclear segmentation data sets show that our model has better recognition and segmentation capability for dense small targets. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Microscopic pathological images observation; Nuclei segmentation; Object detection","algorithm; Article; controlled study; deep learning; feature extraction; histopathology; human; human tissue; image analysis; image segmentation; probability; renal cell carcinoma; statistical distribution","","","MDPI",""
"Manifold B.; Thomas E.; Francis A.T.; Hill A.H.; Fu D.A.N.","Manifold, Bryce (57194636805); Thomas, Elena (57209246846); Francis, Andrew T. (57204630480); Hill, Andrew H. (57189225720); Fu, D.A.N. (7201810686)","57194636805; 57209246846; 57204630480; 57189225720; 7201810686","Denoising of stimulated Raman scattering microscopy images via deep learning","2019","10","8","366874","3860","3874","14","10.1364/BOE.10.003860","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071033901&doi=10.1364%2fBOE.10.003860&partnerID=40&md5=223ac4034a86fc2f4272254187afdd54","Stimulated Raman scattering (SRS) microscopy is a label-free quantitative chemical imaging technique that has demonstrated great utility in biomedical imaging applications ranging from real-time stain-free histopathology to live animal imaging. However, similar to many other nonlinear optical imaging techniques, SRS images often suffer from low signal to noise ratio (SNR) due to absorption and scattering of light in tissue as well as the limitation in applicable power to minimize photodamage. We present the use of a deep learning algorithm to significantly improve the SNR of SRS images. Our algorithm is based on a U-Net convolutional neural network (CNN) and significantly outperforms existing denoising algorithms. More importantly, we demonstrate that the trained denoising algorithm is applicable to images acquired at different zoom, imaging power, imaging depth, and imaging geometries that are not included in the training. Our results identify deep learning as a powerful denoising tool for biomedical imaging at large, with potential towards in vivo applications, where imaging parameters are often variable and ground-truth images are not available to create a fully supervised learning training set. © 2019 Optical Society of America under the terms of the OSA Open Access Publishing Agreement.","","Image enhancement; Learning algorithms; Medical imaging; Neural networks; Signal to noise ratio; Stimulated Raman scattering; Absorption and scattering of light; Biomedical imaging applications; Convolutional neural network; De-noising algorithm; Live animal imaging; Low signal-to-noise ratio; Nonlinear optical imaging; Stimulated Raman scattering (SRS) microscopy; article; deep learning; geometry; in vivo study; microscopy; Deep learning","","","OSA - The Optical Society",""
"Riyad M.; Khalil M.; Adib A.","Riyad, Mouad (57209615613); Khalil, Mohammed (55628523934); Adib, Abdellah (57222401572)","57209615613; 55628523934; 57222401572","Cross-Subject EEG Signal Classification with Deep Neural Networks Applied to Motor Imagery","2019","11557 LNCS","","","124","139","15","10.1007/978-3-030-22885-9_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068268821&doi=10.1007%2f978-3-030-22885-9_12&partnerID=40&md5=1cd172d4953390b55a74a02f6d82dd53","The Brain-Computer Interface (BCI) is a system able to serve as a mean of communication between machine and human where the brainwaves are the control signals acquired by electroencephalography (EEG). One of the most used brainwaves is the sensorimotor rhythm (SMR) which appears for real or imagined motor movement. In general, EEG signals need feature extraction methods and classification algorithms to interpret the raw signals. Deep learning approaches; however, permit the processing of the raw data without any transformation. In this paper, we present a deep learning neural network architecture to classify SMR signals due to its success for some previous works and to visualize the learned features. The architecture is composed of three parts. The first part contains a temporal convolution operation followed by a spatial convolution one. The second part contains recurrent layers. Finally, we use a dense layer to assign the signal to its class. The model is trained with Adam optimizer algorithm. Also, we use various regularization techniques such as dropout to prevent learning problem like overfitting. To evaluate the performance of the proposed architecture, the well known Dataset IIa of the BCI Competition IV is used. As a result, we get equivalent results to those ones of EEGNet. © 2019, Springer Nature Switzerland AG.","BCI; Convolutional neural network; EEG; Hybrid network; Recurrent neural network","Brain computer interface; Computer control systems; Convolution; Deep neural networks; Electroencephalography; Electrophysiology; Image classification; Metadata; Network architecture; Recurrent neural networks; Classification algorithm; Convolutional neural network; EEG signal classification; Feature extraction methods; Hybrid network; Imagined motor movements; Regularization technique; Sensorimotor rhythm (SMR); Biomedical signal processing","","Renault E.; Boumerdassi S.; Bouzefrane S.; Leghris C.","Springer Verlag",""
"Mehrtash A.; Ghafoorian M.; Pernelle G.; Ziaei A.; Heslinga F.G.; Tuncali K.; Fedorov A.; Kikinis R.; Tempany C.M.; Wells W.M.; Abolmaesumi P.; Kapur T.","Mehrtash, Alireza (55891318100); Ghafoorian, Mohsen (55841332000); Pernelle, Guillaume (55891673600); Ziaei, Alireza (48462208200); Heslinga, Friso G. (57191923328); Tuncali, Kemal (6701693745); Fedorov, Andriy (8232501700); Kikinis, Ron (7101859155); Tempany, Clare M. (57202656538); Wells, William M. (21433923100); Abolmaesumi, Purang (6602170125); Kapur, Tina (7003383916)","55891318100; 55841332000; 55891673600; 48462208200; 57191923328; 6701693745; 8232501700; 7101859155; 57202656538; 21433923100; 6602170125; 7003383916","Automatic Needle Segmentation and Localization in MRI With 3-D Convolutional Neural Networks: Application to MRI-Targeted Prostate Biopsy","2019","38","4","8496860","1026","1036","10","10.1109/TMI.2018.2876796","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055060494&doi=10.1109%2fTMI.2018.2876796&partnerID=40&md5=744fb9029f6519e1917b979f642565ce","Image guidance improves tissue sampling during biopsy by allowing the physician to visualize the tip and trajectory of the biopsy needle relative to the target in MRI, CT, ultrasound, or other relevant imagery. This paper reports a system for fast automatic needle tip and trajectory localization and visualization in MRI that has been developed and tested in the context of an active clinical research program in prostate biopsy. To the best of our knowledge, this is the first reported system for this clinical application and also the first reported system that leverages deep neural networks for segmentation and localization of needles in MRI across biomedical applications. Needle tip and trajectory were annotated on 583 T2-weighted intra-procedural MRI scans acquired after needle insertion for 71 patients who underwent transperineal MRI-targeted biopsy procedure at our institution. The images were divided into two independent training-validation and test sets at the patient level. A deep 3-D fully convolutional neural network model was developed, trained, and deployed on these samples. The accuracy of the proposed method, as tested on previously unseen data, was 2.80-mm average in needle tip detection and 0.98° in needle trajectory angle. An observer study was designed in which independent annotations by a second observer, blinded to the original observer, were compared with the output of the proposed method. The resultant error was comparable to the measured inter-observer concordance, reinforcing the clinical acceptability of the proposed method. The proposed system has the potential for deployment in clinical routine. © 1982-2012 IEEE.","biopsy; Convolutional neural networks; deep learning; localization; magnetic resonance imaging; needle; prostate; segmentation","Algorithms; Humans; Image-Guided Biopsy; Magnetic Resonance Imaging; Male; Neural Networks, Computer; Prostate; Prostatic Neoplasms; Biopsy; Clinical research; Computerized tomography; Convolution; Deep learning; Deep neural networks; Image enhancement; Image segmentation; Medical applications; Needles; Neural networks; Software testing; Trajectories; Ultrasonic applications; Urology; Biomedical applications; Clinical application; Convolutional neural network; localization; Needle insertion; Needle segmentation; Needle trajectory; prostate; ambiguity; architecture; Article; artificial neural network; automation; cancer recurrence; human; human tissue; image segmentation; interventional magnetic resonance imaging; major clinical study; male; needle biopsy; partial volume (imaging); prostate biopsy; prostate cancer; retrospective study; three dimensional imaging; algorithm; diagnostic imaging; image guided biopsy; nuclear magnetic resonance imaging; pathology; procedures; prostate; prostate tumor; Magnetic resonance imaging","National Institutes of Health, NIH, (R25CA089017); National Institute of Biomedical Imaging and Bioengineering, NIBIB, (P41EB015898); Canadian Institutes of Health Research, CIHR; Natural Sciences and Engineering Research Council of Canada, NSERC","","Institute of Electrical and Electronics Engineers Inc.","30334789"
"Matuszewski D.J.; Sintorn I.-M.","Matuszewski, Damian J. (57191992837); Sintorn, Ida-Maria (7801464619)","57191992837; 7801464619","Reducing the U-Net size for practical scenarios: Virus recognition in electron microscopy images","2019","178","","","31","39","8","10.1016/j.cmpb.2019.05.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067187368&doi=10.1016%2fj.cmpb.2019.05.026&partnerID=40&md5=51512c28411fa4c5d66ea5a0cdddf57a","Background and objective: Convolutional neural networks (CNNs) offer human experts-like performance and in the same time they are faster and more consistent in their prediction. However, most of the proposed CNNs require an expensive state-of-the-art hardware which substantially limits their use in practical scenarios and commercial systems, especially for clinical, biomedical and other applications that require on-the-fly analysis. In this paper, we investigate the possibility of making CNNs lighter by parametrizing the architecture and decreasing the number of trainable weights of a popular CNN: U-Net. Methods: In order to demonstrate that comparable results can be achieved with substantially less trainable weights than the original U-Net we used a challenging application of a pixel-wise virus classification in Transmission Electron Microscopy images with minimal annotations (i.e. consisting only of the virus particle centers or centerlines). We explored 4 U-Net hyper-parameters: the number of base feature maps, the feature maps multiplier, the number of the encoding-decoding levels and the number of feature maps in the last 2 convolutional layers. Results: Our experiments lead to two main conclusions: 1) the architecture hyper-parameters are pivotal if less trainable weights are to be used, and 2) if there is no restriction on the trainable weights number using a deeper network generally gives better results. However, training larger networks takes longer, typically requires more data and such networks are also more prone to overfitting. Our best model achieved an accuracy of 82.2% which is similar to the original U-Net while using nearly 4 times less trainable weights (7.8 M in comparison to 31.0 M). We also present a network with < 2 M trainable weights that achieved an accuracy of 76.4%. Conclusions: The proposed U-Net hyper-parameter exploration can be adapted to other CNNs and other applications. It allows a comprehensive CNN architecture designing with the aim of a more efficient trainable weight use. Making the networks faster and lighter is crucial for their implementation in many practical applications. In addition, a lighter network ought to be less prone to over-fitting and hence generalize better. © 2019","Deep learning; Hardware integration; Hyper parameter optimization; Transmission Electron Microscopy","Algorithms; Computer Systems; Databases, Factual; Deep Learning; Image Processing, Computer-Assisted; Microscopy, Electron, Transmission; Neural Networks, Computer; Reproducibility of Results; Viruses; Convolution; Deep learning; High resolution transmission electron microscopy; Neural networks; Particle size analysis; Transmission electron microscopy; Viruses; Commercial systems; Convolutional neural network; Electron microscopy images; Encoding-decoding; Hardware integrations; Hyper-parameter optimizations; State of the art; Transmission electron microscopy images; accuracy; Article; convolutional neural network; image analysis; machine learning; nonhuman; transmission electron microscopy; virus classification; virus examination; algorithm; computer system; factual database; image processing; procedures; reproducibility; transmission electron microscopy; ultrastructure; virus; Network architecture","Vetenskapsrådet, VR, (2014-6075)","","Elsevier Ireland Ltd","31416558"
"Raza S.N.; Raza Ur Rehman H.; Lee S.G.; Sang Choi G.","Raza, Syed Navid (57211430321); Raza Ur Rehman, Hafiz (57211430772); Lee, Suk Gyu (7601392069); Sang Choi, Gyu (9734383700)","57211430321; 57211430772; 7601392069; 9734383700","Artificial intelligence based camera calibration","2019","","","8766666","1564","1569","5","10.1109/IWCMC.2019.8766666","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073900272&doi=10.1109%2fIWCMC.2019.8766666&partnerID=40&md5=f13bc68cdad50912587514f713511599","Camera calibration technique plays a vital role in three dimensional computer vision systems. The aim of this technique is to calibrate the camera in order to collect more precise three dimensional data from the images to utilize for robot navigation, three dimensional reconstruction, biomedical, virtual reality and visual surveillance. In camera calibration one of the major issue is to search out the set of image parameters describing the mapping between three dimensional images reference coordinates and two-dimensional images reference coordinates. Currently, MATLAB toolbox and OpenCv are the most popular tools used by the researchers for camera calibration. We utilize the concept of deep learning to recognize the chessboard corners. Our presented technique is a convolutional neural network (CNN) trained on a huge number of chessboard images. The network is trained on different datasets: noisy and with high lens malformation images. The proposed scheme is more accurate than the conventional MATLAB algorithm technique. The presented technique is more accurate against the different sort of ruination present in the training set. Results reaffirmed the correctness and effectiveness of our proposed CNN technique. © 2019 IEEE.","Camera calibration; Checkboard detection; Convolutional neural network","Calibration; Cameras; Convolution; Deep learning; MATLAB; Mobile computing; Neural networks; Robots; Virtual reality; Camera calibration; Camera calibration techniques; Convolutional neural network; Three dimensional images; Three-dimensional computer vision; Three-dimensional data; Three-dimensional reconstruction; Two dimensional images; Security systems","Ministry of Education, MOE, (NRF-2019R1A2C1006159); Ministry of Trade, Industry and Energy, MOTIE, (10063130); Ministry of Science, ICT and Future Planning, MSIP, (IITP-2019-2016-0-00313); National Research Foundation of Korea, NRF; Institute for Information and Communications Technology Promotion, IITP","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","14th International conference on Pattern Recognition and Information Processing, PRIP 2019","2019","1055 CCIS","","","","","311","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076698019&partnerID=40&md5=d739f08078244e0340f18c86d8a47bbb","The proceedings contain 25 papers. The special focus in this conference is on Pattern Recognition and Information Processing. The topics include: Brands and Caps Labeling Recognition in Images Using Deep Learning; influence of Control Parameters and the Size of Biomedical Image Datasets on the Success of Adversarial Attacks; performance of Sequential Tests for Random Data Monitoring Under Distortion; equipment Condition Identification Based on Telemetry Signal Clustering; robots’ Vision Humanization Through Machine-Learning Based Artificial Visual Attention; automatic Analysis of Moving Particles by Total Internal Reflection Fluorescence Microscopy; fuzzy Morphological Filters for Processing of Printed Circuit Board Images; Detection of Bulbar Dysfunction in ALS Patients Based on Running Speech Test; thresholding Neural Network Image Enhancement Based on 2-D Non-separable Quaternionic Filter Bank; method of Creating the 3D Face Model of Character Based on Textures Maps Module; shadow Detection in Satellite Images by Computing Its Characteristics; nearest Convex Hull Classifier with Simplified Proximity Measurement; image Semantic Segmentation Based on Convolutional Neural Networks for Monitoring Agricultural Vegetation; reliability Analysis Based on Incompletely Specified Data; semantic-Based Linguistic Platform for Big Data Processing; cell Nuclei Counting and Segmentation for Histological Image Analysis; robust Person Tracking Algorithm Based on Convolutional Neural Network for Indoor Video Surveillance Systems; modeling of Intelligent Systems Architecture Based on the Brain Topology; temporal Convolutional and Recurrent Networks for Image Captioning; Video-Based Content Extraction Algorithm from Bank Cards for iOS Mobile Devices; FPGA Based Arbiter Physical Unclonable Function Implementation with Reduced Hardware Overhead; preface.","","","","Ablameyko S.V.; Krasnoproshin V.V.; Lukashevich M.M.","Springer",""
"Li E.; Zhang S.; Chen S.; Wei B.; Yang B.; Qiao S.; Lu H.; Shen G.","Li, Enyu (59031245700); Zhang, Shengfa (57214797652); Chen, Sheng (59112194300); Wei, Bo (57202200794); Yang, Bo (57215339485); Qiao, Shan (36969852700); Lu, Huaxin (57214796849); Shen, Guofeng (35303233800)","59031245700; 57214797652; 59112194300; 57202200794; 57215339485; 36969852700; 57214796849; 35303233800","Localization Bar Detection by Deep Learning in Magnetic Resonance Guided Focused Ultrasound","2019","","","8965893","","","","10.1109/CISP-BMEI48845.2019.8965893","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079195564&doi=10.1109%2fCISP-BMEI48845.2019.8965893&partnerID=40&md5=9c1eefe8fdbc77b9c93a77c0f410dc4a","Magnetic resonance guided focused ultrasound (MRgFUS) can focus the ultrasonic energy on a targeted tissue to achieve ablation. In this study, we propose a convolutional neural network (based on Tensorflow) based upon deep learning to detect the position bars to registry the coordinate of MR and HIFU systems, instead of the traditional detection algorithm. The results show that the model achieves the average precision (AP) of 95.6% with the precision of 99.0% and the recall of 99.0% at a score threshold of 0.5. © 2019 IEEE.","convolutional neural network; deep learning; localization bar; MRgFUS","Biomedical engineering; Convolution; Convolutional neural networks; Deep neural networks; Image processing; Magnetic resonance; Ultrasonic applications; Bar detection; Detection algorithm; Focused ultrasound; Magnetic resonance-guided focused ultrasound (MRgFUS); MRgFUS; Ultrasonic energy; Deep learning","National Key Research and Development Program of Ministry of Science and Technology, (2017YFC0108900); Shanghai Pujiang Program, (17PJ1431700); National Natural Science Foundation of China, NSFC, (11774231, 81727806); National Natural Science Foundation of China, NSFC; Science and Technology Commission of Shanghai Municipality, STCSM, (15441900700, 17441906400); Science and Technology Commission of Shanghai Municipality, STCSM","Li Q.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"Chen S.; Lu X.; Li Y.; Wu R.","Chen, Shikun (57214793527); Lu, Xiaobo (14627586600); Li, Yongbin (57203682551); Wu, Renliang (57214801608)","57214793527; 14627586600; 57203682551; 57214801608","A Convolutional Neural Network for Real-Time Vehicle Detection Under the Unmanned Aerial Vehicle Platform","2019","","","8965752","","","","10.1109/CISP-BMEI48845.2019.8965752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079115094&doi=10.1109%2fCISP-BMEI48845.2019.8965752&partnerID=40&md5=890e2d15b44b40031deca82546dd2f0e","The detection of vehicles under the unmanned aerial vehicle platform has several technical challenges. Compared with surveillance videos, aerial videos have more complex background and broader range which lead to larger space for searching. It is also difficult to build a effective background model due to the movement of the unmanned aerial vehicle. The low performance of development board on the aerial vehicle also make it difficult to perform real-time detection. We proposes a convolutional neural network to carry out real-time detection of vehicles under the unmanned aerial vehicle platform. Multi-scale anchor design is carried out to improve the adaptability to different vehicles and the algorithm is time optimized based on the binary weight network. As a consequence, our algorithm runs at 28.8 FPS with average precision of 91.2% under the unmanned aerial vehicle platform. © 2019 IEEE.","convolution neural network; deep learning; real-time; unmanned aerial vehicle; vehicle detection","Antennas; Biomedical engineering; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Image processing; Scales (weighing instruments); Security systems; Signal detection; Unmanned aerial vehicles (UAV); Background model; Complex background; Convolution neural network; Real time; Real-time detection; Surveillance video; Technical challenges; Vehicle detection; Aircraft detection","Key Research and Development Program in Jiangsu Province; National Natural Science Foundation of China, NSFC, (61871123); Priority Academic Program Development of Jiangsu Higher Education Institutions, PAPD; Jiangsu Provincial Key Research and Development Program","Li Q.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"Cheng S.-W.; Zhou T.-C.; Tang Z.-C.; Fan J.; Sun L.-Y.; Zhu A.-J.","Cheng, Shi-Wei (25630245300); Zhou, Tao-Chun (57211976869); Tang, Zhi-Chuan (36976326400); Fan, Jing (35317355100); Sun, Ling-Yun (55492960600); Zhu, An-Jie (57205030119)","25630245300; 57211976869; 36976326400; 35317355100; 55492960600; 57205030119","CNN Based Motor Imagery EEG Classification and Human-robot Interaction; [CNN实现的运动想象脑电分类及人-机器人交互]","2019","30","10","","3005","3016","11","10.13328/j.cnki.jos.005782","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075565690&doi=10.13328%2fj.cnki.jos.005782&partnerID=40&md5=7164c290c7fae53b01a3a72a44538de4","The electroencephalograph (EEG) driven brain-computer interaction can promote daily life and rehabilitation training for physically disabled people, however, EEG has several problems such as low signal-noise ratio, significant individual difference, and these problems result in the low accuracy and efficiency for EEG feature extraction and classification. In the context of reducing numbers of electrodes and increasing identified classes, this study proposed an approach to classify motor imagery (MI) EEG signal based on convolutional neural network (CNN). Firstly, based on existed approaches, experiments were conducted and the CNN was constructed with three convolution layers, three pooling layers, and two full-connection layers. Secondly, MI experiment was conducted with the imagination of left hand movement, right hand movement, foot movement, and resting state, and the MI EEG data were collected at the same time. Thirdly, the MI EEG data set were used to build the classification model based on CNN, and the experiment results indicate that the average accuracy of classification is 82.81%, which is higher than the related classification algorithms. Finally, the classification model was applied in the online classification of MI EEG, and a BCI prototype system was designed and implemented to drive the real-time human-robot interaction. The prototype system can help users to control motion states of the humanoid robot, such as raising hands, moving forward. Furthermore, the experimental results show that the average accuracy of robot controlling reaches to 80.31%, and it verifies the proposed approach not only can classify MI EEG data with high accuracy in real time, but also promote applications of human-robot interaction with BCI. © Copyright 2019, Institute of Software, the Chinese Academy of Sciences. All rights reserved.","Brain computer interface; Convolutional neural network; Deep learning; Human-computer interaction; Motor imagery","Anthropomorphic robots; Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Deep learning; Deep neural networks; Digital storage; Electroencephalography; Human computer interaction; Image classification; Neural networks; Accuracy of classifications; Brain computer interactions; Classification algorithm; Convolutional neural network; Feature extraction and classification; Individual Differences; Motor imagery; Rehabilitation training; Human robot interaction","National Key Research & Development Program of China, (2016YFB1001403); National Natural Science Foundation of China, NSFC, (61672451, 61702454, 61772468); National Key Research and Development Program of China Stem Cell and Translational Research","","Chinese Academy of Sciences",""
"","","","8th International Conference on Sciences of Electronics, Technologies of Information and Telecommunication, SETIT 2018","2020","146","","","","","503","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069498730&partnerID=40&md5=fa907926c750c48114609174296bd09a","The proceedings contain 47 papers. The special focus in this conference is on Sciences of Electronics, Technologies of Information and Telecommunication. The topics include: A New Biomedical Text Summarization Method Based on Sentence Clustering and Frequent Itemsets Mining; An Implementation of InfluxDB for Monitoring and Analytics in Distributed IoT Environments; Publish a Jason Agent BDI Capacity as Web Service REST and SOAP; FPGA Implementation of a Quantum Cryptography Algorithm; health Recommender Systems: A Survey; distributed Architecture of an Intrusion Detection System Based on Cloud Computing and Big Data Techniques; choosing the Right Storage Solution for the Corpus Management System (Analytical Overview and Experiments); requirements Imprecision of Data Warehouse Design Fuzzy Ontology-Based Approach - Fuzzy Connector Case; quantitative Prediction of Toxicity of Substituted Phenols Using Deep Learning; an Affective Tutoring System for Massive Open Online Courses; rationality Measurement for Jadex-Based Applications; a Continuous Optimization Scheme Based on an Enhanced Differential Evolution and a Trust Region Method; strided Convolution Instead of Max Pooling for Memory Efficiency of Convolutional Neural Networks; ear Recognition Based on Improved Features Representations; some Topological Indices of Polar Grid Graph; deep Elman Neural Network for Greenhouse Modeling; High Efficiency Multiplierless DCT Architectures; signature of Electronic Documents Based on the Recognition of Minutiae Fingerprints; person Re-Identification Using Pose-Driven Body Parts; automatic Processing of Oral Arabic Complex Disfluencies; high Securing Cryptography System for Digital Image Transmission; A Novel DWTTH Approach for Denoising X-Ray Images Acquired Using Flat Detector; recent Advances in Fire Detection and Monitoring Systems: A Review; preface.","","","","Bouhlel M.S.; Rovetta S.","Springer Science and Business Media Deutschland GmbH",""
"Rapaport E.; Shriki O.; Puzis R.","Rapaport, Elad (57212536832); Shriki, Oren (6506619366); Puzis, Rami (55992152200)","57212536832; 6506619366; 55992152200","EEGNAS: Neural Architecture Search for Electroencephalography Data Analysis and Decoding","2019","1072","","","3","20","17","10.1007/978-981-15-1398-5_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076955405&doi=10.1007%2f978-981-15-1398-5_1&partnerID=40&md5=eca64b0344e912e09bfbda26cd4c52a3","EEG, Electroencephalography, is the acquisition and decoding of electric brain signals. The data acquired from EEG scans can be put to use in many fields, including seizure prediction, treatment of mental illness, brain-computer interfaces (BCIs) and more. Recent advances in deep learning (DL) in fields of image classification and natural language processing have motivated researchers to apply DL for classification of EEG signals as well. One major caveat in DL is the amount of human effort and expertise required for the development of efficient and effective neural network architectures. Neural architecture search algorithms are used to automatically find good enough neural network architectures for a problem and dataset at hand. In this research, we employ genetic algorithms for optimizing neural network architectures for multiple tasks related to EEG processing while addressing two unique challenges related to EEG: (1) small amounts of labeled EEG data per subject, and (2) high diversity of EEG signal patterns across subjects. Neural network architectures produced during this study successfully compete with state of the art architectures published in the literature. Particularly successful are architectures optimized for all (human) subjects, with evolution and training performed on a mixed dataset including all subjects’ data. © 2019, Springer Nature Singapore Pte Ltd.","EEG; Neural architecture search; Time series","Biomedical signal processing; Brain; Brain computer interface; Decoding; Deep learning; Diseases; Electroencephalography; Electrophysiology; Genetic algorithms; Natural language processing systems; Neural networks; Time series; Brain computer interfaces (BCIs); Mental illness; Multiple tasks; NAtural language processing; Neural architectures; Search Algorithms; Seizure prediction; State of the art; Network architecture","Ministry of Defense, MOD","Zeng A.; Pan D.; Hao T.; Zhang D.; Shi Y.; Song X.","Springer",""
"Ji Y.; Zhang S.; Xiao W.","Ji, Yinsheng (57209587433); Zhang, Sen (56153294200); Xiao, Wendong (35276611800)","57209587433; 56153294200; 35276611800","Electrocardiogram classification based on faster regions with convolutional neural network","2019","19","11","2558","","","","10.3390/s19112558","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068108747&doi=10.3390%2fs19112558&partnerID=40&md5=d6a5576565dc5df048799bf776406000","The classification of electrocardiograms (ECG) plays an important role in the clinical diagnosis of heart disease. This paper proposes an effective system development and implementation for ECG classification based on faster regions with a convolutional neural network (Faster R-CNN) algorithm. The original one-dimensional ECG signals contain the preprocessed patient ECG signals and some ECG recordings from the MIT-BIH database in this experiment. Each ECG beat of one-dimensional ECG signals was transformed into a two-dimensional image for experimental training sets and test sets. As a result, we classified the ECG beats into five categories with an average accuracy of 99.21%. In addition, we did a comparative experiment using the one versus rest support vector machine (OVR SVM) algorithm, and the classification accuracy of the proposed Faster R-CNN was shown to be 2.59% higher. View Full-Text. © 2019, MDPI AG. All rights reserved.","Automatic classification; Convolutional neural network; Deep learning; Electrocardiogram; Electrocardiogram preconditioning","Algorithms; Arrhythmias, Cardiac; Databases, Factual; Electrocardiography; Humans; Neural Networks, Computer; Signal Processing, Computer-Assisted; Software; Support Vector Machine; Computer aided diagnosis; Computerized tomography; Convolution; Deep learning; Deep neural networks; Electrocardiography; Neural networks; Support vector machines; Automatic classification; Classification accuracy; Clinical diagnosis; Comparative experiments; Convolutional neural network; Ecg classifications; Effective systems; Two dimensional images; algorithm; classification; electrocardiography; factual database; heart arrhythmia; human; signal processing; software; support vector machine; Biomedical signal processing","National Natural Science Foundation of China, NSFC, (61673125); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Beijing Municipality, (4182039, 61673055, 61673056); Natural Science Foundation of Beijing Municipality; National Basic Research Program of China (973 Program), (2017YFB1401203); National Basic Research Program of China (973 Program)","","MDPI AG","31195603"
"Sanaat A.; Arabi H.; Zaidi H.","Sanaat, Amirhossein (57207449502); Arabi, Hossein (57220877447); Zaidi, Habib (7004977873)","57207449502; 57220877447; 7004977873","A novel convolutional neural network for predicting full dose from low dose PET scans","2019","","","9059962","","","","10.1109/NSS/MIC42101.2019.9059962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083564910&doi=10.1109%2fNSS%2fMIC42101.2019.9059962&partnerID=40&md5=d1c575183ee6c177fb4f76c271639f10","The use of radiolabeled tracers in PET imaging raises concerns owing to potential risks from radiation exposure. Therefore, to reduce this potential risk in diagnostic PET imaging, efforts have been made to decrease the amount of radiotracer administered to the patient. However, decreasing the injected activity reduces the signal-to-noise Ratio (SNR) and deteriorates image quality, thus adversely impacting clinical diagnosis. Previously proposed techniques are complicated and slow, yet they yield satisfactory results at significantly low dose. In this work, we propose a deep learning algorithm to reconstruct full-dose (FD) from low-dose (LD) PET images using a fully convolutional encoder-decoder deep neural network model. The goal is to train a model to learn to reconstruct from images with only 5% of the counts to produce images corresponding to 100% of the dose. Brain PET/CT images of 140 patients acquired on the Siemens Biograph mCT with a standard injected activity of 18F-FDG (205 ± 10 MBq). Images were acquired for about 20 min. The sinograms of each scan were used to produce a low-dose sinogram by randomly selecting only 1/20th of the counts. To avoid over fitting, data augmentation was used. A modified 3D U-Net, was developed to predict standard-dose sinogram (PSS) from their corresponding LD sinogram. Detailed quantitative and qualitative comparison demonstrated the proposed method can generate artefact-free diagnostic quality images that preserve internal structures without noise amplification. The structural similarity index (SSIM) and peak signal to noise ratio (PSNR) were used as quantitative metrics for assessment. For instance, the PSNR and SSIM in selected slices were 37.30±0.71 and 0.97±0.02, respectively. The proposed algorithm operates in the projection space and is capable of producing diagnostic quality images with only 5% of the standard injected activity. © 2019 IEEE.","","Biomedical signal processing; Brain; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Diagnosis; Image acquisition; Image quality; Image reconstruction; Medical imaging; Positron emission tomography; Convolutional encoders; Neural network model; Noise amplification; Peak signal to noise ratio; Quantitative metrics; Radiation Exposure; Radiolabeled tracers; Structural similarity indices (SSIM); Signal to noise ratio","Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung, SNF, (SNFN 320030-176052); Swiss Cancer Research Foundation, (KFS-3855-02-2016)","","Institute of Electrical and Electronics Engineers Inc.",""
"McCann M.T.; Unser M.","McCann, M.T. (55617614400); Unser, M. (7102049045)","55617614400; 7102049045","Biomedical image reconstruction: From the foundations to deep neural networks","2019","13","3","","283","359","76","10.1561/2000000101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086604683&doi=10.1561%2f2000000101&partnerID=40&md5=7ff436fd7de566a2454876d2f4fb855e","This tutorial covers biomedical image reconstruction, from the foundational concepts of system modeling and direct reconstruction to modern sparsity and learning-based approaches. Imaging is a critical tool in biological research and medicine, and most imaging systems necessarily use an image reconstruction algorithm to create an image; the design of these algorithms has been a topic of research since at least the 1960's. In the last few years, machine learning-based approaches have shown impressive performance on image reconstruction problems, triggering a wave of enthusiasm and creativity around the paradigm of learning. Our goal is to unify this body of research, identifying common principles and reusable building blocks across decades and among diverse imaging modalities. We first describe system modeling, emphasizing how a few building blocks can be used to describe a broad range of imaging modalities. We then discuss reconstruction algorithms, grouping them into three broad generations. The first are the classical direct methods, including Tikhonov regularization; the second are the variational methods based on sparsity and the theory of compressive sensing; and the third are the learning-based (also called data-driven) methods, especially those using deep convolutional neural networks. There are strong links between these generations: classical (first-generation) methods appear as modules inside the latter two, and the former two are used to inspire new designs for learning-based (third-generation) methods. As a result, a solid understanding of all three generations is necessary for the design of state-of-the-art algorithms. © M. T. McCann and M. Unser (2019)","","Bioinformatics; Convolutional neural networks; Deep learning; Deep neural networks; Learning systems; Compressive sensing; Image reconstruction algorithm; Learning-based approach; Reconstruction algorithms; Reconstruction problems; State-of-the-art algorithms; Tikhonov regularization; Variational methods; Image reconstruction","European Union's Horizon 2020 Research and Innovation Program; Louis-Jeantet Foundations; University Hospitals of Geneva; Vaud University Hospital Centre; Horizon 2020 Framework Programme, H2020, (692726); European Research Council, ERC; École Polytechnique Fédérale de Lausanne, EPFL; Louis-Jeantet Foundation; Hôpitaux Universitaires de Genève, HUG; Université de Genève, UNIGE; Université de Lausanne, UNIL; Centre d'Imagerie BioMédicale, CIBM","","Now Publishers Inc",""
"Tong L.; Wu H.; Wang M.D.","Tong, Li (57188816402); Wu, Hang (57037188100); Wang, May D (10739831700)","57188816402; 57037188100; 10739831700","CAESNet: Convolutional AutoEncoder based Semi-supervised Network for improving multiclass classification of endomicroscopic images","2019","26","11","","1286","1296","10","10.1093/jamia/ocz089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073183985&doi=10.1093%2fjamia%2focz089&partnerID=40&md5=f7b9ea41933055d8800134731e5a4c0e","Objective: This article presents a novel method of semisupervised learning using convolutional autoencoders for optical endomicroscopic images. Optical endomicroscopy (OE) is a newly emerged biomedical imaging modality that can support real-time clinical decisions for the grade of dysplasia. To enable real-time decision making, computer-aided diagnosis (CAD) is essential for its high speed and objectivity. However, traditional supervised CAD requires a large amount of training data. Compared with the limited number of labeled images, we can collect a larger number of unlabeled images. To utilize these unlabeled images, we have developed a Convolutional AutoEncoder based Semi-supervised Network (CAESNet) for improving the classification performance. Materials and Methods: We applied our method to an OE dataset collected from patients undergoing endoscope-based confocal laser endomicroscopy procedures for Barrett's esophagus at Emory Hospital, which consists of 429 labeled images and 2826 unlabeled images. Our CAESNet consists of an encoder with 5 convolutional layers, a decoder with 5 transposed convolutional layers, and a classification network with 2 fully connected layers and a softmax layer. In the unsupervised stage, we first update the encoder and decoder with both labeled and unlabeled images to learn an efficient feature representation. In the supervised stage, we further update the encoder and the classification network with only labeled images for multiclass classification of the OE images. Results: Our proposed semisupervised method CAESNet achieves the best average performance for multiclass classification of OE images, which surpasses the performance of supervised methods including standard convolutional networks and convolutional autoencoder network. Conclusions: Our semisupervised CAESNet can efficiently utilize the unlabeled OE images, which improves the diagnosis and decision making for patients with Barrett's esophagus. © 2019 The Author(s).","Barrett's esophagus; convolutional autoencoders; endomicroscopy; semisupervised learning","Algorithms; Barrett Esophagus; Datasets as Topic; Diagnosis, Computer-Assisted; Esophagoscopy; Esophagus; Humans; Microscopy, Confocal; Supervised Machine Learning; Article; autoencoder; Barrett esophagus; classification; computer aided design; confocal laser scanning microscopy; controlled study; deep neural network; diagnostic accuracy; diagnostic imaging; esophagoscopy; human; image analysis; image reconstruction; major clinical study; medical decision making; optical endomicroscopy; algorithm; Barrett esophagus; computer assisted diagnosis; confocal microscopy; esophagoscopy; esophagus; information processing; pathology; procedures; supervised machine learning","National Cancer Institute Transformative, (R01 CA163256); National Institutes of Health or China Scholarship Council; National Institutes of Health, NIH; National Center for Advancing Translational Sciences, NCATS, (UL1TR000454); National Center for Advancing Translational Sciences, NCATS; Microsoft Research; China Scholarship Council, CSC, (CSC 201406010343); China Scholarship Council, CSC","","Oxford University Press","31260038"
"Majidov I.; Whangbo T.","Majidov, Ikhtiyor (57208439956); Whangbo, Taegkeun (35617849900)","57208439956; 35617849900","Efficient classification of motor imagery electroencephalography signals using deep learning methods","2019","19","7","1736","","","","10.3390/s19071736","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064832220&doi=10.3390%2fs19071736&partnerID=40&md5=266ed1035b673dfb5a3ea837189ff0d9","Single-trial motor imagery classification is a crucial aspect of brain–computer applications. Therefore, it is necessary to extract and discriminate signal features involving motor imagery movements. Riemannian geometry-based feature extraction methods are effective when designing these types of motor-imagery-based brain–computer interface applications. In the field of information theory, Riemannian geometry is mainly used with covariance matrices. Accordingly, investigations showed that if the method is used after the execution of the filterbank approach, the covariance matrix preserves the frequency and spatial information of the signal. Deep-learning methods are superior when the data availability is abundant and while there is a large number of features. The purpose of this study is to a) show how to use a single deep-learning-based classifier in conjunction with BCI (brain–computer interface) applications with the CSP (common spatial features) and the Riemannian geometry feature extraction methods in BCI applications and to b) describe one of the wrapper feature-selection algorithms, referred to as the particle swarm optimization, in combination with a decision tree algorithm. In this work, the CSP method was used for a multiclass case by using only one classifier. Additionally, a combination of power spectrum density features with covariance matrices mapped onto the tangent space of a Riemannian manifold was used. Furthermore, the particle swarm optimization method was implied to ease the training by penalizing bad features, and the moving windows method was used for augmentation. After empirical study, the convolutional neural network was adopted to classify the pre-processed data. Our proposed method improved the classification accuracy for several subjects that comprised the well-known BCI competition IV 2a dataset. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","BCI; CSP; EEG; Electro-oscillography (EOG); FBCSP (filter bank common spatial pattern); Online learning; Particle swarm optimization (PSO); Riemannian geometry; Tangent space","Algorithms; Brain; Brain-Computer Interfaces; Decision Trees; Deep Learning; Electroencephalography; Humans; Models, Theoretical; Movement; Neural Networks (Computer); Signal Processing, Computer-Assisted; Software; Biomedical signal processing; Brain computer interface; Covariance matrix; Data mining; Decision trees; Deep learning; Electroencephalography; Electrophysiology; Extraction; Feature extraction; Filter banks; Geometry; Image classification; Information theory; Neural networks; Particle swarm optimization (PSO); Swarm intelligence; Trees (mathematics); Common spatial patterns; Online learning; Oscillography; Riemannian geometry; Tangent space; algorithm; artificial neural network; brain; brain computer interface; decision tree; electroencephalography; human; movement (physiology); physiology; procedures; signal processing; software; theoretical model; Classification (of information)","Ministry of Science and ICT, (IITP-2019-2017-0-01630); Iran Telecommunication Research Center, ITRC; Institute for Information and Communications Technology Promotion, IITP","","MDPI AG","30978978"
"Cicek G.; Cevik M.; Akan A.","Cicek, Gulay (57211992616); Cevik, Mesut (57796708000); Akan, Aydin (35617283100)","57211992616; 57796708000; 35617283100","Classification of ADHD using ensemble algorithms with deep learning and hand crafted features; [Derin öǧrenme ve manuel öznitelik çikarma yöntemleri ile topluluk algoritmalari kullanarak DEHB'nin siniflandirilmasi]","2019","","","8895197","","","","10.1109/TIPTEKNO.2019.8895197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075619561&doi=10.1109%2fTIPTEKNO.2019.8895197&partnerID=40&md5=436caaa0a92de214266e3a8da660c429","Attention Deficit Hyperactivity (ADHD) is a common neurodevelopmental disorder that typically appears in early childhood. Methods developed for diagnosing gives different results at different times. This is a major obstacle in the diagnosis of disease. Diagnosis model of ADHD must be unique, objective, and reliable. In this study, comparative evaluations of both manual and deep features for classification of structural magnetic resonance images is presented. For this purpose, datasets of NPIstanbul Neuropsychiatry Hospital and public datasets of ADHD-200 is used. In order to characterize MRI images First Order, Second Order statictical features and the Alexnet architecture is used. Images are classified with the ensemble algorithm. In order to determine classification performance, accuracy, sensitivity, specificity, tp rate, fp rate and F-measure values are taken into consideration. It was observed that the combination of three manually extracted data sets yielded more successful results in characterizing the data. © 2019 IEEE.","Alexnet; Attention deficit hyperactivity disorder; Convolutional neural network; Hand crafted and automated features","Biomedical engineering; Diagnosis; Magnetic resonance; Magnetic resonance imaging; Neural networks; Alexnet; Attention deficit hyperactivity; Attention deficit hyperactivity disorder; Automated features; Classification performance; Comparative evaluations; Convolutional neural network; Ensemble algorithms; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Liu J.; Kang Y.; Hu D.; Chen Y.","Liu, Jin (55869079600); Kang, Yanqin (57217532725); Hu, Dianlin (57212780742); Chen, Yang (55486576300)","55869079600; 57217532725; 57212780742; 55486576300","4D-CBCT Reconstruction via Motion Compensataion Learning Induced Sparse Tensor Constraint","2019","","","8965916","","","","10.1109/CISP-BMEI48845.2019.8965916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079171016&doi=10.1109%2fCISP-BMEI48845.2019.8965916&partnerID=40&md5=21c3e6fc324d1102d658112b6c615246","The challenge in 4D-CBCT reconstruction is the lacked of projections at each phase, which result in a reconstruction image full of streak artifacts and motion blurring with the conventional analytical algorithms. Aiming at improving the overall quality of 4D-CBCT images, we propose a motion compensation learning induced sparse tensor constraint reconstruction (MCL-STCR) method which tries to explore the high correlation in 4D-CBCT images for different phases. In this method, we additionally conduct motion compensation on the 4D-CBCT volume by using trained image motion compensation convolutional neural network (CNN). Then the compensated 4D-CBCT volume is viewed as a pseudostatic sequence, of which the sparse tensor constraint was imposed on. The cost function of proposed MCL-STCR is optimized by a variable splitting algorithm. Its comparison to other methods through simulated dynamic phantom and lung data experiments demonstrated that the proposed method can lead to a promising improvement of 4D-CBCT reconstruction. © 2019 IEEE.","4D-CBCT; deep learning; image reconstruction; motion compensation; tensor constrained","Biomedical engineering; Convolutional neural networks; Cost functions; Deep learning; Image enhancement; Motion compensation; Tensors; 4D-CBCT; Analytical algorithms; Image motion compensation; Motion blurring; Overall quality; Reconstruction image; Streak artifacts; Variable splitting; Image reconstruction","Anhui Polytechnic University, (2018YQQ021); National Natural Science Foundation; National Natural Science Foundation of China, NSFC, (61801003, 81370040, 81530060); Anhui Polytechnic University, AHPU","Li Q.; Wang L.","Institute of Electrical and Electronics Engineers Inc.",""
"Zeng X.; Chen H.; Luo Y.; Ye W.","Zeng, Xianglong (57207734808); Chen, Haiquan (57207735259); Luo, Yuan (56046167000); Ye, Wenbin (44661755300)","57207734808; 57207735259; 56046167000; 44661755300","Automated diabetic retinopathy detection based on binocular siamese-like convolutional neural network","2019","7","","8660434","30744","30753","9","10.1109/ACCESS.2019.2903171","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064710652&doi=10.1109%2fACCESS.2019.2903171&partnerID=40&md5=95ce57fc6c915b62cae89cb24a5b3a99","Diabetic retinopathy (DR) is an important cause of blindness worldwide. However, DR is hard to be detected in the early stages, and the diagnostic procedure can be time-consuming even for the experienced experts. Therefore, a computer-Aided diagnosis method based on deep learning algorithms is proposed to automatedly diagnose the referable diabetic retinopathy by classifying color retinal fundus photographs into two grades. In this paper, a novel convolutional neural network model with the Siamese-like architecture is trained with a transfer learning technique. Different from the previous works, the proposed model accepts binocular fundus images as inputs and learns their correlation to help to make a prediction. In the case with a training set of only 28 104 images and a test set of 7024 images, an area under the receiver operating curve of 0.951 is obtained by the proposed binocular model, which is 0.011 higher than that obtained by the existing monocular model. To further verify the effectiveness of the binocular design, a binocular model for five-class DR detection is also trained and evaluated on a 10% validation set. The result shows that it achieves a kappa score of 0.829 which is higher than that of the existing non-ensemble model. © 2013 IEEE.","Biomedical imaging processing; convolutional neural network; deep learning; diabetic retinopathy; fundus photograph; Siamese-like network","Binoculars; Computer aided diagnosis; Computer aided instruction; Convolution; Deep learning; Learning algorithms; Medical imaging; Neural networks; Photography; Biomedical imaging; Convolutional neural network; Diabetic retinopathy; Diagnostic procedure; Ensemble modeling; Fundus photographs; Receiver operating curves; Transfer learning; Eye protection","Fundamental Research Foundation of Shenzhen, (JJCYJ20170302151123005); National Natural Science Foundation of China, NSFC, (61601301)","","Institute of Electrical and Electronics Engineers Inc.",""
"Castilla C.; Maska M.; Sorokin D.V.; Meijering E.; Ortiz-De-Solorzano C.","Castilla, Carlos (57038565200); Maska, Martin (23398080800); Sorokin, Dmitry V. (55631871400); Meijering, Erik (55891118400); Ortiz-De-Solorzano, Carlos (55933109800)","57038565200; 23398080800; 55631871400; 55891118400; 55933109800","3-D quantification of filopodia in motile cancer cells","2019","38","3","8482350","862","872","10","10.1109/TMI.2018.2873842","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054522263&doi=10.1109%2fTMI.2018.2873842&partnerID=40&md5=79ac51a8a6a5fb2f58d6561246d06e8a","We present a 3D bioimage analysis workflow to quantitatively analyze single, actin-stained cells with filopodial protrusions of diverse structural and temporal attributes, such as number, length, thickness, level of branching, and lifetime, in time-lapse confocal microscopy image data. Our workflow makes use of convolutional neural networks trained using real as well as synthetic image data, to segment the cell volumes with highly heterogeneous fluorescence intensity levels and to detect individual filopodial protrusions, followed by a constrained nearest-neighbor tracking algorithm to obtain valuable information about the spatio-temporal evolution of individual filopodia. We validated the workflow using real and synthetic 3-D time-lapse sequences of lung adenocarcinoma cells of three morphologically distinct filopodial phenotypes and show that it achieves reliable segmentation and tracking performance, providing a robust, reproducible and less time-consuming alternative to manual analysis of the 3D+t image data. © 1982-2012 IEEE.","3D skeletonization; actin cytoskeleton; Chan-Vese model; confocal microscopy; convolutional neural network; deep learning; Filopodium segmentation and tracking","Adenocarcinoma; Algorithms; Cell Line; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Lung Neoplasms; Neoplasms; Neural Networks, Computer; Pseudopodia; Spatio-Temporal Analysis; Cells; Confocal microscopy; Convolution; Cytology; Deep learning; Diseases; Fluorescence; Image analysis; Image segmentation; Medical imaging; Microscopic examination; Neural networks; Proteins; Actin cytoskeleton; Biomedical imaging; Cancer; Chan-Vese model; Convolutional neural network; Manuals; Segmentation and tracking; Skeletonization; algorithm; Article; cancer cell; cell motility; cell volume; confocal microscopy; cytoskeleton; filopodium; fluorescence analysis; human; human cell; lung adenocarcinoma; phenotype; quantitative analysis; reproducibility; spatiotemporal analysis; workflow; adenocarcinoma; cell line; diagnostic imaging; image processing; lung tumor; neoplasm; pathology; physiology; procedures; pseudopodium; three-dimensional imaging; ultrastructure; Three dimensional displays","MINECO/FEDER; Spanish Ministry of Economy and Competitiveness Competitiveness, (BES-2016-076280, DPI2015-64221-C2-2); Nvidia; European Cooperation in Science and Technology, COST; Grantová Agentura České Republiky, GA ČR, (GJ16-03909Y); Russian Science Foundation, RSF, (17-11-01279)","","Institute of Electrical and Electronics Engineers Inc.","30296215"
"Gi G.; Kim T.Y.; Park H.M.; Park J.M.; Dinh D.-L.; Lee S.Y.; Kim T.-S.","Gi, Geon (57196186341); Kim, Tae Yeon (57196187437); Park, Hye Min (57209362198); Park, Jeong Min (8899154600); Dinh, Dong-Luong (56015754900); Lee, Soo Yeol (57218216918); Kim, Tae-Seong (36072897600)","57196186341; 57196187437; 57209362198; 8899154600; 56015754900; 57218216918; 36072897600","Real Time 3D Pose Estimation of Both Human Hands via RGB-Depth Camera and Deep Convolutional Neural Networks","2020","69","","","467","471","4","10.1007/978-981-13-5859-3_81","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067567006&doi=10.1007%2f978-981-13-5859-3_81&partnerID=40&md5=56891b19e5845864c6472acdff87901d","3D human hand pose estimation (HPE) is an essential methodology for smart human computer interfaces. Especially, 3D hand pose estimation without attached or hand-held sensors provides a more natural and convenient way. In this work, we present a HPE system with a single RGB-Depth camera and deep learning methodologies which recognizes 3D hand poses of both hands in real-time. Our HPE system consists of four steps: hands detection and segmentation, right and left hand classification using a Convolutional Neural Network (CNN) classifier, hand pose estimation using a deep CNN regressor, and 3D hand pose reconstruction. First, both hands are detected and segmented from each RGB and depth images using skin detection and depth cutting algorithms. Second, a CNN classifier is used to distinguish right and left hands. Our CNN classifier consists of three convolutional layers and two fully connected layers, and uses the segmented depth images as input. Third, a trained deep CNN regressor estimates the key sixteen joints of hands in 3D from the segmented left and right depth hands separately. The regressor is hierarchically composed of multiple convolutional layers, pooling layers and dense fully connected layers to estimate the hand joints from the segmented hand depth images. Finally, 3D hand pose of each hand gets reconstructed from the estimated hand joints. The results show that our CNN classifier distinguishes the right and left hands with an accuracy of 96.9%. The 3D human hand poses are estimated with an average distance error of 8.48 mm. The presented HPE system can be used in various application fields including medical VR, AR, and MR applications. Our presented HPE system should allow natural hand gesture interfaces to interact with various medical contents. © 2020, Springer Nature Singapore Pte Ltd.","3-D hand pose recognition; Both hands; Convolutional neural network; Deep learning; RGB-depth","Biomedical engineering; Cameras; Convolution; Deep learning; Deep neural networks; Developing countries; Human computer interaction; Image reconstruction; Neural networks; 3D hand pose estimations; Application fields; Both hands; Convolutional neural network; Hand pose estimations; Hand pose recognition; Human computer interfaces; RGB-depth; Palmprint recognition","Research and Development; Ministry of Trade, Industry and Energy, MOTIE, (N0002252); Ministry of Trade, Industry and Energy, MOTIE","Van Toi V.; Le T.Q.; Ngo H.T.; Nguyen T.-H.","Springer Verlag",""
"Baloglu U.B.; Yildirim Ö.","Baloglu, Ulas Baran (16232502300); Yildirim, Özal (55293146500)","16232502300; 55293146500","CONVOLUTIONAL LONG-SHORT TERM MEMORY NETWORKS MODEL for LONG DURATION EEG SIGNAL CLASSIFICATION","2019","19","1","1940005","","","","10.1142/S0219519419400050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061243825&doi=10.1142%2fS0219519419400050&partnerID=40&md5=b3e20a35e012c2155f68eec516ee31dc","Background and objective: Deep learning structures have recently achieved remarkable success in the field of machine learning. Convolutional neural networks (CNN) in image processing and long-short term memory (LSTM) in the time-series analysis are commonly used deep learning algorithms. Healthcare applications of deep learning algorithms provide important contributions for computer-aided diagnosis research. In this study, convolutional long-short term memory (CLSTM) network was used for automatic classification of EEG signals and automatic seizure detection. Methods: A new nine-layer deep network model consisting of convolutional and LSTM layers was designed. The signals processed in the convolutional layers were given as an input to the LSTM network whose outputs were processed in densely connected neural network layers. The EEG data is appropriate for a model having 1-D convolution layers. A bidirectional model was employed in the LSTM layer. Results: Bonn University EEG database with five different datasets was used for experimental studies. In this database, each dataset contains 23.6s duration 100 single channel EEG segments which consist of 4097 dimensional samples (173.61Hz). Eight two-class and three three-class clinical scenarios were examined. When the experimental results were evaluated, it was seen that the proposed model had high accuracy on both binary and ternary classification tasks. Conclusions: The proposed end-to-end learning structure showed a good performance without using any hand-crafted feature extraction or shallow classifiers to detect the seizures. The model does not require filtering, and also automatically learns to filter the input as well. As a result, the proposed model can process long duration EEG signals without applying segmentation, and can detect epileptic seizures automatically by using the correlation of ictal and interictal signals of raw data. © 2019 World Scientific Publishing Company.","Convolutional neural networks; deep learning; EEG classification; long-short term memory; seizure detection","Biomedical signal processing; Brain; Computer aided diagnosis; Computer aided instruction; Convolution; Correlation detectors; Deep learning; Feature extraction; Image processing; Learning algorithms; Medical computing; Network layers; Time series analysis; Automatic classification; Automatic seizure detections; Classification tasks; Convolutional neural network; EEG classification; EEG signal classification; Health care application; Seizure detection; Long short-term memory","","","World Scientific Publishing Co. Pte Ltd",""
"Zhang R.; Zong Q.; Dou L.; Zhao X.","Zhang, Ruilong (57196197892); Zong, Qun (7006197871); Dou, Liqian (24079928700); Zhao, Xinyi (57200159026)","57196197892; 7006197871; 24079928700; 57200159026","A novel hybrid deep learning scheme for four-class motor imagery classification","2019","16","6","066004","","","","10.1088/1741-2552/ab3471","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073312081&doi=10.1088%2f1741-2552%2fab3471&partnerID=40&md5=b6e23c6e3fe19d0689864dc805aaf248","Objective. Learning the structures and unknown correlations of a motor imagery electroencephalogram (MI-EEG) signal is important for its classification. It is also a major challenge to obtain good classification accuracy from the increased number of classes and increased variability from different people. In this study, a four-class MI task is investigated. Approach. An end-To-end novel hybrid deep learning scheme is developed to decode the MI task from EEG data. The proposed algorithm consists of two parts: A. A one-versus-rest filter bank common spatial pattern is adopted to preprocess and pre-extract the features of the four-class MI signal. b. A hybrid deep network based on the convolutional neural network and long-Term short-Term memory network is proposed to extract and learn the spatial and temporal features of the MI signal simultaneously. Main results. The main contribution of this paper is to propose a hybrid deep network framework to improve the classification accuracy of the four-class MI-EEG signal. The hybrid deep network is a subject-independent shared neural network, which means it can be trained by using the training data from all subjects to form one model. Significance. The classification performance obtained by the proposed algorithm on brain-computer interface (BCI) competition IV dataset 2a in terms of accuracy is 83% and Cohen's kappa value is 0.80. Finally, the shared hybrid deep network is evaluated by every subject respectively, and the experimental results illustrate that the shared neural network has satisfactory accuracy. Thus, the proposed algorithm could be of great interest for real-life BCIs. © 2019 IOP Publishing Ltd.","","Brain; Deep Learning; Electroencephalography; Humans; Imagination; Movement; Neural Networks, Computer; Biomedical signal processing; Brain computer interface; Classification (of information); Electroencephalography; Image classification; Neural networks; Classification accuracy; Classification performance; Common spatial patterns; Convolutional neural network; Motor imagery classification; Network frameworks; Short term memory; Temporal features; accuracy; algorithm; Article; brain computer interface; convolutional neural network; deep learning; electroencephalography; feature extraction; human; imagery; priority journal; short term memory; brain; classification; imagination; movement (physiology); physiology; Deep learning","","","Institute of Physics Publishing","31341093"
"Nahas H.; Ishii T.; Chee A.; Yiu B.; Yu A.","Nahas, Hassan (57209107977); Ishii, Takuro (57404498200); Chee, Adrian (56702486300); Yiu, Billy (26657783600); Yu, Alfred (8699317700)","57209107977; 57404498200; 56702486300; 26657783600; 8699317700","Segmentation of aliasing artefacts in ultrasound color flow imaging using convolutional neural networks","2019","11663 LNCS","","","452","461","9","10.1007/978-3-030-27272-2_40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071468813&doi=10.1007%2f978-3-030-27272-2_40&partnerID=40&md5=66f5780935dd188ba2a7b5b5099e0068","Color flow imaging is a biomedical ultrasound modality used to visualize blood flow dynamics in the blood vessels, which are correlated with cardiovascular function and pathology. This is however done through a pulsed echo sensing mechanism and thus flow measurements can be corrupted by aliasing artefacts, hindering its application. While various methods have attempted to address these artefacts, there is still demand for a robust and flexible solution, particularly at the stage of identifying the aliased regions in the imaging view. In this paper, we investigate the application of convolutional neural networks to segment aliased regions in color flow images due to their strength in translation-invariant learning of complex features. Relevant ultrasound features including phase shifts, speckle images and optical flow were generated from ultrasound data obtained from anthropomorphic flow models. The investigated neural networks all showed strong performance in terms of precision, recall and intersection over union while revealing the important ultrasound features that improved detection. This study paves the way for sophisticated dealiasing algorithms in color flow imaging. © Springer Nature Switzerland AG 2019.","Aliasing; Cardiovascular; Color flow imaging; Convolutional neural networks; Deep learning; Doppler; Ultrasound imaging","Blood; Blood vessels; Color; Convolution; Deep learning; Deep neural networks; Image segmentation; Neural networks; Ultrasonic imaging; Aliasing; Cardiovascular; Color flow imaging; Convolutional neural network; Doppler; Ultrasound imaging; Image analysis","","Karray F.; Yu A.; Campilho A.","Springer Verlag",""
"Anusha C.; Avadhani P.S.","Anusha, Chamarty (57211622942); Avadhani, P.S. (57204399665)","57211622942; 57204399665","Optimal accuracy zone identification in object detection technique-a learning rate methodology","2019","9","1","","6470","6476","6","10.35940/ijeat.A2258.109119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074655906&doi=10.35940%2fijeat.A2258.109119&partnerID=40&md5=00034cb65b7b053da8703fb28736ad43","In the recent past, Deep Learning models [1] are predominantly being used in Object Detection algorithms due to their accurate Image Recognition capability. These models extract features from the input images and videos [2] for identification of objects present in them. Various applications of these models include Image Processing, Video analysis, Speech Recognition, Biomedical Image Analysis, Biometric Recognition, Iris Recognition, National Security applications, Cyber Security, Natural Language Processing [3], Weather Forecasting applications, Renewable Energy Generation Scheduling etc. These models utilize the concept of Convolutional Neural Network (CNN) [3], which constitutes several layers of artificial neurons. The accuracy of Deep Learning models [1] depends on various parameters such as ‘Learning-rate’, ‘Training batch size’, ‘Validation batch size’, ‘Activation Function’, ‘Drop-out rate’ etc. These parameters are known as Hyper-Parameters. Object detection accuracy depends on selection of Hyper-parameters and these in-turn decides the optimum accuracy. Hence, finding the best values for these parameters is a challenging task. Fine-Tuning is a process used for selection of a suitable Hyper-Parameter value for improvement of object detection accuracy. Selection of an inappropriate Hyper-Parameter value, leads to Over-Fitting or Under-Fitting of data. Over-Fitting is a case, when training data is larger than the required, which results in learning noise and inaccurate object detection. Under-fitting is a case, when the model is unable to capture the trend of the data and which leads to more erroneous results in testing or training data. In this paper, a balance between Over-fitting and Under-fitting is achieved by varying the ‘Learning rate’ of various Deep Learning models. Four Deep Learning Models such as VGG16, VGG19, InceptionV3 and Xception are considered in this paper for analysis purpose. The best zone of Learning-rate for each model, in respect of maximum Object Detection accuracy, is analyzed. In this paper a dataset of 70 object classes is taken and the prediction accuracy is analyzed by changing the ‘Learning-rate’ and keeping the rest of the Hyper-Parameters constant. This paper mainly concentrates on the impact of ‘Learning-rate’ on accuracy and identifies an optimum accuracy zone in Object Detection. © BEIESP.","Convolution neural network; Deep learning; Hyper-parameter; InceptionV3; Learning-rate; Object detection; VGG-16; VGG-19; Xception","","","","Blue Eyes Intelligence Engineering and Sciences Publication",""
"Parvan M.; Ghiasi A.R.; Rezaii T.Y.; Farzamnia A.","Parvan, Milad (57210583259); Ghiasi, Amir Rikhtehgar (57193204879); Rezaii, Tohid Yousefi (24776924800); Farzamnia, Ali (48761265400)","57210583259; 57193204879; 24776924800; 48761265400","Transfer Learning based Motor Imagery Classification using Convolutional Neural Networks","2019","","","8786636","1825","1828","3","10.1109/IranianCEE.2019.8786636","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071002235&doi=10.1109%2fIranianCEE.2019.8786636&partnerID=40&md5=75d549c9389204a56d7856b652c5924b","Nowadays, classification of signals is considered as the crucial role of motor imagery brain computer interface. Moreover, deep learning approaches show acceptable performance in image recognition applications as well as speech recognition. However, practicality of the aforementioned technique is not generally deployed on motor imagery tasks. Hence, the goal of this paper is to apply convolutional neural networks to classify the motor imagery EEG signals. In addition, data augmentation along with excusive transfer learning strategy are used to overcome the problem of few trials in motor imagery tasks. On the other hand, analytical regression assessments are also applied to the raw data for mitigating the stress of EOG on EEG. Consequently, the simulation results clearly convey the contribution of the proposed algorithm via testing on BCI competition IV dataset 2b. Applying EOG artifact removal and data augmentation methods resulted in 0.07 improvement in kappa coefficient. Furthermore, using our proposed transfer learning method led to 0.06 improvement in terms of kappa coefficient. © 2019 IEEE.","brain computer interface; deep learning; motor imagery; transfer learning","Biomedical signal processing; Brain computer interface; Convolution; Deep learning; Image recognition; Neural networks; Speech recognition; Statistical tests; Acceptable performance; Convolutional neural network; Motor imagery; Motor imagery classification; Motor imagery eeg signals; Motor imagery tasks; Transfer learning; Transfer learning methods; Image classification","","","Institute of Electrical and Electronics Engineers Inc.",""
"Shikalgar A.J.; Sonavane S.","Shikalgar, Arifa J. (57190161198); Sonavane, Shefali (48761992300)","57190161198; 48761992300","Design and Development of Integrated Deep Convolution Neural Network Approach for Handling Heterogeneous Medical Data","2019","","","8701358","218","223","5","10.1109/AICAI.2019.8701358","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065624934&doi=10.1109%2fAICAI.2019.8701358&partnerID=40&md5=600d5e6ed8bd4b95b6209a67260fd2cc","In recent years, Neural Network (NN) is developed as an optimal technique for the prediction of tasks which include image classification, speech recognition and also useful in biomedical analysis. Biomedical data consists of diverse modalities like X-ray, CT, MRI, PET, EEG and ECG signals. There are several NNs techniques such as Artificial Neural Network (ANN), Convolutional Neural Network (CNN) and Deep Neural Network (DNN) that are used for various prediction applications in handling multimodal heterogeneous data. However, learning and prediction of such multimodal data limits the scope of existing neural techniques. One of the limitations of ANN observes that addition of layer cause back propagation stuck in local minima and reduction of learning speed. Where, DNN causes higher computational complexity in training the features which are based on contrastive divergence. In CNN there is loses of spatial information due to the weight factors variation. To overcome these issues, this paper proposes a novel learning technique in which the weight factor of DNN is integrated with CNN for handling multimodal heterogeneous data. The simulation results prove that the integrated learning technique (IDCNN) obtains better learning performance than ANN, CNN and DNN models in terms of Root Mean Square Error (RMSE) and efficiency in terms of cross entropy. © 2019 IEEE.","Artificial Neural Network (ANN); Convolutional Neural Network (CNN); Deep Neural Network (DNN); Heterogeneous data","Backpropagation; Computerized tomography; Convolution; Data handling; Forecasting; Learning algorithms; Mean square error; Neural networks; Speech recognition; Contrastive divergence; Convolution neural network; Convolutional neural network; Design and Development; Heterogeneous data; Learning performance; Root mean square errors; Spatial informations; Deep neural networks","","","Institute of Electrical and Electronics Engineers Inc.",""
"Toğaçar M.; Ergen B.; Cömert Z.","Toğaçar, Mesut (57205581917); Ergen, Burhan (6508022484); Cömert, Zafer (36543652400)","57205581917; 6508022484; 36543652400","BrainMRNet: Brain tumor detection using magnetic resonance images with a novel convolutional neural network model","2020","134","","109531","","","","10.1016/j.mehy.2019.109531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076824450&doi=10.1016%2fj.mehy.2019.109531&partnerID=40&md5=af1856c13e893721463999b11b0ad0b6","A brain tumor is a mass that grows unevenly in the brain and directly affects human life. This mass occurs spontaneously because of the tissues surrounding the brain or the skull. Surgical methods are generally preferred for the treatment of the brain tumor. Recently, models of deep learning in the diagnosis and treatment of diseases in the biomedical field have gained intense interest. In this study, we propose a new convolutional neural network model named BrainMRNet. This architecture is built on attention modules and hypercolumn technique; it has a residual network. Firstly, image is preprocessed in BrainMRNet. Then, this step is transferred to attention modules using image augmentation techniques for each image. Attention modules select important areas of the image and the image is transferred to convolutional layers. One of the most important techniques that the BrainMRNet model uses in the convolutional layers is hypercolumn. With the help of this technique, the features extracted from each layer of the BrainMRNet model are retained by the array structure in the last layer. The aim is to select the best and the most efficient features among the features maintained in the array. Accessible magnetic resonance images were used to detect brain tumor with the BrainMRNet model. BrainMRNet model is more successful than the pre-trained convolutional neural network models (AlexNet, GoogleNet, VGG-16) used in this study. The classification success achieved with the BrainMRNet model was 96.05%. © 2019 Elsevier Ltd","Attention module; Biomedical signal processing; Brain tumor; Hypercolumn technique; Magnetic resonance image","Algorithms; Brain Neoplasms; Datasets as Topic; Deep Learning; Diagnosis, Computer-Assisted; Early Detection of Cancer; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neuroimaging; Signal Processing, Computer-Assisted; accuracy; Article; brain tumor; calculation; classification algorithm; controlled study; convolutional neural network; human; image analysis; major clinical study; nonlinear system; nuclear magnetic resonance imaging; prediction; simulation; tumor diagnosis; algorithm; brain tumor; classification; comparative study; computer assisted diagnosis; diagnostic imaging; early cancer diagnosis; image processing; information processing; neuroimaging; procedures; signal processing","","","Churchill Livingstone","31877442"
"Liu F.; Feng L.; Kijowski R.","Liu, Fang (55877583300); Feng, Li (55606532200); Kijowski, Richard (8680578300)","55877583300; 55606532200; 8680578300","MANTIS: Model-Augmented Neural neTwork with Incoherent k-space Sampling for efficient MR parameter mapping","2019","82","1","","174","188","14","10.1002/mrm.27707","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062798877&doi=10.1002%2fmrm.27707&partnerID=40&md5=38500362c55f3ae2bdb7288cf3a2fd39","Purpose: To develop and evaluate a novel deep learning-based image reconstruction approach called MANTIS (Model-Augmented Neural neTwork with Incoherent k-space Sampling) for efficient MR parameter mapping. Methods: MANTIS combines end-to-end convolutional neural network (CNN) mapping, incoherent k-space undersampling, and a physical model as a synergistic framework. The CNN mapping directly converts a series of undersampled images straight into MR parameter maps using supervised training. Signal model fidelity is enforced by adding a pathway between the undersampled k-space and estimated parameter maps to ensure that the parameter maps produced synthesized k-space consistent with the acquired undersampling measurements. The MANTIS framework was evaluated on the T2 mapping of the knee at different acceleration rates and was compared with 2 other CNN mapping methods and conventional sparsity-based iterative reconstruction approaches. Global quantitative assessment and regional T2 analysis for the cartilage and meniscus were performed to demonstrate the reconstruction performance of MANTIS. Results: MANTIS achieved high-quality T2 mapping at both moderate (R = 5) and high (R = 8) acceleration rates. Compared to conventional reconstruction approaches that exploited image sparsity, MANTIS yielded lower errors (normalized root mean square error of 6.1% for R = 5 and 7.1% for R = 8) and higher similarity (structural similarity index of 86.2% at R = 5 and 82.1% at R = 8) to the reference in the T2 estimation. MANTIS also achieved superior performance compared to direct CNN mapping and a 2-step CNN method. Conclusion: The MANTIS framework, with a combination of end-to-end CNN mapping, signal model-augmented data consistency, and incoherent k-space sampling, is a promising approach for efficient and robust estimation of quantitative MR parameters. © 2019 International Society for Magnetic Resonance in Medicine","convolutional neural network; deep learning; image reconstruction; incoherence k-space sampling; model augmentation; model-based reconstruction; MR parameter mapping","Aged; Algorithms; Deep Learning; Female; Humans; Image Processing, Computer-Assisted; Knee Joint; Magnetic Resonance Imaging; Male; Middle Aged; Neural Networks, Computer; Biomedical signal processing; Convolution; Deep learning; Deep neural networks; Image reconstruction; Image sampling; Iterative methods; Learning systems; Mapping; Mean square error; Parameter estimation; Estimated parameter; Iterative reconstruction; K-space sampling; Model based reconstruction; Quantitative assessments; Root mean square errors; Structural similarity indices; Supervised trainings; acceleration; article; deep learning; error; image reconstruction; knee meniscus; physical model; quantitative analysis; sampling; aged; algorithm; diagnostic imaging; female; human; image processing; knee; male; middle aged; nuclear magnetic resonance imaging; procedures; Convolutional neural networks","National Institute of Biomedical Imaging and Bioengineering, NIBIB, (P41EB022544)","","John Wiley and Sons Inc","30860285"
"Rudie J.D.; Weiss D.A.; Saluja R.; Rauschecker A.M.; Wang J.; Sugrue L.; Bakas S.; Colby J.B.","Rudie, Jeffrey D. (36911792800); Weiss, David A. (57650432400); Saluja, Rachit (57212755785); Rauschecker, Andreas M. (6505618044); Wang, Jiancong (57195777016); Sugrue, Leo (57192379976); Bakas, Spyridon (55366125000); Colby, John B. (37030647000)","36911792800; 57650432400; 57212755785; 6505618044; 57195777016; 57192379976; 55366125000; 37030647000","Multi-Disease Segmentation of Gliomas and White Matter Hyperintensities in the BraTS Data Using a 3D Convolutional Neural Network","2019","13","","84","","","","10.3389/fncom.2019.00084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077392640&doi=10.3389%2ffncom.2019.00084&partnerID=40&md5=b0f569321ebc713b7f2421680af8fb4d","An important challenge in segmenting real-world biomedical imaging data is the presence of multiple disease processes within individual subjects. Most adults above age 60 exhibit a variable degree of small vessel ischemic disease, as well as chronic infarcts, which will manifest as white matter hyperintensities (WMH) on brain MRIs. Subjects diagnosed with gliomas will also typically exhibit some degree of abnormal T2 signal due to WMH, rather than just due to tumor. We sought to develop a fully automated algorithm to distinguish and quantify these distinct disease processes within individual subjects’ brain MRIs. To address this multi-disease problem, we trained a 3D U-Net to distinguish between abnormal signal arising from tumors vs. WMH in the 3D multi-parametric MRI (mpMRI, i.e., native T1-weighted, T1-post-contrast, T2, T2-FLAIR) scans of the International Brain Tumor Segmentation (BraTS) 2018 dataset (ntraining = 285, nvalidation = 66). Our trained neuroradiologist manually annotated WMH on the BraTS training subjects, finding that 69% of subjects had WMH. Our 3D U-Net model had a 4-channel 3D input patch (80 × 80 × 80) from mpMRI, four encoding and decoding layers, and an output of either four [background, active tumor (AT), necrotic core (NCR), peritumoral edematous/infiltrated tissue (ED)] or five classes (adding WMH as the fifth class). For both the four- and five-class output models, the median Dice for whole tumor (WT) extent (i.e., union of AT, ED, NCR) was 0.92 in both training and validation sets. Notably, the five-class model achieved significantly (p = 0.002) lower/better Hausdorff distances for WT extent in the training subjects. There was strong positive correlation between manually segmented and predicted volumes for WT (r = 0.96) and WMH (r = 0.89). Larger lesion volumes were positively correlated with higher/better Dice scores for WT (r = 0.33), WMH (r = 0.34), and across all lesions (r = 0.89) on a log(10) transformed scale. While the median Dice for WMH was 0.42 across training subjects with WMH, the median Dice was 0.62 for those with at least 5 cm3 of WMH. We anticipate the development of computational algorithms that are able to model multiple diseases within a single subject will be a critical step toward translating and integrating artificial intelligence systems into the heterogeneous real-world clinical workflow. © Copyright © 2019 Rudie, Weiss, Saluja, Rauschecker, Wang, Sugrue, Bakas and Colby.","convolutional neural network; deep learning; glioblastoma; multi-disease classification; radiology; segmentation; white matter hyperintensities","Convolution; Deep learning; Deep neural networks; Image segmentation; Medical imaging; Neural networks; Radiology; Artificial intelligence systems; Brain tumor segmentation; Computational algorithm; Convolutional neural network; Disease classification; Glioblastomas; Positive correlations; White matter hyperintensities; adult; algorithm; Article; artificial intelligence; cancer infiltration; cancer size; contrast enhancement; controlled study; convolutional neural network; disease course; glioblastoma; human; image analysis; image segmentation; major clinical study; multiparametric magnetic resonance imaging; nervous system parameters; neuroradiologist; nuclear magnetic resonance imaging; signal processing; three dimensional imaging; validation process; white matter hyperintensity; Tumors","NIH/NCI; NIH/NIBIB; NIH/NINDS; National Institutes of Health, NIH; National Cancer Institute, NCI, (U24CA189523); National Cancer Institute, NCI; National Institute of Neurological Disorders and Stroke, NINDS, (R01NS042645); National Institute of Neurological Disorders and Stroke, NINDS; National Institute of Biomedical Imaging and Bioengineering, NIBIB, (Penn T32 EB004311-10, UCSF T32-EB001631-14); National Institute of Biomedical Imaging and Bioengineering, NIBIB; Nvidia","","Frontiers Media S.A.",""
"Godec P.; Pančur M.; Ilenič N.; Čopar A.; Stražar M.; Erjavec A.; Pretnar A.; Demšar J.; Starič A.; Toplak M.; Žagar L.; Hartman J.; Wang H.; Bellazzi R.; Petrovič U.; Garagna S.; Zuccotti M.; Park D.; Shaulsky G.; Zupan B.","Godec, Primož (56377091000); Pančur, Matjaž (6505935502); Ilenič, Nejc (57211229867); Čopar, Andrej (56248208600); Stražar, Martin (55603807500); Erjavec, Aleš (26036093300); Pretnar, Ajda (57209645602); Demšar, Janez (55075851300); Starič, Anže (55884822000); Toplak, Marko (35118222500); Žagar, Lan (36100591700); Hartman, Jan (57211229987); Wang, Hamilton (57211227150); Bellazzi, Riccardo (58709404600); Petrovič, Uroš (55917218200); Garagna, Silvia (7004583165); Zuccotti, Maurizio (56256935600); Park, Dongsu (8437663600); Shaulsky, Gad (7003920656); Zupan, Blaž (7003934784)","56377091000; 6505935502; 57211229867; 56248208600; 55603807500; 26036093300; 57209645602; 55075851300; 55884822000; 35118222500; 36100591700; 57211229987; 57211227150; 58709404600; 55917218200; 7004583165; 56256935600; 8437663600; 7003920656; 7003934784","Democratized image analytics by visual programming through integration of deep models and small-scale machine learning","2019","10","1","4551","","","","10.1038/s41467-019-12397-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073058466&doi=10.1038%2fs41467-019-12397-x&partnerID=40&md5=3a477570104ac85aa863c7641f976fe8","Analysis of biomedical images requires computational expertize that are uncommon among biomedical scientists. Deep learning approaches for image analysis provide an opportunity to develop user-friendly tools for exploratory data analysis. Here, we use the visual programming toolbox Orange (http://orange.biolab.si) to simplify image analysis by integrating deep-learning embedding, machine learning procedures, and data visualization. Orange supports the construction of data analysis workflows by assembling components for data preprocessing, visualization, and modeling. We equipped Orange with components that use pre-trained deep convolutional networks to profile images with vectors of features. These vectors are used in image clustering and classification in a framework that enables mining of image sets for both novel and experienced users. We demonstrate the utility of the tool in image analysis of progenitor cells in mouse bone healing, identification of developmental competence in mouse oocytes, subcellular protein localization in yeast, and developmental morphology of social amoebae. © 2019, The Author(s).","","Animals; Computational Biology; Dictyostelium; Green Fluorescent Proteins; Image Processing, Computer-Assisted; Internet; Life Cycle Stages; Machine Learning; Mice, Transgenic; Neural Networks, Computer; Oocytes; Reproducibility of Results; Saccharomyces cerevisiae; Saccharomyces cerevisiae Proteins; green fluorescent protein; Saccharomyces cerevisiae protein; algorithm; biochemical composition; data assimilation; data mining; image analysis; machine learning; numerical model; protein; visualization; animal cell; animal experiment; animal model; Article; cellular distribution; convolutional neural network; data analysis; data classification; data clustering; data mining; data processing; data visualization; deep learning; Dictyostelium discoideum; embedding; female; fracture healing; image analysis; model; mouse; nonhuman; oocyte; protein localization; stem cell; workflow; yeast; animal; biology; cytology; Dictyostelium; genetics; growth, development and aging; image processing; Internet; life cycle stage; machine learning; metabolism; procedures; reproducibility; Saccharomyces cerevisiae; transgenic mouse","National Institute of General Medical Sciences, NIGMS, (R35GM118016)","","Nature Publishing Group","31591416"
"Gavrishchaka V.; Senyukova O.; Koepke M.","Gavrishchaka, Valeriy (35611259700); Senyukova, Olga (42561652200); Koepke, Mark (7003558924)","35611259700; 42561652200; 7003558924","Synergy of physics-based reasoning and machine learning in biomedical applications: Towards unlimited deep learning with limited data","2019","4","1","1582361","","","","10.1080/23746149.2019.1582361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064486372&doi=10.1080%2f23746149.2019.1582361&partnerID=40&md5=8b05d29b2be665717a9c9b850a276ce9","Technological advancements enable collecting vast data, i.e., Big Data, in science and industry including biomedical field. Increased computational power allows expedient analysis of collected data using statistical and machine-learning approaches. Historical data incompleteness problem and curse of dimensionality diminish practical value of pure data-driven approaches, especially in biomedicine. Advancements in deep learning (DL) frameworks based on deep neural networks (DNN) improved accuracy in image recognition, natural language processing, and other applications yet severe data limitations and/or absence of transfer-learning-rele-vant problems drastically reduce advantages of DNN-based DL. Our earlier works demonstrate that hierarchical data representation can be alternatively implemented without NN, using boosting-like algorithms for utilization of existing domain knowledge, tolerating significant data incompleteness, and boosting accuracy of low-complex-ity models within the classifier ensemble, as illustrated in physiological-data analysis. Beyond obvious use in initial-factor selection, existing simplified models are effectively employed for generation of realistic synthetic data for later DNN pre-training. We review existing machine learning approaches, focusing on limitations caused by training-data incompleteness. We outline our hybrid framework that leverages existing domain-expert models/ knowledge, boosting-like model combination, DNN-based DL and other machine learning algorithms for drastic reduction of training-data requirements. Applying this framework is illustrated in context of analyzing physiological data. © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Boosting; Complex biomedical systems; Deep learning (DL); Hybrid machine learning; Nonlinear dynamics; Physiological state quantification","","Council on grants of the President of the Russian Federation","","Taylor and Francis Ltd.",""
"Xiang S.; Liang Q.; Hu Y.; Tang P.; Coppola G.; Zhang D.; Sun W.","Xiang, Shao (57203872779); Liang, Qiaokang (35174463400); Hu, Yucheng (57205548591); Tang, Pen (57209741175); Coppola, Gianmarc (36134250400); Zhang, Dan (58846287300); Sun, Wei (57161531200)","57203872779; 35174463400; 57205548591; 57209741175; 36134250400; 58846287300; 57161531200","AMC-Net: Asymmetric and multi-scale convolutional neural network for multi-label HPA classification","2019","178","","","275","287","12","10.1016/j.cmpb.2019.07.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068552534&doi=10.1016%2fj.cmpb.2019.07.009&partnerID=40&md5=97a5af5007322b59ccd7e20ac6640481","Background and objectives: The multi-label Human Protein Atlas (HPA) classification can yield a better understanding of human diseases and help doctors to enhance the automatic analysis of biomedical images. The existing automatic protein recognition methods have been limited to single pattern. Therefore, an automatic multi-label human protein atlas recognition system with satisfactory performance should be conducted. This work aims to build an automatic recognition system for multi-label human protein atlas classification based on deep learning. Methods: In this work, an automatic feature extraction and multi-label classification framework is proposed. Specifically, an asymmetric and multi-scale convolutional neural network is designed for HPA classification. Furthermore, this work introduces a combined loss that consists of the binary cross-entropy and F1-score losses to improve identification performance. Results: Rigorous experiments are conducted to estimate the proposed system. In particular, unlike the current automatic identification systems, which focus on a limited number of patterns, the proposed method is capable of classifying mixed patterns of proteins in microscope images and can handle the subcellular multi-label protein classification task including 28 subcellular localization patterns. The proposed framework based on deep convolutional neural network outperformed the existing approaches with a F1-score of 0.823, which illustrates the robustness and effectiveness of the proposed system. Conclusion: This study proposed a high-performance recognition system for protein atlas classification based on deep learning, and it achieved an automatic multi-label human protein atlas identification framework with superior performance than previous studies. © 2019 Elsevier B.V.","Convolutional neural network; Deep learning; Human protein atlas; Multi-label classification","Algorithms; Cell Nucleus; Databases, Protein; False Positive Reactions; Humans; Image Processing, Computer-Assisted; Microscopy; Microscopy, Fluorescence; Microtubules; Neural Networks, Computer; Pattern Recognition, Automated; Phenotype; Probability; Proteins; Reproducibility of Results; Automation; Classification (of information); Convolution; Deep learning; Image enhancement; Neural networks; Proteins; protein; Automatic feature extraction; Automatic identification system; Automatic recognition system; Convolutional neural network; Human proteins; Multi label classification; Multi-label proteins; Subcellular localizations; Article; autoanalysis; cellular distribution; classification algorithm; data analysis; deep learning; feature extraction; human protein atlas; microscope image; protein analysis; qualitative analysis; receptive field; algorithm; automated pattern recognition; cell nucleus; chemistry; false positive result; fluorescence microscopy; human; image processing; metabolism; microscopy; microtubule; phenotype; physiology; probability; procedures; protein database; reproducibility; Deep neural networks","Chang-Zhu-Tan National Indigenous Innovation Demonstration Zone Project, (2017XK2102); National Nature Science Foundation of China; National Natural Science Foundation of China, NSFC, (61673163); National Natural Science Foundation of China, NSFC; Changzhou Key Laboratory of Special Robot and Intelligent Technology, (IRT2018003); Changzhou Key Laboratory of Special Robot and Intelligent Technology","","Elsevier Ireland Ltd","31416555"
"Li Y.; Mahjoubfar A.; Chen C.L.; Niazi K.R.; Pei L.; Jalali B.","Li, Yueqin (55653237700); Mahjoubfar, Ata (26028403700); Chen, Claire Lifan (56158834300); Niazi, Kayvan Reza (6603816708); Pei, Li (59286608400); Jalali, Bahram (7004889917)","55653237700; 26028403700; 56158834300; 6603816708; 59286608400; 7004889917","Deep Cytometry: Deep learning with Real-time Inference in Cell Sorting and Flow Cytometry","2019","9","1","","11088","","","10.1038/s41598-019-47193-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070898419&doi=10.1038%2fs41598-019-47193-6&partnerID=40&md5=f2cdeeaa6174f69ec469d7d3e583103b","Deep learning has achieved spectacular performance in image and speech recognition and synthesis. It outperforms other machine learning algorithms in problems where large amounts of data are available. In the area of measurement technology, instruments based on the photonic time stretch have established record real-time measurement throughput in spectroscopy, optical coherence tomography, and imaging flow cytometry. These extreme-throughput instruments generate approximately 1 Tbit/s of continuous measurement data and have led to the discovery of rare phenomena in nonlinear and complex systems as well as new types of biomedical instruments. Owing to the abundance of data they generate, time-stretch instruments are a natural fit to deep learning classification. Previously we had shown that high-throughput label-free cell classification with high accuracy can be achieved through a combination of time-stretch microscopy, image processing and feature extraction, followed by deep learning for finding cancer cells in the blood. Such a technology holds promise for early detection of primary cancer or metastasis. Here we describe a new deep learning pipeline, which entirely avoids the slow and computationally costly signal processing and feature extraction steps by a convolutional neural network that directly operates on the measured signals. The improvement in computational efficiency enables low-latency inference and makes this pipeline suitable for cell sorting via deep learning. Our neural network takes less than a few milliseconds to classify the cells, fast enough to provide a decision to a cell sorter for real-time separation of individual target cells. We demonstrate the applicability of our new method in the classification of OT-II white blood cells and SW-480 epithelial cancer cells with more than 95% accuracy in a label-free fashion.","","Algorithms; Cell Separation; Cells, Cultured; Deep Learning; Flow Cytometry; Humans; Image Processing, Computer-Assisted; Machine Learning; Microscopy; Signal Processing, Computer-Assisted; algorithm; cell culture; cell separation; flow cytometry; human; image processing; machine learning; microscopy; procedures; signal processing","","","NLM (Medline)","31366998"
"Gorantla R.; Singh R.K.; Pandey R.; Jain M.","Gorantla, Rohan (57213834541); Singh, Rajeev Kumar (57213969919); Pandey, Rohan (57215305253); Jain, Mayank (57225721956)","57213834541; 57213969919; 57215305253; 57225721956","Cervical Cancer Diagnosis using CervixNet - A Deep Learning Approach","2019","","","8941985","397","404","7","10.1109/BIBE.2019.00078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077997534&doi=10.1109%2fBIBE.2019.00078&partnerID=40&md5=ca48abb5f5293ce3920024e862cbd43e","Cervical cancer affects 570,000 women globally and is among the most common causes of cancer-related deaths. Cervical cancer is caused due to the Human Papilloma Virus (HPV) which leads to abnormal growth of cells in the cervix region. Regular testing for HPV in women has helped reduce the death rate in developed countries. However, developing nations are still struggling to provide low-cost solutions due to the lack of affordable medical facilities. The skewed ratio of the oncologists to patients has also aggravated the problem. Motivated by the Deep Learning solutions in Bio-medical imaging, we propose a novel CervixNet methodology which performs image enhancement on cervigrams followed by Segmenting the Region of Interest (RoI) and then classifying the RoI to determine the appropriate treatment. For the classification task, a novel Hierarchical Convolutional Mixture of Experts (HCME) algorithm is proposed. HCME is capable of tackling the problem of overfitting, given that small datasets are an inherent problem in the field of biomedical imaging. Our proposed methodology has outperformed all the existing methodologies on publicly available Intel and Mobile-ODT Kaggle dataset giving an Accuracy of 96.77% and kappa score of 0.951. Hence, the results obtained validate our approach to provide first level screening at a low cost. © 2019 IEEE.","Cervical Cancer; Convolutional Neural Networks; Deep Learning; Ensemble Learning","Bioinformatics; Convolution; Costs; Deep learning; Deep neural networks; Diagnosis; Diseases; Image enhancement; Image segmentation; Neural networks; Viruses; Cervical cancers; Classification tasks; Convolutional neural network; Developed countries; Ensemble learning; Human papilloma virus; Mixture of experts; The region of interest (ROI); Medical imaging","","","Institute of Electrical and Electronics Engineers Inc.",""
"Taherisadr M.; Joneidi M.; Rahnavard N.","Taherisadr, Mojtaba (55851614900); Joneidi, Mohsen (55913215300); Rahnavard, Nazanin (6507969392)","55851614900; 55913215300; 6507969392","EEG Signal Dimensionality Reduction and Classification using Tensor Decomposition and Deep Convolutional Neural Networks","2019","2019-October","","8918754","","","","10.1109/MLSP.2019.8918754","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077710084&doi=10.1109%2fMLSP.2019.8918754&partnerID=40&md5=7c9c3661e16a078f701d1515a8e66450","A new deep learning-based electroencephalography (EEG) signal analysis framework is proposed. While deep neural networks, specifically convolutional neural networks (CNNs), have gained remarkable attention recently, they still suffer from high dimensionality of the training data. Two-dimensional input images of CNNs are more vulnerable to be redundant versus one-dimensional input time-series of conventional neural networks. In this study, we propose a new dimensionality reduction framework for reducing the dimension of CNN inputs based on the tensor decomposition of the time-frequency representation of EEG signals. The proposed tensor decomposition-based dimensionality reduction algorithm transforms a large set of slices of the input tensor to a concise set of slices which are called super-slices. Employing super-slices not only handles the artifacts and redundancies of the EEG data but also reduces the dimension of the CNNs training inputs. We also consider different time-frequency representation methods for EEG image generation and provide a comprehensive comparison among them. We test our proposed framework on HCB-MIT data and as results show our approach outperforms other previous studies. © 2019 IEEE.","Convolutional Neural Networks; Dimensionality Reduction; EEG; Tensor Data Analysis; Time-frequency","Biomedical signal processing; Convolution; Deep neural networks; Electroencephalography; Electrophysiology; Machine learning; Neural networks; Tensors; Comprehensive comparisons; Convolutional neural network; Dimensionality reduction; Dimensionality reduction algorithms; High dimensionality; Tensor decomposition; Time frequency; Time-frequency representations; Data reduction","National Science Foundation, NSF; Directorate for Computer and Information Science and Engineering, CISE, (1718195)","","IEEE Computer Society",""
"Lin H.-H.; Lo L.-J.; Chiang W.-C.","Lin, Hsiu-Hsia (35196301700); Lo, Lun-Jou (7102010070); Chiang, Wen-Chung (26658845700)","35196301700; 7102010070; 26658845700","A novel assessment technique for the degree of facial symmetry before and after orthognathic surgery based on three-dimensional contour features using deep learning algorithms","2019","","","","170","173","3","10.1145/3326172.3326222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069219858&doi=10.1145%2f3326172.3326222&partnerID=40&md5=0c25242560f2d2f0695fb21bee8c3cc7","Improvement of the facial asymmetry has become as important as correction of the malocclusion in the evaluation and planning for orthognathic surgery. In this study, we proposed an automatic machine learning system (DLS) to extract three-dimensional (3D) contour features and assess the degree of facial symmetry in patients treated with orthognathic surgery. A total of 500 normal populations were included to construct the DLS. The ground truth was based on an average of the survey of 50 of diverse referees offering their facial symmetry ratings over a 10-point scale for 500 3D facial images via an auto-play and separate slide show. The facial region of interest (ROI) was extracted by removing the disturbed region, such as the ears, the neck and all points above the hairline. A contour map was extracted from the ROI image, and used as an input pattern for automatic DLS, which included a deep convolutional neural network (CNN) for feature extraction, and a regression network provided for prediction. The experimental results showed that our model achieved 78.85% accuracies on held-out test patterns. The facial symmetry degree assessment within 1 degree was 98.63%. In addition, our method was compared with conventional 2D approaches, which obtained better results than 2D-only features which resulted accuracy is 65% using the same sample size, and the CNN system. For clinical application, 100 patients with facial asymmetry were enrolled in evaluating facial symmetry improvement after orthognathic surgery. A paired t-test was used to compare the significance of the differences between the pre-surgery and post- surgery assessing result of facial symmetry using DLS, with p <0.05 considered significant. The mean of preoperative facial symmetry degree (0.92 ± 0.17) was higher than of postoperative (0.65 ± 0.13) with a significant improvement (p = 0.021). © 2019 Copyright is held by the owner/author(s).","Contour map; Degree of facial symmetry; Machine learning; Region of interest (ROI)","Biomedical engineering; Convolutional neural networks; Deep neural networks; Dynamic light scattering; Image segmentation; Learning algorithms; Learning systems; Patient monitoring; Surgery; Assessment technique; Clinical application; Contour map; Facial symmetry; Orthognathic surgeries; Region of interest; Three dimensional contour; Threedimensional (3-d); Deep learning","","","Association for Computing Machinery",""
"Liang Q.; Nan Y.; Coppola G.; Zou K.; Sun W.; Zhang D.; Wang Y.; Yu G.","Liang, Qiaokang (35174463400); Nan, Yang (57217028826); Coppola, Gianmarc (36134250400); Zou, Kunglin (58447764100); Sun, Wei (57161531200); Zhang, Dan (58846287300); Wang, Yaonan (55998880600); Yu, Guanzhen (7403528362)","35174463400; 57217028826; 36134250400; 58447764100; 57161531200; 58846287300; 55998880600; 7403528362","Weakly supervised biomedical image segmentation by reiterative learning","2019","23","3","8394987","1205","1214","9","10.1109/JBHI.2018.2850040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049063548&doi=10.1109%2fJBHI.2018.2850040&partnerID=40&md5=5cbed3aeee7beb49a64dd13b416c09bd","Recent advances in deep learning have produced encouraging results for biomedical image segmentation; however, outcomes rely heavily on comprehensive annotation. In this paper, we propose a neural network architecture and a new algorithm, known as overlapped region forecast, for the automatic segmentation of gastric cancer images. To the best of our knowledge, this report for the first time describes that deep learning has been applied to the segmentation of gastric cancer images. Moreover, a reiterative learning framework that achieves superior performance without pretraining or further manual annotation is presented to train a simple network on weakly annotated biomedical images. We customize the loss function to make the model converge faster while avoiding becoming trapped in local minima. Patch boundary errors were eliminated by our overlapped region forecast algorithm. By studying the characteristics of the model trained using two different patch extraction methods, we train iteratively and integrate predictions and weak annotations to improve the quality of the training data. Using these methods, a mean Intersection over Union coefficient of 0.883 and a mean accuracy of 91.09% were achieved on the partially labeled dataset, thereby securing a win in the 2017 China Big Data and Artificial Intelligence Innovation and Entrepreneurship Competition. © 2018 IEEE.","biomedical image segmentation; deep neural networks; gastric histopathology; Reiterative learning","Algorithms; Histological Techniques; Humans; Image Interpretation, Computer-Assisted; Neural Networks, Computer; Stomach Neoplasms; Supervised Machine Learning; Deep learning; Deep neural networks; Diseases; Forecasting; Iterative methods; Large dataset; Network architecture; Neural networks; Automatic segmentations; Biomedical image segmentation; Biomedical images; Forecast algorithm; gastric histopathology; Learning frameworks; Manual annotation; Reiterative learning; accuracy; Article; histopathology; image preprocessing; image processing; image quality; image segmentation; imaging; inflammation; learning; machine learning; mathematical parameters; necrosis; nerve cell network; recall; reiterative learning; stomach cancer; stomach tumor; training; tumor growth; algorithm; computer assisted diagnosis; diagnostic imaging; histology; human; procedures; supervised machine learning; Image segmentation","Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing; National Natural Science Foundation of China, NSFC, (61673163); National Natural Science Foundation of China, NSFC; Hunan Provincial Science and Technology Department, HSTD, (2016JJ3045); Hunan Provincial Science and Technology Department, HSTD; Natural Science Foundation of Hunan Province; Changzhou Key Laboratory of Special Robot and Intelligent Technology, (IRT2018003); Changzhou Key Laboratory of Special Robot and Intelligent Technology","","Institute of Electrical and Electronics Engineers Inc.","29994489"
"Puchkov A.; Dli M.; Kireyenkova M.","Puchkov, A. (57209225374); Dli, M. (6506157508); Kireyenkova, M. (57209223008)","57209225374; 6506157508; 57209223008","Fuzzy Classification on the Base of Convolutional Neural Networks","2020","902","","","379","391","12","10.1007/978-3-030-12082-5_35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066884136&doi=10.1007%2f978-3-030-12082-5_35&partnerID=40&md5=c3b57004f41f06d9ca9aa0d7617682d9","The paper deals with the algorithm of object classification based on the method of fuzzy logic and the application of artificial convolutional neural networks. Every object can be characterized by a set of data presented in the numerical form and in the form of images (photographs in different parts of the light spectrum). In this case, one object can be matched with a few images associated with it; they can be received by different methods and from different sources. In the algorithm, this generalized totality of images is recognized by convolutional neural networks. A separate neural network is formed for every channel of data receiving. Then, the network outputs are combined for processing in the system of classification on the basis of fuzzy logic output. The normalized outputs of convolutional neural networks are used as values of a membership function to terms of outputs variables when a fuzzy classifier works. For the first adjustment of the convolution neural network hyperparameters, the gradient method is applied. The algorithm is realized in Python language with the use of Keras deep learning library and Tensor Flow library of parallel computation with CUDA technology from NVIDIA company. This paper presents the results of practical application of the developed neuro-fuzzy classifier to forecast the problem of working time losses. © 2020, Springer Nature Switzerland AG.","Classification; Convolutional neural networks; Fuzzy logic; Image recognition","Biomedical engineering; Classification (of information); Computer circuits; Convolution; Deep learning; Fuzzy inference; Fuzzy neural networks; Fuzzy sets; Fuzzy systems; Gradient methods; Image recognition; Membership functions; Convolution neural network; Convolutional neural network; CUDA technologies; Fuzzy classification; Fuzzy classifiers; Neuro fuzzy classifier; Object classification; Parallel Computation; Fuzzy logic","","Petoukhov S.V.; Hu Z.; He M.","Springer Verlag",""
"Mardani M.; Gong E.; Cheng J.Y.; Vasanawala S.S.; Zaharchuk G.; Xing L.; Pauly J.M.","Mardani, Morteza (26325501300); Gong, Enhao (56046651600); Cheng, Joseph Y. (55492647900); Vasanawala, Shreyas S. (6603481663); Zaharchuk, Greg (6602464023); Xing, Lei (7103349003); Pauly, John M. (7101724924)","26325501300; 56046651600; 55492647900; 6603481663; 6602464023; 7103349003; 7101724924","Deep generative adversarial neural networks for compressive sensing MRI","2019","38","1","8417964","167","179","12","10.1109/TMI.2018.2858752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050379878&doi=10.1109%2fTMI.2018.2858752&partnerID=40&md5=deab546e4ac416a20a7101092b158183","                             Undersampled magnetic resonance image (MRI) reconstruction is typically an ill-posed linear inverse task. The time and resource intensive computations require tradeoffs between accuracy and speed. In addition, state-of-the-art compressed sensing (CS) analytics are not cognizant of the image diagnostic quality. To address these challenges, we propose a novel CS framework that uses generative adversarial networks (GAN) to model the (low-dimensional) manifold of high-quality MR images. Leveraging a mixture of least-squares (LS) GANs and pixel-wise ℓ                             1                             /ℓ                             2                              cost, a deep residual network with skip connections is trained as the generator that learns to remove the aliasing artifacts by projecting onto the image manifold. The LSGAN learns the texture details, while the ℓ                             1                             /ℓ                             2                              cost suppresses high-frequency noise. A discriminator network, which is a multilayer convolutional neural network (CNN), plays the role of a perceptual cost that is then jointly trained based on high-quality MR images to score the quality of retrieved images. In the operational phase, an initial aliased estimate (e.g., simply obtained by zero-filling) is propagated into the trained generator to output the desired reconstruction. This demands a very low computational overhead. Extensive evaluations are performed on a large contrast-enhanced MR dataset of pediatric patients. Images rated by expert radiologists corroborate that GANCS retrieves higher quality images with improved fine texture details compared with conventional Wavelet-based and dictionary-learning-based CS schemes as well as with deep-learning-based schemes using pixel-wise training. In addition, it offers reconstruction times of under a few milliseconds, which are two orders of magnitude faster than the current state-of-the-art CS-MRI schemes.                          © 1982-2012 IEEE.","compressed sensing (CS); convolutional neural networks (CNN); Deep learning; diagnostic quality; generative adversarial networks (GAN); rapid reconstruction","Adrenal Glands; Algorithms; Data Compression; Databases, Factual; Humans; Knee; Magnetic Resonance Imaging; Neural Networks, Computer; Phantoms, Imaging; Automobile engine manifolds; Biomedical signal processing; Compressed sensing; Convolution; Costs; Deep learning; Deep neural networks; Diagnosis; Economic and social effects; Gallium nitride; Gas generators; III-V semiconductors; Image enhancement; Image reconstruction; Neural networks; Personnel training; Pixels; Adversarial networks; Compressive sensing; Computational overheads; Contrast-enhanced MR; Convolutional Neural Networks (CNN); Diagnostic quality; High-frequency noise; Magnetic resonance images (MRI); Article; artificial neural network; comparative study; contrast enhancement; controlled study; diagnostic imaging; diagnostic value; entropy; Fourier transformation; human; image quality; image reconstruction; motion; nerve cell network; nuclear magnetic resonance imaging; pediatric patient; quality control; radiologist; total quality management; adrenal gland; algorithm; factual database; imaging phantom; information processing; knee; nuclear magnetic resonance imaging; procedures; Magnetic resonance imaging","National Institute of Biomedical Imaging and Bioengineering, NIBIB, (R01EB009690)","","Institute of Electrical and Electronics Engineers Inc.","30040634"
"Zhang R.; Zhao L.; Lou W.; Abrigo J.M.; Mok V.C.T.; Chu W.C.W.; Wang D.; Shi L.","Zhang, Rongzhao (57207402447); Zhao, Lei (57192935536); Lou, Wutao (37120649300); Abrigo, Jill M. (24461107200); Mok, Vincent C. T. (6603736999); Chu, Winnie C. W. (56588365400); Wang, Defeng (13105571800); Shi, Lin (36107251200)","57207402447; 57192935536; 37120649300; 24461107200; 6603736999; 56588365400; 13105571800; 36107251200","Automatic Segmentation of Acute Ischemic Stroke From DWI Using 3-D Fully Convolutional DenseNets","2018","37","9","8328863","2149","2160","11","10.1109/TMI.2018.2821244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044722617&doi=10.1109%2fTMI.2018.2821244&partnerID=40&md5=6e43d18e8d6f9c6e35fd35e2643a9aae","Acute ischemic stroke is recognized as a common cerebral vascular disease in aging people. Accurate diagnosis and timely treatment can effectively improve the blood supply of the ischemic area and reduce the risk of disability or even death. Understanding the location and size of infarcts plays a critical role in the diagnosis decision. However, manual localization and quantification of stroke lesions are laborious and time-consuming. In this paper, we propose a novel automatic method to segment acute ischemic stroke from diffusion weighted images (DWIs) using deep 3-D convolutional neural networks (CNNs). Our method can efficiently utilize 3-D contextual information and automatically learn very discriminative features in an end-to-end and data-driven way. To relieve the difficulty of training very deep 3-D CNN, we equip our network with dense connectivity to enable the unimpeded propagation of information and gradients throughout the network. We train our model with Dice objective function to combat the severe class imbalance problem in data. A DWI data set containing 242 subjects (90 for training, 62 for validation, and 90 for testing) with various types of acute ischemic stroke was constructed to evaluate our method. Our model achieved high performance on various metrics (Dice similarity coefficient: 79.13%, lesionwise precision: 92.67%, and lesionwise F1 score: 89.25%), outperforming the other state-of-the-art CNN methods by a large margin. We also evaluated the model on ISLES2015-SSIS data set and achieved very competitive performance, which further demonstrated its generalization capacity. The proposed method is fast and accurate, demonstrating a good potential in clinical routines. © 2018 IEEE.","3D convolutional neural networks; Acute ischemic stroke segmentation; deep learning; DWI","Aged; Aged, 80 and over; Algorithms; Brain; Brain Ischemia; Diffusion Magnetic Resonance Imaging; Female; Humans; Imaging, Three-Dimensional; Male; Middle Aged; Neural Networks (Computer); Stroke; Convolution; Deep learning; Diagnosis; Image segmentation; Medical imaging; Neural networks; Personnel training; Statistical tests; Acute ischemic stroke; Biomedical imaging; Convolutional neural network; Lesions; Solid model; Two-dimensional displays; adult; aged; algorithm; Article; artificial neural network; automation; brain ischemia; controlled study; convolutional neural network; diagnostic accuracy; diffusion weighted imaging; entropy; female; functional connectivity; human; image segmentation; intermethod comparison; major clinical study; male; model; qualitative diagnosis; scoring system; three dimensional imaging; training; two-dimensional imaging; validation study; brain; brain ischemia; cerebrovascular accident; diagnostic imaging; diffusion weighted imaging; middle aged; procedures; three dimensional imaging; very elderly; Three dimensional displays","Research Grants Council, (CUHK 14113214, CUHK 14204117); Innovation and Technology Commission, ITC, (GHP-025-17SZ, GHP-028-14SZ); Innovation and Technology Commission, ITC","","Institute of Electrical and Electronics Engineers Inc.","29994088"
"Yang Q.; Yan P.; Zhang Y.; Yu H.; Shi Y.; Mou X.; Kalra M.K.; Zhang Y.; Sun L.; Wang G.","Yang, Qingsong (56288039900); Yan, Pingkun (8346373300); Zhang, Yanbo (38461645700); Yu, Hengyong (20435223800); Shi, Yongyi (57192653283); Mou, Xuanqin (7003389599); Kalra, Mannudeep K. (7007035549); Zhang, Yi (57203829244); Sun, Ling (56683368700); Wang, Ge (7407148134)","56288039900; 8346373300; 38461645700; 20435223800; 57192653283; 7003389599; 7007035549; 57203829244; 56683368700; 7407148134","Low-Dose CT Image Denoising Using a Generative Adversarial Network With Wasserstein Distance and Perceptual Loss","2018","37","6","","1348","1357","9","10.1109/TMI.2018.2827462","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045732471&doi=10.1109%2fTMI.2018.2827462&partnerID=40&md5=4cc9cd720f2ad52e80621f4d5cf568a6","The continuous development and extensive use of computed tomography (CT) in medical practice has raised a public concern over the associated radiation dose to the patient. Reducing the radiation dose may lead to increased noise and artifacts, which can adversely affect the radiologists' judgment and confidence. Hence, advanced image reconstruction from low-dose CT data is needed to improve the diagnostic performance, which is a challenging problem due to its ill-posed nature. Over the past years, various low-dose CT methods have produced impressive results. However, most of the algorithms developed for this application, including the recently popularized deep learning techniques, aim for minimizing the mean-squared error (MSE) between a denoised CT image and the ground truth under generic penalties. Although the peak signal-to-noise ratio is improved, MSE- or weighted-MSE-based methods can compromise the visibility of important structural details after aggressive denoising. This paper introduces a new CT image denoising method based on the generative adversarial network (GAN) with Wasserstein distance and perceptual similarity. The Wasserstein distance is a key concept of the optimal transport theory and promises to improve the performance of GAN. The perceptual loss suppresses noise by comparing the perceptual features of a denoised output against those of the ground truth in an established feature space, while the GAN focuses more on migrating the data noise distribution from strong to weak statistically. Therefore, our proposed method transfers our knowledge of visual perception to the image denoising task and is capable of not only reducing the image noise level but also trying to keep the critical information at the same time. Promising results have been obtained in our experiments with clinical CT images. © 2018 IEEE.","deep learning; image denoising; Low dose CT; perceptual loss; WGAN","Algorithms; Artifacts; Deep Learning; Humans; Image Processing, Computer-Assisted; Radiation Dosage; Signal Processing, Computer-Assisted; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Diagnosis; Gallium nitride; III-V semiconductors; Image enhancement; Image reconstruction; Learning algorithms; Learning systems; Mean square error; Medical imaging; Noise abatement; Signal to noise ratio; Statistical mechanics; Adversarial networks; Biomedical imaging; Continuous development; Diagnostic performance; Low-dose CT; Peak Signal to Noise Ratio (PSNR); Perceptual similarity; WGAN; algorithm; Article; artificial neural network; computer assisted tomography; generative adversarial network; image analysis; image processing; image quality; image reconstruction; noise reduction; photon; quantitative analysis; radiation dose; signal noise ratio; Wasserstein distance; artifact; human; image processing; procedures; signal processing; x-ray computed tomography; Image denoising","National Institute of Biomedical Imaging and Bioengineering/National Institutes of Health; National Institutes of Health, NIH, (U01 EB017140); National Institutes of Health, NIH; National Institute of Biomedical Imaging and Bioengineering, NIBIB, (R01EB016977); National Institute of Biomedical Imaging and Bioengineering, NIBIB; National Natural Science Foundation of China, NSFC, (61671312); National Natural Science Foundation of China, NSFC","","Institute of Electrical and Electronics Engineers Inc.","29870364"
"Zahia S.; Sierra-Sosa D.; Garcia-Zapirain B.; Elmaghraby A.","Zahia, Sofia (57201091335); Sierra-Sosa, Daniel (37076014100); Garcia-Zapirain, Begonya (35732954700); Elmaghraby, Adel (7004230200)","57201091335; 37076014100; 35732954700; 7004230200","Tissue classification and segmentation of pressure injuries using convolutional neural networks","2018","159","","","51","58","7","10.1016/j.cmpb.2018.02.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043369305&doi=10.1016%2fj.cmpb.2018.02.018&partnerID=40&md5=aab242960976e1122e2b5ddd9e25baca","Background and Objectives: This paper presents a new approach for automatic tissue classification in pressure injuries. These wounds are localized skin damages which need frequent diagnosis and treatment. Therefore, a reliable and accurate systems for segmentation and tissue type identification are needed in order to achieve better treatment results. Methods: Our proposed system is based on a Convolutional Neural Network (CNN) devoted to performing optimized segmentation of the different tissue types present in pressure injuries (granulation, slough, and necrotic tissues). A preprocessing step removes the flash light and creates a set of 5x5 sub-images which are used as input for the CNN network. The network output will classify every sub-image of the validation set into one of the three classes studied. Results: The metrics used to evaluate our approach show an overall average classification accuracy of 92.01%, an average total weighted Dice Similarity Coefficient of 91.38%, and an average precision per class of 97.31% for granulation tissue, 96.59% for necrotic tissue, and 77.90% for slough tissue. Conclusions: Our system has been proven to make recognition of complicated structures in biomedical images feasible. © 2018 Elsevier B.V.","Convolutional neural networks; Deep learning; Image segmentation; Pressure injuries; Tissue type classification","Algorithms; Databases, Factual; Humans; Image Processing, Computer-Assisted; Models, Anatomic; Models, Statistical; Necrosis; Neural Networks (Computer); Pressure Ulcer; Reproducibility of Results; Sensitivity and Specificity; Tomography, X-Ray Computed; Wound Healing; Wounds and Injuries; Convolution; Deep learning; Granulation; Image segmentation; Neural networks; Tissue engineering; Classification accuracy; Complicated structures; Convolutional neural network; Convolutional Neural Networks (CNN); Optimized segmentation; Similarity coefficients; Tissue classification; Tissue types; Article; automated pattern recognition; clinical evaluation; constants and coefficients; controlled study; convolutional neural network; decubitus; dice similarity coefficient; granulation tissue; image analysis; image processing; image segmentation; machine learning; measurement accuracy; measurement precision; pathological tissue; sensitivity and specificity; slough tissue; tissue characterization; tissue injury; tissue necrosis; validation process; algorithm; anatomic model; artificial neural network; decubitus; diagnostic imaging; factual database; human; injury; necrosis; reproducibility; statistical model; wound healing; x-ray computed tomography; Tissue","Department of Electricial and Computer Engineering, Boston University, (IT905-16); University of Louisville, UL","","Elsevier Ireland Ltd","29650318"
"Oktay O.; Ferrante E.; Kamnitsas K.; Heinrich M.; Bai W.; Caballero J.; Cook S.A.; De Marvao A.; Dawes T.; O'Regan D.P.; Kainz B.; Glocker B.; Rueckert D.","Oktay, Ozan (36782675600); Ferrante, Enzo (55892013900); Kamnitsas, Konstantinos (57190428353); Heinrich, Mattias (52363917500); Bai, Wenjia (55570917300); Caballero, Jose (56410493800); Cook, Stuart A. (7402119166); De Marvao, Antonio (57190859080); Dawes, Timothy (25027032400); O'Regan, Declan P. (57337412200); Kainz, Bernhard (25937325100); Glocker, Ben (23396784900); Rueckert, Daniel (7004895812)","36782675600; 55892013900; 57190428353; 52363917500; 55570917300; 56410493800; 7402119166; 57190859080; 25027032400; 57337412200; 25937325100; 23396784900; 7004895812","Anatomically Constrained Neural Networks (ACNNs): Application to Cardiac Image Enhancement and Segmentation","2018","37","2","8051114","384","395","11","10.1109/TMI.2017.2743464","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030790219&doi=10.1109%2fTMI.2017.2743464&partnerID=40&md5=8ecc1c7f552cc4896eaadea5451161ab","Incorporation of prior knowledge about organ shape and location is key to improve performance of image analysis approaches. In particular, priors can be useful in cases where images are corrupted and contain artefacts due to limitations in image acquisition. The highly constrained nature of anatomical objects can be well captured with learning-based techniques. However, in most recent and promising techniques such as CNN-based segmentation it is not obvious how to incorporate such prior knowledge. State-of-the-art methods operate as pixel-wise classifiers where the training objectives do not incorporate the structure and inter-dependencies of the output. To overcome this limitation, we propose a generic training strategy that incorporates anatomical prior knowledge into CNNs through a new regularisation model, which is trained end-to-end. The new framework encourages models to follow the global anatomical properties of the underlying anatomy (e.g. shape, label structure) via learnt non-linear representations of the shape. We show that the proposed approach can be easily adapted to different analysis tasks (e.g. image enhancement, segmentation) and improve the prediction accuracy of the state-of-the-art models. The applicability of our approach is shown on multi-modal cardiac data sets and public benchmarks. In addition, we demonstrate how the learnt deep models of 3-D shapes can be interpreted and used as biomarkers for classification of cardiac pathologies. © 1982-2012 IEEE.","convolutional neural network; image super-resolution; medical image segmentation; Shape prior","Algorithms; Cardiac Imaging Techniques; Cardiomyopathies; Databases, Factual; Heart; Humans; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Neural Networks (Computer); Image analysis; Image resolution; Image segmentation; Medical imaging; Neural networks; Biomedical imaging; Computational model; Convolutional neural network; Image super resolutions; Motion segmentation; Shape; Shape priors; Article; cardiac imaging; controlled study; heart disease; heart function; heuristics; human; image analysis; image enhancement; image reconstruction; image segmentation; learning; nerve cell network; normal human; receptive field; three dimensional imaging; ultrasound; algorithm; artificial neural network; cardiac imaging; cardiomyopathy; diagnostic imaging; factual database; heart; nuclear magnetic resonance imaging; procedures; Image enhancement","Medical Research Council, MRC, (MC_UP_1102/19); Medical Research Council, MRC; Engineering and Physical Sciences Research Council, EPSRC, (EP/P001009/1); Engineering and Physical Sciences Research Council, EPSRC; National Institute for Health Research, NIHR; British Heart Foundation, BHF, (PG/12/27/29489); British Heart Foundation, BHF","","Institute of Electrical and Electronics Engineers Inc.","28961105"
"Zhang J.; Xia Y.; Xie Y.; Fulham M.; Feng D.D.","Zhang, Jianpeng (57195070346); Xia, Yong (26427407400); Xie, Yutong (57195069213); Fulham, Michael (7005082387); Feng, David Dagan (7401981167)","57195070346; 26427407400; 57195069213; 7005082387; 7401981167","Classification of Medical Images in the Biomedical Literature by Jointly Using Deep and Handcrafted Visual Features","2018","22","5","8115141","1521","1530","9","10.1109/JBHI.2017.2775662","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035761514&doi=10.1109%2fJBHI.2017.2775662&partnerID=40&md5=eeba12766a99afadfc6a8578b958cbc7","The classification of medical images and illustrations from the biomedical literature is important for automated literature review, retrieval, and mining. Although deep learning is effective for large-scale image classification, it may not be the optimal choice for this task as there is only a small training dataset. We propose a combined deep and handcrafted visual feature (CDHVF) based algorithm that uses features learned by three fine-tuned and pretrained deep convolutional neural networks (DCNNs) and two handcrafted descriptors in a joint approach. We evaluated the CDHVF algorithm on the ImageCLEF 2016 Subfigure Classification dataset and it achieved an accuracy of 85.47%, which is higher than the best performance of other purely visual approaches listed in the challenge leaderboard. Our results indicate that handcrafted features complement the image representation learned by DCNNs on small training datasets and improve accuracy in certain medical image classification problems. © 2013 IEEE.","back-propagation neural network (BPNN); deep convolutional neural network (DCNN); ensemble learning; Medical image classification","Algorithms; Deep Learning; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Backpropagation; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Image enhancement; Large dataset; Medical imaging; Medical problems; Back-propagation neural networks; Biomedical literature; deep convolutional neural network (DCNN); Ensemble learning; Image representations; Literature reviews; Optimal choice; Visual feature; back propagation; classification; computer assisted tomography; diagnostic test accuracy study; extraction; joint; learning; nervous system; nomenclature; algorithm; diagnostic imaging; human; image processing; procedures; Image classification","Australian Research Council, ARC; National Natural Science Foundation of China, NSFC, (61471297, 61771397); National Natural Science Foundation of China, NSFC; Northwestern Polytechnical University, NPU, (Z2017041); Northwestern Polytechnical University, NPU","","Institute of Electrical and Electronics Engineers Inc.","29990115"
"Haenssle H.A.; Fink C.; Schneiderbauer R.; Toberer F.; Buhl T.; Blum A.; Kalloo A.; Ben Hadj Hassen A.; Thomas L.; Enk A.; Uhlmann L.; Alt C.; Arenbergerova M.; Bakos R.; Baltzer A.; Bertlich I.; Blum A.; Bokor-Billmann T.; Bowling J.; Braghiroli N.; Braun R.; Buder-Bakhaya K.; Cabo H.; Cabrijan L.; Cevic N.; Classen A.; Deltgen D.; Georgieva I.; Hakim-Meibodi L.-E.; Hanner S.; Hartmann F.; Hartmann J.; Haus G.; Hoxha E.; Karls R.; Koga H.; Kreusch J.; Lallas A.; Majenka P.; Marghoob A.; Massone C.; Mekokishvili L.; Mestel D.; Meyer V.; Neuberger A.; Nielsen K.; Oliviero M.; Pampena R.; Paoli J.; Pawlik Erika.; Rao B.; Rendon A.; Russo T.; Sadek A.; Samhaber K.; Schweizer A.; Trennheuser L.; Vlahova L.; Wald A.; Winkler J.; Wo¨lbing P.; Zalaudek I.","Haenssle, H.A. (6603657821); Fink, C. (56844769800); Schneiderbauer, R. (37018809400); Toberer, F. (37262045600); Buhl, T. (24463656700); Blum, A. (55644610100); Kalloo, A. (57213031962); Ben Hadj Hassen, A. (57204418301); Thomas, L. (7403526957); Enk, A. (55094698000); Uhlmann, L. (55536615700); Alt, Christina (57192176855); Arenbergerova, Monika (24330974800); Bakos, Renato (57195428961); Baltzer, Anne (57190674203); Bertlich, Ines (57193013968); Blum, Andreas (7402675019); Bokor-Billmann, Therezia (55507231200); Bowling, Jonathan (15019045500); Braghiroli, Naira (59158230000); Braun, Ralph (7402220663); Buder-Bakhaya, Kristina (36489136200); Cabo, Horacio (6603505616); Cabrijan, Leo (6507569489); Cevic, Naciye (57211306123); Classen, Anna (56517810700); Deltgen, David (57211306096); Georgieva, Ivelina (57508446400); Hakim-Meibodi, Lara-Elena (57200074786); Hanner, Susanne (57196464440); Hartmann, Franziska (57190577225); Hartmann, Julia (57205638806); Haus, Georg (12806372600); Hoxha, Elti (57195604799); Karls, Raimonds (57192648627); Koga, Hiroshi (56583488800); Kreusch, Ju¨rgen (7004223015); Lallas, Aimilios (23482399900); Majenka, Pawel (57195969615); Marghoob, Ash (57211306206); Massone, Cesare (55401556200); Mekokishvili, Lali (55544227200); Mestel, Dominik (24464261900); Meyer, Volker (57211306133); Neuberger, Anna (57195053073); Nielsen, Kari (8791360200); Oliviero, Margaret (7004025692); Pampena, Riccardo (55821950800); Paoli, John (14631010100); Pawlik, Erika (57211306205); Rao, Barbar (57211306201); Rendon, Adriana (57192066619); Russo, Teresa (56247908400); Sadek, Ahmed (57198232067); Samhaber, Kinga (56072647800); Schweizer, Anissa (57202898971); Trennheuser, Lukas (55795873900); Vlahova, Lyobomira (57216586101); Wald, Alexander (57207937061); Winkler, Julia (57191580858); Wo¨lbing, Priscila (57194173016); Zalaudek, Iris (6701737036)","6603657821; 56844769800; 37018809400; 37262045600; 24463656700; 55644610100; 57213031962; 57204418301; 7403526957; 55094698000; 55536615700; 57192176855; 24330974800; 57195428961; 57190674203; 57193013968; 7402675019; 55507231200; 15019045500; 59158230000; 7402220663; 36489136200; 6603505616; 6507569489; 57211306123; 56517810700; 57211306096; 57508446400; 57200074786; 57196464440; 57190577225; 57205638806; 12806372600; 57195604799; 57192648627; 56583488800; 7004223015; 23482399900; 57195969615; 57211306206; 55401556200; 55544227200; 24464261900; 57211306133; 57195053073; 8791360200; 7004025692; 55821950800; 14631010100; 57211306205; 57211306201; 57192066619; 56247908400; 57198232067; 56072647800; 57202898971; 55795873900; 57216586101; 57207937061; 57191580858; 57194173016; 6701737036","Man against Machine: Diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists","2018","29","8","","1836","1842","6","10.1093/annonc/mdy166","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054158054&doi=10.1093%2fannonc%2fmdy166&partnerID=40&md5=bb5b77701696a7a4343562a96ae0b60e","Background: Deep learning convolutional neural networks (CNN) May facilitate melanoma detection, but data comparing a CNN’s diagnostic performance to larger groups of dermatologists are lacking. Methods: Google’s Inception v4 CNN architecture was trained and validated using dermoscopic images and corresponding diagnoses. In a comparative cross-sectional reader study a 100-image test-set was used (level-I: dermoscopy only; level-II: dermoscopy plus clinical information and images). Main outcome measures were sensitivity, specificity and area under the curve (AUC) of receiver operating characteristics (ROC) for diagnostic classification (dichotomous) of lesions by the CNN versus an international group of 58 dermatologists during level-I or -II of the reader study. Secondary end points included the dermatologists’ diagnostic performance in their management decisions and differences in the diagnostic performance of dermatologists during level-I and -II of the reader study. Additionally, the CNN’s performance was compared with the top-five algorithms of the 2016 International Symposium on Biomedical Imaging (ISBI) challenge. Results: In level-I dermatologists achieved a mean (6standard deviation) sensitivity and specificity for lesion classification of 86.6% (69.3%) and 71.3% (611.2%), respectively. More clinical information (level-II) improved the sensitivity to 88.9% (69.6%, P ¼ 0.19) and specificity to 75.7% (611.7%, P < 0.05). The CNN ROC curve revealed a higher specificity of 82.5% when compared with dermatologists in level-I (71.3%, P < 0.01) and level-II (75.7%, P < 0.01) at their sensitivities of 86.6% and 88.9%, respectively. The CNN ROC AUC was greater than the mean ROC area of dermatologists (0.86 versus 0.79, P < 0.01). The CNN scored results close to the top three algorithms of the ISBI 2016 challenge. Conclusions: For the first time we compared a CNN’s diagnostic performance with a large international group of 58 dermatologists, including 30 experts. Most dermatologists were outperformed by the CNN. Irrespective of any physicians’ experience, they May benefit from assistance by a CNN’s image classification. © The Author(s) 2018.","Automated melanoma detection; Computer algorithm; Deep learning convolutional neural network; Dermoscopy; Melanocytic nevi; Melanoma","Clinical Competence; Cross-Sectional Studies; Deep Learning; Dermatologists; Dermoscopy; Humans; Image Processing, Computer-Assisted; International Cooperation; Melanoma; Retrospective Studies; ROC Curve; Skin; Skin Neoplasms; area under the curve; Article; artificial neural network; cancer classification; cancer diagnosis; comparative study; cross-sectional study; deep learning convolutional neural network; dermatologist; diagnostic accuracy; diagnostic test accuracy study; epiluminescence microscopy; human; melanoma; outcome assessment; priority journal; receiver operating characteristic; sensitivity and specificity; clinical competence; diagnostic imaging; epiluminescence microscopy; image processing; international cooperation; melanoma; procedures; retrospective study; skin; skin tumor","","","Oxford University Press","29846502"
"Fischer W.; Moudgalya S.S.; Cohn J.D.; Nguyen N.T.T.; Kenyon G.T.","Fischer, Will (15759657800); Moudgalya, Sanketh S. (57205176470); Cohn, Judith D. (12773828500); Nguyen, Nga T.T. (57209863315); Kenyon, Garrett T. (7102602432)","15759657800; 57205176470; 12773828500; 57209863315; 7102602432","Sparse coding of pathology slides compared to transfer learning with deep neural networks","2018","19","","489","","","","10.1186/s12859-018-2504-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058922677&doi=10.1186%2fs12859-018-2504-8&partnerID=40&md5=ecb9bdaa6e0a231528e47ff17482c14c","Background: Histopathology images of tumor biopsies present unique challenges for applying machine learning to the diagnosis and treatment of cancer. The pathology slides are high resolution, often exceeding 1GB, have non-uniform dimensions, and often contain multiple tissue slices of varying sizes surrounded by large empty regions. The locations of abnormal or cancerous cells, which may constitute a small portion of any given tissue sample, are not annotated. Cancer image datasets are also extremely imbalanced, with most slides being associated with relatively common cancers. Since deep representations trained on natural photographs are unlikely to be optimal for classifying pathology slide images, which have different spectral ranges and spatial structure, we here describe an approach for learning features and inferring representations of cancer pathology slides based on sparse coding. Results: We show that conventional transfer learning using a state-of-the-art deep learning architecture pre-trained on ImageNet (RESNET) and fine tuned for a binary tumor/no-tumor classification task achieved between 85% and 86% accuracy. However, when all layers up to the last convolutional layer in RESNET are replaced with a single feature map inferred via a sparse coding using a dictionary optimized for sparse reconstruction of unlabeled pathology slides, classification performance improves to over 93%, corresponding to a 54% error reduction. Conclusions: We conclude that a feature dictionary optimized for biomedical imagery may in general support better classification performance than does conventional transfer learning using a dictionary pre-trained on natural images. © 2018 The Author(s).","Cancer pathology slides; Deep learning; Locally Competitive Algorithm; Sparse coding; TCGA; Transfer learning; Unsupervised learning","Deep Learning; Humans; Neoplasms; Neural Networks (Computer); Codes (symbols); Deep learning; Diagnosis; Diseases; Image coding; Network coding; Pathology; Tumors; Unsupervised learning; Cancer pathology slides; Competitive algorithms; Sparse coding; TCGA; Transfer learning; artificial neural network; human; neoplasm; pathology; trends; Deep neural networks","National Institutes of Health, NIH; U.S. Department of Energy, USDOE; National Cancer Institute, NCI; Los Alamos National Laboratory, LANL, (DE-AC5206NA25396)","","BioMed Central Ltd.","30577746"
"Calimeri F.; Marzullo A.; Stamile C.; Terracina G.","Calimeri, Francesco (8685471300); Marzullo, Aldo (57194212378); Stamile, Claudio (56708797000); Terracina, Giorgio (7003682146)","8685471300; 57194212378; 56708797000; 7003682146","Biomedical data augmentation using generative adversarial neural networks","2017","10614 LNCS","","","626","634","8","10.1007/978-3-319-68612-7_71","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034244846&doi=10.1007%2f978-3-319-68612-7_71&partnerID=40&md5=34d84c6a987e527b564d841e150be61a","Synthesizing photo-realistic images is a challenging problem with many practical applications [15]. In many cases, the availability of a significant amount of images is crucial, yet obtaining them might be not trivial. For instance, obtaining huge databases of images is hard, in the biomedical domain, but strictly needed in order to improve both algorithms and physicians’ skills. In the latest years, new deep learning models have been proposed in the literature, called Generative Adversarial Neural Networks (GANNs) [7], that turned out as effective at synthesizing high-quality image in several domains. In this work we propose a new application of GANNs to the automatic generation of artificial Magnetic Resonance Images (MRI) of slices of the human brain; both quantitative and human-based evaluations of generated images have been carried out in order to assess effectiveness of the method. © Springer International Publishing AG 2017.","Biomedical imaging; Generative adversarial networks; MRI","Bioinformatics; Image processing; Learning systems; Magnetic resonance; Magnetic resonance imaging; Medical imaging; Neural networks; Adversarial networks; Automatic Generation; Biomedical domain; Biomedical imaging; High quality images; Magnetic resonance images (MRI); New applications; Photorealistic images; Image enhancement","Horizon 2020 Framework Programme, H2020, (690974); European Commission, EC, (316679)","Lintas A.; Villa A.E.; Rovetta S.; Verschure P.F.","Springer Verlag",""
"Anwar S.M.; Majid M.; Qayyum A.; Awais M.; Alnowami M.; Khan M.K.","Anwar, Syed Muhammad (36781722700); Majid, Muhammad (55390149500); Qayyum, Adnan (57202908543); Awais, Muhammad (57224215215); Alnowami, Majdi (35812131500); Khan, Muhammad Khurram (58203013200)","36781722700; 55390149500; 57202908543; 57224215215; 35812131500; 58203013200","Medical Image Analysis using Convolutional Neural Networks: A Review","2018","42","11","226","","","","10.1007/s10916-018-1088-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054481246&doi=10.1007%2fs10916-018-1088-1&partnerID=40&md5=59a42a042f712236e2b594b72509d14a","The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Classification; Computer aided diagnosis; Convolutional neural network; Medical image analysis; Segmentation","Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Image Processing, Computer-Assisted; Information Storage and Retrieval; Neural Networks (Computer); algorithm; artificial neural network; computer assisted diagnosis; image processing; information retrieval; procedures","","","Springer New York LLC","30298337"
"Romero Lopez A.; Giro-I-Nieto X.; Burdick J.; Marques O.","Romero Lopez, Adria (57194161714); Giro-I-Nieto, Xavier (35098596700); Burdick, Jack (57194161479); Marques, Oge (7003301322)","57194161714; 35098596700; 57194161479; 7003301322","Skin lesion classification from dermoscopic images using deep learning techniques","2017","","","7893267","49","54","5","10.2316/P.2017.852-053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019000072&doi=10.2316%2fP.2017.852-053&partnerID=40&md5=13a0452369523c3de298ded873fbd691","The recent emergence of deep learning methods for medical image analysis has enabled the development of intelligent medical imaging-based diagnosis systems that can assist the human expert in making better decisions about a patients health. In this paper we focus on the problem of skin lesion classification, particularly early melanoma detection, and present a deep-learning based approach to solve the problem of classifying a dermoscopic image containing a skin lesion as malignant or benign. The proposed solution is built around the VGGNet convolutional neural network architecture and uses the transfer learning paradigm. Experimental results are encouraging: on the ISIC Archive dataset, the proposed method achieves a sensitivity value of 78.66%, which is significantly higher than the current state of the art on that dataset. © 2017 International Association of Science and Technology for Development - IASTED.","Convolutional Neural Networks; Deep Learning; Machine Learning; Medical Decision Support Systems; Medical Image Analysis; Skin Lesions","Artificial intelligence; Biomedical engineering; Convolution; Decision support systems; Deep learning; Dermatology; Diagnosis; Image analysis; Learning algorithms; Learning systems; Medical imaging; Medicine; Network architecture; Neural networks; Convolutional neural network; Dermoscopic images; Learning techniques; Learning-based approach; Medical decision support system; Melanoma detection; Sensitivity values; Skin lesion; Image classification","Industry University, (NSF 13-542)","Kiss R.; Thurner P.J.","Institute of Electrical and Electronics Engineers Inc.",""
"Pang S.; Orgun M.A.; Du A.; Yu Z.","Pang, Shuchao (55639762100); Orgun, Mehmet A. (6603681610); Du, Anan (56167972000); Yu, Zhezhou (8938987700)","55639762100; 6603681610; 56167972000; 8938987700","Leveraging deep preference learning for indexing and retrieval of biomedical images","2017","","","8008308","126","129","3","10.1109/NER.2017.8008308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028599309&doi=10.1109%2fNER.2017.8008308&partnerID=40&md5=e6b7c31eed1e4172f3af6ab7a0d4ea44","This paper presents an original framework based on deep learning and preference learning to retrieve and characterize biomedical images for assisting physicians in diagnosing complex diseases with potentially only small differences between them. In particular, we use deep learning to extract the high-level and compact features for biomedical images. In contrast to the traditional biomedical algorithms or general image retrieval systems that only consider the use of pixel and/or hand-crafted features to represent images, we utilize deep neural networks for feature discovery of biomedical images. Moreover, in order to be able to index the similarly referenced images, we introduce preference learning in a novel way to learn what kinds of images we need so that we can obtain the similarity ranking list of biomedical images. We evaluate the performance of our system in detailed experiments over the well-known available OASIS-MRI database for whole brain neuroimaging as a benchmark and compare it with those of the traditional biomedical and general image retrieval approaches. Our proposed system exhibits an outstanding retrieval ability and efficiency for biomedical image applications. © 2017 IEEE.","","Benchmarking; Bioinformatics; Deep learning; Deep neural networks; Diagnosis; Image retrieval; Magnetic resonance imaging; Neuroimaging; Bio-medical algorithms; Biomedical images; Compact Features; Feature discovery; Image retrieval systems; Indexing and retrieval; Preference learning; Similarity rankings; Search engines","Science and Technology Development Plan of Jilin Province, (20150204007GX); Specialized Research Fund for the Doctoral Program of Higher Education of China, SRFDP, (20120061110045)","","IEEE Computer Society",""
"Pang S.; Orgun M.A.; Yu Z.","Pang, Shuchao (55639762100); Orgun, Mehmet A. (6603681610); Yu, Zhezhou (8938987700)","55639762100; 6603681610; 8938987700","A novel biomedical image indexing and retrieval system via deep preference learning","2018","158","","","53","69","16","10.1016/j.cmpb.2018.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041721081&doi=10.1016%2fj.cmpb.2018.02.003&partnerID=40&md5=83daf49352eb3580b74fd70ba252d771","Background and Objectives: The traditional biomedical image retrieval methods as well as content-based image retrieval (CBIR) methods originally designed for non-biomedical images either only consider using pixel and low-level features to describe an image or use deep features to describe images but still leave a lot of room for improving both accuracy and efficiency. In this work, we propose a new approach, which exploits deep learning technology to extract the high-level and compact features from biomedical images. The deep feature extraction process leverages multiple hidden layers to capture substantial feature structures of high-resolution images and represent them at different levels of abstraction, leading to an improved performance for indexing and retrieval of biomedical images. Methods: We exploit the current popular and multi-layered deep neural networks, namely, stacked denoising autoencoders (SDAE) and convolutional neural networks (CNN) to represent the discriminative features of biomedical images by transferring the feature representations and parameters of pre-trained deep neural networks from another domain. Moreover, in order to index all the images for finding the similarly referenced images, we also introduce preference learning technology to train and learn a kind of a preference model for the query image, which can output the similarity ranking list of images from a biomedical image database. To the best of our knowledge, this paper introduces preference learning technology for the first time into biomedical image retrieval. Results: We evaluate the performance of two powerful algorithms based on our proposed system and compare them with those of popular biomedical image indexing approaches and existing regular image retrieval methods with detailed experiments over several well-known public biomedical image databases. Based on different criteria for the evaluation of retrieval performance, experimental results demonstrate that our proposed algorithms outperform the state-of-the-art techniques in indexing biomedical images. Conclusions: We propose a novel and automated indexing system based on deep preference learning to characterize biomedical images for developing computer aided diagnosis (CAD) systems in healthcare. Our proposed system shows an outstanding indexing ability and high efficiency for biomedical image retrieval applications and it can be used to collect and annotate the high-resolution images in a biomedical database for further biomedical image research and applications. © 2018 Elsevier B.V.","Biomedical image retrieval; Convolutional neural network; Deep learning; Preference learning","Algorithms; Databases, Factual; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Information Storage and Retrieval; Machine Learning; Neural Networks (Computer); Radiology Information Systems; Bioinformatics; Computer aided diagnosis; Computer aided instruction; Content based retrieval; Convolution; Database systems; Deep learning; Deep neural networks; Efficiency; Image enhancement; Indexing (of information); Medical computing; Network layers; Neural networks; Query processing; Biomedical image database; Biomedical images; Computer Aided Diagnosis(CAD); Content-Based Image Retrieval; Convolutional neural network; Convolutional Neural Networks (CNN); Preference learning; State-of-the-art techniques; article; diagnosis; diagnostic test accuracy study; extraction; image retrieval; learning; nervous system; algorithm; artificial neural network; diagnostic imaging; factual database; human; image processing; information retrieval; machine learning; procedures; radiology information system; Search engines","Science and Technology Development Plan of Jilin Province, (20150204007GX); National Natural Science Foundation of China, NSFC, (51409117, 51679105, 61702214); National Natural Science Foundation of China, NSFC; China Scholarship Council, CSC; Specialized Research Fund for the Doctoral Program of Higher Education of China, SRFDP, (20120061110045); Specialized Research Fund for the Doctoral Program of Higher Education of China, SRFDP","","Elsevier Ireland Ltd","29544790"
"Mansour R.F.","Mansour, Romany F. (36960713000)","36960713000","Deep-learning-based automatic computer-aided diagnosis system for diabetic retinopathy","2018","8","1","","41","57","16","10.1007/s13534-017-0047-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042694325&doi=10.1007%2fs13534-017-0047-y&partnerID=40&md5=cdaba8e546a89aa18c383f804092726c","The high-pace rise in advanced computing and imaging systems has given rise to a new research dimension called computer-aided diagnosis (CAD) system for various biomedical purposes. CAD-based diabetic retinopathy (DR) can be of paramount significance to enable early disease detection and diagnosis decision. Considering the robustness of deep neural networks (DNNs) to solve highly intricate classification problems, in this paper, AlexNet DNN, which functions on the basis of convolutional neural network (CNN), has been applied to enable an optimal DR CAD solution. The DR model applies a multilevel optimization measure that incorporates pre-processing, adaptive-learning-based Gaussian mixture model (GMM)-based concept region segmentation, connected component-analysis-based region of interest (ROI) localization, AlexNet DNN-based highly dimensional feature extraction, principle component analysis (PCA)- and linear discriminant analysis (LDA)-based feature selection, and support-vector-machine-based classification to ensure optimal five-class DR classification. The simulation results with standard KAGGLE fundus datasets reveal that the proposed AlexNet DNN-based DR exhibits a better performance with LDA feature selection, where it exhibits a DR classification accuracy of 97.93% with FC7 features, whereas with PCA, it shows 95.26% accuracy. Comparative analysis with spatial invariant feature transform (SIFT) technique (accuracy—94.40%) based DR feature extraction also confirms that AlexNet DNN-based DR outperforms SIFT-based DR. © 2017, Korean Society of Medical and Biological Engineering and Springer-Verlag GmbH Germany.","AlexNet DNN; Computer-aided diagnosis; Convolutional neural network; Deep neural network; Diabetic retinopathy; Gaussian mixture model; Linear discriminant analysis; SVM","Biomedical signal processing; Classification (of information); Computer aided analysis; Computer aided instruction; Convolution; Deep learning; Deep neural networks; Diagnosis; Discriminant analysis; Extraction; Eye protection; Feature extraction; Gaussian distribution; Image retrieval; Image segmentation; Neural networks; Principal component analysis; Support vector machines; AlexNet DNN; Convolutional neural network; Diabetic retinopathy; Gaussian Mixture Model; Linear discriminant analysis; analytical parameters; Article; artificial neural network; computational fluid dynamics; computer assisted diagnosis; diabetic retinopathy; fuzzy system; genetic algorithm; hemodynamics; linear discriminant analysis; measurement accuracy; nerve cell network; normal distribution; optic disk; principle component analysis; priority journal; scanning laser ophthalmoscopy; spatial invariant feature transform; statistical analysis; support vector machine; Computer aided diagnosis","","","Springer Verlag",""
"Thomaz R.L.; Carneiro P.C.; Patrocinio A.C.","Thomaz, Ricardo L. (57200933035); Carneiro, Pedro C. (56734240900); Patrocinio, Ana C. (6507737303)","57200933035; 56734240900; 6507737303","Feature extraction using convolutional neural network for classifying breast density in mammographic images","2017","10134","","101342M","","","","10.1117/12.2254633","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020271990&doi=10.1117%2f12.2254633&partnerID=40&md5=6a812bcce85da067c7ea6e1f22d3c01a","Breast cancer is the leading cause of death for women in most countries. The high levels of mortality relate mostly to late diagnosis and to the direct proportionally relationship between breast density and breast cancer development. Therefore, the correct assessment of breast density is important to provide better screening for higher risk patients. However, in modern digital mammography the discrimination among breast densities is highly complex due to increased contrast and visual information for all densities. Thus, a computational system for classifying breast density might be a useful tool for aiding medical staff. Several machine-learning algorithms are already capable of classifying small number of classes with good accuracy. However, machinelearning algorithms main constraint relates to the set of features extracted and used for classification. Although well-known feature extraction techniques might provide a good set of features, it is a complex task to select an initial set during design of a classifier. Thus, we propose feature extraction using a Convolutional Neural Network (CNN) for classifying breast density by a usual machine-learning classifier. We used 307 mammographic images downsampled to 260x200 pixels to train a CNN and extract features from a deep layer. After training, the activation of 8 neurons from a deep fully connected layer are extracted and used as features. Then, these features are feedforward to a single hidden layer neural network that is cross-validated using 10-folds to classify among four classes of breast density. The global accuracy of this method is 98.4%, presenting only 1.6% of misclassification. However, the small set of samples and memory constraints required the reuse of data in both CNN and MLP-NN, therefore overfitting might have influenced the results even though we cross-validated the network. Thus, although we presented a promising method for extracting features and classifying breast density, a greater database is still required for evaluating the results. © 2017 SPIE.","Breast density; Convolutional Neural Network; Feature extraction; Mammography","Artificial intelligence; Biomedical signal processing; Complex networks; Computer aided diagnosis; Convolution; Diagnosis; Diseases; Extraction; Feature extraction; Image classification; Image processing; Learning algorithms; Learning systems; Mammography; Medical imaging; Network layers; Neural networks; Risk assessment; X ray screens; Breast density; Computational system; Convolutional neural network; Digital mammography; Extracting features; Feature extraction techniques; Mammographic images; Single-hidden-layer neural networks; Classification (of information)","","Petrick N.A.; Armato S.G.","SPIE",""
"Kandaswamy C.; Silva L.M.; Alexandre L.A.; Santos J.M.","Kandaswamy, Chetak (56038853000); Silva, Luís M (57210568776); Alexandre, Luís A (8847713100); Santos, Jorge M (7402389359)","56038853000; 57210568776; 8847713100; 7402389359","Deep transfer learning ensemble for classification","2015","9094","","","335","348","13","10.1007/978-3-319-19258-1_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937439174&doi=10.1007%2f978-3-319-19258-1_29&partnerID=40&md5=3d3beada33ef02236f0429504be93c4f","Transfer learning algorithms typically assume that the training data and the test data come from different distribution. It is better at adapting to learn new tasks and concepts more quickly and accurately by exploiting previously gained knowledge. Deep Transfer Learning (DTL) emerged as a new paradigm in transfer learning in which a deep model offer greater flexibility in extracting high-level features. DTL offers selective layer based transference, and it is problem specific. In this paper, we propose the Ensemble of Deep Transfer Learning (EDTL) methodology to reduce the impact of selective layer based transference and provide optimized framework to work for three major transfer learning cases. Empirical results on character, object and biomedical image recognition tasks achieves that the proposed method indicate statistically significant classification accuracy over the other established transfer learning method. © Springer International Publishing Switzerland 2015.","Deep learning; Ensemble; Transfer learning","Algorithms; Artificial intelligence; Image recognition; Neural networks; Classification accuracy; Deep learning; Different distributions; Ensemble; High-level features; Selective layers; Transfer learning; Transfer learning methods; Learning algorithms","","Rojas I.; Joya G.; Catala A.","Springer Verlag",""
"Al-masni M.A.; Al-antari M.A.; Choi M.-T.; Han S.-M.; Kim T.-S.","Al-masni, Mohammed A. (57192575678); Al-antari, Mugahed A. (57189003551); Choi, Mun-Taek (16229647800); Han, Seung-Moo (8564174800); Kim, Tae-Seong (36072897600)","57192575678; 57189003551; 16229647800; 8564174800; 36072897600","Skin lesion segmentation in dermoscopy images via deep full resolution convolutional networks","2018","162","","","221","231","10","10.1016/j.cmpb.2018.05.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047600387&doi=10.1016%2fj.cmpb.2018.05.027&partnerID=40&md5=18812c13cc0b21ec98c5062d3b4aad2c","Background and objective: Automatic segmentation of skin lesions in dermoscopy images is still a challenging task due to the large shape variations and indistinct boundaries of the lesions. Accurate segmentation of skin lesions is a key prerequisite step for any computer-aided diagnostic system to recognize skin melanoma. Methods: In this paper, we propose a novel segmentation methodology via full resolution convolutional networks (FrCN). The proposed FrCN method directly learns the full resolution features of each individual pixel of the input data without the need for pre- or post-processing operations such as artifact removal, low contrast adjustment, or further enhancement of the segmented skin lesion boundaries. We evaluated the proposed method using two publicly available databases, the IEEE International Symposium on Biomedical Imaging (ISBI) 2017 Challenge and PH2 datasets. To evaluate the proposed method, we compared the segmentation performance with the latest deep learning segmentation approaches such as the fully convolutional network (FCN), U-Net, and SegNet. Results: Our results showed that the proposed FrCN method segmented the skin lesions with an average Jaccard index of 77.11% and an overall segmentation accuracy of 94.03% for the ISBI 2017 test dataset and 84.79% and 95.08%, respectively, for the PH2 dataset. In comparison to FCN, U-Net, and SegNet, the proposed FrCN outperformed them by 4.94%, 15.47%, and 7.48% for the Jaccard index and 1.31%, 3.89%, and 2.27% for the segmentation accuracy, respectively. Furthermore, the proposed FrCN achieved a segmentation accuracy of 95.62% for some representative clinical benign cases, 90.78% for the melanoma cases, and 91.29% for the seborrheic keratosis cases in the ISBI 2017 test dataset, exhibiting better performance than those of FCN, U-Net, and SegNet. Conclusions: We conclude that using the full spatial resolutions of the input image could enable to learn better specific and prominent features, leading to an improvement in the segmentation performance. © 2018 Elsevier B.V.","Deep learning; Dermoscopy; Full resolution convolutional network (FrCN); Melanoma; Skin lesion segmentation","Algorithms; Artifacts; Dermoscopy; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Machine Learning; Melanoma; Neural Networks (Computer); Reproducibility of Results; Sensitivity and Specificity; Skin Diseases; Skin Neoplasms; Convolution; Deep learning; Dermatology; Diagnosis; Image enhancement; Medical imaging; Oncology; Statistical tests; Automatic segmentations; Computer aided diagnostics; Convolutional networks; Dermoscopy; Melanoma; Segmentation accuracy; Segmentation performance; Skin lesion; area under the curve; Article; controlled study; diagnostic test accuracy study; epiluminescence microscopy; human; image segmentation; melanoma; nevus; receiver operating characteristic; seborrheic keratosis; sensitivity and specificity; skin defect; algorithm; artifact; artificial neural network; computer assisted diagnosis; diagnostic imaging; image processing; machine learning; melanoma; reproducibility; skin disease; skin tumor; Image segmentation","Ministry of Trade, Industry and Energy, MOTIE, (N0002252)","","Elsevier Ireland Ltd","29903489"
"Rastogi P.; Singh V.; Yadav M.","Rastogi, Priyanka (57221938650); Singh, Vijendra (57216750407); Yadav, Monika (58443926500)","57221938650; 57216750407; 58443926500","Deep learning and big datatechnologies in medical image analysis","2018","","","8745750","60","63","3","10.1109/PDGC.2018.8745750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069516295&doi=10.1109%2fPDGC.2018.8745750&partnerID=40&md5=2353af54c89df13b8e637f6559ab8c9a","Deep Learning and Big Data Analytics are the two high-focus areas in medical image analysis in the recent times. Owing to the great volume of imaging data in the databases, a lot of research has been focused in the area of medical image analysis involving big data tools and techniques. Also due to the saturation of considerable advances in shallow reasoning-based machine leaning algorithms, complex reasoning-based algorithms like Deep learning are employed to address the issues of image data in biomedical field. This paper discusses the challenges of traditional medical image analysis and reviews some of the latest researches in the areas of medical image analysis involving deep leaning and employing big data platforms. © 2018 IEEE.","Big Data Technologies; Convolutional Neural Network; Deep Learning; Hadoop; Medical Image Analysis","Big data; Bioinformatics; Data Analytics; Deep learning; Deep neural networks; Grid computing; Medical imaging; Neural networks; Biomedical fields; Convolutional neural network; Data platform; Data technologies; Focus areas; Hadoop; Imaging data; Machine leaning; Image analysis","","Singh P.K.; Kumar Y.; Ghrera S.P.","Institute of Electrical and Electronics Engineers Inc.",""
"Tian L.; Mu Z.","Tian, Liang (57193713075); Mu, Zhichun (8452569700)","57193713075; 8452569700","Ear recognition based on deep convolutional network","2017","","","7852751","437","441","4","10.1109/CISP-BMEI.2016.7852751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016003006&doi=10.1109%2fCISP-BMEI.2016.7852751&partnerID=40&md5=e3465d7365add5099caf7a0c8e5ddbd6","Ear recognition is gaining on popularity in recent years. The human ear are neither affected by expressions like faces are nor do need closer touching like finger-prints do. In this paper, a novel algorithm was proposed to do ear recognition using deep convolutional neural network and provide a visualization of the learned network. We design a convolutional neural network with three convolutional layers, a fully-connected layer and a soft-max classifier. The experimental results on USTB ear database indict that our proposed method is easier botain high accuracy and outperforms the traditional method in dealing with partial occlusion. © 2016 IEEE.","convolutional neural network; deep learning; ear recognition","Biomedical engineering; Convolution; Deep learning; Image processing; Neural networks; Convolutional networks; Convolutional neural network; Ear database; Ear recognition; Finger print; High-accuracy; Novel algorithm; Partial occlusions; Signal processing","","","Institute of Electrical and Electronics Engineers Inc.",""
"Gupta H.; Jin K.H.; Nguyen H.Q.; McCann M.T.; Unser M.","Gupta, Harshit (57213136047); Jin, Kyong Hwan (55153576800); Nguyen, Ha Q. (57219758824); McCann, Michael T. (55617614400); Unser, Michael (7102049045)","57213136047; 55153576800; 57219758824; 55617614400; 7102049045","CNN-Based Projected Gradient Descent for Consistent CT Image Reconstruction","2018","37","6","","1440","1453","13","10.1109/TMI.2018.2832656","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046484652&doi=10.1109%2fTMI.2018.2832656&partnerID=40&md5=8a89ac9acbadc64cfa2118f00e090f92","We present a new image reconstruction method that replaces the projector in a projected gradient descent (PGD) with a convolutional neural network (CNN). Recently, CNNs trained as image-to-image regressors have been successfully used to solve inverse problems in imaging. However, unlike existing iterative image reconstruction algorithms, these CNN-based approaches usually lack a feedback mechanism to enforce that the reconstructed image is consistent with the measurements. We propose a relaxed version of PGD wherein gradient descent enforces measurement consistency, while a CNN recursively projects the solution closer to the space of desired reconstruction images. We show that this algorithm is guaranteed to converge and, under certain conditions, converges to a local minimum of a non-convex inverse problem. Finally, we propose a simple scheme to train the CNN to act like a projector. Our experiments on sparse-view computed-tomography reconstruction show an improvement over total variation-based regularization, dictionary learning, and a state-of-the-art deep learning-based direct reconstruction technique. © 2017 IEEE.","biomedical image reconstruction; Deep learning; inverse problems; low-dose computed tomography","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Signal-To-Noise Ratio; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Differential equations; Functions; Inverse problems; Iterative methods; Neural networks; Problem solving; Biomedical measurements; Convex functions; Convolutional Neural Networks (CNN); Image reconstruction methods; Iterative image reconstruction algorithm; Low dose; Reconstruction techniques; Tomography reconstruction; article; computer assisted tomography; feedback system; image reconstruction; learning; nervous system; algorithm; human; image processing; procedures; signal noise ratio; x-ray computed tomography; Image reconstruction","European Union’s Horizon 2020 Frame-work Programme; H2020-ERC; National Institute of Biomedical Imaging and Bioengineering, NIBIB; Mayo Clinic; Nvidia; American Association of Physicists in Medicine, AAPM; Canadian Light Source, CLS; Horizon 2020 Framework Programme, H2020, (665667, 692726); European Research Council, ERC; Paul Scherrer Institut, PSI","","Institute of Electrical and Electronics Engineers Inc.","29870372"
"Alaskar H.","Alaskar, Haya (56028692500)","56028692500","Deep learning-based model architecture for time-frequency images analysis","2018","9","12","","486","494","8","10.14569/IJACSA.2018.091268","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059518886&doi=10.14569%2fIJACSA.2018.091268&partnerID=40&md5=4766d1b19e48ef96d41c93580af02dbb","Time-frequency analysis is an initial step in the design of invariant representations for any type of time series signals. Time-frequency analysis has been studied and developed widely for decades, but accurate analysis using deep learning neural networks has only been presented in the last few years. In this paper, a comprehensive survey of deep learning neural network architectures for time-frequency analysis is presented and compares the networks with previous approaches to time-frequency analysis based on feature extraction and other machine learning algorithms. The results highlight the improvements achieved by deep learning networks, critically review the application of deep learning for time-frequency analysis and provide a holistic overview of current works in the literature. Finally, this work facilitates discussions regarding research opportunities with deep learning algorithms in future researches. © 2018 International Journal of Advanced Computer Science and Applications.","Biomedical signals; Convolutional neural network; Deep learning; Hilbert-Huang transform; Scalograms; Sound signals; Spectrogram; Time-frequency","","","","Science and Information Organization",""
"Yang H.; Sun J.; Li H.; Wang L.; Xu Z.","Yang, Heran (57192062510); Sun, Jian (57650520100); Li, Huibin (48861263800); Wang, Lisheng (7409186133); Xu, Zongben (7405426248)","57192062510; 57650520100; 48861263800; 7409186133; 7405426248","Neural multi-atlas label fusion: Application to cardiac MR images","2018","49","","","60","75","15","10.1016/j.media.2018.07.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051117640&doi=10.1016%2fj.media.2018.07.009&partnerID=40&md5=a5759778f4d9af9f159514498bdb0f3d","Multi-atlas segmentation approach is one of the most widely-used image segmentation techniques in biomedical applications. There are two major challenges in this category of methods, i.e., atlas selection and label fusion. In this paper, we propose a novel multi-atlas segmentation method that formulates multi-atlas segmentation in a deep learning framework for better solving these challenges. The proposed method, dubbed deep fusion net (DFN), is a deep architecture that integrates a feature extraction subnet and a non-local patch-based label fusion (NL-PLF) subnet in a single network. The network parameters are learned by end-to-end training for automatically learning deep features that enable optimal performance in a NL-PLF framework. The learned deep features are further utilized in defining a similarity measure for atlas selection. By evaluating on two public cardiac MR datasets of SATA-13 and LV-09 for left ventricle segmentation, our approach achieved 0.833 in averaged Dice metric (ADM) on SATA-13 dataset and 0.95 in ADM for epicardium segmentation on LV-09 dataset, comparing favorably with the other automatic left ventricle segmentation methods. We also tested our approach on Cardiac Atlas Project (CAP) testing set of MICCAI 2013 SATA Segmentation Challenge, and our method achieved 0.815 in ADM, ranking highest at the time of writing. © 2018 Elsevier B.V.","Atlas selection; Deep fusion net; Left ventricle segmentation; Multi-atlas label fusion","Algorithms; Anatomic Landmarks; Heart Ventricles; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks (Computer); Pattern Recognition, Automated; Deep learning; Feature extraction; Magnetic resonance imaging; Medical applications; Atlas selection; Biomedical applications; Deep fusion net; Label fusions; Left ventricles; Optimal performance; Segmentation methods; Segmentation techniques; article; epicardium; feature extraction; heart left ventricle; human; human experiment; learning; nervous system; writing; algorithm; anatomic landmark; artificial neural network; automated pattern recognition; computer assisted diagnosis; diagnostic imaging; heart ventricle; image enhancement; nuclear magnetic resonance imaging; procedures; Image segmentation","International Exchange Foundation of China NSFC; United Kingdom RS, (61711530242); National Natural Science Foundation of China, NSFC, (11622106, 11690011, 61472313, 61721002)","","Elsevier B.V.","30099151"
"Kermany D.S.; Goldbaum M.; Cai W.; Valentim C.C.S.; Liang H.; Baxter S.L.; McKeown A.; Yang G.; Wu X.; Yan F.; Dong J.; Prasadha M.K.; Pei J.; Ting M.; Zhu J.; Li C.; Hewett S.; Dong J.; Ziyar I.; Shi A.; Zhang R.; Zheng L.; Hou R.; Shi W.; Fu X.; Duan Y.; Huu V.A.N.; Wen C.; Zhang E.D.; Zhang C.L.; Li O.; Wang X.; Singer M.A.; Sun X.; Xu J.; Tafreshi A.; Lewis M.A.; Xia H.; Zhang K.","Kermany, Daniel S. (57193116279); Goldbaum, Michael (7005893154); Cai, Wenjia (57196088938); Valentim, Carolina C.S. (57200758379); Liang, Huiying (35334583200); Baxter, Sally L. (57200760006); McKeown, Alex (55880755400); Yang, Ge (57200758769); Wu, Xiaokang (57200754293); Yan, Fangbing (57200756883); Dong, Justin (57200757776); Prasadha, Made K. (57200757714); Pei, Jacqueline (55913141300); Ting, Magdalena (57195422417); Zhu, Jie (56297070000); Li, Christina (57200752315); Hewett, Sierra (57211733435); Dong, Jason (57200757774); Ziyar, Ian (57200761977); Shi, Alexander (57200750760); Zhang, Runze (57194446671); Zheng, Lianghong (56828486500); Hou, Rui (59032425700); Shi, William (56888195600); Fu, Xin (58832881500); Duan, Yaou (55331946100); Huu, Viet A.N. (56473600000); Wen, Cindy (55913674200); Zhang, Edward D. (57194448343); Zhang, Charlotte L. (57202885027); Li, Oulan (7003521973); Wang, Xiaobo (57221484941); Singer, Michael A. (54915646600); Sun, Xiaodong (23482893500); Xu, Jie (58009380800); Tafreshi, Ali (59026773600); Lewis, M. Anthony (57224603791); Xia, Huimin (56533028500); Zhang, Kang (56418957000)","57193116279; 7005893154; 57196088938; 57200758379; 35334583200; 57200760006; 55880755400; 57200758769; 57200754293; 57200756883; 57200757776; 57200757714; 55913141300; 57195422417; 56297070000; 57200752315; 57211733435; 57200757774; 57200761977; 57200750760; 57194446671; 56828486500; 59032425700; 56888195600; 58832881500; 55331946100; 56473600000; 55913674200; 57194448343; 57202885027; 7003521973; 57221484941; 54915646600; 23482893500; 58009380800; 59026773600; 57224603791; 56533028500; 56418957000","Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning","2018","172","5","","1122","1131.e9","","10.1016/j.cell.2018.02.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042389905&doi=10.1016%2fj.cell.2018.02.010&partnerID=40&md5=e83d2ef0a11cfa54b6663a859ef708fe","The implementation of clinical-decision support algorithms for medical imaging faces challenges with reliability and interpretability. Here, we establish a diagnostic tool based on a deep-learning framework for the screening of patients with common treatable blinding retinal diseases. Our framework utilizes transfer learning, which trains a neural network with a fraction of the data of conventional approaches. Applying this approach to a dataset of optical coherence tomography images, we demonstrate performance comparable to that of human experts in classifying age-related macular degeneration and diabetic macular edema. We also provide a more transparent and interpretable diagnosis by highlighting the regions recognized by the neural network. We further demonstrate the general applicability of our AI system for diagnosis of pediatric pneumonia using chest X-ray images. This tool may ultimately aid in expediting the diagnosis and referral of these treatable conditions, thereby facilitating earlier treatment, resulting in improved clinical outcomes. Video Abstract: [Figure presented] Image-based deep learning classifies macular degeneration and diabetic retinopathy using retinal optical coherence tomography images and has potential for generalized applications in biomedical image interpretation and medical decision making. © 2018 Elsevier Inc.","age-related macular degeneration; artificial intelligence; choroidal neovascularization; deep learning; diabetic macular edema; diabetic retinopathy; optical coherence tomography; pneumonia; screening; transfer learning","Child; Deep Learning; Diagnostic Imaging; Humans; Neural Networks (Computer); Pneumonia; Reproducibility of Results; ROC Curve; Tomography, Optical Coherence; Article; artificial intelligence; bacterial pneumonia; bacterium detection; clinical outcome; comparative effectiveness; diabetic macular edema; diabetic retinopathy; diagnostic accuracy; diagnostic imaging; drusen; learning algorithm; macular degeneration; medical decision making; nerve cell network; optical coherence tomography; pathology; pneumonia; priority journal; retina disease; subretinal neovascularization; thorax radiography; virus pneumonia; artificial neural network; child; human; pneumonia; receiver operating characteristic; reproducibility","Dick and Carol Hertzberg Fund; Guangzhou Women and Children’s Medical Center; Michael Martin Fund; Richard Annesser Fund; National Natural Science Foundation of China, NSFC, (81700882, 81771629); National Natural Science Foundation of China, NSFC; National Key Research and Development Program of China, NKRDPC, (2017YFC1104600); National Key Research and Development Program of China, NKRDPC; Guangzhou Regenerative Medicine and Health Guangdong Laboratory, GRMH-GDL","","Cell Press","29474911"
"Popescu D.; Ichim L.","Popescu, Dan (12792410200); Ichim, Loretta (15077990200)","12792410200; 15077990200","Intelligent image processing system for detection and segmentation of regions of interest in retinal images","2018","10","3","73","","","","10.3390/SYM10030073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047252054&doi=10.3390%2fSYM10030073&partnerID=40&md5=7fc85b8d68f446c5873f3b9276869f2b","The automatic detection, segmentation, localization, and evaluation of the optic disc, macula, exudates, and hemorrhages are very important for diagnosing retinal diseases. One of the difficulties in detecting such regions of interest (RoIs) with computer vision is their symmetries, e.g., between the optic disc and exudates and also between exudates and hemorrhages. This paper proposes an original, intelligent, and high-performing image processing system for the simultaneous detection and segmentation of retinal RoIs. The basic principles of the method are image decomposition in small boxes and local texture analysis. The processing flow contains three phases: preprocessing, learning, and operating. As a first novelty, we propose proper feature selection based on statistical analysis in confusion matrices for different feature types (extracted from a co-occurrence matrix, fractal type, and local binary patterns). Mainly, the selected features are chosen to differentiate between similar RoIs. The second novelty consists of local classifier fusion. To this end, the local classifiers associated with features are grouped in global classifiers corresponding to the RoIs. The local classifiers are based on minimum distances to the representatives of classes and the global classifiers are based on confidence intervals, weights, and a voting scheme. A deep convolutional neural network, based on supervised learning, for blood vessel segmentation is proposed in order to improve the RoI detection performance. Finally, the experimental results on real images from different databases demonstrate the rightness of our methodologies and algorithms. © 2019 by the authors.","Biomedical image processing; Convolutional neural network; Exudates; Feature selection; Hemorrhages; Macula; Optic disc; Retinal image segmentation; Texture analysis","","","","MDPI AG",""
"Lin J.; Clancy N.T.; Qi J.; Hu Y.; Tatla T.; Stoyanov D.; Maier-Hein L.; Elson D.S.","Lin, Jianyu (56606450100); Clancy, Neil T. (34978108100); Qi, Ji (45761341500); Hu, Yang (57116675300); Tatla, Taran (57203131729); Stoyanov, Danail (57203105770); Maier-Hein, Lena (22634618600); Elson, Daniel S. (7005533698)","56606450100; 34978108100; 45761341500; 57116675300; 57203131729; 57203105770; 22634618600; 7005533698","Dual-modality endoscopic probe for tissue surface shape reconstruction and hyperspectral imaging enabled by deep neural networks","2018","48","","","162","176","14","10.1016/j.media.2018.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048705488&doi=10.1016%2fj.media.2018.06.004&partnerID=40&md5=48ae180c3cf428569e620ef396b95b8f","Surgical guidance and decision making could be improved with accurate and real-time measurement of intra-operative data including shape and spectral information of the tissue surface. In this work, a dual-modality endoscopic system has been proposed to enable tissue surface shape reconstruction and hyperspectral imaging (HSI). This system centers around a probe comprised of an incoherent fiber bundle, whose fiber arrangement is different at the two ends, and miniature imaging optics. For 3D reconstruction with structured light (SL), a light pattern formed of randomly distributed spots with different colors is projected onto the tissue surface, creating artificial texture. Pattern decoding with a Convolutional Neural Network (CNN) model and a customized feature descriptor enables real-time 3D surface reconstruction at approximately 12 frames per second (FPS). In HSI mode, spatially sparse hyperspectral signals from the tissue surface can be captured with a slit hyperspectral imager in a single snapshot. A CNN based super-resolution model, namely “super-spectral-resolution” network (SSRNet), has also been developed to estimate pixel-level dense hypercubes from the endoscope cameras standard RGB images and the sparse hyperspectral signals, at approximately 2 FPS. The probe, with a 2.1 mm diameter, enables the system to be used with endoscope working channels. Furthermore, since data acquisition in both modes can be accomplished in one snapshot, operation of this system in clinical applications is minimally affected by tissue surface movement and deformation. The whole apparatus has been validated on phantoms and tissue (ex vivo and in vivo), while initial measurements on patients during laryngeal surgery show its potential in real-world clinical applications. © 2018 Elsevier B.V.","3D reconstruction; Deep learning; Hyperspectral imaging; Intra-operative imaging; Structured light; Super-spectral-resolution","Algorithms; Endoscopes; Fiber Optic Technology; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Intraoperative Period; Neural Networks (Computer); Spatial Analysis; Spectrum Analysis; Biomedical signal processing; Convolutional neural networks; Data acquisition; Decision making; Deep learning; Deep neural networks; Endoscopy; Image reconstruction; Light; Probes; Spectral resolution; Spectroscopy; Surgery; Textures; Three dimensional computer graphics; Tissue; 3D reconstruction; 3D surface reconstruction; Hyperspectral imagers; Hyperspectral signals; Intra-operative imaging; Real time measurements; Structured Light; Super-resolution models; accuracy; Article; deep neural network; human; human tissue; hyperspectral imaging; image quality; imaging; larynx; machine learning; prediction; priority journal; three dimensional imaging; algorithm; artificial neural network; endoscope; fiber optics; image processing; intraoperative period; procedures; spatial analysis; spectroscopy; Hyperspectral imaging","Cancer Research UK Imperial Centre; IGHI; National Institute for Health Research Imperial Biomedical Research Centre; Horizon 2020 Framework Programme, H2020, (637960); Imperial Experimental Cancer Medicine Centre, ECMC; European Research Council, ERC, (242991)","","Elsevier B.V.","29933116"
"Cao C.; Liu F.; Tan H.; Song D.; Shu W.; Li W.; Zhou Y.; Bo X.; Xie Z.","Cao, Chensi (57201095774); Liu, Feng (55946542300); Tan, Hai (57225973247); Song, Deshou (57201085147); Shu, Wenjie (12798780300); Li, Weizhong (57215118233); Zhou, Yiming (57221212620); Bo, Xiaochen (7005391024); Xie, Zhi (35775013100)","57201095774; 55946542300; 57225973247; 57201085147; 12798780300; 57215118233; 57221212620; 7005391024; 35775013100","Deep Learning and Its Applications in Biomedicine","2018","16","1","","17","32","15","10.1016/j.gpb.2017.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043357845&doi=10.1016%2fj.gpb.2017.07.003&partnerID=40&md5=9567c9737feac0eed667c3b83ae210b9","Advances in biological and medical technologies have been providing us explosive volumes of biological and physiological data, such as medical images, electroencephalography, genomic and protein sequences. Learning from these data facilitates the understanding of human health and disease. Developed from artificial neural networks, deep learning-based algorithms show great promise in extracting features and learning patterns from complex data. The aim of this paper is to provide an overview of deep learning techniques and some of the state-of-the-art applications in the biomedical field. We first introduce the development of artificial neural network and deep learning. We then describe two main components of deep learning, i.e., deep learning architectures and model optimization. Subsequently, some examples are demonstrated for deep learning applications, including medical image classification, genomic sequence analysis, as well as protein structure classification and prediction. Finally, we offer our perspectives for the future directions in the field of deep learning. © 2018","Big data; Bioinformatics; Biomedical informatics; Deep learning; High-throughput sequencing; Medical image","Algorithms; Computational Biology; Diagnostic Imaging; Genomics; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Protein Structure, Secondary; Proteins; protein; algorithm; artificial neural network; biomedicine; classification; deep learning based algorithm; entropy; gene expression; genomics; image segmentation; learning; model; parameters; process optimization; protein structure; Review; artificial neural network; biology; computer assisted diagnosis; diagnostic imaging; human; machine learning; metabolism; procedures; protein secondary structure","Center for Precision Medicine, Sun Yat-sen University; National High-tech Research and Development Program, (2015AA020110)","","Beijing Genomics Institute","29522900"
"Ding J.; Li X.; Gudivada V.N.","Ding, Junhua (7402608357); Li, Xinchuan (36194758400); Gudivada, Venkat N. (6602858683)","7402608357; 36194758400; 6602858683","Augmentation and evaluation of training data for deep learning","2017","2018-January","","","2603","2611","8","10.1109/BigData.2017.8258220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047761559&doi=10.1109%2fBigData.2017.8258220&partnerID=40&md5=a55fd08262459b1a6b2d24cc9bc3a6c2","Deep learning is an important technique for extracting value from big data. However, the effectiveness of deep learning requires large volumes of high quality training data. In many cases, the size of training data is not large enough for effectively training a deep learning classifier. Data augmentation is a widely adopted approach for increasing the amount of training data. But the quality of the augmented data may be questionable. Therefore, a systematic evaluation of training data is critical. Furthermore, if the training data is noisy, it is necessary to separate out the noise data automatically. In this paper, we propose a deep learning classifier for automatically separating good training data from noisy data. To effectively train the deep learning classifier, the original training data need to be transformed to suit the input format of the classifier. Moreover, we investigate different data augmentation approaches to generate sufficient volume of training data from limited size original training data. We evaluated the quality of the training data through cross validation of the classification accuracy with different classification algorithms. We also check the pattern of each data item and compare the distributions of datasets. We demonstrate the effectiveness of the proposed approach through an experimental investigation of automated classification of massive biomedical images. Our approach is generic and is easily adaptable to other big data domains. © 2017 IEEE.","big data; convolutional neural network; deep learning; diffraction image; machine learning; neural network; support vector machine","Big data; Clustering algorithms; Deep learning; Deep neural networks; Learning systems; Neural networks; Quality control; Support vector machines; Automated classification; Classification accuracy; Classification algorithm; Convolutional neural network; Diffraction images; Experimental investigations; Learning classifiers; Systematic evaluation; Classification (of information)","National Science Foundation, NSF, (1730568); East Carolina University, ECU","Nie J.-Y.; Obradovic Z.; Suzumura T.; Ghosh R.; Nambiar R.; Wang C.; Zang H.; Baeza-Yates R.; Baeza-Yates R.; Hu X.; Kepner J.; Cuzzocrea A.; Tang J.; Toyoda M.","Institute of Electrical and Electronics Engineers Inc.",""
"Aubreville M.; Goncalves M.; Knipfer C.; Oetter N.; Würfl T.; Neumann H.; Stelzle F.; Bohr C.; Maier A.","Aubreville, Marc (56940880900); Goncalves, Miguel (57194557921); Knipfer, Christian (35090081500); Oetter, Nicolai (55892022000); Würfl, Tobias (57191574553); Neumann, Helmut (23100999100); Stelzle, Florian (32267673500); Bohr, Christopher (8549789900); Maier, Andreas (23392966100)","56940880900; 57194557921; 35090081500; 55892022000; 57191574553; 23100999100; 32267673500; 8549789900; 23392966100","Patch-based carcinoma detection on confocal laser endomicroscopy images - a cross-site robustness assessment","2018","2","","","27","34","7","10.5220/0006534700270034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051722163&doi=10.5220%2f0006534700270034&partnerID=40&md5=f6f6c089fb81af13d158d45271c6fb72","Deep learning technologies such as convolutional neural networks (CNN) provide powerful methods for image recognition and have recently been employed in the field of automated carcinoma detection in confocal laser endomicroscopy (CLE) images. CLE is a (sub-)surface microscopic imaging technique that reaches magnifications of up to 1000x and is thus suitable for in vivo structural tissue analysis. In this work, we aim to evaluate the prospects of a priorly developed deep learning-based algorithm targeted at the identification of oral squamous cell carcinoma with regard to its generalization to further anatomic locations of squamous cell carcinomas in the area of head and neck. We applied the algorithm on images acquired from the vocal fold area of five patients with histologically verified squamous cell carcinoma and presumably healthy control images of the clinically normal contra-lateral vocal cord. We find that the network trained on the oral cavity data reaches an accuracy of 89.45% and an area-under-the-curve (AUC) value of 0.955, when applied on the vocal cords data. Compared to the state of the art, we achieve very similar results, yet with an algorithm that was trained on a completely disjunct data set. Concatenating both data sets yielded further improvements in cross-validation with an accuracy of 90.81% and AUC of 0.970. In this study, for the first time to our knowledge, a deep learning mechanism for the identification of oral carcinomas using CLE Images could be applied to other disciplines in the area of head and neck. This study shows the prospect of the algorithmic approach to generalize well on other malignant entities of the head and neck, regardless of the anatomical location and furthermore in an examiner-independent manner. Copyright © 2018 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved","Automatic Carcinoma Detection; Confocal Laser Endomicroscopy; Deep Convolutional Networks; Squamous Cell Carcinoma","Biomedical engineering; Engineering education; Image recognition; Imaging techniques; Neural networks; Algorithmic approach; Area under the curves; Confocal laser endomicroscopy; Convolutional neural network; Learning-based algorithms; Oral squamous cell carcinomata; Robustness assessment; Squamous cell carcinoma; Deep learning","","Wiebe S.; Gamboa H.; Fred A.; Bermudez i Badia S.","SciTePress",""
"Wu Y.-T.; Huang T.H.; Yi Lin C.; Tsai S.J.; Wang P.-S.","Wu, Yu-Te (7406890264); Huang, Tzu Hsuan (57203099841); Yi Lin, Chun (57203089489); Tsai, Sheng Jia (57203091026); Wang, Po-Shan (7405458546)","7406890264; 57203099841; 57203089489; 57203091026; 7405458546","Classification of EEG Motor Imagery Using Support Vector Machine and Convolutional Neural Network","2018","","","8606765","","","","10.1109/CACS.2018.8606765","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062429665&doi=10.1109%2fCACS.2018.8606765&partnerID=40&md5=613ea47d028b115aa802a16dfd6749e2","In this study, we used two machine learning algorithms, namely, linear support vector machine (SVM) and convolutional neural network (CNN), to classify the BCI (Brain Computer interface) competition IV-2a 2-class MI (motor imagery) data set which consists of EEG data from 9 subjects. For each subject, 5 sessions of signals from three electrodes (C3, Cz, and C4) were recorded with sampling rate 250Hz. The training data, which consisted of the first 3 sessions, included 400 trials. The evaluation data, which consisted of the last 2 sessions, included 320 trials. Each trial started with gazing at fix cross on screen for 3 seconds followed by a one-second visual cue pointing either to the left or right to instruct the subject for left or right motor imagery over a period of 4 seconds, and then followed by a short break of at least 1.5 seconds. Features were extracted from the 0.5 to 2.5 second signals after the cue for each trial from C3 and C4. Each EEG trial was band pass filtered into different frequency bands, namely, delta (0.5-3Hz), theta (4-8Hz), alpha (8-12Hz), beta bands (13-30Hz), gamma bands (31-60Hz). Those filtered signals were then used as the input data for training the linear SVM. In addition, we generated a 2 by 500 matrix by down sampling the training data from each trial. There are 5760 such matrices in total generated from all subjects and serve as the input data for training CNN and the trained model was evaluated by another 340 matrices from each subject. Our CNN architecture consisted of 2 convolution layer and 2 fully connect layers, and there was a batch normalization layer before the activated layer and a dropout layer with a probability of 50% after the activated layer. The classification accuracies evaluated by averaged kappa values obtained from linear SVM and CNN are 0.5 and 0.621, respectively, suggesting the deep learning CNN method is superior to the classical linear SVM on the EEG classification. © 2018 IEEE.","Brain Computer Interface (BCI); Convolution Neural Networks (CNN).; Electroencephalography (EEG); Machine Learning (ML); Motor Imagery (MI); Signal Processing; Support Vector Machine (SVM)","Biomedical signal processing; Brain computer interface; Classification (of information); Convolution; Deep learning; Electrophysiology; Image classification; Learning algorithms; Matrix algebra; Neural networks; Signal sampling; Support vector machines; Brain computer interface; Convolution neural network; Convolution neural network .; Electroencephalography; Machine learning; Machine-learning; Motor imagery; Signal-processing; Support vector machine; Support vectors machine; Electroencephalography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Lee C.S.; Tyring A.J.; Deruyter N.P.; Wu Y.; Rokem A.; Lee A.Y.","Lee, Cecilia S. (56472056400); Tyring, Ariel J. (56221971100); Deruyter, Nicolaas P. (57193351908); Wu, Yue (57194851622); Rokem, Ariel (6507945628); Lee, Aaron Y. (26635526200)","56472056400; 56221971100; 57193351908; 57194851622; 6507945628; 26635526200","Deep-learning based, automated segmentation of macular edema in optical coherence tomography","2017","8","7","295030","3440","3448","8","10.1364/BOE.8.003440","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023600747&doi=10.1364%2fBOE.8.003440&partnerID=40&md5=23e1aa7909ff747ee8d7b8a90f60665b","Evaluation of clinical images is essential for diagnosis in many specialties. Therefore the development of computer vision algorithms to help analyze biomedical images will be important. In ophthalmology, optical coherence tomography (OCT) is critical for managing retinal conditions. We developed a convolutional neural network (CNN) that detects intraretinal fluid (IRF) on OCT in a manner indistinguishable from clinicians. Using 1,289 OCT images, the CNN segmented images with a 0.911 cross-validated Dice coefficient, compared with segmentations by experts. Additionally, the agreement between experts and between experts and CNN were similar. Our results reveal that CNN can be trained to perform automated segmentations of clinically relevant image features. © 2017 Optical Society of America.","","Bioinformatics; Deep learning; Image segmentation; Neural networks; Ophthalmology; Tomography; Automated segmentation; Biomedical images; Clinical images; Computer vision algorithms; Convolutional neural network; Dice coefficient; Intra-retinal fluids; Segmented images; Article; artificial neural network; correlation coefficient; human; image analysis; image segmentation; learning algorithm; macular edema; optical coherence tomography; retina detachment; training; validation process; Optical tomography","National Eye Institute, NEI, (K23EY02492); Alfred P. Sloan Foundation; Gordon and Betty Moore Foundation, GBMF; Research to Prevent Blindness, RPB; Nvidia","","OSA - The Optical Society",""
"Bobrov E.; Georgievskaya A.; Kiselev K.; Sevastopolsky A.; Zhavoronkov A.; Gurov S.; Rudakov K.; Tobar M.P.B.; Jaspers S.; Clemann S.","Bobrov, Eugene (57204955857); Georgievskaya, Anastasia (57204955063); Kiselev, Konstantin (57204955979); Sevastopolsky, Artem (57195675236); Zhavoronkov, Alex (39862415800); Gurov, Sergey (57192988543); Rudakov, Konstantin (6603540895); Tobar, Maria del Pilar Bonilla (57204949557); Jaspers, Sören (7003534930); Clemann, Sven (6507975498)","57204955857; 57204955063; 57204955979; 57195675236; 39862415800; 57192988543; 6603540895; 57204949557; 7003534930; 6507975498","PhotoAgeClock: Deep learning algorithms for development of noninvasive visual biomarkers of aging","2018","10","11","","3249","3259","10","10.18632/aging.101629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057278319&doi=10.18632%2faging.101629&partnerID=40&md5=1444e108d56ace3a49d20eda7e29c824","Aging biomarkers are the qualitative and quantitative indicators of the aging processes of the human body. Estimation of biological age is important for assessing the physiological state of an organism. The advent of machine learning lead to the development of the many age predictors commonly referred to as the ""aging clocks"" varying in biological relevance, ease of use, cost, actionability, interpretability, and applications. Here we present and investigate a novel non-invasive class of visual photographic biomarkers of aging. We developed a simple and accurate predictor of chronological age using just the anonymized images of eye corners called the PhotoAgeClock. Deep neural networks were trained on 8414 anonymized high-resolution images of eye corners labeled with the correct chronological age. For people within the age range of 20 to 80 in a specific population, the model was able to achieve a mean absolute error of 2.3 years and 95% Pearson and Spearman correlation. © Bobrov et al.","Age prediction; Biomedical imaging; Computer vision; Deep learning; Photographic aging biomarker; Photographic aging clock","Adult; Aged; Aged, 80 and over; Aging; Algorithms; Biomarkers; Deep Learning; Face; Female; Humans; Machine Learning; Middle Aged; Neural Networks, Computer; Skin Aging; Young Adult; biological marker; adult; aged; aging; algorithm; cutaneous parameters; face; female; human; machine learning; middle aged; physiology; very elderly; young adult","","","Impact Journals LLC","30414596"
"Ahmed M.R.; Zhang Y.; Feng Z.; Lo B.; Inan O.T.; Liao H.","Ahmed, Md Rishad (35177456400); Zhang, Yuan (55971560500); Feng, Zhiquan (7403443516); Lo, Benny (15834859900); Inan, Omer T. (15753969900); Liao, Hongen (7201507586)","35177456400; 55971560500; 7403443516; 15834859900; 15753969900; 7201507586","Neuroimaging and Machine Learning for Dementia Diagnosis: Recent Advancements and Future Prospects","2019","12","","8572804","19","33","14","10.1109/RBME.2018.2886237","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058630419&doi=10.1109%2fRBME.2018.2886237&partnerID=40&md5=adc280dc28673fa8348a0530eaa07998","Dementia, a chronic and progressive cognitive declination of brain function caused by disease or impairment, is becoming more prevalent due to the aging population. A major challenge in dementia is achieving accurate and timely diagnosis. In recent years, neuroimaging with computer-aided algorithms have made remarkable advances in addressing this challenge. The success of these approaches is mostly attributed to the application of machine learning techniques for neuroimaging. In this review paper, we present a comprehensive survey of automated diagnostic approaches for dementia using medical image analysis and machine learning algorithms published in the recent years. Based on the rigorous review of the existing works, we have found that, while most of the studies focused on Alzheimer's disease, recent research has demonstrated reasonable performance in the identification of other types of dementia remains a major challenge. Multimodal imaging analysis deep learning approaches have shown promising results in the diagnosis of these other types of dementia. The main contributions of this review paper are as follows. 1) Based on the detailed analysis of the existing literature, this paper discusses neuroimaging procedures for dementia diagnosis. 2) It systematically explains the most recent machine learning techniques and, in particular, deep learning approaches for early detection of dementia. © 2008 IEEE.","computer-aided diagnosis (CAD); deep learning; Dementia; image processing; machine learning; neuroimaging","Algorithms; Alzheimer Disease; Cognitive Dysfunction; Dementia; Early Diagnosis; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Multimodal Imaging; Neuroimaging; Pattern Recognition, Automated; Artificial intelligence; Computer aided diagnosis; Computer aided instruction; Deep learning; Image processing; Learning systems; Magnetic resonance imaging; Medical computing; Neurodegenerative diseases; Neuroimaging; dopamine transporter; Alzheimer's disease; Automated diagnostics; Biomedical imaging; Computer Aided Diagnosis(CAD); Dementia; Machine learning techniques; Multi-modal imaging; Recent researches; aging; algorithm; Alzheimer disease; arterial spin labeling; artificial neural network; brain blood flow; clinical feature; controlled study; deep learning; dementia; diagnostic value; early diagnosis; electroencephalogram; functional connectivity; gray matter; human; image analysis; image processing; machine learning; major clinical study; multimodal imaging; myocardial perfusion imaging; neuroimaging; nuclear magnetic resonance imaging; positron emission tomography; predictive value; Review; right hippocampus; short term memory; single photon emission computed tomography; white matter; Alzheimer disease; automated pattern recognition; cognitive defect; computer assisted diagnosis; dementia; diagnostic imaging; machine learning; neuroimaging; pathophysiology; procedures; trends; Learning algorithms","Alzheimer’s disease; Beijing National Science Foundation; Shandong Provincial Key Research & Development Project, (2017GGX10141); National Natural Science Foundation of China, NSFC, (61472163, 61572231, 7172122, 81427803, 81771940, L172003); National Basic Research Program of China (973 Program), (2017YFC0108000)","","Institute of Electrical and Electronics Engineers","30561351"
"Harangi B.","Harangi, Balazs (36198305300)","36198305300","Skin lesion classification with ensembles of deep convolutional neural networks","2018","86","","","25","32","7","10.1016/j.jbi.2018.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052633192&doi=10.1016%2fj.jbi.2018.08.006&partnerID=40&md5=976b6f7af1e908dca4d1dbd7b68c53df","Skin cancer is a major public health problem with over 123,000 newly diagnosed cases worldwide in every year. Melanoma is the deadliest form of skin cancer, responsible for over 9000 deaths in the United States each year. Thus, reliable automatic melanoma screening systems would provide a great help for clinicians to detect the malignant skin lesions as early as possible. In the last five years, the efficiency of deep learning-based methods increased dramatically and their performances seem to outperform conventional image processing methods in classification tasks. However, this type of machine learning-based approaches have a main drawback, namely they require thousands of labeled images per classes for their training. In this paper, we investigate how we can create an ensemble of deep convolutional neural networks to improve further their individual accuracies in the task of classifying dermoscopy images into the three classes melanoma, nevus, and seborrheic keratosis when we have no opportunity to train them on adequate number of annotated images. To achieve high classification accuracy, we fuse the outputs of the classification layers of four different deep neural network architectures. More specifically, we propose the aggregation of robust convolutional neural networks (CNNs) into one framework, where the final classification is achieved based on the weighted output of the member CNNs. For aggregation, we consider different fusion-based methods and select the best performing one for this problem. Our experimental results also prove that the creation of an ensemble of different neural networks is a meaningful approach, since each of the applied fusion strategies outperforms the individual networks regarding classification accuracy. The average area under the receiver operating characteristic curve has been found to be 0.891 for the 3-class classification task. For an objective evaluation of our approach, we have tested its performance on the official test database of the IEEE International Symposium on Biomedical Imaging (ISBI) 2017 challenge on Skin Lesion Analysis Towards Melanoma Detection dedicated to skin cancer recognition. © 2018 Elsevier Inc.","Deep convolutional neural network; Ensemble-based system; Information fusion; Melanoma detection","Algorithms; Databases, Factual; Dermoscopy; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Keratosis, Seborrheic; Machine Learning; Melanocytes; Melanoma; Neural Networks (Computer); Nevus; ROC Curve; Skin Neoplasms; Convolution; Dermatology; Diagnosis; Diseases; Image classification; Image enhancement; Information fusion; Learning algorithms; Medical imaging; Network architecture; Neural networks; Oncology; Classification accuracy; Convolutional neural network; Deep convolutional neural networks; Ensemble-based systems; Image processing - methods; Learning-based methods; Melanoma detection; Receiver operating characteristic curves; algorithm; area under the curve; Article; artificial neural network; convolutional neural network; deep convolutional neural network; epiluminescence microscopy; genetic algorithm; measurement accuracy; melanoma; nevus; priority journal; receiver operating characteristic; seborrheic keratosis; sensitivity and specificity; simulated annealing algorithm; stochastic gradient descent algorithm; theoretical model; computer assisted diagnosis; diagnostic imaging; factual database; human; image processing; machine learning; melanocyte; melanoma; nevus; pathology; procedures; seborrheic keratosis; skin tumor; Deep neural networks","European Commission, EC; European Social Fund, ESF","","Academic Press Inc.","30103029"
"Shah A.; Zhou L.N.; Abrámoff M.D.; Wu X.A.","Shah, Abhay (56595996000); Zhou, Leixi N. (57219055429); Abrámoff, Michael D. (6602158360); Wu, Xi Aodong (56191850800)","56595996000; 57219055429; 6602158360; 56191850800","Multiple surface segmentation using convolution neural nets: Application to retinal layer segmentation in OCT images","2018","9","9","#335964","4509","4526","17","10.1364/BOE.9.004509","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052752339&doi=10.1364%2fBOE.9.004509&partnerID=40&md5=af8a5cf9352b300f99bb08543d68310b","Automated segmentation of object boundaries or surfaces is crucial for quantitative image analysis in numerous biomedical applications. For example, retinal surfaces in optical coherence tomography (OCT) images play a vital role in the diagnosis and management of retinal diseases. Recently, graph based surface segmentation and contour modeling have been developed and optimized for various surface segmentation tasks. These methods require expertly designed, application specific transforms, including cost functions, constraints and model parameters. However, deep learning based methods are able to directly learn the model and features from training data. In this paper, we propose a convolutional neural network (CNN) based framework to segment multiple surfaces simultaneously. We demonstrate the application of the proposed method by training a single CNN to segment three retinal surfaces in two types of OCT images-normal retinas and retinas affected by intermediate age-related macular degeneration (AMD). The trained network directly infers the segmentations for each B-scan in one pass. The proposed method was validated on 50 retinal OCT volumes (3000 B-scans) including 25 normal and 25 intermediate AMD subjects. Our experiment demonstrated statistically significant improvement of segmentation accuracy compared to the optimal surface segmentation method with convex priors (OSCS) and two deep learning based UNET methods for both types of data. The average computation time for segmenting an entire OCT volume (consisting of 60 B-scans each) for the proposed method was 12.3 seconds, demonstrating low computation costs and higher performance compared to the graph based optimal surface segmentation and UNET based methods. © 2018 Optical Society of America.","","Convolution; Cost functions; Deep learning; Diagnosis; Graphic methods; Medical applications; Neural networks; Ophthalmology; Optical tomography; Age-related macular degeneration; Automated segmentation; Biomedical applications; Convolutional Neural Networks (CNN); Learning-based methods; Multiple surface segmentations; Quantitative image analysis; Segmentation accuracy; age related macular degeneration; Article; B scan; comparative study; convolutional neural network; diagnostic accuracy; human; image analysis; image processing; image segmentation; learning algorithm; multiple surface segmentation; optical coherence tomography; quantitative analysis; retinal layer segmentation; retinal pigment epithelium; spectral domain optical coherence tomography; surface property; two-dimensional imaging; Image segmentation","","","OSA - The Optical Society",""
"","","","International Conference on Computers and Information Processing Technologies, ICCIPT 2014","2014","571-572","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903445629&partnerID=40&md5=4d99cfb04c5d3dd6e4e752446f64f5d7","The proceedings contain 223 papers. The special focus in this conference is on Computers and Information Processing Technologies. The topics include: A large-scale and flexible BMS design; research on map reduce task dynamic balancing strategy based on file label; researches on data privacy in cloud computing based on game theory; the MPI and OpenMP implementation of parallel algorithm for generating Mandelbrot set; adaptive congestion control via dynamic output feedback; an advanced ECC dynamic password-based remote authentication scheme for cloud computing; an audio hiding algorithm based on spline interpolation and wavelet transform; evaluation method for anti-interference performance of measuring based on entropy loss; RE-based weighted distributed equipment layout; algorithms of mining maximum frequent itemsets based on compression matrix; a secret sharing scheme on access structure; a tag-based signature scheme with shorter signature length; an identity-based conditional proxy re-encryption in cloud computing environments; fine-grained access control with efficient revocation in cloud storage; integrity and fidelity evaluation of digital evidence in live forensics; MANET-based stable clustering algorithm and its performance analysis;; reinforcement learning for cloud computing digital library; research on design and construction method of bent functions; a novelty model for reliability assessment of complex system; a multi-attribute decision-making method based on SPAOWA operator; the forecasting research of Beijing tourism demand based on the BP neural network; setting of academic warning based on multivariate copula functions; the application of iteration learning control in silkworm incubation chamber system; fault diagnoses using inverse fuzzy model; a community detection method based on multi-objective optimization method; a high precision indoor positioning system based on VLC and smart handheld; a hybrid IGA-SA algorithm for optimization problems in fault diagnosis; efficient particle swarm optimization algorithm based on affinity propagation; fault diagnosis of transformer based on RBF neural network; features extraction for Lhasa Tibetan speech recognition; FECG extraction algorithm based on BSS using temporal structure and DWT; fuzzy clustering segmentation algorithm research for biomedical image based on artificial life; hourly solar radiation forecast based on k-NN nonparametric regression model; multi-thread memory particle swarm optimization for dynamic optimization problems; recognizing event in short text based on decision tree; reliability analysis based on Markov process for repairable systems; short-term prediction of ship motion based on EMD-SVM; design of a two-wheel self-balanced vehicle system; moving target detection and tracking control simulation platform; new research for traffic state identification; large naval ship evaluation method attended by multiple experts; fuzzy comprehensive evaluation method of experimental teaching quality based on AHP; the planning system based on the postponement manufacturing theory; Tibetan-Chinese named entity extraction based on comparable corpus; the research on the development of smart library; an Iot-based remote health monitoring and management system; analysis of user influence using user behavior and random walk; tax revenue loss under electronic commerce in China; tax administration problem in the e-business environment; research on the elements of e-government performance evaluation; application of information technology in the county government; a study on simulative system of mobile payment; casting process solutions optimization of LFC forklift box; FEM analysis of sheet incremental forming process; application research of PBL method in PLC control technology; a phase anti-ambiguity method for USBL system; smart community security system based on sensor web; research on static game theory based secure routing algorithm in WSN; human activity recognition using smart-phone sensors; design of circuit for alcohol measurements using three-electrode biosensor; study on passivity-based control of TNPC PV grid-connected inverter; theoretical studies of novel high power millimeter generator based on vacuum electron devices; the study on intelligent insecticidal lamp with LED; the intelligent desk lamp designed for special populations; the design of freeform surface Fresnel lens used for LED uniform illumination; stabilization of a class of chaotic systems via single-state adaptive feedback controller; research on 5V internal power supply circuit of switching power supply; optimization design of photovoltaic system MPPT controller; modeling hydraulic power system with surge tank; dispersion curves and fields for a chiral negative refraction parallel-plate waveguide under PMC boundary; a novel dead-time control method for double end converter; a low standby power consumption control circuit for switching power supply; a flyback 25W switching power supply for electric vehicle; a distributed DC power devise based on DSP; a 3 GHz semi-digital delay locked loop with high resolution; a dual-DSP sonobuoy signal processing system; transmission of image information in the network multimedia teaching; context-assisted fast face detection; the EMD analysis AE signals of rock failure under uniaxial compression; simulation of dynamic light scattering signal based on AR Model; disparity estimation of 3-D mesh for stereo video coding; taxi bidirectional search system based on smart phone; dynamic biomedical image segmentation based on wavelet transform; research on issues of across border area in network games; an RFID-assisted digital souvenir generation system; rock image pore identification based on fuzzy C-means clustering and neural networks; a video characteristics watermarking algorithm based on bees evolutional computation; study of slice cell counting system; upper-body pose recognition using cylinder pattern model; tomato disease image retrieval based on composite features the research of ortho-rectification to QuickBird image with more mountains based on ERDAS10.0; pedestrian detection optimization algorithm based on low-altitude UAV; improved face recognition using 2D-LDA with weighted covariance scatter; challenging the recognition of facial expression via deep learning and applied study of size measurement based on image.","","","","","Trans Tech Publications Ltd",""
"Uysal F.; Hardalac F.; Koc M.","Uysal, Fatih (57206468020); Hardalac, Firat (6602517195); Koc, Mustafa (57486067400)","57206468020; 6602517195; 57486067400","Classification of T1 and T2 Weighted Magnetic Resonance Prostate Images Using Convolutional Neural Networks; [Evrişimsel Sinir Aǧlari Kullanilarak T1 ve T2 Aǧirlikli Manyetik Rezonans Prostat Imgelerinin Siniflandirilmasi]","2018","","","8596792","","","","10.1109/TIPTEKNO.2018.8596792","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061721383&doi=10.1109%2fTIPTEKNO.2018.8596792&partnerID=40&md5=cfe15cd0a665730b020e165662353284","Prostate cancer is a type of cancer that is very common in men. Literature review, it has been observed that there are many studies conducted on this prostate image using various image processing methods for cancer diagnosis and treatment. Secondary hemorrhage sites in prostate biopsy may cause misdiagnosis in T2-weighted magnetic resonance (MR) prostate images, in terms of tumor. In these cases, T1-weighted MR imaging of the prostate is helpful in diagnosing. In such situations, it may be helpful to prevent misdiagnosis and to help diagnosis; In this study, one deep convolutional neural network learning algorithms (CNN) using T1 and T2-weighted MR image classification process of the prostate were performed. As a result of this, an CNN model was developed that can classify MR prostate images. © 2018 IEEE.","convolutional neural networks; deep learning; image classification; magnetic resonance prostate images","Biomedical engineering; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Diseases; Learning algorithms; Magnetic resonance; Magnetic resonance imaging; Magnetism; Neural networks; Urology; Cancer diagnosis; Convolutional neural network; Image processing - methods; Literature reviews; Prostate biopsy; Prostate cancers; Prostate images; T1-weighted; Image classification","","","Institute of Electrical and Electronics Engineers Inc.",""
"Ayan E.; Unver H.M.","Ayan, Enes (57203007065); Unver, Halil Murat (55220789500)","57203007065; 55220789500","Data augmentation importance for classification of skin lesions via deep learning","2018","","","","1","4","3","10.1109/EBBT.2018.8391469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050224605&doi=10.1109%2fEBBT.2018.8391469&partnerID=40&md5=62cb60c297ecba7340106d578a0b4da4","Melanoma is a fatal type of cancer which is mostly curable if detected in early stages. Various machine learning algorithms are used for distinguishing benign lesions from malignant such as deep learning. To obtain successful result from deep learning, large and quality training data set is essential. But, existing data sets maybe insufficient for training a deep learning network. Building a powerful classifier from insufficient data, data augmentation methods are useful. In this article the same network trained with augmented skin lesion images and non- augmented skin lesion images for detecting malignant skin lesions. When compered results, it has been seen that the network using augmented data for training has achieved better results than training with non-augmented data. © 2018 IEEE.","convolutional neural networks; data augmentation; deep learning; melanoma; skin lesions","Biomedical engineering; Classification (of information); Dermatology; Learning algorithms; Neural networks; Oncology; Convolutional neural network; Data augmentation; Learning network; Malignant skin; melanoma; Quality training; Skin lesion; Skin lesion images; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Tang Z.-C.; Zhang K.-J.; Li C.; Sun S.-Q.; Huang Q.; Zhang S.-Y.","Tang, Zhi-Chuan (36976326400); Zhang, Ke-Jun (36106527100); Li, Chao (57212831322); Sun, Shou-Qian (7404509594); Huang, Qi (57704293700); Zhang, San-Yuan (35338606200)","36976326400; 36106527100; 57212831322; 7404509594; 57704293700; 35338606200","Motor Imagery Classification Based on Deep Convolutional Neural Network and Its Application in Exoskeleton Controlled by EEG","2017","40","6","","1367","1378","11","10.11897/SP.J.1016.2017.01367","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029566727&doi=10.11897%2fSP.J.1016.2017.01367&partnerID=40&md5=e8784ef8ae03fd72bb252f2d19eaf77a","Brain-Computer Interface (BCI) based on motor imagery (MI) has been applied in the rehabilitation exoskeleton widely. In the practical use, the low signal-noise ratio of electroencephalogram (EEG) signal results in the low classification accuracy in BCI. Therefore, many studies have focused on the improvement of feature extraction and classification algorithms. In this paper, we proposed an original method based on the deep convolutional neural network (CNN) to perform feature extraction and classification for single-trial MI EEG signal. Firstly, according to the EEG signal's characteristic that combining time and space information, we constructed a 5-layer CNN model to classify the MI; secondly, MI experimental paradigm was designed based on imagining left hand movement and foot movement, and the experimental data of MI were collected; thirdly, the proposed method was used in the public data set and experimental data set to build classification model, compared with the other three methods (power+SVM, CSP+SVM and MRA+LDA); finally, the classification model which achieved the best classification performance was applied in real-time control of upper-limb exoskeleton to verify the effectiveness of our proposed method. The results demonstrate that CNN can further improve classification performance: the average accuracies of public data set (90.75%±2.47%) and experimental data set (89.51%±2.95%) using CNN are both higher than that using the other three methods. Furthermore, in real-time control of upper-limb exoskeleton, the average accuracy of all subjects reaches to 88.75%±3.42%, which verifies the effectiveness of the CNN method. The proposed method can recognize MI, and provides theoretical basis and technical support for BCI applications in the field of rehabilitation exoskeleton. © 2017, Science Press. All right reserved.","Artificial intelligence; BCI; CNN; Deep learning; Motor imagery; Rehabilitation exoskeleton","Artificial intelligence; Biomedical signal processing; Brain computer interface; Convolution; Deep learning; Deep neural networks; Electroencephalography; Exoskeleton (Robotics); Extraction; Feature extraction; Image classification; Interfaces (computer); Neural networks; Real time control; Classification accuracy; Classification models; Classification performance; Convolutional neural network; Electroencephalogram signals; Feature extraction and classification; Motor imagery; Motor imagery classification; Classification (of information)","","","Science Press",""
"Pang S.; Du A.; Orgun M.A.; Yu Z.","Pang, Shuchao (55639762100); Du, Anan (56167972000); Orgun, Mehmet A. (6603681610); Yu, Zhezhou (8938987700)","55639762100; 56167972000; 6603681610; 8938987700","A novel fused convolutional neural network for biomedical image classification","2019","57","1","","107","121","14","10.1007/s11517-018-1819-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049792899&doi=10.1007%2fs11517-018-1819-y&partnerID=40&md5=8ca3352a38bcbdb12e2a314503d6dec5","With the advent of biomedical imaging technology, the number of captured and stored biomedical images is rapidly increasing day by day in hospitals, imaging laboratories and biomedical institutions. Therefore, more robust biomedical image analysis technology is needed to meet the requirement of the diagnosis and classification of various kinds of diseases using biomedical images. However, the current biomedical image classification methods and general non-biomedical image classifiers cannot extract more compact biomedical image features or capture the tiny differences between similar images with different types of diseases from the same category. In this paper, we propose a novel fused convolutional neural network to develop a more accurate and highly efficient classifier for biomedical images, which combines shallow layer features and deep layer features from the proposed deep neural network architecture. In the analysis, it was observed that the shallow layers provided more detailed local features, which could distinguish different diseases in the same category, while the deep layers could convey more high-level semantic information used to classify the diseases among the various categories. A detailed comparison of our approach with traditional classification algorithms and popular deep classifiers across several public biomedical image datasets showed the superior performance of our proposed method for biomedical image classification. In addition, we also evaluated the performance of our method in modality classification of medical images using the ImageCLEFmed dataset. [Figure not available: see fulltext.]. © 2018, International Federation for Medical and Biological Engineering.","Biomedical image classification; Convolutional neural networks; Deep feature; Deep learning; Shallow feature","Bioinformatics; Classification (of information); Classifiers; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Medical imaging; Network architecture; Neural networks; Semantics; Biomedical image analysis; Biomedical imaging; Classification algorithm; Classification methods; Convolutional neural network; Deep feature; High level semantics; Shallow feature; Article; classification algorithm; convolutional neural network; digital imaging and communications in medicine; diseases; feature extraction; human; image analysis; intermethod comparison; k nearest neighbor; learning algorithm; machine learning; nuclear magnetic resonance imaging; priority journal; support vector machine; Image classification","","","Springer Verlag",""
"Hong J.; Park B.-Y.; Park H.","Hong, Jisu (57191960862); Park, Bo-Yong (56975729200); Park, Hyunjin (56512679000)","57191960862; 56975729200; 56512679000","Convolutional neural network classifier for distinguishing Barrett's esophagus and neoplasia endomicroscopy images","2017","","","8037461","2892","2895","3","10.1109/EMBC.2017.8037461","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032210988&doi=10.1109%2fEMBC.2017.8037461&partnerID=40&md5=9b4942f3b81d712a0a1193acea15ee2c","Barrett's esophagus is a diseased condition with abnormal changes of the cells in the esophagus. Intestinal metaplasia (IM) and gastric metaplasia (GM) are two sub-classes of Barrett's esophagus. As IM can progress to the esophageal cancer, the neoplasia (NPL), developing methods for classifying between IM and GM are important issues in clinical practice. We adopted a deep learning (DL) algorithm to classify three conditions of IM, GM, and NPL based on endimicroscopy images. We constructed a convolutional neural network (CNN) architecture to distinguish among three classes. A total of 262 endomicroscopy imaging data of Barrett's esophagus were obtained from the international symposium on biomedical imaging (ISBI) 2016 challenge. 155 IM, 26 GM and 55 NPL cases were used to train the architecture. We implemented image distortion to augment the sample size of the training data. We tested our proposed architecture using the 26 test images that include 17 IM, 4 GM and 5 NPL cases. The classification accuracy was 80.77%. Our results suggest that CNN architecture could be used as a good classifier for distinguishing endomicroscopy imaging data of Barrett's esophagus. © 2017 IEEE.","","Barrett Esophagus; Esophageal Diseases; Esophageal Neoplasms; Humans; Metaplasia; Neural Networks (Computer); artificial neural network; Barrett esophagus; esophagus disease; esophagus tumor; human; metaplasia","Korea Basic Science Institute, (IBS-R015-D1); National Research Foundation of Korea, NRF, (NRF-2016H1A2A1907833, NRF-2016R1A2B4008545)","","Institute of Electrical and Electronics Engineers Inc.","29060502"
"","","","7th International Conference on IT Convergence and Security, ICITCS 2017","2017","449","","","1","348","347","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029444610&partnerID=40&md5=3e4c1b6912574cc654ed673bbd59c70b","The proceedings contain 40 papers. The special focus in this conference is on IT Convergence and Security. The topics include: Image-based content retrieval via class-based histogram comparisons; smart content recognition from images using a mixture of convolutional neural networks; failure part mining using an association rules mining by FP-growth and apriori algorithms: case of ATM maintenance in thailand; improving classification of imbalanced student dataset using ensemble method of voting, bagging, and adaboost with under-sampling technique; improving classification of imbalanced student dataset using ensemble method of voting, bagging, and adaboost with under-sampling technique; an improved SVM-T-RFE based on intensity-dependent normalization for feature selection in gene expression of big-data; vehicle counting system based on vehicle type classification using deep learning method; metadata discovery of heterogeneous biomedical datasets using token-based features; heavy rainfall forecasting model using artificial neural network for flood prone area; i-vector extraction using speaker relevancy for short duration speaker recognition; a recommended replacement algorithm for the scalable asynchronous cache consistency scheme; multiple constraints satisfaction-based reliable localization for mobile underwater sensor networks; a design of kernel-level remote memory extension system; a design of kernel-level remote memory extension system; multi-focus image fusion based on non-subsampled shearlet transform and sparse representation; implementation of large-scale network flow collection system and flow analysis in KREONET; a novel BP neural network based system for face detection and  a distributed CBIR system based on improved surf on apache spark.","","","","Baek N.; Kim H.; Kim K.J.; iCatse, Kyonggi University, B-3001, Intellige 2, Seongnam-si, Kyonggi-do","Springer Verlag",""
"","","","2nd International Workshop on Graphs in Biomedical Image Analysis, GRAIL 2018 and 1st International Workshop on Integrating Medical Imaging and Non-Imaging Modalities, Beyond MIC 2018 Held in Conjunction with 21st International Conference on Medical Imaging and Computer-Assisted Intervention, MICCAI 2018","2018","11044 LNCS","","","","","99","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054352907&partnerID=40&md5=07d3354071ffdee46bc4100d1887c83c","The proceedings contain 10 papers. The special focus in this conference is on Graphs in Biomedical Image Analysis. The topics include: A graph representation and similarity measure for brain networks with nodal features; multi-modal disease classification in incomplete datasets using geometric matrix completion; brainParcel: A brain parcellation algorithm for cognitive state classification; modeling brain networks with artificial neural networks; a bayesian disease progression model for clinical trajectories; multi-modal brain connectivity study using deep collaborative learning; towards subject and diagnostic identifiability in the alzheimer’s disease spectrum based on functional connectomes; predicting conversion of mild cognitive impairments to alzheimer’s disease and exploring impact of neuroimaging.","","","","Stoyanov D.; Sotiras A.; Papiez B.; Dalca A.V.; Martel A.; Parisot S.; Ferrante E.; Maier-Hein L.; Sabuncu M.R.; Shen L.; Taylor Z.","Springer Verlag",""
"Xie Y.; Xing F.; Shi X.; Kong X.; Su H.; Yang L.","Xie, Yuanpu (56903340500); Xing, Fuyong (38461688800); Shi, Xiaoshuang (56029222900); Kong, Xiangfei (55613407300); Su, Hai (44661704600); Yang, Lin (55771607100)","56903340500; 38461688800; 56029222900; 55613407300; 44661704600; 55771607100","Efficient and robust cell detection: A structured regression approach","2018","44","","","245","254","9","10.1016/j.media.2017.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026880496&doi=10.1016%2fj.media.2017.07.003&partnerID=40&md5=d73d834859cceefb038129b72398e8cb","Efficient and robust cell detection serves as a critical prerequisite for many subsequent biomedical image analysis methods and computer-aided diagnosis (CAD). It remains a challenging task due to touching cells, inhomogeneous background noise, and large variations in cell sizes and shapes. In addition, the ever-increasing amount of available datasets and the high resolution of whole-slice scanned images pose a further demand for efficient processing algorithms. In this paper, we present a novel structured regression model based on a proposed fully residual convolutional neural network for efficient cell detection. For each testing image, our model learns to produce a dense proximity map that exhibits higher responses at locations near cell centers. Our method only requires a few training images with weak annotations (just one dot indicating the cell centroids). We have extensively evaluated our method using four different datasets, covering different microscopy staining methods (e.g., H & E or Ki-67 staining) or image acquisition techniques (e.g., bright-filed image or phase contrast). Experimental results demonstrate the superiority of our method over existing state of the art methods in terms of both detection accuracy and running time. © 2017","Biomedical image analysis; Cell detection; Deep learning; Structured regression","Algorithms; Bone Marrow Cells; Breast Neoplasms; Cytological Techniques; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Neural Networks (Computer); Neuroendocrine Tumors; Reproducibility of Results; Sensitivity and Specificity; Uterine Cervical Neoplasms; Cells; Computer aided analysis; Computer aided diagnosis; Cytology; Deep learning; Neural networks; Regression analysis; eosin; hematoxylin; Biomedical image analysis; Cell detection; Computer Aided Diagnosis(CAD); Convolutional neural network; Detection accuracy; Processing algorithms; State-of-the-art methods; Structured regression; Article; breast cancer; cell detection; controlled study; image analysis; microscopy; neuroendocrine tumor; phase contrast microscopy; priority journal; procedures concerning cells; staining; uterine cervix cancer; algorithm; artificial neural network; bone marrow cell; breast tumor; computer assisted diagnosis; cytology; female; human; pathology; procedures; reproducibility; sensitivity and specificity; uterine cervix tumor; Image analysis","National Institutes of Health, NIH; National Institute of Arthritis and Musculoskeletal and Skin Diseases, NIAMS, (R01AR065479)","","Elsevier B.V.","28797548"
"Zhang X.-L.","Zhang, Xiao-Lei (37023669300)","37023669300","Nonlinear dimensionality reduction of data by deep distributed random samplings","2014","39","2014","","221","233","12","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984704780&partnerID=40&md5=34ff4ed18d7765f4636304c297720af2","Dimensionality reduction is a fundamental problem of machine learning, and has been intensively studied, where classification and clustering are two special cases of dimensionality reduction that reduce high-dimensional data to discrete points. Here we describe a simple multilayer network for dimensionality reduction that each layer of the network is a group of mutually independent k-centers clusterings. We find that the network can be trained successfully layer-by-layer by simply assigning the centers of each clustering by randomly sampled data points from the input. Our results show that the described simple method outperformed 7 well-known dimensionality reduction methods on both very small-scale biomedical data and large-scale image and document data, with less training time than multilayer neural networks on large-scale data. © 2014 X.-L. Zhang.","Bootstrap; Deep learning; Dimensionality reduction; Ensemble methods; Evolutionary computing; Kernel methods; Sparse coding","Artificial intelligence; Clustering algorithms; Learning systems; Multilayer neural networks; Multilayers; Network layers; Reduction; Bootstrap; Deep learning; Dimensionality reduction; Ensemble methods; Evolutionary computing; Kernel methods; Sparse coding; Data reduction","","Phung D.; Li H.","Microtome Publishing",""
"Alkanhal I.; Kumar B.V.K.V.; Savvides M.","Alkanhal, Ibrahim (57207113566); Kumar, B.V.K Vijaya (57053595000); Savvides, Marios (6603557177)","57207113566; 57053595000; 6603557177","Automatic Seizure Detection via an Optimized Image-Based Deep Feature Learning","2018","","","8614111","536","540","4","10.1109/ICMLA.2018.00086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062241294&doi=10.1109%2fICMLA.2018.00086&partnerID=40&md5=955cc97a44de528e8a0995c4ec381444","In this paper, our goal is to find an optimized approach that can learn features from multichannel EEG time-series data to perform automatic seizure detection. In general, it is not easy to learn robust features from EEG signals due to the variations in both intra and inter-patient variability. However, to achieve good generalization, we use an algorithm that tries to capture spectral, temporal and spatial information, in contrast to standard EEG analysis techniques that ignore spatial aspects. The first stage of this algorithm is to transform EEG signals into a sequence of topology-preserving multi-spectral and temporal images. After that, these generated images are fed as inputs to a convolutional neural network. By overcoming the lack of data, especially the positive samples, and creating a process to deal with unbalanced datasets and optimizing the complexity of the network, our convolutional neural network learns a general spatially invariant representation of a seizure in a reasonable time and improves sensitivity, specificity and accuracy result comparable to the state-of-the-art results. © 2018 IEEE.","Deep learning; Sampling; Seizure Detection; Training","Biomedical signal processing; Convolution; Deep learning; Feature extraction; Automatic seizure detections; Convolutional neural network; Deep feature learning; Deep learning; EEG signals; Image-based; Learn+; Multichannel EEG; Seizure-detection; Time-series data; Neural networks","","Wani M.A.; Kantardzic M.; Sayed-Mouchaweh M.; Gama J.; Lughofer E.","Institute of Electrical and Electronics Engineers Inc.",""
"Shao Z.; Zhang L.; Wang L.","Shao, Zhenfeng (7202244409); Zhang, Linjing (56579595600); Wang, Lei (59089539000)","7202244409; 56579595600; 59089539000","Stacked Sparse Autoencoder Modeling Using the Synergy of Airborne LiDAR and Satellite Optical and SAR Data to Map Forest Above-Ground Biomass","2017","10","12","8039160","5569","5582","13","10.1109/JSTARS.2017.2748341","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030755958&doi=10.1109%2fJSTARS.2017.2748341&partnerID=40&md5=d01df9ad133728a85aaaf0f0f461c5f2","Timely, spatially complete, and reliable forest above-ground biomass (AGB) data are a prerequisite to support forest management and policy formulation. Traditionally, forest AGB is spatially estimated by integrating satellite images, in particular, optical data, with field plots from forest inventory programs. However, field data are limited in remote and unmanaged areas. In addition, optical reflectance usually saturates at high-density biomass level and is subject to cloud contaminations. Thus, this study aimed to develop a deep learning based workflow for mapping forest AGB by integrating Landsat 8 and Sentinel-1A images with airborne light detection and ranging (LiDAR) data. A reference AGB map was derived from the wall-to-wall LiDAR data and field measurements. The LiDAR plots - stratified random samples of forest biomass extracted from the LiDAR simulated strips in the reference map - were adopted as a surrogate for traditional field plots. In addition to the deep learning model, i.e., stacked sparse autoencoder network (SSAE), five different prediction techniques including multiple stepwise linear regressions, K-nearest neighbor, support vector machine, back propagation neural networks, and random forest were individually used to establish the relationship between LiDAR-derived forest biomass and the satellite predictors. Optical variables (Landsat 8 OLI), SAR variables (Sentinel-1A), and their combined variables were individually input to the six prediction models. Results showed that the SSAE model had the best performance for the forest biomass estimation. The combined optical and microwave dataset as explanatory variables improved the modeling performance compared to either the optical-only or microwave-only data, regardless of prediction algorithms. The best mapping accuracy was obtained by the SSAE model with inputs of optical and microwave integrated metrics that yielded R2 of 0.812, root mean squared error (RMSE) of 21.753 Mg/ha, and relative RMSE (RMSEr) of 14.457%. Overall, the SSAE model with inputs of combined Landsat 8 OLI and Sentinel-1A information could result in accurate estimation of forest biomass by using the stratification-sampled and LiDAR-derived AGB as ground reference data. The modeling workflow has the potential to promote future forest growth monitoring and carbon stock assessment across large areas. © 2008-2012 IEEE.","Biomass; deep learning (DL); Landsat 8; light detection and ranging (LiDAR); Sentinel-1A; stacked sparse autoencoder network (SSAE)","Backpropagation; Biomass; Carbon; Data integration; Decision trees; Deep learning; Forecasting; Forestry; Imaging techniques; Learning systems; Mapping; Mean square error; Nearest neighbor search; Neural networks; Optical image storage; Radar imaging; Remote sensing; Satellites; Space-based radar; Synthetic aperture radar; Tracking radar; Auto encoders; Biomedical optical imaging; LANDSAT; Light detection and ranging; Optical imaging; Optical saturation; Sentinel-1; aboveground biomass; forest inventory; lidar; machine learning; mapping; modeling; satellite imagery; Sentinel; synthetic aperture radar; Optical radar","Wuhan Chen Guang Project, (2016070204010114); Guangzhou Municipal Science and Technology Project, (201604020070); Guangzhou Municipal Science and Technology Project; National Administration of Surveying, Mapping and Geoinformation of China, NASG, (2015NGCM); National Administration of Surveying, Mapping and Geoinformation of China, NASG; Key Technologies Research and Development Program, (2016YFB0502603); Key Technologies Research and Development Program; Fundamental Research Funds for the Central Universities, (2042016kf0179, 2042016kf1019); Fundamental Research Funds for the Central Universities; technical innovation in Hubei Province, (2016AAA018)","","Institute of Electrical and Electronics Engineers",""
"Liao H.; Mesfin A.; Luo J.","Liao, Haofu (57193613750); Mesfin, Addisu (14325501600); Luo, Jiebo (7404182441)","57193613750; 14325501600; 7404182441","Joint vertebrae identification and localization in spinal CT images by combining short- and long-range contextual information","2018","37","5","","1266","1275","9","10.1109/TMI.2018.2798293","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040995907&doi=10.1109%2fTMI.2018.2798293&partnerID=40&md5=23aea7953dca1ddf50d4433e351a9bfa","Automatic vertebrae identification and localization from arbitrary computed tomography (CT) images is challenging. Vertebrae usually share similar morphological appearance. Because of pathology and the arbitrary field-of-view of CT scans, one can hardly rely on the existence of some anchor vertebrae or parametric methods to model the appearance and shape. To solve the problem, we argue that: 1) one should make use of the short-range contextual information, such as the presence of some nearby organs (if any), to roughly estimate the target vertebrae; and 2) due to the unique anatomic structure of the spine column, vertebrae have fixed sequential order, which provides the important long-range contextual information to further calibrate the results. We propose a robust and efficient vertebrae identification and localization system that can inherently learn to incorporate both the short- and long-range contextual information in a supervised manner. To this end, we develop a multi-task 3-D fully convolutional neural network to effectively extract the short-range contextual information around the target vertebrae. For the long-range contextual information, we propose a multi-task bidirectional recurrent neural network to encode the spatial and contextual information among the vertebrae of the visible spine column. We demonstrate the effectiveness of the proposed approach on a challenging data set, and the experimental results show that our approach outperforms the state-of-the-art methods by a significant margin. © 1982-2012 IEEE.","Automatic vertebrae identification and localization; convolutional neural network; CT image; deep learning; multi-task learning; recurrent neural network","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Spine; Tomography, X-Ray Computed; Convolution; Deep learning; Feature extraction; Image processing; Job analysis; Medical imaging; Musculoskeletal system; Pathology; Recurrent neural networks; Three dimensional displays; Automatic vertebrae identification and localization; Biomedical imaging; Convolutional neural network; CT Image; Multitask learning; Task analysis; Two-dimensional displays; accuracy; Article; computer assisted tomography; human; image analysis; image processing; prediction; vertebra; x-ray computed tomography; algorithm; diagnostic imaging; procedures; spine; Computerized tomography","","","Institute of Electrical and Electronics Engineers Inc.","29727289"
"Hamidinekoo A.; Denton E.; Rampun A.; Honnor K.; Zwiggelaar R.","Hamidinekoo, Azam (56568239100); Denton, Erika (55578429200); Rampun, Andrik (55785202900); Honnor, Kate (57201680128); Zwiggelaar, Reyer (6701923709)","56568239100; 55578429200; 55785202900; 57201680128; 6701923709","Deep learning in mammography and breast histology, an overview and future trends","2018","47","","","45","67","22","10.1016/j.media.2018.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045702232&doi=10.1016%2fj.media.2018.03.006&partnerID=40&md5=cb6ae23f2661ac7180281abecb6e371b","Recent improvements in biomedical image analysis using deep learning based neural networks could be exploited to enhance the performance of Computer Aided Diagnosis (CAD) systems. Considering the importance of breast cancer worldwide and the promising results reported by deep learning based methods in breast imaging, an overview of the recent state-of-the-art deep learning based CAD systems developed for mammography and breast histopathology images is presented. In this study, the relationship between mammography and histopathology phenotypes is described, which takes biological aspects into account. We propose a computer based breast cancer modelling approach: the Mammography–Histology–Phenotype–Linking–Model, which develops a mapping of features/phenotypes between mammographic abnormalities and their histopathological representation. Challenges are discussed along with the potential contribution of such a system to clinical decision making and treatment management. © 2018","Breast histopathology; Computer Aided Diagnosis; Deep learning; Mammography","Algorithms; Breast Neoplasms; Deep Learning; Diagnosis, Computer-Assisted; Female; Forecasting; Humans; Mammography; Neural Networks (Computer); Phenotype; Radiographic Image Interpretation, Computer-Assisted; Sensitivity and Specificity; Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Decision making; Diseases; Histology; Image enhancement; Mammography; Medical imaging; Biological aspects; Biomedical image analysis; Breast histopathology; Breast imaging; Clinical decision making; Computer Aided Diagnosis(CAD); Learning-based methods; Treatment management; Article; breast cancer; cancer screening; clinical decision making; computer assisted diagnosis; computer model; histopathology; human; image analysis; image processing; learning algorithm; mammography; phenotype; priority journal; algorithm; artificial neural network; breast tumor; diagnostic imaging; female; forecasting; pathology; procedures; sensitivity and specificity; Deep learning","","","Elsevier B.V.","29679847"
"Cui S.; Hong J.; Zheng W.; Shen C.","Cui, Shuqi (57195628774); Hong, Jiang (57195631139); Zheng, Wang (57195629921); Shen, Chaomin (15081309500)","57195628774; 57195631139; 57195629921; 15081309500","Application of neural network based on SIFT local feature extraction in medical image classification","2017","","","7984525","92","97","5","10.1109/ICIVC.2017.7984525","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029386888&doi=10.1109%2fICIVC.2017.7984525&partnerID=40&md5=6820746b1b55032454c321f7cc936ce6","In the medical image analysis, ROI (Region of Interest) is one of the key features of clinical diagnostic analysis. The applying of local features of ROI to the deep learning of image classification has the advantage of noise eliminating and information reducing. Based on existing research results, using Scale Invariant Feature Transformation (SIFT) algorithm combined with SVM classifier and sliding window to extract the local features and describe ROI precisely in the image. Finally, the extracted feature is used as the input layer of BP neural network in mammary gland X - ray image classification. The experimental results show that the accuracy of neural network classifier based on SIFT is 96.57%, which is 3.44% higher than that of traditional SVM classification accuracy. It is verified that our classifier is important to support clinical diagnosis and diagnosis. © 2017 IEEE.","BP neural network; ROI; SIFT; Slide the window; SVM","Biomedical signal processing; Classification (of information); Diagnosis; Image processing; Image segmentation; Medical imaging; Neural networks; BP neural networks; Clinical diagnostics; Local feature extraction; Neural network classifier; Scale invariant feature transformations; SIFT; SVM classification; X-ray image classifications; Image classification","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","3rd International Conference on Green Power, Materials and Manufacturing Technology and Applications, GPMMTA 2013","2014","484-485","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892702905&partnerID=40&md5=9ba462f5292b701bce8cdc9b997b979c","The proceedings contain 234 papers. The special focus in this conference is on Green Power, Materials and Manufacturing Technology and Applications. The topics include: Cemented filling in a certain old iron goaf; study of material forming comprehensive evaluation method based on fuzzy technology; a new rust conversion coating and its working mechanism in rust remove and painting; study on fabric recreation and clothing design based on active materials; study on sports games based on smart materials; study of smart clothing materials based on computer technology; study of green low-carbon ceramics materials; building materials in landscape design; study on physical training approach based on multimedia and smart materials; study of a new type of nanometer materials in interior design; study of new environmentally friendly materials in interior design; study on official kiln ceramic materials shape based on mechanics analysis; study of innovative military engineering in smart materials system; study on degumming technology and properties of pineapple leaf fiber; application of aspen to lithium bromide refrigerator; analysis of the movement of materials; research of new materials in sports equipment; experimental study on asphalt composite UV absorption anti-aging agent; research on polymeric biomedical materials; research on shape memory alloy to petroleum industry; research on nano materials in the chemical aspects; material research of stone sculpture in installation; microwave technology based polymer process; water-filter ratio on heat resistance of condensate polishing filter material in water; demagnetizing experiment of magnetism-concealed tank based on smart materials; analysis of organic low-carbon solar material; machinery manufacturing based on computer control; study on application model of internet of things for green manufacturing; study on ARP protocol and network security in digital manufacturing; study on innovative instruction technology in manufacturing engineering; study on risk of logistics and transport in digital manufacturing environment; research on cloud computing and network security in digital manufacturing platform; study on integrated transportation network for manufacturing engineering; research of machinery production technique based on green manufacturing; improving learning quality of advanced manufacturing engineering; new technology of installing the attached self-climbing tower steel gantry cranes; large amount of off-axis machining ellipsoidal reflector; gear vibration analysis and gear fault diagnosis based on mathematical morphology; research on aviation piston engine camshaft repair; study on digital substation in green environment engineering; application of medical robot in the aspect of endoscope; todaro migration model research under automation control; power control based channel allocation method for ad hoc networks; on-line thickness measurement of thin film based on neural network; sensor-based real-time monitoring hazardous chemical cargo; research of building automatic control based on CAN bus technology; functional module of computer application and regulation control; research on information supervision system of city infrastructure construction project; research on optical radiation measuring system based on virtual instrument; remote network control system for web service; C/S-based network remote control system; research on face tracking in community monitoring system; transmission performance of the mechanical control system in the aircraft; study on pressure detection and relief device of bio chemical equipment; PLC programmable control technology in the mine pit transportation system; research on wireless positioning technology base on zigbee; remote control of manipulator electronic system; information monitoring and management system for tailings based on LabVIEW; deep foundation pit monitoring based on CX-3C inclinometer; analysis of changes in gas composition during startup process; characteristic analyzation of cyber physical systems; AHP based technology selection for emerging industry; study of alternating load training methods based on mechanics analysis; study of supply chain management theory in manufacturing innovation; reliability optimization analysis based on structure of probabilistic model; research on basic standard of roadmap for green manufacturing; study on holism horizon of whitehead based on mechanics analysis; study on desert ecological resources in green environment; analysis on garden irrigation for the recycling and use of reclaimed water; fuzzy comprehensive evaluation of air quality in home; study on information security of network-based manufacturing environment; motor drive control based on microcontroller and PID; analysis on fission-style communication mode of mobile TV; research on the reliability of the electromechanical products based on the fuzzy theory; study on transformation of intelligent electronic engineering structural model; study of FIDIC condition in innovative engineering environment; study and realization of camera wafer image fusion algorithm; adaptive evaluation system based on IRT theory; study of rural drinking water safety engineering management; design for robot control board based on AVR single chip microcomputer; study on mining materials products of central and south America; data mining-based smart industrial park energy efficiency management system; study on innovative engineering of energy industry; gas emission prediction based on coal mine operating data; SVMR model for coal mine cost management prediction; fault surface models of coal rake based on RBF neural network; evaluation of gold geochemical anomalies in the liaodong paleorift; multi-objective evaluation of PV; research on agriculture reactive power optimization control based on DSP; three-phase power flow of less ring distribution network; on-line power system analysis based on hybrid network model; analysis of SMPS in clinical medical equipment; study on constructing arch-centre structure of wood arcade bridges; study on smart materials of library buildings; study on the efficient design scheme of intelligent building; efficient development scheme of green building; study on urban residential quality engineering based on government regulation; research of whole process planning of green architecture; city vision oriented design based on vision communication factors; study of construction ecological livable city in nanning; lighting energy-saving design for industrial factory building; durability analysis and carbonation life prediction of river bridge; study on river landscape ecological restoration project; game theory analysis of demolition and reconstruction urban renewal; strengthening design and construction technique of simply supported girder bridge; a smart home architectural design of cyber physical systems; CFG pile based soft foundation treatment; study of computer network resource sharing for advanced engineering applications; test paper materials auto-generation system; cumulative absolute velocity parameter and LABVIEW implementation; cloud-based university library management system; study on modern innovative logistics engineering based on computer network; on the maintenance management and network security of local area network; image interpolation based on wavelet transform; study on security of information exchange of SOA application system; research on heterogeneous network data communication; research of logistics information system based on GPS; research on remote aerobics network learning system based on B/S; multi-scale noise reduction based wavelet; ISCSI network storage system based on android system; study on the construction of 3-dimensional image by support vector machine; improvement of hadoop security mechanism; research of big data processing platform; fault detection way for computer networks based on multiple stages; integrated design of testing software in machinery production; gear class components parameterization based on AUTOCAD; manufacturing image in painting based on partial differential equations; research on the mine slope stress detection and warning system; research on energy decision system based on network technology; video segmentation based on area selection; an indirect fingerprint authentication scheme in cloud computing; study on factors of college student's network service time based on Bayesian networks; study on component composition frame based on XCM model; CAN-bus intelligent network communication equipment based on PLC; design of MP3 player decoder based on FPGA; differentiability of the energy functional of a class of quasi-linear elliptic; face recognition algorithm based on multi-resolution and classification; research on the simulation system of the sports training; PID control of four-rotor aircraft based on quaternion; modeling and meshing of A320 aircraft rudder; simulation research on vehicle handling inverse dynamics based on radial basis; industrial design instruction based on simulation technology; an intelligent transportation systems model based on multi-agent technology; three-dimensional configuration in the graphic design; design of workspace of human fingers and computer keyboard operation and mobile robot design based on ant colony algorithm.","","","","","",""
"Hajinoroozi M.; Mao Z.; Lin Y.-P.; Huang Y.","Hajinoroozi, Mehdi (56156590600); Mao, Zijing (56047854100); Lin, Yuan-Pin (16318996800); Huang, Yufei (35558675700)","56156590600; 56047854100; 16318996800; 35558675700","Deep transfer learning for cross-subject and cross-experiment prediction of image rapid serial visual presentation events from EEG data","2017","10284 11th International Conference, AC 2017, Held as Part of HCI International 2017, Vancouver, BC, Canada, July 9-14, 2017, Proceedings, Part I","","","45","55","10","10.1007/978-3-319-58628-1_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025134516&doi=10.1007%2f978-3-319-58628-1_4&partnerID=40&md5=3da5e9963e42977d88e3df4c4beed98a","Transfer learning (TL) has gained significant interests recently in brain computer interface (BCI) as a key approach to design robust predictors for cross-subject and cross-experiment prediction of the brain activities in response to cognitive events. We carried out in this.aper the first comprehensive investigation of the transferability of deep convolutional neural network (CNN) for cross-subject and cross-experiment prediction of image Rapid Serial Visual Presentation (RSVP) events. We show that for both cross-subject and cross-experiment predictions, all convolutional layers and fully connected layers contain both general and subject/experiment-specific features and transfer learning with weights fine-tuning can improve the prediction performance over that without transfer. However, for cross-subject prediction, the convolutional layers capture more subject-specific features, whereas for cross-experiment prediction, the convolutional layers capture more general features across experiment. Our study provides important information that will guide the design of more sophisticated deep transfer learning algorithms for EEG based classifications in BCI applications. © Springer International Publishing AG 2017.","Deep convolutional neural networks; EEG signals; Transfer learning","Biomedical signal processing; Brain; Brain computer interface; Classification (of information); Convolution; Deep neural networks; Interfaces (computer); Learning algorithms; Brain activity; Convolutional neural network; Deep convolutional neural network; EEG signals; Feature learning; Fine tuning; Prediction performance; Rapid serial visual presentations; Subject experiment; Transfer learning; Forecasting","","","Springer Verlag",""
"Fu H.; Cheng J.; Xu Y.; Zhang C.; Wong D.W.K.; Liu J.; Cao X.","Fu, Huazhu (35317209500); Cheng, Jun (57535555300); Xu, Yanwu (55516961100); Zhang, Changqing (56313466500); Wong, Damon Wing Kee (56903519800); Liu, Jiang (23389932700); Cao, Xiaochun (8920951000)","35317209500; 57535555300; 55516961100; 56313466500; 56903519800; 23389932700; 8920951000","Disc-Aware Ensemble Network for Glaucoma Screening from Fundus Image","2018","37","11","8359118","2493","2501","8","10.1109/TMI.2018.2837012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046993976&doi=10.1109%2fTMI.2018.2837012&partnerID=40&md5=27d24e3aaf04613292218bb1031c1fd1","Glaucoma is a chronic eye disease that leads to irreversible vision loss. Most of the existing automatic screening methods first segment the main structure and subsequently calculate the clinical measurement for the detection and screening of glaucoma. However, these measurement-based methods rely heavily on the segmentation accuracy and ignore various visual features. In this paper, we introduce a deep learning technique to gain additional image-relevant information and screen glaucoma from the fundus image directly. Specifically, a novel disc-aware ensemble network for automatic glaucoma screening is proposed, which integrates the deep hierarchical context of the global fundus image and the local optic disc region. Four deep streams on different levels and modules are, respectively, considered as global image stream, segmentation-guided network, local disc region stream, and disc polar transformation stream. Finally, the output probabilities of different streams are fused as the final screening result. The experiments on two glaucoma data sets (SCES and new SINDI data sets) show that our method outperforms other state-of-the-art algorithms. © 1982-2012 IEEE.","Deep learning; glaucoma screening; neural network; optic disc segmentation","Deep Learning; Diagnostic Techniques, Ophthalmological; Glaucoma; Humans; Image Interpretation, Computer-Assisted; Optic Disk; Deep learning; Diagnosis; Edge detection; Feature extraction; Flow visualization; Media streaming; Neural networks; Ophthalmology; Optical fibers; Optical image storage; Biomedical optical imaging; Glaucoma screenings; Optic disc; Optical fiber networks; Optical imaging; Streaming media; Article; diagnostic test accuracy study; disc aware ensemble network; eye fundus; false negative result; false positive result; glaucoma; human; measurement accuracy; optic disk; screening; sensitivity and specificity; computer assisted diagnosis; diagnostic imaging; glaucoma; procedures; visual system examination; Image segmentation","National Key Research and Development Plan, (2016YFB0800603); Ningbo 3315 Innovation Team, (Y61102DL03); National Natural Science Foundation of China, (61602337, 61650202, 61733007, U1605252); Chinese Academy of Sciences, (QYZDB-SSW-JSC003); Key Programme","","Institute of Electrical and Electronics Engineers Inc.","29994764"
"Wang H.; Zhang J.; Xia Y.","Wang, Hongyu (57215109146); Zhang, Jianpeng (57195070346); Xia, Yong (26427407400)","57215109146; 57195070346; 26427407400","Jointly using deep model learned features and traditional visual features in a stacked SVM for medical subfigure classification","2017","10559 LNCS","","","191","199","8","10.1007/978-3-319-67777-4_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030030181&doi=10.1007%2f978-3-319-67777-4_17&partnerID=40&md5=a39bc43843bae990b544518aa32e467a","Classification of diagnose images and illustrations in the literature is a major challenge towards automated literature review and retrieval. Although being widely recognized as the most successful image classification technique, deep learning models, however, may need to be complemented by traditional visual features to solve this problem, in which there are intra-class variation, inter-class similarity and a small training dataset. In this paper, we propose an approach to classifying diagnose images and biomedical publication illustrations. This algorithm jointly uses the image representations learned by three pre-trained deep convolutional neural network models and ten types of traditional visual features in a stacked support vector machine (SVM) classifier. We have evaluated this algorithm on the ImageCLEF 2016 Subfigure Classification dataset and achieved an accuracy of 85.62%, which is higher than the top performance of purely visual approaches in this challenge. © 2017, Springer International Publishing AG.","Deep convolutional neural network; Feature extraction; Medical image classification; Stacked support vector machine","Big data; Classification (of information); Convolution; Deep neural networks; Feature extraction; Medical imaging; Neural networks; Support vector machines; Classification technique; Convolutional neural network; Image representations; Intra-class variation; Learning models; Literature reviews; Small training; Visual feature; Image classification","National Natural Science Foundation of China, NSFC, (61471297, 61771397); Northwestern Polytechnical University, NPU","Sun Y.; Lu H.; Zhang L.; Yang J.; Huang H.","Springer Verlag",""
"Cardoso I.; Almeida E.; Allende-Cid H.; Frery A.C.; Rangayyan R.M.; Azevedo-Marques P.M.; Ramos H.S.","Cardoso, Isadora (57191339334); Almeida, Eliana (8295156100); Allende-Cid, Hector (57208732887); Frery, Alejandro C. (7003561251); Rangayyan, Rangaraj M. (7005319550); Azevedo-Marques, Paulo M. (57218760488); Ramos, Heitor S. (25655377800)","57191339334; 8295156100; 57208732887; 7003561251; 7005319550; 57218760488; 25655377800","Analysis of Machine Learning Algorithms for Diagnosis of Diffuse Lung Diseases","2018","57","5-6","","272","279","7","10.1055/s-0039-1681086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062992252&doi=10.1055%2fs-0039-1681086&partnerID=40&md5=d012875b4843abe14c00b5e756e5098f","Computational Intelligence Re-meets Medical Image Processing A Comparison of Some Nature-Inspired Optimization Metaheuristics Applied in Biomedical Image Registration Summary Background Diffuse lung diseases (DLDs) are a diverse group of pulmonary disorders, characterized by inflammation of lung tissue, which may lead to permanent loss of the ability to breathe and death. Distinguishing among these diseases is challenging to physicians due their wide variety and unknown causes. Computer-aided diagnosis (CAD) is a useful approach to improve diagnostic accuracy, by combining information provided by experts with Machine Learning (ML) methods. Objectives Exploring the potential of dimensionality reduction combined with ML methods for diagnosis of DLDs; improving the classification accuracy over state-of-the-art methods. Methods A data set composed of 3252 regions of interest (ROIs) was used, from which 28 features were extracted per ROI. We used Principal Component Analysis, Linear Discriminant Analysis, and Stepwise Selection - Forward, Backward, and Forward-Backward to reduce feature dimensionality. The feature subsets obtained were used as input to the following ML methods: Support Vector Machine, Gaussian Mixture Model, k-Nearest Neighbor, and Deep Feedforward Neural Network. We also applied a Deep Convolutional Neural Network directly to the ROIs. Results We achieved the maximum reduction from 28 to 5 dimensions using LDA. The best classification results were obtained by DFNN, with 99.60% of overall accuracy. Conclusions This work contributes to the analysis and selection of features that can efficiently characterize the DLDs studied. © 2018 Georg Thieme Verlag KG Stuttgart. New York.","Deep learning; diffuse lung diseases; dimensionality reduction; machine learning","Algorithms; Diagnosis, Computer-Assisted; Discriminant Analysis; Humans; Lung Diseases; Machine Learning; Principal Component Analysis; Time Factors; algorithm; computer assisted diagnosis; discriminant analysis; human; lung disease; machine learning; principal component analysis; time factor","SEFAZ-AL; Fondo Nacional de Desarrollo Científico y Tecnológico, FONDECYT, (11150248); Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq","","Georg Thieme Verlag","30875707"
"Moradi H.; Foruzan A.H.; Chen Y.-W.","Moradi, Hamid (57208719886); Foruzan, Amir Hossein (14628801300); Chen, Yen-Wei (56036268200)","57208719886; 14628801300; 56036268200","Automatic segmentation of prostate in MR images using deep learning and multi-atlas techniques","2018","","","8703532","","","","10.1109/ICBME.2018.8703532","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065605728&doi=10.1109%2fICBME.2018.8703532&partnerID=40&md5=5662a1bb78b4b30ecc481ecc8116b6e2","Precise segmentation of prostate in magnetic resonance images is an essential step in treatment planning and a challenging task due to high variability in shape and size of the tissue. In this paper, we propose an automatic algorithm for accurate and robust segmentation of prostate in MR images. First, we employ a deep neural network to locate the prostate region of interest which removes background pixels and reduces the size of the image. Then, we obtain an initial segmentation of the tissue using a probabilistic atlas. Finally, we utilize statistical shape models to restrict the final contour inside the allowable shape domain. We performed a quantitative evaluation on 30 MR images and obtained a mean Dice similarity coefficient of 0.85±0.06. Compared to recent researches, our method is both robust and accurate. © 2018 IEEE.","deep neural network; multi-atlas segmentation; probabilistic atlas; prostate segmentation; statistical shape model (SSM)","Biomedical engineering; Biophysics; Deep neural networks; Magnetic resonance; Magnetic resonance imaging; Tissue; Urology; Allowable shape domains; Automatic algorithms; Automatic segmentations; Probabilistic atlas; Prostate segmentation; Quantitative evaluation; Similarity coefficients; Statistical shape model; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","BIOIMAGING 2018 - 5th International Conference on Bioimaging, Proceedings; Part of 11th International Joint Conference on Biomedical Engineering Systems and Technologies, BIOSTEC 2018","2018","2","","","","","222","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053124282&partnerID=40&md5=44e9cec124f2258cab12f8aacd00110a","The proceedings contain 25 papers. The topics discussed include: designing for self-management of mental ill-health - the need to extend interdisciplinary bioengineering agenda; affordable diagnostics with biosignal analysis; patch-based carcinoma detection on confocal laser endomicroscopy images - a cross-site robustness assessment; graph-cut segmentation of retinal layers from OCT images; EndoCal 10 obturation voids in root canal and isthmus of a human premolar: a synchrotron micro-ct imaging study; colorectal cancer classification using deep convolutional networks - an experimental study; spot detection in microscopy images using convolutional neural network with sliding-window approach; brain tumor segmentation in magnetic resonance images using genetic algorithm clustering and Adaboost classifier; the face recognition processes - neurofuzzy approach; learning rigid image registration - utilizing convolutional neural networks for medical image registration; robust plant segmentation from challenging background with a multiband acquisition and a supervised machine learning algorithm; multispectral 3d surface scanning system RoScan and its application in inflammation monitoring and quantification; semi-automatic CT image segmentation using random forests learned from partial annotations; and an automated method for generating training sets for deep learning based image registration.","","","","Wiebe S.; Bermudez i Badia S.; Gamboa H.; Fred A.","SciTePress",""
"Jo Y.; Park S.; Jung J.; Yoon J.; Joo H.; Kim M.-H.; Kang S.-J.; Choi M.C.; Lee S.Y.; Park Y.","Jo, YoungJu (55646242600); Park, Sangjin (55717272100); Jung, JaeHwang (55646822800); Yoon, Jonghee (36005566100); Joo, Hosung (57200605950); Kim, Min-Hyeok (57188719831); Kang, Suk-Jo (55628575704); Choi, Myung Chul (55461961100); Lee, Sang Yup (57193960263); Park, YongKeun (55494376500)","55646242600; 55717272100; 55646822800; 36005566100; 57200605950; 57188719831; 55628575704; 55461961100; 57193960263; 55494376500","Holographic deep learning for rapid optical screening of anthrax spores","2017","3","8","e1700606","","","","10.1126/sciadv.1700606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035768626&doi=10.1126%2fsciadv.1700606&partnerID=40&md5=acb013830e9a37157d2feb1e8be0a994","Establishing early warning systems for anthrax attacks is crucial in biodefense. Despite numerous studies for decades, the limited sensitivity of conventional biochemical methods essentially requires preprocessing steps and thus has limitations to be used in realistic settings of biological warfare. We present an optical method for rapid and label-free screening of Bacillus anthracis spores through the synergistic application of holographic microscopy and deep learning. A deep convolutional neural network is designed to classify holographic images of unlabeled living cells. After training, the network outperforms previous techniques in all accuracy measures, achieving single-spore sensitivity and subgenus specificity. The unique ""representation learning"" capability of deep learning enables direct training from raw images instead of manually extracted features. The method automatically recognizes key biological traits encoded in the images and exploits them as fingerprints. This remarkable learning ability makes the proposed method readily applicable to classifying various single cells in addition to B. anthracis, as demonstrated for the diagnosis of Listeria monocytogenes, without any modification. We believe that our strategy will make holographic microscopy more accessible to medical doctors and biomedical scientists for easy, rapid, and accurate point-of-care diagnosis of pathogens. Copyright © 2017 The Authors, some rights reserved.","","Algorithms; Anthrax; Bacillus anthracis; Data Analysis; Deep Learning; Holography; Humans; Image Processing, Computer-Assisted; Machine Learning; Microscopy; Spores, Bacterial; Bacteriology; Deep neural networks; Diagnosis; Diseases; Holography; Neural networks; Pathogens; Bacillus anthracis spores; Biochemical methods; Convolutional neural network; Early Warning System; Holographic microscopy; Limited sensitivity; Listeria monocytogenes; Pre-processing step; algorithm; anthrax; Bacillus anthracis; bacterial spore; cytology; data analysis; devices; holography; human; image processing; machine learning; microbiology; microscopy; procedures; Deep learning","","","American Association for the Advancement of Science","28798957"
"Lu N.; Li T.; Ren X.; Miao H.","Lu, Na (39161672600); Li, Tengfei (56532771100); Ren, Xiaodong (56039808100); Miao, Hongyu (8979782400)","39161672600; 56532771100; 56039808100; 8979782400","A Deep Learning Scheme for Motor Imagery Classification based on Restricted Boltzmann Machines","2017","25","6","7546909","566","576","10","10.1109/TNSRE.2016.2601240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021307758&doi=10.1109%2fTNSRE.2016.2601240&partnerID=40&md5=02b14aa8d772c1d50e648b273371d627","Motor imagery classification is an important topic in brain-computer interface (BCI) research that enables the recognition of a subject's intension to, e.g., implement prosthesis control. The brain dynamics of motor imagery are usually measured by electroencephalography (EEG) as nonstationary time series of low signal-to-noise ratio. Although a variety of methods have been previously developed to learn EEG signal features, the deep learning idea has rarely been explored to generate new representation of EEG features and achieve further performance improvement for motor imagery classification. In this study, a novel deep learning scheme based on restricted Boltzmann machine (RBM) is proposed. Specifically, frequency domain representations of EEG signals obtained via fast Fourier transform (FFT) and wavelet package decomposition (WPD) are obtained to train three RBMs. These RBMs are then stacked up with an extra output layer to form a four-layer neural network, which is named the frequential deep belief network (FDBN). The output layer employs the softmax regression to accomplish the classification task. Also, the conjugate gradient method and backpropagation are used to fine tune the FDBN. Extensive and systematic experiments have been performed on public benchmark datasets, and the results show that the performance improvement of FDBN over other selected state-of-the-art methods is statistically significant. Also, several findings that may be of significant interest to the BCI community are presented in this article. © 2016 IEEE.","Brain-computer interface (BCI); deep learning; motor imagery; restricted Boltzman machine (RBM)","Algorithms; Brain Mapping; Brain-Computer Interfaces; Electroencephalography; Evoked Potentials, Motor; Fourier Analysis; Humans; Imagination; Intention; Machine Learning; Motor Cortex; Movement; Neural Networks (Computer); Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Signal Processing, Computer-Assisted; Benchmarking; Biomedical signal processing; Brain computer interface; Conjugate gradient method; Deep neural networks; Education; Electroencephalography; Electrophysiology; Fast Fourier transforms; Image classification; Interfaces (computer); Network layers; Signal to noise ratio; Wavelet decomposition; Four-layer neural networks; Frequency-domain representations; Motor imagery; Motor imagery classification; Non-stationary time series; restricted Boltzman machine (RBM); Restricted boltzmann machine; Wavelet package decomposition; Article; artificial neural network; brain computer interface; electroencephalography; electromyography; electrooculography; Fourier transformation; human; human experiment; mathematical model; measurement accuracy; motor imagery classification; normal human; restricted Boltzmann machine; sensitivity and specificity; signal noise ratio; training; weight change; algorithm; automated pattern recognition; behavior; brain computer interface; brain mapping; evaluation study; Fourier analysis; imagination; machine learning; motor cortex; motor evoked potential; movement (physiology); physiology; procedures; reproducibility; signal processing; Deep learning","National Natural Science Foundation of China, NSFC, (61105034, 61673312); China Postdoctoral Science Foundation, (20110491662, 2012T50805); Fundamental Research Funds for the Central Universities; Specialized Research Fund for the Doctoral Program of Higher Education of China, SRFDP, (20100201120040)","","Institute of Electrical and Electronics Engineers Inc.","27542114"
"Li J.-Y.; Li J.-H.","Li, Jun-Yi (55268828300); Li, Jian-Hua (56103299700)","55268828300; 56103299700","Supervised hashing binary code with deep CNN for image retrieval","2016","","","7401584","649","655","6","10.1109/BMEI.2015.7401584","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964344433&doi=10.1109%2fBMEI.2015.7401584&partnerID=40&md5=2e2fbe9675dbbecd1df951ec198e7a18","Approximate nearest neighbor search is a good method for large-scale image retrieval. We put forward an effective deep learning framework to generate binary hash codes for fast image retrieval after knowing the recent benefits of convolutional neural networks (CNNs). Our concept is that we can learn binary codes by using a hidden layer to present the latent concepts dominating the class labels when the data labels are usable. CNN also can be used to learn image representations. Other supervised methods require pair-wised inputs for binary code learning. However, our method can be used to learn hash codes and image representations in a point-by-point manner so it is suitable for large-scale datasets. Experimental results show that our method is better than several most advanced hashing algorithms on the CIFAR-10 and MNIST datasets. We will further demonstrate its scalability and efficiency on a large-scale dataset with 1 million clothing images. © 2015 IEEE.","convolutional neural networks; hidden layer; LSH; nearest neighbor search; supervised learning","Binary codes; Bins; Biomedical engineering; Codes (symbols); Convolution; Hash functions; Information science; Nearest neighbor search; Network layers; Neural networks; Supervised learning; Convolutional neural network; Deep learning; Hashing algorithms; Hidden layers; Image representations; Large-scale dataset; Large-scale datasets; Supervised methods; Image retrieval","","Tao Z.; Bai L.; Lin S.; Sun J.; Wang L.; Shao L.","Institute of Electrical and Electronics Engineers Inc.",""
"Jia Z.; Huang X.; Chang E.I.-C.; Xu Y.","Jia, Zhipeng (56939734100); Huang, Xingyi (57194830372); Chang, Eric I-Chao (7401837784); Xu, Yan (57192065052)","56939734100; 57194830372; 7401837784; 57192065052","Constrained Deep Weak Supervision for Histopathology Image Segmentation","2017","36","11","7971941","2376","2388","12","10.1109/TMI.2017.2724070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023175219&doi=10.1109%2fTMI.2017.2724070&partnerID=40&md5=864ea1943786953282f76c3b36c510ab","In this paper, we develop a new weakly supervised learning algorithm to learn to segment cancerous regions in histopathology images. This paper is under a multiple instance learning (MIL) framework with a new formulation, deep weak supervision (DWS); we also propose an effective way to introduce constraints to our neural networks to assist the learning process. The contributions of our algorithm are threefold: 1) we build an end-to-end learning system that segments cancerous regions with fully convolutional networks (FCNs) in which image-to-image weakly-supervised learning is performed; 2) we develop a DWS formulation to exploit multi-scale learning under weak supervision within FCNs; and 3) constraints about positive instances are introduced in our approach to effectively explore additional weakly supervised information that is easy to obtain and enjoy a significant boost to the learning process. The proposed algorithm, abbreviated as DWS-MIL, is easy to implement and can be trained efficiently. Our system demonstrates the state-of-the-art results on large-scale histopathology image data sets and can be applied to various applications in medical imaging beyond histopathology images, such as MRI, CT, and ultrasound images. © 1982-2012 IEEE.","Convolutional neural networks; fully convolutional networks; histopathology image segmentation; multiple instance learning; weakly supervised learning","Algorithms; Colon; Colonic Neoplasms; Databases, Factual; Histocytochemistry; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Supervised Machine Learning; Tissue Array Analysis; Bioinformatics; Computerized tomography; Convolution; Deep learning; Deep neural networks; Education; Image segmentation; Learning systems; Magnetic resonance imaging; Medical imaging; Neural networks; Personnel training; Supervised learning; Biomedical imaging; Cancer; Convolutional networks; Convolutional neural network; Multiple instance learning; Prediction algorithms; Weakly supervised learning; accuracy; Article; computer assisted tomography; conceptual framework; diagnostic imaging; echography; histopathology; human; image segmentation; information processing; learning; learning algorithm; nuclear magnetic resonance imaging; algorithm; artificial neural network; colon; colon tumor; cytochemistry; factual database; image processing; procedures; supervised machine learning; tissue microarray; Learning algorithms","","","Institute of Electrical and Electronics Engineers Inc.","28692971"
"Albarqouni S.; Baur C.; Achilles F.; Belagiannis V.; Demirci S.; Navab N.","Albarqouni, Shadi (55129204800); Baur, Christoph (56982679100); Achilles, Felix (57118240900); Belagiannis, Vasileios (35483155200); Demirci, Stefanie (57213376774); Navab, Nassir (7003458998)","55129204800; 56982679100; 57118240900; 35483155200; 57213376774; 7003458998","AggNet: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images","2016","35","5","7405343","1313","1321","8","10.1109/TMI.2016.2528120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969939903&doi=10.1109%2fTMI.2016.2528120&partnerID=40&md5=ff385d9219cfc107aeb2fa15261a230e","The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration. © 2016 IEEE.","Aggregation; crowdsourcing; deep learning; gamification; online learning","Breast Neoplasms; Crowdsourcing; Female; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Internet; Machine Learning; Mitosis; Neural Networks (Computer); Video Games; Agglomeration; Artificial intelligence; Crowdsourcing; Image retrieval; Learning systems; Neural networks; Biomedical image database; Conventional machines; Convolutional neural network; Deep learning; Gamification; Large-scale database; Online learning; Precise definition; algorithm; Article; breast biopsy; breast cancer; cancer diagnosis; clinical article; convolutional neural network; crowdsourcing; data base; experimental study; histopathology; human; human tissue; machine learning; mitosis; artificial neural network; breast tumor; computer assisted diagnosis; crowdsourcing; cytochemistry; diagnostic imaging; female; Internet; machine learning; physiology; procedures; video game; Medical imaging","","","Institute of Electrical and Electronics Engineers Inc.","26891484"
"Tabar Y.R.; Halici U.","Tabar, Yousef Rezaei (57193087364); Halici, Ugur (7003652887)","57193087364; 7003652887","A novel deep learning approach for classification of EEG motor imagery signals","2017","14","1","016003","","","","10.1088/1741-2560/14/1/016003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010685974&doi=10.1088%2f1741-2560%2f14%2f1%2f016003&partnerID=40&md5=643508265b386375ff712faa91184301","Objective. Signal classification is an important issue in brain computer interface (BCI) systems. Deep learning approaches have been used successfully in many recent studies to learn features and classify different types of data. However, the number of studies that employ these approaches on BCI applications is very limited. In this study we aim to use deep learning methods to improve classification performance of EEG motor imagery signals. Approach. In this study we investigate convolutional neural networks (CNN) and stacked autoencoders (SAE) to classify EEG Motor Imagery signals. A new form of input is introduced to combine time, frequency and location information extracted from EEG signal and it is used in CNN having one 1D convolutional and one max-pooling layers. We also proposed a new deep network by combining CNN and SAE. In this network, the features that are extracted in CNN are classified through the deep network SAE. Main results. The classification performance obtained by the proposed method on BCI competition IV dataset 2b in terms of kappa value is 0.547. Our approach yields 9% improvement over the winner algorithm of the competition. Significance. Our results show that deep learning methods provide better classification performance compared to other state of art approaches. These methods can be applied successfully to BCI systems where the amount of data is alarge due to daily recording. © 2016 IOP Publishing Ltd.","BCI; convolutional neural networks; deep learning; EEG; motor imagery; stacked autoencoders","Algorithms; Brain-Computer Interfaces; Electroencephalography; Evoked Potentials, Motor; Humans; Imagination; Machine Learning; Movement; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Sensorimotor Cortex; Brain computer interface; Classification (of information); Convolution; Deep learning; Electroencephalography; Image classification; Image enhancement; Interfaces (computer); Neural networks; Autoencoders; Classification performance; Convolutional neural network; Convolutional Neural Networks (CNN); Learning approach; Location information; Motor imagery; Signal classification; accuracy; algorithm; Article; brain computer interface; classifier; electroencephalography; learning; priority journal; validation process; automated pattern recognition; brain computer interface; comparative study; electroencephalography; evaluation study; human; imagination; machine learning; motor evoked potential; movement (physiology); physiology; procedures; reproducibility; sensitivity and specificity; sensorimotor cortex; validation study; Biomedical signal processing","","","Institute of Physics Publishing","27900952"
"Li H.; Wu Z.; Zhang J.","Li, Hailong (57112810400); Wu, Zhendong (58939526400); Zhang, Jianwu (57113044300)","57112810400; 58939526400; 57113044300","Pedestrian detection based on deep learning model","2017","","","7852818","796","800","4","10.1109/CISP-BMEI.2016.7852818","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016055713&doi=10.1109%2fCISP-BMEI.2016.7852818&partnerID=40&md5=130186f55888564022e7bda249abdfca","Pedestrian detection remains an important task in the theory research and practical application of objects detection. Traditional pedestrian detection algorithms require experts design features to describe the pedestrian characteristics and combine with the classifiers. In recent years, deep learning and especially Convolutional Neural Networks (CNN) have made great success on image and audio, which is the important component of deep learning. Artificial designed methods of feature extracting has an imperfect description of pedestrian in the complex background. In this paper, we propose a pedestrian detection method based on deep convolutional neural network with multi-layers. It can make full use of the advantages of deep convolutional neural network and extract features from the database of pedestrian detection. At the stage of region proposal, to solve the problem of too much redundant windows generated by traditional methods, we use the edge boxes algorithm instead of sliding window algorithm to extract windows. At last, we get a smaller number of windows with high-quality, which is of great importance for the subsequent classification task. At the end of the paper, we carried out multi-sets of comparison experiments in this system. Experiments show that the pedestrian detection system based on deep learning outperforms the traditional methods based on both handcrafted and learned features. © 2016 IEEE.","Convolution Neural Network (CNN); Deep Learning; Feature Extracting; Pedestrian Detection","Biomedical engineering; Communication channels (information theory); Convolution; Deep learning; Deep neural networks; Image processing; Network layers; Neural networks; Object detection; Signal processing; Classification tasks; Complex background; Convolution neural network; Convolutional neural network; Feature extracting; Pedestrian detection; Pedestrian detection system; Sliding window algorithms; Feature extraction","","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","Proceedings of the 13th IASTED International Conference on Biomedical Engineering, BioMed 2017","2017","","","","","","280","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018963576&partnerID=40&md5=a2257dc9628952bab023364f93ab95a0","The proceedings contain 44 papers. The topics discussed include: performance feedback assists practice driven plasticity; patient-specific ECG classification based on recurrent neural networks and clustering technique; extraction and visualization of structural information based on FDG-PET images; microarray missing data imputation using regression; a numerical analysis of magneto-acousto electrical tomography with a simplified breast model; Haralick's texture analysis applied to colorectal T2-weighted MRI: a preliminary study of significance for cancer evolution; intelligent PillBox: automatic and programmable assistive technology device; low-intensity electrical stimulation and stem cells in a dog with acute spinal cord injury; deformable surface registration for breast tumors tracking: a phantom study; novice and expert haptic behaviours while using a robot controlled surgery system; depth-sensitive detection of absorbing objects in a liquid tissue phantom from diffuse reflectance; cognitive task analysis of spatial skills in hysterectomy with the Da Vinchi surgical system; skin lesion classification from dermoscopic images using deep learning techniques; implants using SPI communication with Reed Solomon error correction codes; a new approach to classification of upper limb and wrist movements using EEG signals; signal detection and discrimination for medical devices using windowed state space filters; fatigue detection based on facial images processed by difference algorithm; and liver-on-a-chip for evaluating hepatic activation of clopidogrel in patients with coronary stents.","","","","Kiss R.; Thurner P.J.","Institute of Electrical and Electronics Engineers Inc.",""
"Masood A.; Sheng B.; Li P.; Hou X.; Wei X.; Qin J.; Feng D.","Masood, Anum (57213374479); Sheng, Bin (7004699346); Li, Ping (55268425500); Hou, Xuhong (25653889700); Wei, Xiaoer (43761775900); Qin, Jing (35339855100); Feng, Dagan (7401981167)","57213374479; 7004699346; 55268425500; 25653889700; 43761775900; 35339855100; 7401981167","Computer-Assisted Decision Support System in Pulmonary Cancer detection and stage classification on CT images","2018","79","","","117","128","11","10.1016/j.jbi.2018.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040686779&doi=10.1016%2fj.jbi.2018.01.005&partnerID=40&md5=47d37605644db9dd116bf96abd9341e4","Pulmonary cancer is considered as one of the major causes of death worldwide. For the detection of lung cancer, computer-assisted diagnosis (CADx) systems have been designed. Internet-of-Things (IoT) has enabled ubiquitous internet access to biomedical datasets and techniques; in result, the progress in CADx is significant. Unlike the conventional CADx, deep learning techniques have the basic advantage of an automatic exploitation feature as they have the ability to learn mid and high level image representations. We proposed a Computer-Assisted Decision Support System in Pulmonary Cancer by using the novel deep learning based model and metastasis information obtained from MBAN (Medical Body Area Network). The proposed model, DFCNet, is based on the deep fully convolutional neural network (FCNN) which is used for classification of each detected pulmonary nodule into four lung cancer stages. The performance of proposed work is evaluated on different datasets with varying scan conditions. Comparison of proposed classifier is done with the existing CNN techniques. Overall accuracy of CNN and DFCNet was 77.6% and 84.58%, respectively. Experimental results illustrate the effectiveness of proposed method for the detection and classification of lung cancer nodules. These results demonstrate the potential for the proposed technique in helping the radiologists in improving nodule detection accuracy with efficiency. © 2018 Elsevier Inc.","Convolutional neural networks (CNN); Deep learning; Lung cancer stages; MBAN (Medical Body Area Network); mIoT (medical Internet of Things); Nodule detection","Algorithms; Databases, Factual; Decision Making; Decision Support Systems, Clinical; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Internet; Lung; Lung Neoplasms; Machine Learning; Neoplasm Staging; Neural Networks (Computer); Pattern Recognition, Automated; Software; Solitary Pulmonary Nodule; Symptom Assessment; Tomography, X-Ray Computed; Biological organs; Computer aided instruction; Computerized tomography; Convolution; Decision support systems; Deep learning; Diseases; Image classification; Internet of things; Medical information systems; Neural networks; Body Area Network; Convolutional Neural Networks (CNN); Lung Cancer; mIoT (medical Internet of Things); Nodule detection; analytic method; Article; artificial neural network; cancer classification; cancer diagnosis; cancer staging; clinical article; clinical effectiveness; computer assisted diagnosis; computer assisted tomography; controlled study; decision support system; diagnostic accuracy; diagnostic test accuracy study; false positive result; fully convolutional neural network; human; Internet; lung cancer; lung nodule; machine learning; Medical Body Area Network; medical Internet of Thing; priority journal; retrospective study; sensitivity and specificity; algorithm; automated pattern recognition; cancer staging; clinical decision support system; computer assisted diagnosis; decision making; diagnostic imaging; factual database; image processing; lung; lung nodule; lung tumor; procedures; software; symptom assessment; x-ray computed tomography; Computer aided diagnosis","General Program of Cross of Medicine and Engineering of SJTU, (YG2015MS19); Key Program for International S&T Cooperation Project; National High-tech R&D Program of China (863 Program); Research Grants Council of Hong Kong; National Natural Science Foundation of China, NSFC, (61572316, 61671290); Research Grants Council, University Grants Committee, RGC, UGC, (28200215); Science and Technology Commission of Shanghai Municipality, STCSM, (16DZ0501100, 17411952600); Hong Kong Polytechnic University, PolyU, (1-ZE8J); Shanghai Jiao Tong University, SJTU, (14JCY10); National High-tech Research and Development Program, (2015AA015904); International Science and Technology Cooperation Programme, ISTCP, (2016YFE0129500)","","Academic Press Inc.","29366586"
"Li J.; Si Y.; Xu T.; Jiang S.","Li, Jia (57203287412); Si, Yujuan (8417025100); Xu, Tao (57200299506); Jiang, Saibiao (57205168413)","57203287412; 8417025100; 57200299506; 57205168413","Deep Convolutional Neural Network Based ECG Classification System Using Information Fusion and One-Hot Encoding Techniques","2018","2018","","7354081","","","","10.1155/2018/7354081","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058900317&doi=10.1155%2f2018%2f7354081&partnerID=40&md5=f858089b521ae9bac975424b4496e830","Although convolutional neural networks (CNNs) can be used to classify electrocardiogram (ECG) beats in the diagnosis of cardiovascular disease, ECG signals are typically processed as one-dimensional signals while CNNs are better suited to multidimensional pattern or image recognition applications. In this study, the morphology and rhythm of heartbeats are fused into a two-dimensional information vector for subsequent processing by CNNs that include adaptive learning rate and biased dropout methods. The results demonstrate that the proposed CNN model is effective for detecting irregular heartbeats or arrhythmias via automatic feature extraction. When the proposed model was tested on the MIT-BIH arrhythmia database, the model achieved higher performance than other state-of-the-art methods for five and eight heartbeat categories (the average accuracy was 99.1% and 97%). In particular, the proposed system had better performance in terms of the sensitivity and positive predictive rate for V beats by more than 4.3% and 5.4%, respectively, and also for S beats by more than 22.6% and 25.9%, respectively, when compared to existing algorithms. It is anticipated that the proposed method will be suitable for implementation on portable devices for the e-home health monitoring of cardiovascular disease. © 2018 Jia Li et al.","","Cardiology; Classification (of information); Convolution; Deep neural networks; Diseases; Electrocardiography; Feature extraction; Image recognition; Network coding; Neural networks; State assignment; Adaptive learning rates; Automatic feature extraction; Cardio-vascular disease; Convolutional neural network; Deep convolutional neural networks; Home health monitoring; One dimensional signal; State-of-the-art methods; Biomedical signal processing","Guangdong Government Funds, (2016GDYSZDXK036); Key Scientific and Technological Research Project of Jilin Province, (20170414017GH)","","Hindawi Limited",""
"Jin K.H.; McCann M.T.; Froustey E.; Unser M.","Jin, Kyong Hwan (55153576800); McCann, Michael T. (55617614400); Froustey, Emmanuel (56431076100); Unser, Michael (7102049045)","55153576800; 55617614400; 56431076100; 7102049045","Deep Convolutional Neural Network for Inverse Problems in Imaging","2017","26","9","7949028","4509","4522","13","10.1109/TIP.2017.2713099","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023170573&doi=10.1109%2fTIP.2017.2713099&partnerID=40&md5=6ea849721174e81f76ba5c8c3e4ac5b5","In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difficulty of hyperparameter selection. The starting point of this paper is the observation that unrolled iterative methods have the form of a CNN (filtering followed by pointwise non-linearity) when the normal operator (H∗H, where H∗ is the adjoint of the forward imaging operator, H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512× 512 image on the GPU. © 1992-2012 IEEE.","biomedical imaging; biomedical signal processing; computed tomography; image reconstruction; Image restoration; magnetic resonance imaging; reconstruction algorithms; tomography","Computerized tomography; Convolution; Deep neural networks; Differential equations; Image processing; Image reconstruction; Iterative methods; Neural networks; Tomography; Algorithm for solving; Convolutional neural network; ILL-posed inverse problem; Iterative algorithm; Iterative reconstruction; Multi resolution decomposition; Sparse-view reconstruction; X-ray computed tomography; Inverse problems","Horizon 2020 Framework Programme, H2020, (665667, 692726)","","Institute of Electrical and Electronics Engineers Inc.","28641250"
"Park S.H.; Han K.","Park, Seong Ho (57049729900); Han, Kyunghwa (57205679159)","57049729900; 57205679159","Methodologic guide for evaluating clinical performance and effect of artificial intelligence technology for medical diagnosis and prediction","2018","286","3","","800","809","9","10.1148/radiol.2017171920","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042425427&doi=10.1148%2fradiol.2017171920&partnerID=40&md5=f1c2b864cd6a9c4846af645b06383517","The use of artificial intelligence in medicine is currently an issue of great interest, especially with regard to the diagnostic or predictive analysis of medical images. Adoption of an artificial intelligence tool in clinical practice requires careful confirmation of its clinical utility. Herein, the authors explain key methodology points involved in a clinical evaluation of artificial intelligence technology for use in medicine, especially high-dimensional or overparameterized diagnostic or predictive models in which artificial deep neural networks are used, mainly from the standpoints of clinical epidemiology and biostatistics. First, statistical methods for assessing the discrimination and calibration performances of a diagnostic or predictive model are summarized. Next, the effects of disease manifestation spectrum and disease prevalence on the performance results are explained, followed by a discussion of the difference between evaluating the performance with use of internal and external datasets, the importance of using an adequate external dataset obtained from a well-defined clinical cohort to avoid overestimating the clinical performance as a result of overfitting in high-dimensional or overparameterized classification model and spectrum bias, and the essentials for achieving a more robust clinical evaluation. Finally, the authors review the role of clinical trials and observational outcome studies for ultimate clinical verification of diagnostic or predictive artificial intelligence tools through patient outcomes, beyond performance metrics, and how to design such studies. © RSNA, 2018.","","Artificial Intelligence; Data Interpretation, Statistical; Diagnostic Imaging; Humans; Image Interpretation, Computer-Assisted; Neural Networks (Computer); Predictive Value of Tests; Technology Assessment, Biomedical; Terminology as Topic; area under the curve; artificial deep neural network; artificial intelligence; artificial neural network; calibration; decision support system; diagnostic procedure; external validation; human; hypothetical deep learning algorithm; information processing; internal validation; learning algorithm; lung cancer; methodology; prediction; prevalence; priority journal; propensity score; receiver operating characteristic; Review; sensitivity and specificity; statistical analysis; treatment outcome; artificial neural network; biomedical technology assessment; computer assisted diagnosis; diagnostic imaging; nomenclature; predictive value; procedures; standards","Industrial Technologies Program, (10072064); Industrial Technologies Program; Ministry of Trade, Industry and Energy, MOTIE","","Radiological Society of North America Inc.","29309734"
"Kergosien Y.L.; Racoceanu D.","Kergosien, Yannick L. (7801688542); Racoceanu, Daniel (6603452376)","7801688542; 6603452376","Semantic knowledge for histopathological image analysis: From ontologies to processing portals and deep learning","2017","10572","","105721F","","","","10.1117/12.2285916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038428283&doi=10.1117%2f12.2285916&partnerID=40&md5=cf7993dbd67b8a0bfb90957756cd7490","This article presents our vision about the next generation of challenges in computational/digital pathology. The key role of the domain ontology, developed in a sustainable manner (i.e. using reference checklists and protocols, as the living semantic repositories), opens the way to effective/sustainable traceability and relevance feedback concerning the use of existing machine learning algorithms, proven to be very performant in the latest digital pathology challenges (i.e. convolutional neural networks). Being able to work in an accessible web-service environment, with strictly controlled issues regarding intellectual property (image and data processing/analysis algorithms) and medical data/image confidentiality is essential for the future. Among the web-services involved in the proposed approach, the living yellow pages in the area of computational pathology seems to be very important in order to reach an operational awareness, validation, and feasibility. This represents a very promising way to go to the next generation of tools, able to bring more guidance to the computer scientists and confidence to the pathologists, towards an effective/efficient daily use. Besides, a consistent feedback and insights will be more likely to emerge in the near future - from these sophisticated machine learning tools - back to the pathologists - , strengthening, therefore, the interaction between the different actors of a sustainable biomedical ecosystem (patients, clinicians, biologists, engineers, scientists etc.). Beside going digital/computational - with virtual slide technology demanding new workflows - , Pathology must prepare for another coming revolution: semantic web technologies now enable the knowledge of experts to be stored in databases, shared through the Internet, and accessible by machines. Traceability, disambiguation of reports, quality monitoring, interoperability between health centers are some of the associated benefits that pathologists were seeking. However, major changes are also to be expected for the relation of human diagnosis to machine based procedures. Improving on a former imaging platform which used a local knowledge base and a reasoning engine to combine image processing modules into higher level tasks, we propose a framework where different actors of the histopathology imaging world can cooperate using web services - exchanging knowledge as well as imaging services - and where the results of such collaborations on diagnostic related tasks can be evaluated in international challenges such as those recently organized for mitosis detection, nuclear atypia, or tissue architecture in the context of cancer grading. This framework is likely to offer an effective context-guidance and traceability to Deep Learning approaches, with an interesting promising perspective given by the multi-task learning (MTL) paradigm, distinguished by its applicability to several different learning algorithms, its non- reliance on specialized architectures and the promising results demonstrated, in particular towards the problem of weak supervision - , an issue found when direct links from pathology terms in reports to corresponding regions within images are missing. © 2017 SPIE.","Challenges; Computational/Digital Pathology; Deep Learning; Multitask learning; Semantics/Ontology; Web-Services","Artificial intelligence; Bioinformatics; Data handling; Deep learning; Diagnosis; Feedback; Grading; Image enhancement; Image processing; Knowledge based systems; Knowledge management; Learning systems; Medical imaging; Network architecture; Neural networks; Ontology; Pathology; Semantic Web; Web services; Websites; Challenges; Convolutional neural network; Histopathological image analysis; Image Processing Module; Multitask learning; Semantic repository; Semantic Web technology; Sophisticated machines; Learning algorithms","","Lepore N.; Brieva J.; Garcia J.D.; Romero E.","SPIE",""
"Hu J.; Chen Y.; Zhong J.; Ju R.; Yi Z.","Hu, Junjie (57203241882); Chen, Yuanyuan (55364324300); Zhong, Jie (36521832100); Ju, Rong (10639971000); Yi, Zhang (7102297045)","57203241882; 55364324300; 36521832100; 10639971000; 7102297045","Automated analysis for retinopathy of prematurity by deep neural networks","2019","38","1","8425798","269","279","10","10.1109/TMI.2018.2863562","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051043254&doi=10.1109%2fTMI.2018.2863562&partnerID=40&md5=8290d9a8a4ac29ccdab82d04f9bfae77","Retinopathy of Prematurity (ROP) is a retinal vasproliferative disorder disease principally observed in infants born prematurely with low birth weight. ROP is an important cause of childhood blindness. Although automatic or semi-automatic diagnosis of ROP has been conducted, most previous studies have focused on 'plus' disease, which is indicated by abnormalities of retinal vasculature. Few studies have reported methods for identifying the 'stage' of the ROP disease. Deep neural networks have achieved impressive results in many computer vision and medical image analysis problems, raising expectations that it might be a promising tool in the automatic diagnosis of ROP. In this paper, convolutional neural networks with a novel architecture are proposed to recognize the existence and severity of ROP disease per-examination. The severity of ROP is divided into mild and severe cases according to the disease progression. The proposed architecture consists of two sub-networks connected by a feature aggregate operator. The first sub-network is designed to extract high-level features from images of the fundus. These features from different images in an examination are fused by the aggregate operator, then used as the input for the second sub-network to predict its class. A large data set imaged by RetCam 3 is used to train and evaluate the model. The high classification accuracy in the experiment demonstrates the effectiveness of the proposed architecture for recognizing the ROP disease. © 1982-2012 IEEE.","deep neural networks; feature aggregate operator; medical image analysis; Retinopathy of Prematurity","Algorithms; Diagnostic Techniques, Ophthalmological; Humans; Image Interpretation, Computer-Assisted; Infant, Newborn; Neural Networks, Computer; Retinopathy of Prematurity; Aggregates; Computer architecture; Diagnosis; Diseases; Eye protection; Feature extraction; Image analysis; Large scale systems; Medical imaging; Medical problems; Network architecture; Neural networks; Ophthalmology; Pediatrics; Automatic diagnosis; Biomedical imaging; Classification accuracy; Convolutional neural network; feature aggregate operator; Proposed architectures; Retina; Retinopathy of prematurity; Article; classification algorithm; comparative study; computer assisted diagnosis; deep neural network; diagnostic accuracy; disease severity; feature extraction; gestational age; human; image analysis; machine learning; major clinical study; newborn; receiver operating characteristic; retrolental fibroplasia; sensitivity and specificity; transfer of learning; algorithm; computer assisted diagnosis; diagnostic imaging; procedures; retrolental fibroplasia; visual system examination; Deep neural networks","","","Institute of Electrical and Electronics Engineers Inc.","30080144"
"Pang S.; Yu Z.; Orgun M.A.","Pang, Shuchao (55639762100); Yu, Zhezhou (8938987700); Orgun, Mehmet A. (6603681610)","55639762100; 8938987700; 6603681610","A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images","2017","140","","","283","293","10","10.1016/j.cmpb.2016.12.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011883667&doi=10.1016%2fj.cmpb.2016.12.019&partnerID=40&md5=3461c46640f53b42561a301ee3e549bd","Background and objectives Highly accurate classification of biomedical images is an essential task in the clinical diagnosis of numerous medical diseases identified from those images. Traditional image classification methods combined with hand-crafted image feature descriptors and various classifiers are not able to effectively improve the accuracy rate and meet the high requirements of classification of biomedical images. The same also holds true for artificial neural network models directly trained with limited biomedical images used as training data or directly used as a black box to extract the deep features based on another distant dataset. In this study, we propose a highly reliable and accurate end-to-end classifier for all kinds of biomedical images via deep learning and transfer learning. Methods We first apply domain transferred deep convolutional neural network for building a deep model; and then develop an overall deep learning architecture based on the raw pixels of original biomedical images using supervised training. In our model, we do not need the manual design of the feature space, seek an effective feature vector classifier or segment specific detection object and image patches, which are the main technological difficulties in the adoption of traditional image classification methods. Moreover, we do not need to be concerned with whether there are large training sets of annotated biomedical images, affordable parallel computing resources featuring GPUs or long times to wait for training a perfect deep model, which are the main problems to train deep neural networks for biomedical image classification as observed in recent works. Results With the utilization of a simple data augmentation method and fast convergence speed, our algorithm can achieve the best accuracy rate and outstanding classification ability for biomedical images. We have evaluated our classifier on several well-known public biomedical datasets and compared it with several state-of-the-art approaches. Conclusions We propose a robust automated end-to-end classifier for biomedical images based on a domain transferred deep convolutional neural network model that shows a highly reliable and accurate performance which has been confirmed on several public biomedical image datasets. © 2017 Elsevier Ireland Ltd","Biomedical image classification; Convolutional neural network; Data augmentation; Deep learning; Transfer learning","Diagnostic Imaging; Machine Learning; Models, Theoretical; Neural Networks (Computer); Bioinformatics; Computer aided diagnosis; Convolution; Data mining; Deep learning; Deep neural networks; Diagnosis; Image classification; Image segmentation; Medical imaging; Neural networks; Program processors; Vector spaces; Artificial neural network models; Classification ability; Classification methods; Convolutional neural network; Data augmentation; Fast convergence speed; State-of-the-art approach; Transfer learning; Article; artificial neural network; automation; back propagation; biomedicine; classification algorithm; classifier; controlled study; convolutional neural network; deep learning; diagnostic imaging; high resolution computer tomography; histogram; human; image analysis; image processing; machine learning; medical technology; support vector machine; training; transfer learning; velocity; machine learning; theoretical model; Classification (of information)","","","Elsevier Ireland Ltd","28254085"
"Xing F.; Xie Y.; Su H.; Liu F.; Yang L.","Xing, Fuyong (38461688800); Xie, Yuanpu (56903340500); Su, Hai (44661704600); Liu, Fujun (55541334700); Yang, Lin (55771607100)","38461688800; 56903340500; 44661704600; 55541334700; 55771607100","Deep Learning in Microscopy Image Analysis: A Survey","2018","29","10","8118310","4550","4568","18","10.1109/TNNLS.2017.2766168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035790459&doi=10.1109%2fTNNLS.2017.2766168&partnerID=40&md5=116e43fd3ab898ab2901ec2b8bfdb2a8","Computerized microscopy image analysis plays an important role in computer aided diagnosis and prognosis. Machine learning techniques have powered many aspects of medical investigation and clinical practice. Recently, deep learning is emerging as a leading machine learning tool in computer vision and has attracted considerable attention in biomedical image analysis. In this paper, we provide a snapshot of this fast-growing field, specifically for microscopy image analysis. We briefly introduce the popular deep neural networks and summarize current deep learning achievements in various tasks, such as detection, segmentation, and classification in microscopy image analysis. In particular, we explain the architectures and the principles of convolutional neural networks, fully convolutional networks, recurrent neural networks, stacked autoencoders, and deep belief networks, and interpret their formulations or modelings for specific tasks on various microscopy images. In addition, we discuss the open challenges and the potential trends of future research in microscopy image analysis using deep learning. © 2012 IEEE.","Classification; deep learning; detection; microscopy image analysis; segmentation","Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Image Processing, Computer-Assisted; Male; Microscopy; Neural Networks (Computer); Surveys and Questionnaires; Classification (of information); Computer aided analysis; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Error detection; Image segmentation; Learning systems; Medical imaging; Microscopic examination; Neural networks; Recurrent neural networks; Biomedical image analysis; Biomedical imaging; Convolutional networks; Convolutional neural network; Deep belief networks; Learning achievement; Machine learning techniques; Microscopy image analysis; algorithm; artificial neural network; computer assisted diagnosis; female; human; image processing; male; microscopy; procedures; questionnaire; Image analysis","","","Institute of Electrical and Electronics Engineers Inc.","29989994"
"Khanh H.T.K.; Hung T.C.; Dang V.-H.; Thang N.D.","Khanh, Ho Thi Kieu (57196003816); Hung, Tran Cong (16678854400); Dang, Viet-Hung (57218103791); Thang, Nguyen Duc (35304327500)","57196003816; 16678854400; 57218103791; 35304327500","Human organ classifications from computed tomography images using deep-convolutional neural network","2018","63","","","917","923","6","10.1007/978-981-10-4361-1_155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030866338&doi=10.1007%2f978-981-10-4361-1_155&partnerID=40&md5=587520cee01d12c7ba4c43f94fbdd90e","Deep neural networks (DNNs) have recently indicated outstanding performance on image learning feature tasks while Convolutional neural networks (CNNs) have been applied for classification tasks by reducing spectral variations and the spectral correlations of the model which existed in images. In this paper, we independently approached our work as a sequence of steps. We first implemented sparse autoencoders as an unsupervised algorithm to obtain learned features in two hidden layers for the DNN model by evaluating the appropriate input features and the optimal number of hidden units, which allow us to validate basic capabilities of the dataset. Secondly, we trained a deep CNN which consisted of five main convolutional layers, followed by Rectified Linear Units (ReLUs) layers, max-pooling layers, three fully-connected layers and a final softmax probability layer, to classify the high-resolution medical images of Computed Tomography (CT) into five anatomical classes, corresponding to five organs in abdominal regions. As a result, we considerably achieved the classification accuracy of 83.74 ± 3.34% in testing. We also visualized the layer representations on CT datasets, where they indicated the state-of-the-art performance, and could hold much promise to initialize further research on computer-aided diagnosis. © Springer Nature Singapore Pte Ltd. 2018.","CNN; Convolution; CT images; DNN; Fully-connected; Optimization; Pooling; ReLUs; Softmax; Sparse autoencoders","Biomedical engineering; Computer aided diagnosis; Convolution; Deep neural networks; Diagnosis; Image classification; Learning systems; Medical imaging; Neural networks; Optimization; Tomography; Autoencoders; CT Image; Fully-connected; Pooling; ReLUs; Softmax; Computerized tomography","Vietnam National Foundation for Science and Technology Development; National Foundation for Science and Technology Development, NAFOSTED, (102.05-2016.18); National Foundation for Science and Technology Development, NAFOSTED","Vo Van T.; Nguyen Le T.A.; Nguyen Duc T.","Springer Verlag",""
"Kamrul Hasan S.M.; Linte C.A.","Kamrul Hasan, S.M. (57188664990); Linte, Cristian A. (57202997616)","57188664990; 57202997616","A Modified U-Net Convolutional Network Featuring a Nearest-neighbor Re-sampling-based Elastic-Transformation for Brain Tissue Characterization and Segmentation","2018","","","8576421","","","","10.1109/WNYIPW.2018.8576421","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060302593&doi=10.1109%2fWNYIPW.2018.8576421&partnerID=40&md5=fa5af0a5b01453035d8474470fe52b2e","The detection and segmentation of brain tumors from Magnetic Resonance Imaging (MRI) is a very challenging task, despite the availability of modern medical image processing tools. Neuro-radiologists still diagnose deadly brain cancers such as even glioblastoma using manual segmentation. This approach is not only tedious, but also highly variable, featuring limited accuracy and precision, and hence raising the need for more robust, automated techniques. Deep learning methods such as the U-Net deep convolutional neural networks have been widely used in biomedical image segmentation. Although this model was demonstrated to yield desirable results on the BRATS 2015 dataset by using a pixel-wise segmentation map of the input image as an auto-encoder, which assures best segmentation accuracy, the output only showed limited accuracy and robustness for a number of cases. The goal of this work was to improve the U-net model by replacing the de-convolution component with an up-sampled by the Nearest-neighbor algorithm and also employing an elastic transformation to augment the training dataset to render the model more robust, especially for the segmentation of low-grade tumors. The proposed Nearest-Neighbor Re-sampling Based Elastic-Transformed (NNRET) U-net Deep CNN framework has been trained on 285 glioma patients BRATS 2017 MR dataset available through the MICCAI 2017 grand challenge. The framework has been tested on 146 patients using Dice similarity coefficient (DSC) Intersection over Union (IoU) performance metrics and outweighed the classic U-net model. © 2018 IEEE.","Brain tissue segmentation; deep convolutional networks; modified U-net; nearest-neighbor interpolation","Brain; Convolution; Deep neural networks; Magnetic resonance imaging; Medical imaging; Neural networks; Tumors; Biomedical image segmentation; Brain tissue segmentations; Convolutional networks; Deep convolutional neural networks; Magnetic Resonance Imaging (MRI); modified U-net; Nearest neighbor algorithm; Nearest neighbor interpolation; Image segmentation","","","Institute of Electrical and Electronics Engineers Inc.",""
"Badretale S.; Shaker F.; Babyn P.; Alirezaie J.","Badretale, Seyyedomid (57197825593); Shaker, Fariba (57189217355); Babyn, Paul (7006367819); Alirezaie, Javad (6701846696)","57197825593; 57189217355; 7006367819; 6701846696","Deep Convolutional Approach for Low-Dose CT Image Noise Reduction","2018","","","8430255","","","","10.1109/ICBME.2017.8430255","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052484083&doi=10.1109%2fICBME.2017.8430255&partnerID=40&md5=9b58661f6b70897179e1944827d8743a","An essential objective in medical low-dose Computed Tomography (CT) imaging is how best to preserve the quality of the image. While, reducing the X-ray radiation dose is desired, in general, the image quality lowers by reducing the dose. Therefore, improving image quality is remarkably crucial for diagnostic purposes. A novel method to denoise low-dose CT images has been presented in this study. Different from the prevalent and traditional algorithms which utilize similar shared features of CT images in the spatial or transform domain, the deep learning approach is suggested for low-dose CT denoising. In this paper, a fully convolutional neural network architecture consisting of five parts, namely-Feature extraction, Compressing, Mapping, Enlarging, and Assembling, are introduced to directly map the low-dose CT images onto the corresponding normal-dose CT images. The results of the proposed technique were compared with three state-of-the-art algorithms. To illustrate the superiority of our proposed technique, three performance measures, including root mean squared error, peak signal to noise ratio, and structural similarity index are presented. © 2017 IEEE.","convolutional neural networks; Deep learning; low-dose CT; parametric rectified linear unit","Biomedical engineering; Biophysics; Convolution; Deep learning; Diagnosis; Image coding; Image denoising; Image enhancement; Image quality; Mean square error; Medical imaging; Network architecture; Neural networks; Signal to noise ratio; Convolutional neural network; Learning approach; Linear units; Low-dose CT; Peak signal to noise ratio; Performance measure; Root mean squared errors; Structural similarity indices; Computerized tomography","","","Institute of Electrical and Electronics Engineers Inc.",""
"Rahman M.M.","Rahman, Md Mahmudur (57199763102)","57199763102","A cross modal deep learning based approach for caption prediction and concept detection by CS Morgan State","2018","2125","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051071889&partnerID=40&md5=5e82b7d8b194e866640c1d783ed84c96","This article describes the participation of the Computer Science Department of Morgan State University, Baltimore, Maryland, USA in the ImageCLEFcaption under ImageCLEF 2018. The problem of automatic image caption prediction involves outputting a human-readable and concise textual description of the contents of a figure appeared in a biomedical journal. It is a challenging problem in biomedical literature as it requires techniques from both the fields of Computer Vision to understand the visual contents of the image and Natural Language Processing (NLP) to turn the understanding of the image into words in the right order to generate the textual description for caption. Recently, deep learning methods have achieved state-of-the-art results on this challenging problem in general domain of natural photographic images. For the tasks of caption prediction and concept detection, we used the merge architectures for the encoder-decoder recurrent neural network (RNN) due to it's success over inject for caption generation. The merge model combines both the encoded form of the image input with the encoded form of the text description generated so far. The combination of these two encoded inputs is then used by a very simple decoder model to generate the next word in the sequence. In this article, we present main objectives of experiments, overview of these approaches, resources employed, and describe our submitted runs and results with conclusions and future directions.","Caption generation; Concept Detection; Cross Modality; Deep Learning; Encoder-Decoder; Merge Architecture; Performance evaluation","Decoding; Forecasting; Image processing; Learning algorithms; Natural language processing systems; Network architecture; Photography; Recurrent neural networks; Signal encoding; Visual languages; Caption generation; Concept detection; Cross modality; Encoder-decoder; Performance evaluations; Deep learning","National Science Foundation, NSF; National Science Foundation, NSF, (1601044); National Science Foundation, NSF","Ferro N.; University of Padua, Department of Information Engineering (DEI), Via Gradenigo 6/B, Padova; Nie J.-Y.; Soulier L.; Soulier L.; Cappellato L.; University of Padua, Department of Information Engineering (DEI), Via Gradenigo 6/B, Padova","CEUR-WS",""
"Raman R.; Srinivasan S.; Virmani S.; Sivaprasad S.; Rao C.; Rajalakshmi R.","Raman, Rajiv (10044575200); Srinivasan, Sangeetha (56059320400); Virmani, Sunny (57220390352); Sivaprasad, Sobha (35547907400); Rao, Chetan (16246049700); Rajalakshmi, Ramachandran (56370604500)","10044575200; 56059320400; 57220390352; 35547907400; 16246049700; 56370604500","Fundus photograph-based deep learning algorithms in detecting diabetic retinopathy","2019","33","1","","97","109","12","10.1038/s41433-018-0269-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056160290&doi=10.1038%2fs41433-018-0269-y&partnerID=40&md5=a9612ed4b8f6578254078440bef9c08c","Remarkable advances in biomedical research have led to the generation of large amounts of data. Using artificial intelligence, it has become possible to extract meaningful information from large volumes of data, in a shorter frame of time, with very less human interference. In effect, convolutional neural networks (a deep learning method) have been taught to recognize pathological lesions from images. Diabetes has high morbidity, with millions of people who need to be screened for diabetic retinopathy (DR). Deep neural networks offer a great advantage of screening for DR from retinal images, in improved identification of DR lesions and risk factors for diseases, with high accuracy and reliability. This review aims to compare the current evidences on various deep learning models for diagnosis of diabetic retinopathy (DR). © 2018, The Royal College of Ophthalmologists.","","Algorithms; Deep Learning; Diabetic Retinopathy; Diagnostic Techniques, Ophthalmological; Fundus Oculi; Humans; Neural Networks (Computer); Photography; ROC Curve; deep learning; diabetic retinopathy; disease severity; ethnicity; eye fundus; eye photography; human; image quality; race; Review; screening; algorithm; artificial neural network; diabetic retinopathy; photography; procedures; receiver operating characteristic; visual system examination","","","Nature Publishing Group","30401899"
"Xia Y.; Wulan N.; Wang K.; Zhang H.","Xia, Yong (57079412300); Wulan, Naren (58882459400); Wang, Kuanquan (9733243800); Zhang, Henggui (9532347100)","57079412300; 58882459400; 9733243800; 9532347100","Atrial fibrillation detection using stationary wavelet transform and deep learning","2017","44","","","1","4","3","10.22489/CinC.2017.210-084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045124783&doi=10.22489%2fCinC.2017.210-084&partnerID=40&md5=319e5202c6dccaa20abd8807af81788d","Deep learning has achieved a great success in the fields of image and audio recognition because of avoiding explicit feature extraction and attaining high classification accuracy. In this paper, we explore the application of deep convolutional neural networks (DCNNs) for automatic detection of atrial fibrillation (AF). The 2-dimension parameter input structure is essential for DCNNs and tens of thousands of samples are also needed for the proper operation. As we know, ECG is one-dimension time-varying signal, which doesn't match the requirement for the input structure of DCNNs. Furthermore the number of the marked AF samples is also limited. To address these problems, we adopt the stationary wavelet transform (SWT) for ECG preprocessing and then the processed signal is reorganized into two-dimensional parameter structure to meet the requirement of input structure of DCNNs. Besides, the original ECG signals are divided into very short data segments (namely 5-second segments) for the following reasons. On the one hand, short ECG segment is helpful for the algorithm assessment of short AF episode detection. On the other hand, it can also increase the number of AF sample for machine learning and experiment evaluation. As for DCNNs, multiple convolutional layers and fully connected layers are used for deep learning. On the MIT-BIH Atrial fibrillation data set, the proposed method can achieve sensitivity of 98.79%, specificity of 97.87% and accuracy of 98.63%, which outperforms most of other algorithms. © 2017 IEEE Computer Society. All rights reserved.","","Biomedical signal processing; Cardiology; Convolution; Deep neural networks; Diseases; Electrocardiography; Neural networks; Atrial fibrillation; Automatic Detection; Classification accuracy; Deep convolutional neural networks; ECG preprocessing; Fully-connected layers; Stationary wavelet transforms; Time varying signal; Wavelet transforms","Department of Science and Technology of Shandong Province, (2014GSF118152); China Scholarship Council, CSC, (201606125090); Natural Science Foundation of Shandong Province, (ZR2015FM028)","","IEEE Computer Society",""
"Zhao Y.; Ganti R.; Yao S.; Srivatsa M.; Hu S.; Li S.; Chang S.; Abdelzaher T.","Zhao, Yiran (57189000922); Ganti, Raghu (57203061258); Yao, Shuochao (56937565400); Srivatsa, Mudhakar (8510987100); Hu, Shaohan (55606150900); Li, Shen (47962294300); Chang, Shiyu (55494279500); Abdelzaher, Tarek (7004058432)","57189000922; 57203061258; 56937565400; 8510987100; 55606150900; 47962294300; 55494279500; 7004058432","On the improvement of classifying EEG recordings using neural networks","2017","","","","1709","1711","2","10.1109/BigData.2017.8258112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068340760&doi=10.1109%2fBigData.2017.8258112&partnerID=40&md5=909f9d0c563397c553271300e0354438","This paper presents improved results on classifying electroencephalography (EEG) recordings using deep learning. The task is to classify movements that the subject is thinking about (motor imagery), using only the recorded electrical activities on the scalp. The challenges are: poor signal-to-noise ratio; interference from numerous sources such as electrical line noise, muscle activity, and eye movements; considerable variability between individuals and even recording sessions. Traditional signal processing techniques such as frequency band analysis, common spatial pattern (CSP) algorithm or independent component analysis (ICA) fall short due to their limited capacity. Thanks to the rise of big data in healthcare, medical recordings now come in abundance. Therefore deep learning which relies on large amounts of training data is becoming the new cutting edge tool. We present a significant improvement of classification accuracy on the Brain-Computer Interfaces Competition IV dataset (2a), and compare the results of various state of the art neural network structures. © 2017 IEEE.","BCI Competition IV; Deep learning; EEG; Motor imagery","Big data; Biomedical signal processing; Brain computer interface; Classification (of information); Deep learning; Electroencephalography; Eye movements; Image classification; Image enhancement; Independent component analysis; Interface states; Signal to noise ratio; BCI competition IV; Common spatial patterns; Deep learning; Electrical activities; Frequency band analysis; Line noise; Motor imagery; Muscle activities; Neural-networks; Signal processing technique; Electrophysiology","U.S. Government; Army Research Laboratory, ARL; Ministry of Defence, MOD, (W911NF-16-3-0001)","Nie J.-Y.; Obradovic Z.; Suzumura T.; Ghosh R.; Nambiar R.; Wang C.; Zang H.; Baeza-Yates R.; Baeza-Yates R.; Hu X.; Kepner J.; Cuzzocrea A.; Tang J.; Toyoda M.","Institute of Electrical and Electronics Engineers Inc.",""
"Santini G.; Della Latta D.; Martini N.; Valvano G.; Gori A.; Ripoli A.; Susini C.L.; Landini L.; Chiappino D.","Santini, Gianmarco (57194703031); Della Latta, D. (6507141723); Martini, N. (23025355600); Valvano, G. (57208740501); Gori, A. (57194713086); Ripoli, A. (55882952700); Susini, C.L. (36605283600); Landini, L. (25422522900); Chiappino, D. (8446507300)","57194703031; 6507141723; 23025355600; 57208740501; 57194713086; 55882952700; 36605283600; 25422522900; 8446507300","An automatic deep learning approach for coronary artery calcium segmentation","2017","65","","","374","377","3","10.1007/978-981-10-5122-7_94","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021739085&doi=10.1007%2f978-981-10-5122-7_94&partnerID=40&md5=fb50ca30e922f56e0a67fa5ce26c1540","Coronary artery calcium (CAC) is a significant marker of atherosclerosis and cardiovascular events. In this work we present a system for the automatic quantification of calcium score in ECG-triggered non-contrast enhanced cardiac computed tomography (CT) images. The proposed system uses a supervised deep learning algorithm, i.e. convolutional neural network (CNN) for the segmentation and classification of candidate lesions as coronary or not, previously extracted in the region of the heart using a cardiac atlas. We trained our network with 45 CT volumes; 18 volumes were used to validate the model and 56 to test it. Individual lesions were detected with a sensitivity of 91.24%, a specificity of 95.37% and a positive predicted value (PPV) of 90.5%; comparing calcium score obtained by the system and calcium score manually evaluated by an expert operator, a Pearson coefficient of 0.983 was obtained. A high agreement (Cohen’s κ = 0.879) between manual and automatic risk prediction was also observed. These results demonstrated that convolutional neural networks can be effectively applied for the automatic segmentation and classification of coronary calcifications. © Springer Nature Singapore Pte Ltd. 2018.","Calcium score; CNN; Computed tomography; Deep Learning; Segmentation","Biochemical engineering; Biomedical engineering; Biomineralization; Calcium; Computerized tomography; Convolution; Deep neural networks; Education; Heart; Image segmentation; Learning algorithms; Neural networks; Tomography; Automatic quantification; Automatic segmentations; Calcium score; Cardiac-computed tomography; Cardiovascular event; Convolutional neural network; Coronary artery calciums; Coronary calcifications; Deep learning","","Eskola H.; Vaisanen O.; Viik J.; Hyttinen J.","Springer Verlag",""
"Seo J.D.; Seo D.W.; Alirezaie J.","Seo, Jae Duk (57202966850); Seo, Dong Wan (7201422887); Alirezaie, Javad (6701846696)","57202966850; 7201422887; 6701846696","Simple net: Convolutional neural network to perform differential diagnosis of ampullary tumors","2018","2018-March","","","187","192","5","10.1109/MECBME.2018.8402431","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050017557&doi=10.1109%2fMECBME.2018.8402431&partnerID=40&md5=a064f4865ec3c78c2f1c28b3030b3f9a","Diagnosing different stages of cancer has only been performed by doctors due to the complexity of the task. However recent advancements made in the field of deep learning has pushed the capabilities of what an algorithm can achieve. In this study, we have trained a convolutional neural network to perform differential diagnosis of Ampullary tumors. Our proposed network is only made out of seven layers. However, when compared with other state of the art classification networks such as VGG 16, VGG 19, Res Net, and Dense Net our model not only had the best performance but also shortest training time. All of the networks were trained for 150 epochs with step wise learning rate with Adam optimizer to converge as quick as possible. Our model was able to reach average of 78.14 percent accuracy with average training time of 50.60 seconds on Asus Zephyrus, with Nvidia 1080 GPU and Max Q technology. © 2018 IEEE.","Ampullary tumors; Convolutional Neural Net work; Medical Image Analysis","Biomedical engineering; Convolution; Deep learning; Medical imaging; Neural networks; Tumors; Classification networks; Convolutional Neural Net work; Different stages; Differential diagnosis; Learning rates; Optimizers; State of the art; Training time; Diagnosis","","","IEEE Computer Society",""
"Deperlioǧlu O.; Köse U.","Deperlioǧlu, Ömer (6505689513); Köse, Utku (36544118500)","6505689513; 36544118500","Diagnogsis of Diabetic Retinopathy Using Image Processing and Convolutional Neural Network; [Görüntü İşleme ve Evrişimsel Sinir Aǧlari Kullanarak Diyabetik retinopati Teşhisi]","2018","","","8596894","","","","10.1109/TIPTEKNO.2018.8596894","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061739122&doi=10.1109%2fTIPTEKNO.2018.8596894&partnerID=40&md5=52a1c334ba14ed467d4dcff36f4c2592","Diabetic retinopathy is a serious eye disease that originates from diabetes mellitus and is the most common cause of blindness in the developed countries. This study describes the use of image processing and deep learning to diagnose diabetic retinopathy from retinal fundus images. For retinal fundus images enhancement approach, a practical method which contains HSV, V transform algorithm and histogram equalization technics was used. Finally, Gaussian low-pass filter was applied to the retinal fundus image. After the image processing, the classification was made using the Convolutional Neural Network. The performance of the proposed method was assessed using 400 retinal fundus images in the Kaggle Diabetic Retinopathy Detection database. In experiments, classification work has been done for each stage of the image processing. The classification study performed after image processing. Twenty experiments were done for every stage and average values were found. In this experiment, the accuracy was 96.67%, the sensitivity was 93.33%, the specificity was 93.33%, the precision was 93.33%, the recall was 93.33%, and the F-score was 93.33%. The obtained results show that the proposed method is very efficient and successful to diagnose diabetic retinopathy from retinal fundus images. © 2018 IEEE.","Convolutional Neural Network; Diabetic Retinopathy; Image Processing; Kaggle Diabetic Retinopathy Detection database","Biomedical engineering; Convolution; Deep learning; Image classification; Image enhancement; Image processing; Low pass filters; Neural networks; Ophthalmology; Convolutional neural network; Developed countries; Diabetes mellitus; Diabetic retinopathy; Histogram equalizations; Practical method; Retinal fundus images; Transform algorithm; Eye protection","","","Institute of Electrical and Electronics Engineers Inc.",""
"Wang Y.; Wu Z.; Zhang J.","Wang, Yani (57113352900); Wu, Zhendong (58939526400); Zhang, Jianwu (57113044300)","57113352900; 58939526400; 57113044300","Damaged fingerprint classification by Deep Learning with fuzzy feature points","2017","","","7852722","280","285","5","10.1109/CISP-BMEI.2016.7852722","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016047065&doi=10.1109%2fCISP-BMEI.2016.7852722&partnerID=40&md5=2f1bfa72dbbb952f71a235407f3ea4f0","As the world enters the information age, the need for identity verification becomes more and more urgent. Therefore, fingerprint identification technology is widely used in the field of personal authentication. With the efforts of researchers, the algorithms of fingerprint recognition have currently made great progress. However, the authentication of low quality fingerprint still needs further improvement. Aiming at imperfect fingerprints, we propose an improved damaged fingerprint recognition algorithm by feature points, based on Convolution Neural Network (CNN) of Deep Learning. Finally, the recognition rate based on Deep Learning is compared with the fingerprint identification algorithm based on Kernel Principal Component Analysis (KPCA) and k-Nearest Neighbor (KNN). Experiments' results show that fingerprint recognition based on Deep Learning has a higher recognition rate. © 2016 IEEE.","Convolution Neural Network (CNN); fingerprint identification; fuzzy feature points; recognition rate","Authentication; Biomedical engineering; Convolution; Deep learning; Image processing; Image recognition; Learning algorithms; Nearest neighbor search; Palmprint recognition; Principal component analysis; Signal processing; Convolution neural network; Fingerprint classification; Fingerprint identification; Fingerprint identification algorithm; Fingerprint recognition algorithm; Fuzzy features; K nearest neighbor (KNN); Kernel principal component analyses (KPCA); Pattern recognition","","","Institute of Electrical and Electronics Engineers Inc.",""
"Korolev S.; Safiullin A.; Belyaev M.; Dodonova Y.","Korolev, Sergey (36907781900); Safiullin, Amir (57194833602); Belyaev, Mikhail (57196947665); Dodonova, Yulia (36631699700)","36907781900; 57194833602; 57196947665; 36631699700","Residual and plain convolutional neural networks for 3D brain MRI classification","2017","","","7950647","835","838","3","10.1109/ISBI.2017.7950647","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023166391&doi=10.1109%2fISBI.2017.7950647&partnerID=40&md5=f2a24cee7b0adbf37fa7ecb98743eaf4","In the recent years there have been a number of studies that applied deep learning algorithms to neuroimaging data. Pipelines used in those studies mostly require multiple processing steps for feature extraction, although modern advancements in deep learning for image classification can provide a powerful framework for automatic feature generation and more straightforward analysis. In this paper, we show how similar performance can be achieved skipping these feature extraction steps with the residual and plain 3D convolutional neural network architectures. We demonstrate the performance of the proposed approach for classification of Alzheimer's disease versus mild cognitive impairment and normal controls on the Alzheimers Disease National Initiative (ADNI) dataset of 3D structural MRI brain scans. © 2017 IEEE.","Alzheimer's Disease; Convolutional Neural Network; Deep Learning; MRI; Residual Neural Network","Biomedical signal processing; Classification (of information); Convolution; Deep learning; Education; Extraction; Feature extraction; Learning algorithms; Magnetic resonance imaging; Medical imaging; Network architecture; Neural networks; Neurodegenerative diseases; Neuroimaging; Alzheimer's disease; Convolutional neural network; Feature generation; Mild cognitive impairments; Modern advancement; Multiple processing; National initiatives; Normal controls; Deep neural networks","","","IEEE Computer Society",""
"Mamoshina P.; Vieira A.; Putin E.; Zhavoronkov A.","Mamoshina, Polina (56893719500); Vieira, Armando (7103040327); Putin, Evgeny (57189310406); Zhavoronkov, Alex (39862415800)","56893719500; 7103040327; 57189310406; 39862415800","Applications of Deep Learning in Biomedicine","2016","13","5","","1445","1454","9","10.1021/acs.molpharmaceut.5b00982","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968861400&doi=10.1021%2facs.molpharmaceut.5b00982&partnerID=40&md5=0991811a8afb433697c7486dfd2404a5","Increases in throughput and installed base of biomedical research equipment led to a massive accumulation of -omics data known to be highly variable, high-dimensional, and sourced from multiple often incompatible data platforms. While this data may be useful for biomarker identification and drug discovery, the bulk of it remains underutilized. Deep neural networks (DNNs) are efficient algorithms based on the use of compositional layers of neurons, with advantages well matched to the challenges -omics data presents. While achieving state-of-the-art results and even surpassing human accuracy in many challenging tasks, the adoption of deep learning in biomedicine has been comparatively slow. Here, we discuss key features of deep learning that may give this approach an edge over other machine learning methods. We then consider limitations and review a number of applications of deep learning in biomedical studies demonstrating proof of concept and practical utility. © 2016 American Chemical Society.","artificial intelligence; biomarker development; deep learning; deep neural networks; genomics; RBM; transcriptomics","Animals; Biomarkers; Biomedical Research; Drug Discovery; Humans; Machine Learning; Nerve Net; untranslated RNA; biological marker; biology; biomedicine; chemistry; clinical data repository; deep learning; genomics; image processing; machine learning; medical research; priority journal; proteomics; quantitative trait locus; Review; transcriptomics; animal; drug development; human; medical research; metabolism; nerve cell network; physiology; procedures","","","American Chemical Society","27007977"
"Soomro M.H.; De Cola G.; Conforto S.; Schmid M.; Giunta G.; Guidi E.; Neri E.; Caruso D.; Ciolina M.; Laghi A.","Soomro, Mumtaz Hussain (57194166068); De Cola, Gianluca (57217968410); Conforto, Silvia (6602688693); Schmid, Maurizio (7402632723); Giunta, Gaetano (7006413308); Guidi, Elisa (57002950600); Neri, Emanuele (57957781200); Caruso, Damiano (48661669800); Ciolina, Maria (36097706000); Laghi, Andrea (58045378100)","57194166068; 57217968410; 6602688693; 7402632723; 7006413308; 57002950600; 57957781200; 48661669800; 36097706000; 58045378100","Automatic segmentation of colorectal cancer in 3D MRI by combining deep learning and 3D level-set algorithm-a preliminary study","2018","2018-March","","","198","203","5","10.1109/MECBME.2018.8402433","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050034774&doi=10.1109%2fMECBME.2018.8402433&partnerID=40&md5=caf49bab5c2281e7654f59f0c03ab67e","In this paper, a novel method to automatically segment colorectal cancer from 3D MR images based on combination of 3D fully convolutional neural networks (3D-FCNNs) and 3D level-set is proposed. The 3D-level set is incorporated in the 3D-FCNNs aiming at: i) a fine-tuning of the training phase; ii) a refinement of the outputs during the testing phase by integrating smoothing function and prior information in a post-processing step. The proposed method is assessed and compared with 3D-FCNNs without 3D-level set (3D-FCNNs alone) in terms of Dice Similarity Coefficient (DSC) as a performance metric. The proposed method showed higher DSC than 3D-FCNNs alone on both training and testing data set as, (0.91813 vs 0.8568) and (0.9378 vs 0.86238), respectively. Our results on 3D colorectal MRI data demonstrated that the proposed method gives better and accurate segmentation results than 3D-FCNNs alone. © 2018 IEEE.","3D level-set; 3D MRI Segmentation; 3D-FCNNs; Colorectal Cancer","Biomedical engineering; Diseases; Functions; Image segmentation; Integration testing; Magnetic resonance imaging; Neural networks; Numerical methods; Statistical tests; 3D-FCNNs; Automatic segmentations; Colorectal cancer; Convolutional neural network; Level Set; MRI segmentation; Performance metrices; Similarity coefficients; Deep learning","","","IEEE Computer Society",""
"McQuin C.; Goodman A.; Chernyshev V.; Kamentsky L.; Cimini B.A.; Karhohs K.W.; Doan M.; Ding L.; Rafelski S.M.; Thirstrup D.; Wiegraebe W.; Singh S.; Becker T.; Caicedo J.C.; Carpenter A.E.","McQuin, Claire (57203329560); Goodman, Allen (57203331310); Chernyshev, Vasiliy (56083430300); Kamentsky, Lee (55190103600); Cimini, Beth A. (55632428200); Karhohs, Kyle W. (55252738600); Doan, Minh (57200420144); Ding, Liya (57222145864); Rafelski, Susanne M. (6506240617); Thirstrup, Derek (36132444300); Wiegraebe, Winfried (24333614100); Singh, Shantanu (24470175500); Becker, Tim (54379752400); Caicedo, Juan C. (36830392700); Carpenter, Anne E. (8063969900)","57203329560; 57203331310; 56083430300; 55190103600; 55632428200; 55252738600; 57200420144; 57222145864; 6506240617; 36132444300; 24333614100; 24470175500; 54379752400; 36830392700; 8063969900","CellProfiler 3.0: Next-generation image processing for biology","2018","16","7","e2005970","","","","10.1371/journal.pbio.2005970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051293036&doi=10.1371%2fjournal.pbio.2005970&partnerID=40&md5=741fff6c1ea7997a2cef5972eee64e79","CellProfiler has enabled the scientific research community to create flexible, modular image analysis pipelines since its release in 2005. Here, we describe CellProfiler 3.0, a new version of the software supporting both whole-volume and plane-wise analysis of three-dimensional (3D) image stacks, increasingly common in biomedical research. CellProfiler’s infrastructure is greatly improved, and we provide a protocol for cloud-based, large-scale image processing. New plugins enable running pretrained deep learning models on images. Designed by and for biologists, CellProfiler equips researchers with powerful computational tools via a well-documented user interface, empowering biologists in all fields to create quantitative, reproducible image analysis workflows. © 2018 McQuin et al. http://creativecommons.org/licenses/by/4.0/.","","Animals; Cell Nucleus; Deep Learning; DNA; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Induced Pluripotent Stem Cells; Mice; RNA, Messenger; Software; DNA; messenger RNA; algorithm; animal cell; Article; artificial neural network; blastocyst; cell count; cloud computing; controlled study; convolutional neural network; embryo; equipment design; feature detection; feature extraction; filtration; HL-60 cell line; human; human cell; image analysis; image processing; image segmentation; induced pluripotent stem cell; medical research; mouse; noise reduction; nonhuman; pattern recognition; quantitative analysis; reproducibility; three dimensional imaging; trophoblast; workflow; animal; cell nucleus; cytology; genetics; metabolism; software","National Institute of General Medical Sciences, NIGMS, (R35GM122547)","","Public Library of Science","29969450"
"Yalcin H.","Yalcin, Hulya (36917264600)","36917264600","Phenology recognition using deep learning","2018","","","","1","5","4","10.1109/EBBT.2018.8391423","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050211506&doi=10.1109%2fEBBT.2018.8391423&partnerID=40&md5=4e818877d51f9721cc13ad4b2aefc2d4","One of the essential part of agricultural technologies and crop monitoring is automating accurate plant phenotyping. Environmental conditions have tremendous impact on a plant's growth. Hence, accurate monitoring of phenology can provide a lot of information that can be used for increasing the yield quality and accelerating crop production. Advancements in both computer vision algorithms and communication systems have been transforming the perception of precision agriculture. Enourmous amount of information is being collected through sensors positioned on ground stations in national agriculture monitoring networks. Availability of this higher-quality measurements coupled with modern image processing algorithms steadily grows the applications possibilites in agriculture. The advancement of machine learning techniques offer a different approach comparatively to the traditional ways for agricultural applications. In this paper, we employ a deep learning approach to recognize and classify phenological stages of agricultural plants. The visual data for plants are captured every half an hour by cameras mounted on the ground agro-stations. In contrast to traditional feature extraction approaches, a pre-trained Convolutional Neural Network architecture (CNN) is employed to automatically extract the features of images. The results obtained through CNN model are compared with those obtained by employing hand crafted feature descriptors. Experimental results indicate that CNN architecture outperforms the machine learning algorithms based on hand crafted features. © 2018 IEEE.","convolutional neural networks; deep learning; image processing; plant phenotyping; precision agriculture","Biology; Biomedical engineering; Convolution; Crops; Cultivation; Image processing; Learning algorithms; Network architecture; Neural networks; Precision agriculture; Agricultural technologies; Agriculture monitoring; Computer vision algorithms; Convolutional neural network; Environmental conditions; Image processing algorithm; Machine learning techniques; Plant phenotyping; Deep learning","ITU TARBIL Agro-informatics Research Fund, (2012A020130); Istanbul Technical University Scientific Research Fund, (34912); Ministry of Food, Agricultural and Livestock","","Institute of Electrical and Electronics Engineers Inc.",""
"","","","13th International Conference on Biomedical Engineering, ICBME 2008","2009","23","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891932253&partnerID=40&md5=dfcb80bfb790616255cdf1a365a3373e","The proceedings contain 570 papers. The special focus in this conference is on Biomedical Engineering. The topics include: Electroencephalograph signal analysis during ujjayi pranayama; a study of stochastic resonance as a mathematical model of electrogastrography during sitting position; possibility of MEG as an early diagnosis tool for Alzheimer's disease; new architecture for NN based image compression for optimized power, area and speed; a statistical model to estimate flow mediated dilation using recorded finger photoplethysmogram; automatic extraction of blood vessels, bifurcations and end points in the retinal vascular tree; recent developments in optimizing optical tools for air bubble detection in medical devices used in fluid transport; general purpose adaptive biosignal acquisition system combining FPGA and FPAA; segmentation of brain MRI and comparison using different approaches of 2D seed growing; SQUID biomagnetometer systems for non-invasive investigation of spinal cord dysfunction; a study on the relation between stability of EEG and respiration; the feature-based microscopic image segmentation for thyroid tissue; heart disease classification using discrete wavelet transform coefficients of isolated beats; non-invasive techniques for assessing the endothelial dysfunction; high performance EEG analysis for brain interface; denoising of transient visual evoked potential using wavelets; permeability of an in vitro model of blood brain barrier (BBB); decision making algorithm through LVQ neural network for ECG arrhythmias; a low-noise CMOS receiver frontend for NMR-based surgical guidance; automated fluorescence as a system to assist the diagnosis of retinal blood vessel leakage; a new method of extraction of FECG from abdominal signal; analysis of EGG signals for digestive system disorders using neural networks; a reliable measurement to assess atherosclerosis of differential arterial systems; an automated segmentation algorithm for medical images; quantitative assessment of movement disorders in clinical practice; design and intra-operative studies of an economic versatile portable biopotential recorder; comparison of various imaging modes for photoacoustic tomography; modeling the microstructure of neonatal EEG sleep stages by temporal profiles; automatic processing of EEG-EOG-EMG artifacts in sleep stage classification; medical image registration using mutual information similarity measure; a feasibility study of commercially available audio transducers in ABR studies; simultaneous measurement of PPG and functional MRI; a comparison of two synchronization measures for neural data; protein classification using decision trees with bottom-up classification approach; extracting speech signals using independent component analysis; age-related changes in specific harmonic indices of pressure pulse waveform; processing of NMR slices for preparation of multi-dimensional model; application of advanced methods of NMR image segmentation for monitoring the development of growing cultures; design of a wireless intraocular pressure monitoring system for a glaucoma drainage implant; integrating FCM and level sets for liver tumor segmentation; an intelligent implantable wireless shunting system for hydrocephalus patients; a developed Zeeman model for HRV signal generation in different stages of sleep; two wavelengths hematocrit monitoring by light transmittance method; higher order spectra based support vector machine for arrhythmia classification; transcutaneous energy transfer system for powering implantable biomedical devices; the automatic sleep stage diagnosis method by using SOM; a development of the EEG telemetry system under exercising; computerized cephalometric line tracing technique on X-ray images; brain activation in response to disgustful face images with different backgrounds; automated detection of optic disc and exudates in retinal images; qualitative studies on the development of ultraviolet sterilization system for biological applications; from e-health to personalised medicine; quantitative biological models as dynamic, user-generated online content; a novel method to describe and share complex mathematical models of cellular physiology; new paradigm in journal reference management; incremental learning method for biological signal identification; a vocoder for a novel cochlear implant stimulating strategy based on virtual channel technology; a novel multivariate analysis method for bio-signal processing; diagnosis of diabetic retinopathy through slit lamp images; tracing of central serous retinopathy from retinal fundus images; a confidence measure for real-time eye movement detection in video-oculography; design and development of an interactive proteomic website; a new interaction modality for the visualization of 3D models of human organ; a feasibility study for the cancer therapy using cold plasma; brain-computer interfaces for virtual environment control; position reconstruction of awake rodents by evaluating neural spike information from place cells in the hippocampus; heart rate variability response to stressful event in healthy subjects; automatic quantitative analysis of myocardial perfusion MRI; visualization of articular cartilage using magnetic resonance imaging data; a chaotic detection method for steady-state visual evoked potentials; speckle reduction of echocardiograms via wavelet shrinkage of ultrasonic RF signals; advanced pre-surgery planning by animated biomodels in virtual reality; computerized handwriting analysis in children with/without motor incoordination; the development of computer-assisted assessment in Chinese handwriting performance; novel tools for quantification of brain responses to music stimuli; an autocorrection algorithm for detection of misaligned fingerprints; a low power wireless downlink transceiver for implantable glucose sensing biosystems; early cancer diagnosis by image processing sensors measuring the conductive or radiative heat; system design of ultrasonic image-guided focused ultrasound for blood brain barrier disruption; laser speckle contrast analysis using adaptive window; neural decoding of single and multi-finger movements based on ML; cardiorespiratory coordination in rats is influenced by autonomic blockade; real-time detection of nimodipine effect on ischemia model; digital dental model analysis; cervical cell classification using Fourier transform; an oscillometry-based approach for measuring blood flow of brachial arteries; study of the effect of short-time cold stress on heart rate variability; estimation of central aortic blood pressure using a noninvasive automatic blood pressure monitor; design of a PDA-based asthma peak flow monitor system; development of the tongue diagnosis system by using surface coating mirror; design a moving artifacts detection system for a radial pulse wave analyzer; a real-time interactive editor for 3D image registration; a novel headset with a transmissive PPG sensor for heart rate measurement; feature extraction methods for tongue diagnostic system; on calculating the time-varying elastance curve of a radial artery using a miniature vibration method; a wide current range readout circuit with potentiostat for amperometric chemical sensors; phase synchronization index of vestibular system activity in schizophrenia; constrained spatiotemporal ICA and its application for fMRI data analysis; a force sensor system for evaluation of behavioural recovery after spinal cord injury in rats; flow imaging and validation of MR fluid motion tracking; high frequency electromagnetic thermotherapy for cancer treatment; the design of oximeter in sleep monitoring; ECG feature extraction by multi resolution wavelet analysis based selective coefficient method; microarray image denoising using spatial filtering and wavelet transformation; investigation of a classification about time series signal using SOM; characteristic of AEP and SEP for localization of evoked potential by recalling; automatic detection of left and right eye in retinal fundus images; visualizing occlusal contact points using laser surface dental scans; modeling deep brain stimulation; implementation of trajectory analysis system for metabolic syndrome detection; using saliency features for graphcut segmentation of perfusion kidney images; low power electrocardiogram QRS detection in real-time; effects of task difficulty and training of visuospatial working memory task on brain activity; performance comparison of bone segmentation on dental CT images; multi scale assessment of bone architecture and quality from CT images; an empirical approach for objective pain measurement using dermal and cardiac parameters; an electroencephalogram signal based triggering circuit for controlling hand grasp in neuroprosthetics; a mobile phone for people suffering from the locked in syndrome; generating different views of clinical guidelines using ontology based semantic annotation; a high-voltage discharging system for extracorporeal shock-wave therapy; development of the robot arm control system using forearm SEMG; small-world network for investigating functional connectivity in bipolar disorder; a novel method in detecting CCA lumen diameter and IMT in dynamic B-mode sonography; acoustic imaging of heart using microphone arrays; statistical variations of ultrasound backscattering from the blood under steady flow; a comparative study for disease identification from heart auscultation using FFT, cepstrum and DCT correlation coefficients; multi resolution analysis of pediatric ECG signal; analysis of quantified indices of EMG for evaluation of Parkinson's disease; a test for the assessment of reaction time for narcotic rehabilitation patients; microdevice for trapping circulating tumor cells for cancer diagnostics; in-situ optical oxygen sensing for bio-artificial liver bioreactors; non-invasive acquisition of blood pulse using magnetic disturbance technique.","","","","","",""
"Hashemi S.R.; Salehi S.S.M.; Erdogmus D.; Prabhu S.P.; Warfield S.K.; Gholipour A.","Hashemi, Seyed Raein (57202377609); Salehi, Seyed Sadegh Mohseni (57188865502); Erdogmus, Deniz (7004584113); Prabhu, Sanjay P. (57203031367); Warfield, Simon K. (7005171959); Gholipour, Ali (57192251309)","57202377609; 57188865502; 7004584113; 57203031367; 7005171959; 57192251309","Asymmetric Loss Functions and Deep Densely-Connected Networks for Highly-Imbalanced Medical Image Segmentation: Application to Multiple Sclerosis Lesion Detection","2019","7","","8573779","1721","1735","14","10.1109/ACCESS.2018.2886371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058626597&doi=10.1109%2fACCESS.2018.2886371&partnerID=40&md5=02765d6c0d0a5180492c9288e0f1ccb5","Fully convolutional deep neural networks have been asserted to be fast and precise frameworks with great potential in image segmentation. One of the major challenges in training such networks raises when the data are unbalanced, which is common in many medical imaging applications, such as lesion segmentation, where lesion class voxels are often much lower in numbers than non-lesion voxels. A trained network with unbalanced data may make predictions with high precision and low recall, being severely biased toward the non-lesion class which is particularly undesired in most medical applications where false negatives are actually more important than false positives. Various methods have been proposed to address this problem, including two-step training, sample re-weighting, balanced sampling, and more recently, similarity loss functions and focal loss. In this paper, we fully trained convolutional deep neural networks using an asymmetric similarity loss function to mitigate the issue of data imbalance and achieve much better tradeoff between precision and recall. To this end, we developed a 3D fully convolutional densely connected network (FC-DenseNet) with large overlapping image patches as input and an asymmetric similarity loss layer based on Tversky index (using Fβ scores). We used large overlapping image patches as inputs for intrinsic and extrinsic data augmentation, a patch selection algorithm, and a patch prediction fusion strategy using B-spline weighted soft voting to account for the uncertainty of prediction in patch borders. We applied this method to multiple sclerosis (MS) lesion segmentation based on two different datasets of MSSEG 2016 and ISBI longitudinal MS lesion segmentation challenge, where we achieved average Dice similarity coefficients of 69.9% and 65.74%, respectively, achieving top performance in both the challenges. We compared the performance of our network trained with Fβ loss, focal loss, and generalized Dice loss functions. Through September 2018, our network trained with focal loss ranked first according to the ISBI challenge overall score and resulted in the lowest reported lesion false positive rate among all submitted methods. Our network trained with the asymmetric similarity loss led to the lowest surface distance and the best lesion true positive rate that is arguably the most important performance metric in a clinical decision support system for lesion detection. The asymmetric similarity loss function based on Fβ scores allows training networks that make a better balance between precision and recall in highly unbalanced image segmentation. We achieved superior performance in MS lesion segmentation using a patch-wise 3D FC-DenseNet with a patch prediction fusion strategy, trained with asymmetric similarity loss functions. © 2013 IEEE.","Asymmetric loss function; convolutional neural network; deep learning; F<sub>β</sub> scores; FC-DenseNet; focal loss; lesion segmentation; multiple sclerosis; patch prediction fusion; Tversky index","Convolution; Decision support systems; Deep learning; Deep neural networks; Forecasting; Image fusion; Medical applications; Medical image processing; Medical imaging; Network architecture; Neural networks; Personnel training; Three dimensional displays; Asymmetric loss function; Biomedical imaging; Convolutional neural network; FC-DenseNet; Indexes; Lesion segmentations; Lesions; Multiple sclerosis; Tversky index; Image segmentation","National Institutes of Health, NIH, (R01 EB018988, R01 NS079788); McKnight Foundation","","Institute of Electrical and Electronics Engineers Inc.",""
"Allman D.; Reiter A.; Bell M.A.L.","Allman, Derek (57200087368); Reiter, Austin (24072196400); Bell, Muyinatu A. Lediju (25936417400)","57200087368; 24072196400; 25936417400","Photoacoustic Source Detection and Reflection Artifact Removal Enabled by Deep Learning","2018","37","6","","1464","1477","13","10.1109/TMI.2018.2829662","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045771861&doi=10.1109%2fTMI.2018.2829662&partnerID=40&md5=dcda3ebfa345732e9cb381727d871c66","Interventional applications of photoacoustic imaging typically require visualization of point-like targets, such as the small, circular, cross-sectional tips of needles, catheters, or brachytherapy seeds. When these point-like targets are imaged in the presence of highly echogenic structures, the resulting photoacoustic wave creates a reflection artifact that may appear as a true signal. We propose to use deep learning techniques to identify these types of noise artifacts for removal in experimental photoacoustic data. To achieve this goal, a convolutional neural network (CNN) was first trained to locate and classify sources and artifacts in pre-beamformed data simulated with k-Wave. Simulations initially contained one source and one artifact with various medium sound speeds and 2-D target locations. Based on 3,468 test images, we achieved a 100% success rate in classifying both sources and artifacts. After adding noise to assess potential performance in more realistic imaging environments, we achieved at least 98% success rates for channel signal-to-noise ratios (SNRs) of -9dB or greater, with a severe decrease in performance below -21dB channel SNR. We then explored training with multiple sources and two types of acoustic receivers and achieved similar success with detecting point sources. Networks trained with simulated data were then transferred to experimental waterbath and phantom data with 100% and 96.67% source classification accuracy, respectively (particularly when networks were tested at depths that were included during training). The corresponding mean ± one standard deviation of the point source location error was 0.40 ± 0.22 mm and 0.38 ± 0.25 mm for waterbath and phantom experimental data, respectively, which provides some indication of the resolution limits of our new CNN-based imaging system. We finally show that the CNN-based information can be displayed in a novel artifact-free image format, enabling us to effectively remove reflection artifacts from photoacoustic images, which is not possible with traditional geometry-based beamforming. © 2018 IEEE.","artifact reduction; deep learning; machine learning; neural networks; Photoacoustic imaging; reflection artifacts","Artifacts; Deep Learning; Humans; Image Processing, Computer-Assisted; Photoacoustic Techniques; Acoustic noise; Biomedical signal processing; Deep learning; Image resolution; Neural networks; Phantoms; Photoacoustic effect; Convolutional Neural Networks (CNN); Learning techniques; Phantom experimental data; Photo-acoustic imaging; Photoacoustic image; Photoacoustic wave; Source classification; Standard deviation; analytical error; Article; artifact reduction; controlled study; data analysis software; human; image analysis; image processing; learning algorithm; mathematical model; photoacoustics; signal noise ratio; simulation; sound; transfer of learning; artifact; photoacoustics; procedures; Signal to noise ratio","National Science Foundation, NSF, (ECCS 1751522); National Institute of Biomedical Imaging and Bioengineering, NIBIB, (R00EB018994)","","Institute of Electrical and Electronics Engineers Inc.","29870374"
"Ishaq O.; Sadanandan S.K.; Wählby C.","Ishaq, Omer (23975972600); Sadanandan, Sajith Kecheril (57188750507); Wählby, Carolina (6603157675)","23975972600; 57188750507; 6603157675","Deep Fish: Deep Learning-Based Classification of Zebrafish Deformation for High-Throughput Screening","2017","22","1","","102","107","5","10.1177/1087057116667894","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007199315&doi=10.1177%2f1087057116667894&partnerID=40&md5=8384ee1520b5363b302f0a5d3710d1f5","Zebrafish (Danio rerio) is an important vertebrate model organism in biomedical research, especially suitable for morphological screening due to its transparent body during early development. Deep learning has emerged as a dominant paradigm for data analysis and found a number of applications in computer vision and image analysis. Here we demonstrate the potential of a deep learning approach for accurate high-throughput classification of whole-body zebrafish deformations in multifish microwell plates. Deep learning uses the raw image data as an input, without the need of expert knowledge for feature design or optimization of the segmentation parameters. We trained the deep learning classifier on as few as 84 images (before data augmentation) and achieved a classification accuracy of 92.8% on an unseen test data set that is comparable to the previous state of the art (95%) based on user-specified segmentation and deformation metrics. Ablation studies by digitally removing whole fish or parts of the fish from the images revealed that the classifier learned discriminative features from the image foreground, and we observed that the deformations of the head region, rather than the visually apparent bent tail, were more important for good classification performance. © 2016 Society for Laboratory Automation and Screening.","deep learning; high-throughput screening; quantitative microscopy; shape deformation; zebrafish (Danio rerio)","Animals; Camptothecin; Deep Learning; Neural Networks (Computer); Zebrafish; camptothecin; camptothecin; animal experiment; Article; classification algorithm; classifier; controlled study; high throughput screening; image analysis; image processing; learning algorithm; nonhuman; priority journal; probability; zebra fish; computer model; data analysis; image segmentation; learning; measurement accuracy; measurement precision; microwell plate; nerve cell network; Note; process optimization; skeleton malformation; zebra fish; animal; artificial neural network; genetics","Swedish research program; Vetenskapsrådet, VR, (2012-4968)","","SAGE Publications Inc.","27613194"
"Singh K.; Malhotra J.","Singh, Kuldeep (57216243325); Malhotra, Jyoteesh (25628189800)","57216243325; 25628189800","Stacked Autoencoders Based Deep Learning Approach for Automatic Epileptic Seizure Detection","2018","","","8703357","249","254","5","10.1109/ICSCCC.2018.8703357","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065640334&doi=10.1109%2fICSCCC.2018.8703357&partnerID=40&md5=1423234b52c62840b8ed4a407fb399b4","Epilepsy is one of the major chronic nervous disorders, which affects the lives of millions of patients per annum globally, because of occurrence of sudden death or major injuries occurred during walk, driving or working in hazardous work environment. Its prognosis through modern technologies is the need of the day, which is attaining worldwide attention in research community with the use of latest technologies like internet of things, machine learning and cloud computing. This paper presents a model of automatic epileptic seizure detection model using Stacked Autoencoders based deep learning approach, which is an advanced form of machine leaning, employed for effectively handling the problem of big data with reduced complexity and processing time and to make this process more real time compatible with least delays. This model processes the sensed EEG signals by breaking it into short duration segments. Then, these EEG segments are fed to Stacked Autoencoders for its classification into different epileptic seizure stages like normal, preictal and ictal. The performance of this model has been compared with other existing models consisting of higher order spectral analysis based feature extraction and classification using traditional machine learning algorithms like Bayes Net, Naïve Bayes, Multilayer Perceptron, Radial basis function neural networks and C4.5 decision tree classifier. The analysis of performance through simulation results reveal that Stacked Autoencoders based deep learning approach is an efficient model for real time automatic epileptic seizures detection at early stage with classification accuracy 88.8%, sensitivity 89.44%, specificity 93.77% values and least value of processing time, which is approximately 23 times lesser than that of models utilizing traditional higher order statistics feature extraction and machine learning based classification approaches. © 2018 IEEE.","Cloud Computing; Deep Learning; EEG; Epilepsy; healthcare; Internet of things; Stacked Autoencoders","Biomedical signal processing; Classification (of information); Cloud computing; Data mining; Decision trees; Diagnosis; Electroencephalography; Engineering education; Extraction; Feature extraction; Health care; Higher order statistics; Image segmentation; Internet of things; Learning algorithms; Machine learning; Multilayer neural networks; Neurodegenerative diseases; Neurophysiology; Radial basis function networks; Spectrum analysis; Autoencoders; C4.5 Decision tree classifier; Classification approach; Epilepsy; Epileptic seizure detection; Feature extraction and classification; Higher-order spectral analysis; Radial basis function neural networks; Deep learning","","","Institute of Electrical and Electronics Engineers Inc.",""
"Vigneault D.M.; Xie W.; Ho C.Y.; Bluemke D.A.; Noble J.A.","Vigneault, Davis M. (56611878900); Xie, Weidi (57192403839); Ho, Carolyn Y. (35299617300); Bluemke, David A. (7006047770); Noble, J. Alison (56185660000)","56611878900; 57192403839; 35299617300; 7006047770; 56185660000","Ω-Net (Omega-Net): Fully automatic, multi-view cardiac MR detection, orientation, and segmentation with deep neural networks","2018","48","","","95","106","11","10.1016/j.media.2018.05.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047610606&doi=10.1016%2fj.media.2018.05.008&partnerID=40&md5=1e5d602932ac3fc7473940e57a55164f","Pixelwise segmentation of the left ventricular (LV) myocardium and the four cardiac chambers in 2-D steady state free precession (SSFP) cine sequences is an essential preprocessing step for a wide range of analyses. Variability in contrast, appearance, orientation, and placement of the heart between patients, clinical views, scanners, and protocols makes fully automatic semantic segmentation a notoriously difficult problem. Here, we present Ω-Net (Omega-Net): A novel convolutional neural network (CNN) architecture for simultaneous localization, transformation into a canonical orientation, and semantic segmentation. First, an initial segmentation is performed on the input image; second, the features learned during this initial segmentation are used to predict the parameters needed to transform the input image into a canonical orientation; and third, a final segmentation is performed on the transformed image. In this work, Ω-Nets of varying depths were trained to detect five foreground classes in any of three clinical views (short axis, SA; four-chamber, 4C; two-chamber, 2C), without prior knowledge of the view being segmented. This constitutes a substantially more challenging problem compared with prior work. The architecture was trained using three-fold cross-validation on a cohort of patients with hypertrophic cardiomyopathy (HCM, N=42) and healthy control subjects (N=21). Network performance, as measured by weighted foreground intersection-over-union (IoU), was substantially improved for the best-performing Ω-Net compared with U-Net segmentation without localization or orientation (0.858 vs 0.834). In addition, to be comparable with other works, Ω-Net was retrained from scratch using five-fold cross-validation on the publicly available 2017 MICCAI Automated Cardiac Diagnosis Challenge (ACDC) dataset. The Ω-Net outperformed the state-of-the-art method in segmentation of the LV and RV bloodpools, and performed slightly worse in segmentation of the LV myocardium. We conclude that this architecture represents a substantive advancement over prior approaches, with implications for biomedical image segmentation more generally. © 2018","Cardiac magnetic resonance; Deep convolutional neural networks; Semantic segmentation; Spatial transformer networks","Algorithms; Cardiac Imaging Techniques; Cardiomyopathy, Hypertrophic; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Convolution; Deep neural networks; Diagnosis; Heart; Magnetic levitation vehicles; Magnetic resonance; Network architecture; Neural networks; Semantics; Biomedical image segmentation; Cardiac magnetic resonance; Convolutional Neural Networks (CNN); Deep convolutional neural networks; Hypertrophic cardiomyopathy; Left ventricular myocardiums; Semantic segmentation; Steady state free precessions; accuracy; Article; cardiac muscle; cardiovascular magnetic resonance; clinical article; cohort analysis; controlled study; deep neural network; heart atrioventricular valve; heart papillary muscle; human; hypertrophic cardiomyopathy; image segmentation; machine learning; orientation; priority journal; algorithm; artificial neural network; cardiac imaging; diagnostic imaging; image processing; procedures; Image segmentation","Google DeepMind; NIH-Oxford; National Institutes of Health, NIH; Engineering and Physical Sciences Research Council, EPSRC, (EP/M013774/1)","","Elsevier B.V.","29857330"
"Dawson M.; Zisserman A.; Nellåker C.","Dawson, Mitchell (57196047258); Zisserman, Andrew (7006619672); Nellåker, Christoffer (57209053608)","57196047258; 7006619672; 57209053608","Mining faces from biomedical literature using deep learning","2017","","","","562","567","5","10.1145/3107411.3107476","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031329267&doi=10.1145%2f3107411.3107476&partnerID=40&md5=edb1812a35b91b0d72dc4654076c7c20","Gaining access to large, labelled sets of relevant images is crucial for the development and testing of biomedical imaging algorithms. Using images found in biomedical research articles would contribute some way towards a solution to this problem. However, this approach critically depends on being able to identify the most relevant images from very large sets of potentially useful figures. In this paper a deep convolutional neural network (CNN) classifier is trained using only synthetic data, to rapidly and accurately label raw images taken from biomedical articles. We apply this method in the context of detecting faces in biomedical images; and show that the classifier is able to retrieve figures containing faces with an average precision of 94.8%, from a dataset of over 31,000 images taken from articles held in the PubMed database. The utility of the classifier is then demonstrated through a case study, by aiding the mining of photographs of patients with rare genetic disorders from targeted articles. This approach is readily adaptable to facilitate the retrieval of other categories of biomedical images.","Biomedical data mining; Computer vision; Convolutional neural network; Deep learning; Image classification; Machine learning","Classification (of information); Computer vision; Convolution; Data mining; Deep learning; Deep neural networks; Image classification; Learning systems; Medical imaging; Neural networks; Biomedical data; Biomedical images; Biomedical imaging; Biomedical literature; Biomedical research; Convolutional neural network; Development and testing; Genetic disorders; Bioinformatics","EPSRC Systems Biology DTC, (EP/G03706X/1); Medical Research Council, MRC, (MR/M014568/1); Engineering and Physical Sciences Research Council, EPSRC, (EP/M013774/1)","","Association for Computing Machinery, Inc",""
"","","","International Conference on Communications and Cyber Physical Engineering, ICCCE 2018","2019","500","","","","","797","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053612739&partnerID=40&md5=836fcc050ca32933bc1232e54294dfb2","The proceedings contain 79 papers. The special focus in this conference is on Communications and Cyber Physical Engineering. The topics include: Design of a smart water-saving irrigation system for agriculture based on a wireless sensor network for better crop yield; SVM—A way to measure the trust ability of a cloud service based on rank; an optimized five-layer model with rainfall effects for wireless propagation in forests; leak detection methods—A technical review; text message classification using supervised machine learning algorithms; error assessment of fundamental matrix parameters; a two-band convolutional neural network for satellite image classification; dimensionally reduced features for hyperspectral image classification using deep learning; asymptotic symbol error rate analysis of weibull/shadowed composite fading channel; fog computing: Overview, architecture, security issues and applications; Vehicle detection and categorization for a toll charging system based on TESSERACT OCR using the IoT; transmission spectrum of a typical waveguide in photonic crystal with tunable width: Simulation and analysis; An anamnesis on the internet of nano things (IoNT) for biomedical applications; Minimization of the size of an antipodal vivaldi antenna for Wi-MAX and WLAN applications; Physical layer impairment (PLI) aware lightpath selection in WDM/DWDM networks; Miniaturized MIMO wideband antenna with L-shaped DGS for wireless communication; An enhanced reputation-based data forwarding mechanism for VANETs; statistical metric measurement approach for hazy images; image enhancement for fingerprint recognition using Otsu’s method; estimation of success probability in cognitive radio networks; proposal of linear specific functions for R-L-C as fundamental elements in terms of considered specific electric constants.","","","","Mozar S.; Kumar A.","Springer Verlag",""
"Barisoni L.; Hodgin J.B.","Barisoni, Laura (22233538700); Hodgin, Jeffrey B. (6603785012)","22233538700; 6603785012","Digital pathology in nephrology clinical trials, research, and pathology practice","2017","26","6","","450","459","9","10.1097/MNH.0000000000000360","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030751839&doi=10.1097%2fMNH.0000000000000360&partnerID=40&md5=153b97f51955931761f53f2c4fd6cd48","Purpose of review In this review, we will discuss (i) how the recent advancements in digital technology and computational engineering are currently applied to nephropathology in the setting of clinical research, trials, and practice; (ii) the benefits of the new digital environment; (iii) how recognizing its challenges provides opportunities for transformation; and (iv) nephropathology in the upcoming era of kidney precision and predictive medicine. Recent findings Recent studies highlighted how new standardized protocols facilitate the harmonization of digital pathology database infrastructure and morphologic, morphometric, and computer-aided quantitative analyses. Digital pathology enables robust protocols for clinical trials and research, with the potential to identify previously underused or unrecognized clinically useful parameters. The integration of digital pathology with molecular signatures is leading the way to establishing clinically relevant morpho-omic taxonomies of renal diseases. Summary The introduction of digital pathology in clinical research and trials, and the progressive implementation of the modern software ecosystem, opens opportunities for the development of new predictive diagnostic paradigms and computer-aided algorithms, transforming the practice of renal disease into a modern computational science. Copyright © 2017 Wolters Kluwer Health, Inc. All rights reserved.","computational disease; convolutional neural network; deep learning; focal segmental glomerulosclerosis; morphometry; nephrotic syndrome; podocytes; structural feature extraction","Algorithms; Biomedical Research; Biotechnology; Clinical Trials as Topic; Computers; Humans; Image Processing, Computer-Assisted; Kidney; Kidney Diseases; Microscopy; Nephrology; Pathology; Precision Medicine; Software; Telemedicine; classification; clinical practice; clinical research; clinical trial (topic); digital imaging; digital pathology; drug development; ecosystem; financial management; human; human computer interaction; investment; kidney biopsy; medical education; microscopy; nephrology; pathology; personalized medicine; priority journal; Review; standard; virtual reality; algorithm; biotechnology; clinical trial (topic); computer; education; genetics; image processing; kidney; kidney disease; legislation and jurisprudence; medical research; metabolism; nephrology; pathology; procedures; software; telemedicine","Halperin Foundation; National Institute of Diabetes, Digestive, and Kidney Diseases; NephCure Kidney International; Nephrotic Syndrome Study Network Consortium; ORDR; Office of Rare Diseases Research; Rare Disease Clinical Research Network; National Institute of Diabetes and Digestive and Kidney Diseases, NIDDK, (U54DK083912); National Center for Advancing Translational Sciences, NCATS; University of Michigan, U-M","","Lippincott Williams and Wilkins","28858910"
